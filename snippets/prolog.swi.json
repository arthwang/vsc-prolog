{
  "':- chr_constraint'/1": {
    "body":":- chr_constraint(${1:Specifier})$2\n$0",
    "description":":- chr_constraint(+Specifier).\nEvery constraint used in CHR rules has to be declared with a chr_constraint/1  declaration by the constraint specifier. For convenience  multiple constraints may be declared at once with the same chr_constraint/1  declaration followed by a comma-separated list of constraint specifiers.  A constraint specifier is, in its compact form, F/A  where F and A are respectively the functor name and  arity of the constraint, e.g.: \n\n\n\n:- chr_constraint foo/1.\n:- chr_constraint bar/2, baz/3.\n\n  In its extended form, a constraint specifier is c(A_1, ... ,A_n) where c  is the constraint's functor, n its arity and the A_i are argument specifiers.  An argument specifier is a mode, optionally followed by a type. Example: \n\n\n\n:- chr_constraint get_value(+,?).\n:- chr_constraint domain(?int, +list(int)),\n                  alldifferent(?list(int)).\n\n  \n\n",
    "prefix":"chr_constraint"
  },
  "':- chr_option'/2": {
    "body":":- chr_option(${1:Option}, ${2:Value})$3\n$0",
    "description":":- chr_option(+Option, +Value).\nIt is possible to specify options that apply to all the CHR rules in the  module. Options are specified with the chr_option/2  declaration:  \n\n:- chr_option(Option,Value).\n\n  and may appear in the file anywhere after the first constraints  declaration. \n\nAvailable options are: \n\ncheck_guard_bindings: This option controls whether guards should be checked for (illegal)  variable bindings or not. Possible values for this option are on  to enable the checks, and off to disable the checks. If  this option is on, any guard fails when it binds a variable that appears  in the head of the rule. When the option is off (default), the behaviour  of a binding in the guard is undefined.\n\noptimize: This option controls the degree of optimization. Possible values are full  to enable all available optimizations, and off (default) to  disable all optimizations. The default is derived from the SWI-Prolog  flag optimise, where true is mapped to full. Therefore the command  line option -O provides full CHR optimization. If  optimization is enabled, debugging must be disabled.\n\ndebug: This option enables or disables the possibility to debug the CHR code.  Possible values are on (default) and off. See section 8.4 for more details on  debugging. The default is derived from the Prolog flag generate_debug_info,  which is true by default. See -nodebug. If  debugging is enabled, optimization must be disabled.\n\n ",
    "prefix":"chr_option"
  },
  "':- chr_type'/1": {
    "body":":- chr_type(${1:TypeDeclaration})$2\n$0",
    "description":":- chr_type(+TypeDeclaration).\nUser-defined types are algebraic data types, similar to those in Haskell  or the discriminated unions in Mercury. An algebraic data type is  defined using chr_type/1:  \n\n:- chr_type type ---> body.\n\n  If the type term is a functor of arity zero (i.e. one having zero  arguments), it names a monomorphic type. Otherwise, it names a  polymorphic type; the arguments of the functor must be distinct type  variables. The body term is defined as a sequence of constructor  definitions separated by semi-colons. \n\nEach constructor definition must be a functor whose arguments (if  any) are types. Discriminated union definitions must be transparent: all  type variables occurring in the body must also occur in the type. \n\nHere are some examples of algebraic data type definitions: \n\n\n\n:- chr_type color ---> red ; blue ; yellow ; green.\n\n:- chr_type tree --->  empty ; leaf(int) ; branch(tree, tree).\n\n:- chr_type list(T) ---> [] ; [T | list(T)].\n\n:- chr_type pair(T1, T2) ---> (T1 - T2).\n\n  Each algebraic data type definition introduces a distinct type. Two  algebraic data types that have the same bodies are considered to be  distinct types (name equivalence). \n\nConstructors may be overloaded among different types: there may be  any number of constructors with a given name and arity, so long as they  all have different types. \n\nAliases can be defined using ==. For example, if your program uses  lists of lists of integers, you can define an alias as follows: \n\n\n\n:- chr_type lli == list(list(int)).\n\n  \n\n",
    "prefix":"chr_type"
  },
  "':- elif'/1": {
    "body":":- elif(${1:Goal})$2\n$0",
    "description":":- elif(:Goal).\nEquivalent to :- else. :-if(Goal). ... :- endif.  In a sequence as below, the section below the first matching elif  is processed. If no test succeeds, the else branch is processed.  \n\n:- if(test1).\nsection_1.\n:- elif(test2).\nsection_2.\n:- elif(test3).\nsection_3.\n:- else.\nsection_else.\n:- endif.\n\n ",
    "prefix":"elif"
  },
  "':- else'/0": {
    "body":":- else$1\n$0",
    "description":":- else.\nStart `else' branch.",
    "prefix":"else"
  },
  "':- endif'/0": {
    "body":":- endif$1\n$0",
    "description":":- endif.\nEnd of conditional compilation.",
    "prefix":"endif"
  },
  "':- expects_dialect'/1": {
    "body":":- expects_dialect(${1:Dialect})$2\n$0",
    "description":":- expects_dialect(+Dialect).\nThis directive states that the code following the directive is written  for the given Prolog Dialect. See also dialect.  The declaration holds until the end of the file in which it appears. The  current dialect is available using prolog_load_context/2.  The exact behaviour of this predicate is still subject to discussion.  Of course, if Dialect matches the running dialect the  directive has no effect. Otherwise we check for the existence of library(dialect/Dialect) and load it if the file is found.  Currently, this file has this functionality: \n\n\n\nDefine system predicates of the requested dialect we do not have.  \nApply goal_expansion/2  rules that map conflicting predicates to versions emulating the  requested dialect. These expansion rules reside in the dialect  compatibility module, but are applied if prolog_load_context(dialect,  Dialect) is active.  \nModify the search path for library directories, putting libraries  compatible with the target dialect before the native libraries.  \nSetup support for the default filename extension of the dialect.\n\n",
    "prefix":"expects_dialect"
  },
  "':- if'/1": {
    "body":":- if(${1:Goal})$2\n$0",
    "description":":- if(:Goal).\nCompile subsequent code only if Goal succeeds. For enhanced  portability, Goal is processed by expand_goal/2  before execution. If an error occurs, the error is printed and  processing proceeds as if Goal has failed.",
    "prefix":"if"
  },
  "':- initialization'/1": {
    "body":":- initialization(${1:Goal})$2\n$0",
    "description":"[ISO]:- initialization(:Goal).\nCall Goal after loading the source file in which  this directive appears has been completed. In addition, Goal  is executed if a saved state created using qsave_program/1  is restored.  The ISO standard only allows for using :- Term if Term  is a directive. This means that arbitrary goals can only be called  from a directive by means of the initialization/1  directive. SWI-Prolog does not enforce this rule. \n\nThe initialization/1  directive must be used to do program initialization in saved states (see qsave_program/1).  A saved state contains the predicates, Prolog flags and operators  present at the moment the state was created. Other resources (records,  foreign resources, etc.) must be recreated using initialization/1  directives or from the entry goal of the saved state. \n\nUp to SWI-Prolog 5.7.11, Goal was executed immediately  rather than after loading the program text in which the directive  appears as dictated by the ISO standard. In many cases the exact moment  of execution is irrelevant, but there are exceptions. For example, load_foreign_library/1  must be executed immediately to make the loaded foreign predicates  available for exporting. SWI-Prolog now provides the directive use_foreign_library/1  to ensure immediate loading as well as loading after restoring a saved  state. If the system encounters a directive :-  initialization(load_foreign_library(...)), it will load the  foreign library immediately and issue a warning to update your code.  This behaviour can be extended by providing clauses for the multifile  hook predicate prolog:initialize_now(Term, Advice), where Advice  is an atom that gives advice on how to resolve the compatibility issue.\n\n",
    "prefix":"initialization"
  },
  "':- module'/2": {
    "body":":- module(${1:Module}, ${2:PublicList})$3\n$0",
    "description":":- module(+Module, +PublicList).\nThis directive can only be used as the first term of a source file. It  declares the file to be a module file, defining a module named Module. Note that a module name is an atom. The module  exports the predicates of PublicList. PublicList  is a list of predicate indicators (name/arity or name//arity pairs) or  operator declarations using the format op(Precedence, Type, Name).  Operators defined in the export list are available inside the module as  well as to modules importing this module. See also section  4.25.  Compatible to Ciao Prolog, if Module is unbound, it is  unified with the basename without extension of the file being loaded.\n\n",
    "prefix":"module"
  },
  "':- module'/3": {
    "body":":- module(${1:Module}, ${2:PublicList}, ${3:Dialect})$4\n$0",
    "description":":- module(+Module, +PublicList, +Dialect).\nSame as module/2.  The additional Dialect argument provides a list of language  options. Each atom in the list Dialect is mapped to a use_module/1  goal as given below. See also section  C. The third argument is supported for compatibility with the http://prolog-commons.org/Prolog Commons project .  \n\n:- use_module(library(dialect/LangOption)).\n\n  \n\n",
    "prefix":"module"
  },
  "':- module_transparent'/1": {
    "body":":- module_transparent(${1:Preds})$2\n$0",
    "description":":- module_transparent(+Preds).\nPreds is a comma-separated list of name/arity pairs (like dynamic/1).  Each goal associated with a transparent-declared predicate will inherit  the context module from its parent goal.",
    "prefix":"module_transparent"
  },
  "'NAMED_PREDICATE'/3": {
    "body":"NAMED_PREDICATE(${1:plname}, ${2:cname}, ${3:arity})$4\n$0",
    "description":"NAMED_PREDICATE(plname, cname, arity).\nThis version can be used to create predicates whose name is not a valid  C++ identifier. Here is a ---hypothetical--- example, which unifies the  second argument with a stringified version of the first. The `cname' is  used to create a name for the functions. The concrete name does not  matter, but must be unique. Typically it is a descriptive name using the  limitations imposed by C++ indentifiers.  \n\n    NAMED_PREDICATE(\"#\", hash, 2)\n    { A2 = (wchar_t*)A1;\n    }\n    \n\n ",
    "prefix":"NAMED_PREDICATE"
  },
  "'NAMED_PREDICATE_NONDET'/3": {
    "body":"NAMED_PREDICATE_NONDET(${1:plname}, ${2:cname}, ${3:arity})$4\n$0",
    "description":"NAMED_PREDICATE_NONDET(plname, cname, arity).\nDefine a non-deterministic Prolog predicate in C++. See SWI-cpp.h. FIXME: Needs cleanup and an example.",
    "prefix":"NAMED_PREDICATE_NONDET"
  },
  "'PREDICATE0'/1": {
    "body":"PREDICATE0(${1:name})$2\n$0",
    "description":"PREDICATE0(name).\nThis is the same as PREDICATE(name, 0). It avoids a compiler warning  about that PL_av is not used.",
    "prefix":"PREDICATE0"
  },
  "'Xserver':ensure_x_server/2": {
    "body": ["ensure_x_server(${1:Display}, ${2:Depth})$3\n$0" ],
    "description":"  ensure_x_server(+Display, +Depth)\n\n   Ensure the existence of a graphics environment for XPCE.  This\n   library uses the `head-less' server Xvfb if there is no X-server\n   in the environment.\n\n   Currently this library deals with Windows (where no explicit\n   server is required) and Xfree using the Xfree socket naming\n   conventions.  Please send platform-specific code to\n   info@swi-prolog.org",
    "prefix":"ensure_x_server"
  },
  "(div)/2": {
    "body":"div(${1:IntExpr1}, ${2:IntExpr2})$3\n$0",
    "description":"[ISO]div(+IntExpr1, +IntExpr2).\nInteger division, defined as Result is (IntExpr1 - IntExpr1 mod IntExpr2)  // IntExpr2. In other words, this is integer division that  rounds towards -infinity. This function guarantees behaviour that is  consistent with mod/2, i.e., the  following holds for every pair of integers X,Y where Y =\\= 0.  \n\n        Q is div(X, Y),\n        M is mod(X, Y),\n        X =:= Y*Q+M.\n\n ",
    "prefix":"div"
  },
  "(initialization)/2": {
    "body":"initialization(${1:Goal}, ${2:When})$3\n$0",
    "description":"initialization(:Goal, +When).\nSimilar to initialization/1,  but allows for specifying when Goal is executed while loading  the program text:  now: Execute Goal immediately.\n\nafter_load: Execute Goal after loading program text. This is the same as initialization/1.\n\nrestore: Do not execute Goal while loading the program, but only  when restoring a state.\n\n ",
    "prefix":"initialization"
  },
  "(thread_initialization)/1": {
    "body":"thread_initialization(${1:Goal})$2\n$0",
    "description":"thread_initialization(:Goal).\nRun Goal when thread is started. This predicate is similar to initialization/1,  but is intended for initialization operations of the runtime stacks,  such as setting global variables as described in section 4.33. Goal is run  on four occasions: at the call to this predicate, after loading a saved  state, on starting a new thread and on creating a Prolog engine through  the C interface. On loading a saved state, Goal is executed after  running the initialization/1  hooks.",
    "prefix":"thread_initialization"
  },
  "abolish/1": {
    "body":"abolish(${1:PredicateIndicator})$2\n$0",
    "description":"[ISO]abolish(:PredicateIndicator).\nRemoves all clauses of a predicate with functor Functor and  arity Arity from the database. All predicate attributes (dynamic,  multifile, index, etc.) are reset to their defaults. Abolishing an  imported predicate only removes the import link; the predicate will keep  its old definition in its definition module.  According to the ISO standard, abolish/1  can only be applied to dynamic procedures. This is odd, as for dealing  with dynamic procedures there is already retract/1  and retractall/1.  The abolish/1  predicate was introduced in DEC-10 Prolog precisely for dealing with  static procedures. In SWI-Prolog, abolish/1  works on static procedures, unless the Prolog flag iso  is set to true. \n\nIt is advised to use retractall/1  for erasing all clauses of a dynamic predicate.\n\n",
    "prefix":"abolish"
  },
  "abolish/2": {
    "body":"abolish(${1:Name}, ${2:Arity})$3\n$0",
    "description":"abolish(+Name, +Arity).\nSame as abolish(Name/Arity). The predicate abolish/2  conforms to the Edinburgh standard, while abolish/1  is ISO compliant.",
    "prefix":"abolish"
  },
  "abort/0": {
    "body":"abort$1\n$0",
    "description":"abort.\nAbort the Prolog execution and restart the top level. If the -t toplevel command line option is given,  this goal is started instead of entering the default interactive top  level.  Aborting is implemented by throwing the reserved exception '$aborted'. This exception can be caught using catch/3,  but the recovery goal is wrapped with a predicate that prunes the choice  points of the recovery goal (i.e., as once/1)  and re-throws the exception. This is illustrated in the example below,  where we press control-C and `a'. \n\n\n\n?- catch((repeat,fail), E, true).\n^CAction (h for help) ? abort\n% Execution Aborted\n\n ",
    "prefix":"abort"
  },
  "abs/1": {
    "body":"abs(${1:Expr})$2\n$0",
    "description":"[ISO]abs(+Expr).\nEvaluate Expr and return the absolute value of it.",
    "prefix":"abs"
  },
  "absolute_file_name/2": {
    "body":"absolute_file_name(${1:File}, ${2:Absolute})$3\n$0",
    "description":"absolute_file_name(+File, -Absolute).\nExpand a local filename into an absolute path. The absolute path is  canonicalised: references to . and .. are  deleted. This predicate ensures that expanding a filename returns the  same absolute path regardless of how the file is addressed. SWI-Prolog  uses absolute filenames to register source files independent of the  current working directory. See also absolute_file_name/3.  See also absolute_file_name/3  and expand_file_name/2.",
    "prefix":"absolute_file_name"
  },
  "absolute_file_name/3": {
    "body":"absolute_file_name(${1:Spec}, ${2:Absolute}, ${3:Options})$4\n$0",
    "description":"absolute_file_name(+Spec, -Absolute, +Options).\nConvert the given file specification into an absolute path. Spec  is a term Alias(Relative) (e.g., (library(lists)), a  relative filename or an absolute filename. The primary intention of this  predicate is to resolve files specified as Alias(Relative). Option is a list of options to guide the conversion:  extensions(ListOfExtensions): List of file extensions to try. Default is ''. For each  extension, absolute_file_name/3  will first add the extension and then verify the conditions imposed by  the other options. If the condition fails, the next extension on the  list is tried. Extensions may be specified both as .ext or  plain ext.\n\nrelative_to(+FileOrDir): Resolve the path relative to the given directory or the directory  holding the given file. Without this option, paths are resolved relative  to the working directory (see working_directory/2)  or, if Spec is atomic and absolute_file_name/[2,3]  is executed in a directive, it uses the current source file as  reference.\n\naccess(Mode): Imposes the condition access_file(File, Mode). Mode  is one of read, write, append, execute, exist or none. See also access_file/2.\n\nfile_type(Type): Defines extensions. Current mapping: txt implies [''], prolog implies ['.pl', ''], executable  implies ['.so', ''], qlf implies ['.qlf', '']  and directory implies ['']. The file type source  is an alias for prolog for compatibility with SICStus  Prolog. See also prolog_file_type/2.  This predicate only returns non-directories, unless the option file_type(directory)  is specified.\n\nfile_errors(fail/error): If error (default), throw an existence_error  exception if the file cannot be found. If fail, stay  silent.128Silent operation was the  default up to version 3.2.6.\n\nsolutions(first/all): If first (default), the predicate leaves no choice point.  Otherwise a choice point will be left and backtracking may yield more  solutions.\n\nexpand(true/false): If true (default is false) and Spec  is atomic, call expand_file_name/2  followed by member/2  on Spec before proceeding. This is a SWI-Prolog extension.\n\n  The Prolog flag verbose_file_search  can be set to true to help debugging Prolog's search for  files. \n\nThis predicate is derived from Quintus Prolog. In Quintus Prolog, the  argument order was absolute_file_name(+Spec, +Options, -Path).  The argument order has been changed for compatibility with ISO and  SICStus. The Quintus argument order is still accepted.\n\n",
    "prefix":"absolute_file_name"
  },
  "access_file/2": {
    "body":"access_file(${1:File}, ${2:Mode})$3\n$0",
    "description":"access_file(+File, +Mode).\nTrue if File exists and can be accessed by this Prolog  process under mode Mode. Mode is one of the atoms read, write, append, exist, none  or execute. File may also be the name of a  directory. Fails silently otherwise. access_file(File, none)  simply succeeds without testing anything.  If Mode is write or append, this  predicate also succeeds if the file does not exist and the user has  write access to the directory of the specified location. \n\nThe bahaviour is backed up by the POSIX access() API. The Windows  replacement (_waccess()) returns incorrect results because it does not  consider ACLs (Access Control Lists). The Prolog flag win_file_access_check  may be used to control the level of checking performed by Prolog. Please  note that checking access never provides a guarantee that a subsequent  open succeeds without errors due to inherent concurrency in file  operations. It is generally more robust to try and open the file and  handle possible exceptions. See open/4  and catch/3.\n\n",
    "prefix":"access_file"
  },
  "acos/1": {
    "body":"acos(${1:Expr})$2\n$0",
    "description":"[ISO]acos(+Expr).\nResult = arccos(Expr). Result  is the angle in radians.",
    "prefix":"acos"
  },
  "acosh/1": {
    "body":"acosh(${1:Expr})$2\n$0",
    "description":"acosh(+Expr).\nResult = arccosh(Expr) (inverse  hyperbolic cosine).",
    "prefix":"acosh"
  },
  "acyclic_term/1": {
    "body":"acyclic_term(${1:Term})$2\n$0",
    "description":"[ISO]acyclic_term(@Term).\nTrue if Term does not contain cycles, i.e. can be processed  recursively in finite time. See also cyclic_term/1  and section 2.16.",
    "prefix":"acyclic_term"
  },
  "add_import_module/3": {
    "body":"add_import_module(${1:Module}, ${2:Import}, ${3:StartOrEnd})$4\n$0",
    "description":"add_import_module(+Module, +Import, +StartOrEnd).\nIf Import is not already an import module for Module,  add it to this list at the start or end  depending on StartOrEnd. See also import_module/2  and delete_import_module/2.",
    "prefix":"add_import_module"
  },
  "aggregate:aggregate/3": {
    "body":"aggregate(${1:Template}, ${2:Goal}, ${3:Result})$4\n$0",
    "description":"[nondet]aggregate(+Template, :Goal, -Result).\nAggregate bindings in Goal according to Template.  The aggregate/3  version performs bagof/3  on Goal.",
    "prefix":"aggregate"
  },
  "aggregate:aggregate/4": {
    "body":"aggregate(${1:Template}, ${2:Discriminator}, ${3:Goal}, ${4:Result})$5\n$0",
    "description":"[nondet]aggregate(+Template, +Discriminator, :Goal, -Result).\nAggregate bindings in Goal according to Template.  The aggregate/4  version performs setof/3  on Goal.",
    "prefix":"aggregate"
  },
  "aggregate:aggregate_all/3": {
    "body":"aggregate_all(${1:Template}, ${2:Goal}, ${3:Result})$4\n$0",
    "description":"[semidet]aggregate_all(+Template, :Goal, -Result).\nAggregate bindings in Goal according to Template.  The aggregate_all/3  version performs findall/3  on Goal. Note that this predicate fails if Template  contains one or more of min(X), max(X), min(X,Witness) or max(X,Witness)  and Goal has no solutions, i.e., the minumum and maximum of  an empty set is undefined.",
    "prefix":"aggregate_all"
  },
  "aggregate:aggregate_all/4": {
    "body":"aggregate_all(${1:Template}, ${2:Discriminator}, ${3:Goal}, ${4:Result})$5\n$0",
    "description":"[semidet]aggregate_all(+Template, +Discriminator, :Goal, -Result).\nAggregate bindings in Goal according to Template.  The aggregate_all/4  version performs findall/3  followed by sort/2 on Goal. See aggregate_all/3  to understand why this predicate can fail.",
    "prefix":"aggregate_all"
  },
  "aggregate:foreach/2": {
    "body":"foreach(${1:Generator}, ${2:Goal})$3\n$0",
    "description":"foreach(:Generator, :Goal).\nTrue if conjunction of results is true. Unlike forall/2,  which runs a failure-driven loop that proves Goal for each  solution of Generator, foreach/2  creates a conjunction. Each member of the conjunction is a copy of Goal,  where the variables it shares with Generator are filled with  the values from the corresponding solution.  The implementation executes forall/2  if Goal does not contain any variables that are not shared  with Generator. \n\nHere is an example: \n\n\n\n?- foreach(between(1,4,X), dif(X,Y)), Y = 5.\nY = 5.\n?- foreach(between(1,4,X), dif(X,Y)), Y = 3.\nfalse.\n\n  bug: Goal is copied repeatedly, which may cause problems if  attributed variables are involved.\n\n ",
    "prefix":"foreach"
  },
  "aggregate:free_variables/4": {
    "body":"free_variables(${1:Generator}, ${2:Template}, ${3:VarList0}, ${4:VarList})$5\n$0",
    "description":"[det]free_variables(:Generator, +Template, +VarList0, -VarList).\nFind free variables in bagof/setof template. In order to handle  variables properly, we have to find all the universally quantified  variables in the Generator. All variables as yet unbound are  universally quantified, unless  \n\nthey occur in the template\nthey are bound by X^P, setof/3,  or bagof/3\n\n  free_variables(Generator, Template, OldList, NewList)  finds this set using OldList as an accumulator. \n\nauthor: - Richard O'Keefe  - Jan Wielemaker (made some SWI-Prolog enhancements)\n\nlicense: Public domain (from DEC10 library).\n\nTo be done: - Distinguish between control-structures and data terms.  - Exploit our built-in term_variables/2  at some places?\n\n ",
    "prefix":"free_variables"
  },
  "ansi_term:ansi_format/3": {
    "body": ["ansi_format(${1:Attributes}, ${2:Format}, ${3:Args})$4\n$0" ],
    "description":"  ansi_format(+Attributes, +Format, +Args) is det.\n\n   Format text with ANSI  attributes.   This  predicate  behaves as\n   format/2 using Format and Args, but if the =current_output= is a\n   terminal, it adds ANSI escape sequences according to Attributes.\n   For example, to print a text in bold cyan, do\n\n     ==\n     ?- ansi_format([bold,fg(cyan)], 'Hello ~w', [world]).\n     ==\n\n   Attributes is either a single attribute   or a list thereof. The\n   attribute names are derived from the ANSI specification. See the\n   source for sgr_code/2 for details. Some commonly used attributes\n   are:\n\n     - bold\n     - underline\n     - fg(Color), bg(Color), hfg(Color), hbg(Color)\n\n   Defined color constants are below.  =default=   can  be  used to\n   access the default color of the terminal.\n\n     - black, red, green, yellow, blue, magenta, cyan, white\n\n   ANSI sequences are sent if and only if\n\n     - The =current_output= has the property tty(true) (see\n       stream_property/2).\n     - The Prolog flag =color_term= is =true=.",
    "prefix":"ansi_format"
  },
  "append/1": {
    "body":"append(${1:File})$2\n$0",
    "description":"append(+File).\nSimilar to tell/1,  but positions the file pointer at the end of File rather than  truncating an existing file. The pipe construct is not accepted by this  predicate.",
    "prefix":"append"
  },
  "apply/2": {
    "body":"apply(${1:Goal}, ${2:List})$3\n$0",
    "description":"apply(:Goal, +List).\nAppend the members of List to the arguments of Goal  and call the resulting term. For example: apply(plus(1), [2, X])  calls plus(1, 2, X). New code should use call/[2..] if the length  of List is fixed.",
    "prefix":"apply"
  },
  "apply:exclude/3": {
    "body":"exclude(${1:Goal}, ${2:List1}, ${3:List2})$4\n$0",
    "description":"[det]exclude(:Goal, +List1, ?List2).\nFilter elements for which Goal fails. True if List2  contains those elements Xi of List1 for which call(Goal, Xi)  fails.",
    "prefix":"exclude"
  },
  "apply:foldl/4": {
    "body":"foldl(${1:Goal}, ${2:List}, ${3:V0}, ${4:V})$5\n$0",
    "description":"foldl(:Goal, +List, +V0, -V).\n",
    "prefix":"foldl"
  },
  "apply:foldl/5": {
    "body":"foldl(${1:Goal}, ${2:List1}, ${3:List2}, ${4:V0}, ${5:V})$6\n$0",
    "description":"foldl(:Goal, +List1, +List2, +V0, -V).\n",
    "prefix":"foldl"
  },
  "apply:foldl/6": {
    "body":"foldl(${1:Goal}, ${2:List1}, ${3:List2}, ${4:List3}, ${5:V0}, ${6:V})$7\n$0",
    "description":"foldl(:Goal, +List1, +List2, +List3, +V0, -V).\n",
    "prefix":"foldl"
  },
  "apply:foldl/7": {
    "body":"foldl(${1:Goal}, ${2:List1}, ${3:List2}, ${4:List3}, ${5:List4}, ${6:V0}, ${7:V})$8\n$0",
    "description":"foldl(:Goal, +List1, +List2, +List3, +List4, +V0, -V).\nFold a list, using arguments of the list as left argument. The foldl  family of predicates is defined by:  \n\nfoldl(P, [X11,...,X1n], ..., [Xm1,...,Xmn], V0, Vn) :-\n      P(X11, ..., Xm1, V0, V1),\n      ...\n      P(X1n, ..., Xmn, V', Vn).\n\n ",
    "prefix":"foldl"
  },
  "apply:include/3": {
    "body":"include(${1:Goal}, ${2:List1}, ${3:List2})$4\n$0",
    "description":"[det]include(:Goal, +List1, ?List2).\nFilter elements for which Goal succeeds. True if List2  contains those elements Xi of List1 for which call(Goal, Xi)  succeeds.  See also: Older versions of SWI-Prolog had sublist/3  with the same arguments and semantics.\n\n ",
    "prefix":"include"
  },
  "apply:maplist/2": {
    "body":"maplist(${1:Goal}, ${2:List})$3\n$0",
    "description":"maplist(:Goal, ?List).\nTrue if Goal can successfully be applied on all elements of List. Arguments are reordered to gain performance as well as  to make the predicate deterministic under normal circumstances.",
    "prefix":"maplist"
  },
  "apply:maplist/3": {
    "body":"maplist(${1:Goal}, ${2:List1}, ${3:List2})$4\n$0",
    "description":"maplist(:Goal, ?List1, ?List2).\nAs maplist/2, operating  on pairs of elements from two lists.",
    "prefix":"maplist"
  },
  "apply:maplist/4": {
    "body":"maplist(${1:Goal}, ${2:List1}, ${3:List2}, ${4:List3})$5\n$0",
    "description":"maplist(:Goal, ?List1, ?List2, ?List3).\nAs maplist/2, operating  on triples of elements from three lists.",
    "prefix":"maplist"
  },
  "apply:maplist/5": {
    "body":"maplist(${1:Goal}, ${2:List1}, ${3:List2}, ${4:List3}, ${5:List4})$6\n$0",
    "description":"maplist(:Goal, ?List1, ?List2, ?List3, ?List4).\nAs maplist/2, operating  on quadruples of elements from four lists.",
    "prefix":"maplist"
  },
  "apply:partition/4": {
    "body":"partition(${1:Pred}, ${2:List}, ${3:Included}, ${4:Excluded})$5\n$0",
    "description":"[det]partition(:Pred, +List, ?Included, ?Excluded).\nFilter elements of List according to Pred. True if Included  contains all elements for which call(Pred, X) succeeds and Excluded contains the remaining elements.",
    "prefix":"partition"
  },
  "apply:partition/5": {
    "body":"partition(${1:Pred}, ${2:List}, ${3:Less}, ${4:Equal}, ${5:Greater})$6\n$0",
    "description":"[semidet]partition(:Pred, +List, ?Less, ?Equal, ?Greater).\nFilter List according to Pred in three sets. For  each element Xi of List, its destination is determined by call(Pred, Xi, Place),  where Place must be unified to one of <, =  or >. Pred must be deterministic.",
    "prefix":"partition"
  },
  "apply:scanl/4": {
    "body":"scanl(${1:Goal}, ${2:List}, ${3:V0}, ${4:Values})$5\n$0",
    "description":"scanl(:Goal, +List, +V0, -Values).\n",
    "prefix":"scanl"
  },
  "apply:scanl/5": {
    "body":"scanl(${1:Goal}, ${2:List1}, ${3:List2}, ${4:V0}, ${5:Values})$6\n$0",
    "description":"scanl(:Goal, +List1, +List2, +V0, -Values).\n",
    "prefix":"scanl"
  },
  "apply:scanl/6": {
    "body":"scanl(${1:Goal}, ${2:List1}, ${3:List2}, ${4:List3}, ${5:V0}, ${6:Values})$7\n$0",
    "description":"scanl(:Goal, +List1, +List2, +List3, +V0, -Values).\n",
    "prefix":"scanl"
  },
  "apply:scanl/7": {
    "body":"scanl(${1:Goal}, ${2:List1}, ${3:List2}, ${4:List3}, ${5:List4}, ${6:V0}, ${7:Values})$8\n$0",
    "description":"scanl(:Goal, +List1, +List2, +List3, +List4, +V0, -Values).\nLeft scan of list. The scanl family of higher order list operations is  defined by:  \n\nscanl(P, [X11,...,X1n], ..., [Xm1,...,Xmn], V0,\n      [V0,V1,...,Vn]) :-\n      P(X11, ..., Xm1, V0, V1),\n      ...\n      P(X1n, ..., Xmn, V', Vn).\n\n  \n\n",
    "prefix":"scanl"
  },
  "apply_macros:expand_phrase/2": {
    "body": ["expand_phrase(${1:PhraseGoal}, ${2:Goal})$3\n$0" ],
    "description":"  expand_phrase(+PhraseGoal, -Goal) is semidet.\n  expand_phrase(+PhraseGoal, +Pos0, -Goal, -Pos) is semidet.\n\n   Provide goal-expansion for  PhraseGoal.   PhraseGoal  is  either\n   phrase/2,3  or  call_dcg/2,3.  The  current   version  does  not\n   translate control structures, but  only   simple  terminals  and\n   non-terminals.\n\n   For example:\n\n     ==\n     ?- expand_phrase(phrase((\"ab\", rule)), List), Goal).\n     Goal = (List=[97, 98|_G121], rule(_G121, [])).\n     ==\n\n   @throws Re-throws errors from dcg_translate_rule/2",
    "prefix":"expand_phrase"
  },
  "apply_macros:expand_phrase/4": {
    "body": [
      "expand_phrase(${1:PhraseGoal}, ${2:Pos0}, ${3:Goal}, ${4:Pos})$5\n$0"
    ],
    "description":"  expand_phrase(+PhraseGoal, -Goal) is semidet.\n  expand_phrase(+PhraseGoal, +Pos0, -Goal, -Pos) is semidet.\n\n   Provide goal-expansion for  PhraseGoal.   PhraseGoal  is  either\n   phrase/2,3  or  call_dcg/2,3.  The  current   version  does  not\n   translate control structures, but  only   simple  terminals  and\n   non-terminals.\n\n   For example:\n\n     ==\n     ?- expand_phrase(phrase((\"ab\", rule)), List), Goal).\n     Goal = (List=[97, 98|_G121], rule(_G121, [])).\n     ==\n\n   @throws Re-throws errors from dcg_translate_rule/2",
    "prefix":"expand_phrase"
  },
  "apropos/1": {
    "body":"apropos(${1:Pattern})$2\n$0",
    "description":"apropos(+Pattern).\nDisplay all predicates, functions and sections that have Pattern  in their name or summary description. Lowercase letters in Pattern also match a corresponding uppercase letter. Example: ?- apropos(file). Display  predicates, functions and sections that have `file' (or `File', etc.) in  their summary description. ",
    "prefix":"apropos"
  },
  "archive:archive_close/1": {
    "body":"archive_close(${1:Archive})$2\n$0",
    "description":"[det]archive_close(+Archive).\nClose the archive. If close_parent(true) is specified, the  underlying stream is closed too. If there is an entry opened with archive_open_entry/2,  actually closing the archive is delayed until the stream associated with  the entry is closed. This can be used to open a stream to an archive  entry without having to worry about closing the archive:  \n\narchive_open_named(ArchiveFile, EntryName, Stream) :-\n    archive_open(ArchiveFile, Handle, []),\n    archive_next_header(Handle, Name),\n    archive_open_entry(Handle, Stream),\n    archive_close(Archive).\n\n ",
    "prefix":"archive_close"
  },
  "archive:archive_create/3": {
    "body":"archive_create(${1:OutputFile}, ${2:InputFiles}, ${3:Options})$4\n$0",
    "description":"[det]archive_create(+OutputFile, +InputFiles, +Options).\nConvenience predicate to create an archive in OutputFile with  data from a list of InputFiles and the given Options.  Besides options supported by archive_open/4,  the following options are supported: \n\ndirectory(+Directory): Changes the directory before adding input files. If this is specified,  paths of input files must be relative to Directory and archived files will not have Directory  as leading path. This is to simulate -C option of the tar  program.\n\nformat(+Format): Write mode supports the following formats: `7zip, cpio, gnutar, iso9660, xar and zip`.  Note that a particular installation may support only a subset of these,  depending on the configuration of libarchive.\n\n ",
    "prefix":"archive_create"
  },
  "archive:archive_data_stream/3": {
    "body":"archive_data_stream(${1:Archive}, ${2:DataStream}, ${3:Options})$4\n$0",
    "description":"[nondet]archive_data_stream(+Archive, -DataStream, +Options).\nTrue when DataStream is a stream to a data object inside Archive. This predicate transparently unpacks data inside possibly nested archives, e.g., a tar file inside a zip  file. It applies the appropriate decompression filters and thus ensures  that Prolog reads the plain data from DataStream. DataStream must be closed after the content has been  processed. Backtracking opens the next member of the (nested) archive.  This predicate processes the following options:  meta_data(-Data:list(dict)): If provided, Data is unified with a list of filters applied  to the (nested) archive to open the current DataStream. The  first element describes the outermost archive. Each Data dict  contains the header properties (archive_header_property/2)  as well as the keys:  filters(Filters:list(atom))Filter list as obtained from archive_property/2name(Atom)Name of the entry. \n\n  Note that this predicate can handle a non-archive files as a pseudo  archive holding a single stream by using archive_open/3  with the options [format(all), format(raw)].\n\n",
    "prefix":"archive_data_stream"
  },
  "archive:archive_entries/2": {
    "body":"archive_entries(${1:Archive}, ${2:Paths})$3\n$0",
    "description":"[det]archive_entries(+Archive, -Paths).\nTrue when Paths is a list of pathnames appearing in Archive.",
    "prefix":"archive_entries"
  },
  "archive:archive_extract/3": {
    "body":"archive_extract(${1:ArchiveFile}, ${2:Dir}, ${3:Options})$4\n$0",
    "description":"archive_extract(+ArchiveFile, +Dir, +Options).\nExtract files from the given archive into Dir. Supported  options:  remove_prefix(+Prefix): Strip Prefix from all entries before extracting\n\n  Errors: - existence_error(directory, Dir) if Dir does  not exist or is not a directory.  - domain_error(path_prefix(Prefix), Path) if a path in the  archive does not start with Prefix\n\nTo be done: Add options\n\n ",
    "prefix":"archive_extract"
  },
  "archive:archive_header_property/2": {
    "body":"archive_header_property(${1:Archive}, ${2:Property})$3\n$0",
    "description":"archive_header_property(+Archive, ?Property).\nTrue when Property is a property of the current header.  Defined properties are:  filetype(-Type): Type is one of file, link, socket, character_device, block_device, directory or fifo.  It appears that this library can also return other values. These are  returned as an integer.\n\nmtime(-Time): True when entry was last modified at time.\n\nsize(-Bytes): True when entry is Bytes long.\n\nlink_target(-Target): Target for a link. Currently only supported for symbolic  links.\n\nformat(-Format): Provides the name of the archive format applicable to the current entry.  The returned value is the lowercase version of the output of archive_format_name().\n\npermissions(-Integer): True when entry has the indicated permission mask.\n\n ",
    "prefix":"archive_header_property"
  },
  "archive:archive_next_header/2": {
    "body":"archive_next_header(${1:Handle}, ${2:Name})$3\n$0",
    "description":"[semidet]archive_next_header(+Handle, -Name).\nForward to the next entry of the archive for which Name  unifies with the pathname of the entry. Fails silently if the name of  the archive is reached before success. Name is typically  specified if a single entry must be accessed and unbound otherwise. The  following example opens a Prolog stream to a given archive entry. Note  that Stream must be closed using close/1 and the archive must be closed  using archive_close/1 after  the data has been used. See also setup_call_cleanup/3.  \n\nopen_archive_entry(ArchiveFile, Entry, Stream) :-\n    open(ArchiveFile, read, In, [type(binary)]),\n    archive_open(In, Archive, [close_parent(true)]),\n    archive_next_header(Archive, Entry),\n    archive_open_entry(Archive, Stream).\n\n  Errors: permission_error(next_header, archive, Handle) if a  previously opened entry is not closed.\n\n ",
    "prefix":"archive_next_header"
  },
  "archive:archive_open/3": {
    "body": ["archive_open(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"archive_open('Param1','Param2','Param3')",
    "prefix":"archive_open"
  },
  "archive:archive_open/4": {
    "body":"archive_open(${1:Data}, ${2:Mode}, ${3:Archive}, ${4:Options})$5\n$0",
    "description":"[det]archive_open(+Data, +Mode, -Archive, +Options).\nOpen the archive in Data and unify Archive with a  handle to the opened archive. Data is either a file or a  stream that contains a valid archive. Details are controlled by Options.  Typically, the option close_parent(true) is used to close  stream if the archive is closed using archive_close/1.  For other options, the defaults are typically fine. The option format(raw)  must be used to process compressed streams that do not contain explicit  entries (e.g., gzip'ed data) unambibuously. The raw format  creates a pseudo archive holding a single member named data.  close_parent(+Boolean): If this option is true (default false), Stream  is closed if archive_close/1  is called on Archive.\n\ncompression(+Compression): Synomym for filter(Compression). Deprecated.\n\nfilter(+Filter): Support the indicated filter. This option may be used multiple times to  support multiple filters. In read mode, If no filter options are  provided, all is assumed. In write mode, none is assumed.  Supported values are all, bzip2, compress, gzip, grzip, lrzip, lzip, lzma, lzop, none, rpm, uu  and xz. The value all is default for read, none  for write.\n\nformat(+Format): Support the indicated format. This option may be used multiple times to  support multiple formats in read mode. In write mode, you must supply a  single format. If no format options are provided, all is  assumed for read mode. Note that all does not include raw. To open both  archive and non-archive files, both format(all) and format(raw) must be specified. Supported values are: all, 7zip, ar, cab, cpio, empty, gnutar, iso9660, lha, mtree, rar, raw, tar, xar  and zip. The value all is default for read.\n\n  Note that the actually supported compression types and formats may  vary depending on the version and installation options of the underlying  libarchive library. This predicate raises a domain error if the  (explicitly) requested format is not supported. \n\nErrors: - domain_error(filter, Filter) if the requested filter is  not supported.  - domain_error(format, Format) if the requested format type  is not supported.\n\n ",
    "prefix":"archive_open"
  },
  "archive:archive_open_entry/2": {
    "body":"archive_open_entry(${1:Archive}, ${2:Stream})$3\n$0",
    "description":"[det]archive_open_entry(+Archive, -Stream).\nOpen the current entry as a stream. Stream must be closed. If  the stream is not closed before the next call to archive_next_header/2,  a permission error is raised.",
    "prefix":"archive_open_entry"
  },
  "archive:archive_property/2": {
    "body":"archive_property(${1:Handle}, ${2:Property})$3\n$0",
    "description":"[nondet]archive_property(+Handle, ?Property).\nTrue when Property is a property of the archive Handle.  Defined properties are:  filters(List): True when the indicated filters are applied before reaching the archive  format.\n\n ",
    "prefix":"archive_property"
  },
  "archive:archive_set_header_property/2": {
    "body":"archive_set_header_property(${1:Archive}, ${2:Property})$3\n$0",
    "description":"archive_set_header_property(+Archive, +Property).\nSet Property of the current header. Write-mode only. Defined  properties are:  filetype(-Type): Type is one of file, link, socket, character_device, block_device, directory or fifo.  It appears that this library can also return other values. These are  returned as an integer.\n\nmtime(-Time): True when entry was last modified at time.\n\nsize(-Bytes): True when entry is Bytes long.\n\nlink_target(-Target): Target for a link. Currently only supported for symbolic  links.\n\n ",
    "prefix":"archive_set_header_property"
  },
  "area:side_pattern/3": {
    "body": ["side_pattern(${1:SideA}, ${2:SideB}, ${3:Pattern})$4\n$0" ],
    "description":"   side_pattern(+SideA, +SideB, -Pattern)\n\n   Pattern is the bit if SideA on area A corresponds to SideB on area B.",
    "prefix":"side_pattern"
  },
  "arg/3": {
    "body":"arg(${1:Arg}, ${2:Term}, ${3:Value})$4\n$0",
    "description":"[ISO]arg(?Arg, +Term, ?Value).\nTerm should be instantiated to a term, Arg to an  integer between 1 and the arity of Term. Value is  unified with the Arg-th argument of Term. Arg may also  be unbound. In this case Value will be unified with the  successive arguments of the term. On successful unification, Arg  is unified with the argument number. Backtracking yields alternative  solutions.91The instantiation  pattern (-, +, ?) is an extension to `standard' Prolog. Some systems  provide genarg/3 that covers this pattern. The predicate arg/3  fails silently if Arg = 0 or Arg > arity and raises the exception domain_error(not_less_than_zero, Arg) if Arg  < 0.",
    "prefix":"arg"
  },
  "arithmetic:arithmetic_expression_value/2": {
    "body": ["arithmetic_expression_value(${1:Expression}, ${2:Result})$3\n$0" ],
    "description":"  arithmetic_expression_value(:Expression, -Result) is det.\n\n   True  when  Result  unifies  with    the  arithmetic  result  of\n   evaluating Expression.",
    "prefix":"arithmetic_expression_value"
  },
  "arithmetic:arithmetic_function/1": {
    "body": ["arithmetic_function(${1:NameArity})$2\n$0" ],
    "description":"  arithmetic_function(:NameArity) is det.\n\n   Declare a predicate as an arithmetic function.\n\n   @deprecated This function provides  a   partial  work around for\n   pure Prolog user-defined arithmetic  functions   that  has  been\n   dropped in SWI-Prolog  5.11.23.  Notably,   it  only  deals with\n   expression know at compile time.",
    "prefix":"arithmetic_function"
  },
  "asin/1": {
    "body":"asin(${1:Expr})$2\n$0",
    "description":"[ISO]asin(+Expr).\nResult = arcsin(Expr). Result  is the angle in radians.",
    "prefix":"asin"
  },
  "asinh/1": {
    "body":"asinh(${1:Expr})$2\n$0",
    "description":"asinh(+Expr).\nResult = arcsinh(Expr) (inverse  hyperbolic sine).",
    "prefix":"asinh"
  },
  "assert/1": {
    "body":"assert(${1:Term})$2\n$0",
    "description":"assert(+Term).\nEquivalent to assertz/1.  Deprecated: new code should use assertz/1.",
    "prefix":"assert"
  },
  "assert/2": {
    "body":"assert(${1:Term}, ${2:Reference})$3\n$0",
    "description":"assert(+Term, -Reference).\nEquivalent to assertz/2.  Deprecated: new code should use assertz/2.",
    "prefix":"assert"
  },
  "asserta/1": {
    "body":"asserta(${1:Term})$2\n$0",
    "description":"[ISO]asserta(+Term).\nAssert a fact or clause in the database. Term is asserted as  the first fact or clause of the corresponding predicate. Equivalent to assert/1,  but Term is asserted as first clause or fact of the  predicate. If the program space for the target module is limited (see set_module/1), asserta/1  can raise a resource_error(program_space).",
    "prefix":"asserta"
  },
  "asserta/2": {
    "body":"asserta(${1:Term}, ${2:Reference})$3\n$0",
    "description":"asserta(+Term, -Reference).\nAsserts a clause as asserta/1  and unifies Reference with a handle to this clause. The  handle can be used to access this specific clause using clause/3  and erase/1.",
    "prefix":"asserta"
  },
  "assertz/1": {
    "body":"assertz(${1:Term})$2\n$0",
    "description":"[ISO]assertz(+Term).\nEquivalent to asserta/1,  but Term is asserted as the last clause or fact of the  predicate.",
    "prefix":"assertz"
  },
  "assertz/2": {
    "body":"assertz(${1:Term}, ${2:Reference})$3\n$0",
    "description":"assertz(+Term, -Reference).\nEquivalent to asserta/1,  asserting the new clause as the last clause of the predicate.",
    "prefix":"assertz"
  },
  "assoc:assoc_to_keys/2": {
    "body":"assoc_to_keys(${1:Assoc}, ${2:Keys})$3\n$0",
    "description":"[det]assoc_to_keys(+Assoc, -Keys).\nTrue if Keys is the list of keys in Assoc. The  keys are sorted in ascending order.",
    "prefix":"assoc_to_keys"
  },
  "assoc:assoc_to_list/2": {
    "body":"assoc_to_list(${1:Assoc}, ${2:Pairs})$3\n$0",
    "description":"[det]assoc_to_list(+Assoc, -Pairs).\nTranslate Assoc to a list Pairs of Key-Value  pairs. The keys in Pairs are sorted in ascending order.",
    "prefix":"assoc_to_list"
  },
  "assoc:assoc_to_values/2": {
    "body":"assoc_to_values(${1:Assoc}, ${2:Values})$3\n$0",
    "description":"[det]assoc_to_values(+Assoc, -Values).\nTrue if Values is the list of values in Assoc. Values  are ordered in ascending order of the key to which they were associated. Values  may contain duplicates.",
    "prefix":"assoc_to_values"
  },
  "assoc:del_assoc/4": {
    "body":"del_assoc(${1:Key}, ${2:Assoc0}, ${3:Value}, ${4:Assoc})$5\n$0",
    "description":"[semidet]del_assoc(+Key, +Assoc0, ?Value, -Assoc).\nTrue if Key-Value is in Assoc0. Assoc  is Assoc0 with Key-Value removed.",
    "prefix":"del_assoc"
  },
  "assoc:del_max_assoc/4": {
    "body":"del_max_assoc(${1:Assoc0}, ${2:Key}, ${3:Val}, ${4:Assoc})$5\n$0",
    "description":"[semidet]del_max_assoc(+Assoc0, ?Key, ?Val, -Assoc).\nTrue if Key-Value is in Assoc0 and Key  is the greatest key. Assoc is Assoc0 with Key-Value removed.  Warning: This will succeed with no bindings for Key or Val  if Assoc0 is empty.",
    "prefix":"del_max_assoc"
  },
  "assoc:del_min_assoc/4": {
    "body":"del_min_assoc(${1:Assoc0}, ${2:Key}, ${3:Val}, ${4:Assoc})$5\n$0",
    "description":"[semidet]del_min_assoc(+Assoc0, ?Key, ?Val, -Assoc).\nTrue if Key-Value is in Assoc0 and Key  is the smallest key. Assoc is Assoc0 with Key-Value removed.  Warning: This will succeed with no bindings for Key or Val  if Assoc0 is empty.",
    "prefix":"del_min_assoc"
  },
  "assoc:empty_assoc/1": {
    "body":"empty_assoc(${1:Assoc})$2\n$0",
    "description":"[semidet]empty_assoc(?Assoc).\nIs true if Assoc is the empty association list.",
    "prefix":"empty_assoc"
  },
  "assoc:gen_assoc/3": {
    "body":"gen_assoc(${1:Key}, ${2:Assoc}, ${3:Value})$4\n$0",
    "description":"[nondet]gen_assoc(?Key, +Assoc, ?Value).\nTrue if Key-Value is an association in Assoc.  Enumerates keys in ascending order on backtracking.  See also: get_assoc/3.\n\n ",
    "prefix":"gen_assoc"
  },
  "assoc:get_assoc/3": {
    "body":"get_assoc(${1:Key}, ${2:Assoc}, ${3:Value})$4\n$0",
    "description":"[semidet]get_assoc(+Key, +Assoc, -Value).\nTrue if Key-Value is an association in Assoc.  Errors: type_error(assoc, Assoc) if Assoc is not an  association list.\n\n ",
    "prefix":"get_assoc"
  },
  "assoc:get_assoc/5": {
    "body":"get_assoc(${1:Key}, ${2:Assoc0}, ${3:Val0}, ${4:Assoc}, ${5:Val})$6\n$0",
    "description":"[semidet]get_assoc(+Key, +Assoc0, ?Val0, ?Assoc, ?Val).\nTrue if Key-Val0 is in Assoc0 and Key-Val  is in Assoc.",
    "prefix":"get_assoc"
  },
  "assoc:is_assoc/1": {
    "body":"is_assoc(${1:Assoc})$2\n$0",
    "description":"[semidet]is_assoc(+Assoc).\nTrue if Assoc is an association list. This predicate checks  that the structure is valid, elements are in order, and tree is balanced  to the extent guaranteed by AVL trees. I.e., branches of each subtree  differ in depth by at most 1.",
    "prefix":"is_assoc"
  },
  "assoc:list_to_assoc/2": {
    "body":"list_to_assoc(${1:Pairs}, ${2:Assoc})$3\n$0",
    "description":"[det]list_to_assoc(+Pairs, -Assoc).\nCreate an association from a list Pairs of Key-Value pairs.  List must not contain duplicate keys.  Errors: domain_error(unique_key_pairs, List) if List contains  duplicate keys\n\n ",
    "prefix":"list_to_assoc"
  },
  "assoc:map_assoc/2": {
    "body":"map_assoc(${1:Pred}, ${2:Assoc})$3\n$0",
    "description":"[semidet]map_assoc(:Pred, +Assoc).\nTrue if Pred(Value) is true for all values in Assoc.",
    "prefix":"map_assoc"
  },
  "assoc:map_assoc/3": {
    "body":"map_assoc(${1:Pred}, ${2:Assoc0}, ${3:Assoc})$4\n$0",
    "description":"[semidet]map_assoc(:Pred, +Assoc0, ?Assoc).\nMap corresponding values. True if Assoc is Assoc0  with Pred applied to all corresponding pairs of of values.",
    "prefix":"map_assoc"
  },
  "assoc:max_assoc/3": {
    "body":"max_assoc(${1:Assoc}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"[semidet]max_assoc(+Assoc, -Key, -Value).\nTrue if Key-Value is in Assoc and Key  is the largest key.",
    "prefix":"max_assoc"
  },
  "assoc:min_assoc/3": {
    "body":"min_assoc(${1:Assoc}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"[semidet]min_assoc(+Assoc, -Key, -Value).\nTrue if Key-Value is in assoc and Key  is the smallest key.",
    "prefix":"min_assoc"
  },
  "assoc:ord_list_to_assoc/2": {
    "body":"ord_list_to_assoc(${1:Pairs}, ${2:Assoc})$3\n$0",
    "description":"[det]ord_list_to_assoc(+Pairs, -Assoc).\nAssoc is created from an ordered list Pairs of  Key-Value pairs. The pairs must occur in strictly ascending order of  their keys.  Errors: domain_error(key_ordered_pairs, List) if pairs are not  ordered.\n\n ",
    "prefix":"ord_list_to_assoc"
  },
  "assoc:put_assoc/4": {
    "body":"put_assoc(${1:Key}, ${2:Assoc0}, ${3:Value}, ${4:Assoc})$5\n$0",
    "description":"[det]put_assoc(+Key, +Assoc0, +Value, -Assoc).\nAssoc is Assoc0, except that Key is  associated with Value. This can be used to insert and change associations.",
    "prefix":"put_assoc"
  },
  "at_end_of_stream/1": {
    "body":"at_end_of_stream(${1:Stream})$2\n$0",
    "description":"[ISO]at_end_of_stream(+Stream).\nSucceeds after the last character of the named stream is read, or Stream is not a valid input stream. The end-of-stream test is  only available on buffered input streams (unbuffered input streams are  rarely used; see open/4).",
    "prefix":"at_end_of_stream"
  },
  "at_halt/1": {
    "body":"at_halt(${1:Goal})$2\n$0",
    "description":"at_halt(:Goal).\nRegister Goal to be run from PL_cleanup(),  which is called when the system halts. The hooks are run in the reverse  order they were registered (FIFO). Success or failure executing a hook  is ignored. If the hook raises an exception this is printed using print_message/2.  An attempt to call halt/[0,1]  from a hook is ignored. Hooks may call cancel_halt/1,  causing halt/0  and PL_halt(0)  to print a message indicating that halting the system has been  cancelled.",
    "prefix":"at_halt"
  },
  "atan/1": {
    "body":"atan(${1:Expr})$2\n$0",
    "description":"[ISO]atan(+Expr).\nResult = arctan(Expr). Result  is the angle in radians.",
    "prefix":"atan"
  },
  "atan/2": {
    "body":"atan(${1:YExpr}, ${2:XExpr})$3\n$0",
    "description":"atan(+YExpr, +XExpr).\nSame as atan2/2  (backward compatibility).",
    "prefix":"atan"
  },
  "atan2/2": {
    "body":"atan2(${1:YExpr}, ${2:XExpr})$3\n$0",
    "description":"[ISO]atan2(+YExpr, +XExpr).\nResult = arctan(YExpr/XExpr). Result  is the angle in radians. The return value is in the range [- pi ...  pi ]. Used to convert between rectangular and polar coordinate  system.  Note that the ISO Prolog standard demands atan2(0.0,0.0)  to raise an evaluation error, whereas the C99 and POSIX standards demand  this to evaluate to 0.0. SWI-Prolog follows C99 and POSIX.\n\n",
    "prefix":"atan2"
  },
  "atanh/1": {
    "body":"atanh(${1:Expr})$2\n$0",
    "description":"atanh(+Expr).\nResult = arctanh(Expr). (inverse  hyperbolic tangent).",
    "prefix":"atanh"
  },
  "atom/1": {
    "body":"atom(${1:Term})$2\n$0",
    "description":"[ISO]atom(@Term).\nTrue if Term is bound to an atom.",
    "prefix":"atom"
  },
  "atom_chars/2": {
    "body":"atom_chars(${1:Atom}, ${2:CharList})$3\n$0",
    "description":"[ISO]atom_chars(?Atom, ?CharList).\nAs atom_codes/2,  but CharList is a list of one-character atoms rather than a  list of character codes.94Up to  version 3.2.x, atom_chars/2  behaved as the current atom_codes/2.  The current definition is compliant with the ISO standard.  \n\n?- atom_chars(hello, X).\n\nX = [h, e, l, l, o]\n\n ",
    "prefix":"atom_chars"
  },
  "atom_codes/2": {
    "body":"atom_codes(${1:Atom}, ${2:String})$3\n$0",
    "description":"[ISO]atom_codes(?Atom, ?String).\nConvert between an atom and a list of character codes. If Atom is instantiated, it will be translated into a list of  character codes and the result is unified with String. If Atom  is unbound and String is a list of character codes, Atom will be unified with an atom constructed from this list.",
    "prefix":"atom_codes"
  },
  "atom_concat/3": {
    "body":"atom_concat(${1:Atom1}, ${2:Atom2}, ${3:Atom3})$4\n$0",
    "description":"[ISO]atom_concat(?Atom1, ?Atom2, ?Atom3).\nAtom3 forms the concatenation of Atom1 and Atom2.  At least two of the arguments must be instantiated to atoms. This  predicate also allows for the mode (-,-,+), non-deterministically  splitting the 3rd argument into two parts (as append/3  does for lists). SWI-Prolog allows for atomic arguments. Portable code  must use atomic_concat/3  if non-atom arguments are involved.",
    "prefix":"atom_concat"
  },
  "atom_length/2": {
    "body":"atom_length(${1:Atom}, ${2:Length})$3\n$0",
    "description":"[ISO]atom_length(+Atom, -Length).\nTrue if Atom is an atom of Length characters. The  SWI-Prolog version accepts all atomic types, as well as code-lists and  character-lists. New code should avoid this feature and use write_length/3  to get the number of characters that would be written if the argument  was handed to write_term/3.",
    "prefix":"atom_length"
  },
  "atom_number/2": {
    "body":"atom_number(${1:Atom}, ${2:Number})$3\n$0",
    "description":"atom_number(?Atom, ?Number).\nRealises the popular combination of atom_codes/2  and number_codes/2  to convert between atom and number (integer or float) in one predicate,  avoiding the intermediate list. Unlike the ISO number_codes/2  predicates, atom_number/2  fails silently in mode (+,-) if Atom does not represent a  number.97Versions prior to 6.1.7  raise a syntax error, compliant to number_codes/2  See also atomic_list_concat/2  for assembling an atom from atoms and numbers.",
    "prefix":"atom_number"
  },
  "atom_prefix/2": {
    "body":"atom_prefix(${1:Atom}, ${2:Prefix})$3\n$0",
    "description":"[deprecated]atom_prefix(+Atom, +Prefix).\nTrue if Atom starts with the characters from Prefix.  Its behaviour is equivalent to ?- sub_atom(Atom, 0, _, _, Prefix).  Deprecated.",
    "prefix":"atom_prefix"
  },
  "atom_string/2": {
    "body":"atom_string(${1:Atom}, ${2:String})$3\n$0",
    "description":"atom_string(?Atom, ?String).\nBi-directional conversion between an atom and a string. At least one of  the two arguments must be instantiated. Atom can also be an  integer or floating point number.",
    "prefix":"atom_string"
  },
  "atom_to_stem_list/2": {
    "body":"atom_to_stem_list(${1:In}, ${2:ListOfStems})$3\n$0",
    "description":"atom_to_stem_list(+In, -ListOfStems).\nCombines the three above routines, returning a list holding an atom with  the stem of each word encountered and numbers for encountered numbers.",
    "prefix":"atom_to_stem_list"
  },
  "atom_to_term/3": {
    "body":"atom_to_term(${1:Atom}, ${2:Term}, ${3:Bindings})$4\n$0",
    "description":"[deprecated]atom_to_term(+Atom, -Term, -Bindings).\nUse Atom as input to read_term/2  using the option variable_names and return the read term in Term  and the variable bindings in Bindings. Bindings is  a list of Name = Var couples, thus providing  access to the actual variable names. See also read_term/2.  If Atom has no valid syntax, a syntax_error  exception is raised. New code should use read_term_from_atom/3.",
    "prefix":"atom_to_term"
  },
  "atomic/1": {
    "body":"atomic(${1:Term})$2\n$0",
    "description":"[ISO]atomic(@Term).\nTrue if Term is bound (i.e., not a variable) and is not  compound. Thus, atomic acts as if defined by:  \n\natomic(Term) :-\n        nonvar(Term),\n        \\+ compound(Term).\n\n  SWI-Prolog defines the following atomic datatypes: atom (atom/1),  string (string/1),  integer (integer/1),  floating point number (float/1)  and blob (blob/2).  In addition, the symbol [] (empty list) is atomic, but not  an atom. See section 5.1.\n\n",
    "prefix":"atomic"
  },
  "atomic_concat/3": {
    "body":"atomic_concat(${1:Atomic1}, ${2:Atomic2}, ${3:Atom})$4\n$0",
    "description":"atomic_concat(+Atomic1, +Atomic2, -Atom).\nAtom represents the text after converting Atomic1  and Atomic2 to text and concatenating the result:  \n\n?- atomic_concat(name, 42, X).\nX = name42.\n\n ",
    "prefix":"atomic_concat"
  },
  "atomic_list_concat/2": {
    "body":"atomic_list_concat(${1:List}, ${2:Atom})$3\n$0",
    "description":"[commons]atomic_list_concat(+List, -Atom).\nList is a list of strings, atoms, integers or floating point  numbers. Succeeds if Atom can be unified with the  concatenated elements of List. Equivalent to atomic_list_concat(List,  '', Atom).",
    "prefix":"atomic_list_concat"
  },
  "atomic_list_concat/3": {
    "body":"atomic_list_concat(${1:List}, ${2:Separator}, ${3:Atom})$4\n$0",
    "description":"[commons]atomic_list_concat(+List, +Separator, -Atom).\nCreates an atom just like atomic_list_concat/2,  but inserts Separator between each pair of inputs. For  example:  \n\n?- atomic_list_concat([gnu, gnat], ', ', A).\n\nA = 'gnu, gnat'\n\n  The SWI-Prolog version of this predicate can also be used to split  atoms by instantiating Separator and Atom as shown  below. We kept this functionality to simplify porting old SWI-Prolog  code where this predicate was called concat_atom/3.  When used in mode (-,+,+), Separator must be a non-empty atom. See also split_string/4. \n\n\n\n?- atomic_list_concat(L, -, 'gnu-gnat').\n\nL = [gnu, gnat]\n\n ",
    "prefix":"atomic_list_concat"
  },
  "atomics_to_string/2": {
    "body":"atomics_to_string(${1:List}, ${2:String})$3\n$0",
    "description":"atomics_to_string(+List, -String).\nList is a list of strings, atoms, integers or floating point  numbers. Succeeds if String can be unified with the  concatenated elements of List. Equivalent to atomics_to_string(List,  '', String).",
    "prefix":"atomics_to_string"
  },
  "atomics_to_string/3": {
    "body":"atomics_to_string(${1:List}, ${2:Separator}, ${3:String})$4\n$0",
    "description":"atomics_to_string(+List, +Separator, -String).\nCreates a string just like atomics_to_string/2,  but inserts Separator between each pair of inputs. For example:  \n\n?- atomics_to_string([gnu, \"gnat\", 1], ', ', A).\n\nA = \"gnu, gnat, 1\"\n\n ",
    "prefix":"atomics_to_string"
  },
  "attr_portray_hook/2": {
    "body":"attr_portray_hook(${1:AttValue}, ${2:Var})$3\n$0",
    "description":"[deprecated]attr_portray_hook(+AttValue, +Var).\nCalled by write_term/2  and friends for each attribute if the option attributes(portray) is in effect. If the hook succeeds the  attribute is considered printed. Otherwise Module = ... is  printed to indicate the existence of a variable. This predicate is  deprecated because it cannot work with pure interface predicates like copy_term/3.  Use attribute_goals/3  instead to map attributes to residual goals.",
    "prefix":"attr_portray_hook"
  },
  "attr_unify_hook/2": {
    "body":"attr_unify_hook(${1:AttValue}, ${2:VarValue})$3\n$0",
    "description":"attr_unify_hook(+AttValue, +VarValue).\nA hook that must be defined in the module to which an attributed  variable refers. It is called after the attributed variable has  been unified with a non-var term, possibly another attributed variable. AttValue is the attribute that was associated to the variable  in this module and VarValue is the new value of the variable.  If this predicate fails, the unification fails. If VarValue  is another attributed variable the hook often combines the two  attributes and associates the combined attribute with VarValue  using put_attr/3.  To be done: The way in which this hook currently works makes the implementation of  important classes of constraint solvers impossible or at least extremely  impractical. For increased generality and convenience, simultaneous  unifications as in [X,Y]=[0,1] should be processed  sequentially by the Prolog engine, or a more general hook should be  provided in the future. See Triska,  2016 for more information.\n\n ",
    "prefix":"attr_unify_hook"
  },
  "attribute_goals/1": {
    "body":"attribute_goals(${1:Var})$2\n$0",
    "description":"attribute_goals(+Var)//.\nThis nonterminal is the main mechanism in which residual constraints are  obtained. It is called in every module where it is defined, and Var has an attribute. Its argument is that variable. In each  module, attribute_goals/3  must describe a list of Prolog goals that are declaratively equivalent  to the goals that caused the attributes of that module to be present and  in their current state. It is always possible to do this (since these  attributes stem from such goals), and it is the responsibility of  constraint library authors to provide this mapping without exposing any  library internals. Ideally and typically, remaining relevant attributes  are mapped to pure and potentially simplified Prolog goals that  satisfy both of the following:  \n\nThey are declaratively equivalent to the constraints that were  originally posted.  \nThey use only predicates that are themselves exported and documented  in the modules they stem from.\n\n  The latter property ensures that users can reason about residual  goals, and see for themselves whether a constraint library behaves  correctly. It is this property that makes it possible to thoroughly test  constraint solvers by contrasting obtained residual goals with expected  answers. \n\nThis nonterminal is used by copy_term/3,  on which the Prolog top level relies to ensure the basic invariant of  pure Prolog programs: The answer is declaratively equivalent to  the query. \n\nNote that instead of defaulty representations, a Prolog list is used to represent residual goals. This simplifies  processing and reasoning about residual goals throughout all programs  that need this functionality.\n\n",
    "prefix":"attribute_goals"
  },
  "attvar/1": {
    "body":"attvar(${1:Term})$2\n$0",
    "description":"attvar(@Term).\nSucceeds if Term is an attributed variable. Note that var/1  also succeeds on attributed variables. Attributed variables are created  with put_attr/3.",
    "prefix":"attvar"
  },
  "autoload/0": {
    "body":"autoload$1\n$0",
    "description":"autoload.\nCheck the current Prolog program for predicates that are referred to,  are undefined and have a definition in the Prolog library. Load the  appropriate libraries.  This predicate is used by qsave_program/[1,2]  to ensure the saved state does not depend on availability of the  libraries. The predicate autoload/0  examines all clauses of the loaded program (obtained with clause/2)  and analyzes the body for referenced goals. Such an analysis cannot be  complete in Prolog, which allows for the creation of arbitrary terms at  runtime and the use of them as a goal. The current analysis is limited  to the following: \n\n\n\nDirect goals appearing in the body\nArguments of declared meta-predicates that are marked with an  integer (0..9). See meta_predicate/1.\n\n  The analysis of meta-predicate arguments is limited to cases where  the argument appears literally in the clause or is assigned using =/2  before the meta-call. That is, the following fragment is processed  correctly: \n\n\n\n        ...,\n        Goal = prove(Theory),\n        forall(current_theory(Theory),\n               Goal)),\n\n  But, the calls to prove_simple/1 and prove_complex/1 in the example  below are not discovered by the analysis and therefore the  modules that define these predicates must be loaded explicitly using use_module/1,2. \n\n\n\n        ...,\n        member(Goal, [ prove_simple(Theory),\n                       prove_complex(Theory)\n                     ]),\n        forall(current_theory(Theory),\n               Goal)),\n\n  It is good practice to use gxref/0  to make sure that the program has sufficient declarations such that the  analaysis tools can verify that all required predicates can be resolved  and that all code is called. See meta_predicate/1, dynamic/1, public/1  and prolog:called_by/2.\n\n",
    "prefix":"autoload"
  },
  "autoload_path/1": {
    "body":"autoload_path(${1:DirAlias})$2\n$0",
    "description":"autoload_path(+DirAlias).\nAdd DirAlias to the libraries that are used by the  autoloader. This extends the search path autoload and  reloads the library index. For example:  \n\n:- autoload_path(library(http)).\n\n  If this call appears as a directive, it is term-expanded into a  clause for user:file_search_path/2 and a directive calling reload_library_index/0.  This keeps source information and allows for removing this directive.\n\n",
    "prefix":"autoload_path"
  },
  "b_getval/2": {
    "body":"b_getval(${1:Name}, ${2:Value})$3\n$0",
    "description":"b_getval(+Name, -Value).\nGet the value associated with the global variable Name and  unify it with Value. Note that this unification may further  instantiate the value of the global variable. If this is undesirable the  normal precautions (double negation or copy_term/2)  must be taken. The b_getval/2  predicate generates errors if Name is not an atom or the  requested variable does not exist.",
    "prefix":"b_getval"
  },
  "b_set_dict/3": {
    "body":"b_set_dict(${1:Key}, ${2:Dict}, ${3:Value})$4\n$0",
    "description":"[det]b_set_dict(+Key, !Dict, +Value).\nDestructively update the value associated with Key in Dict  to Value. The update is trailed and undone on backtracking. This  predicate raises an existence error if Key does not appear in Dict. The update semantics are equivalent to setarg/3  and b_setval/2.",
    "prefix":"b_set_dict"
  },
  "b_setval/2": {
    "body":"b_setval(${1:Name}, ${2:Value})$3\n$0",
    "description":"b_setval(+Name, +Value).\nAssociate the term Value with the atom Name or  replace the currently associated value with Value. If Name  does not refer to an existing global variable, a variable with initial  value [] is created (the empty list). On backtracking the  assignment is reversed.",
    "prefix":"b_setval"
  },
  "backward_compatibility:'$apropos_match'/2": {
    "body": ["\\$apropos_match(${1:Needle}, ${2:Haystack})$3\n$0" ],
    "description":"  '$apropos_match'(+Needle, +Haystack) is semidet.\n\n   True if Needle is a sub atom of Haystack.  Ignores the case\n   of Haystack.",
    "prefix":"$apropos_match"
  },
  "backward_compatibility:'$arch'/2": {
    "body": ["\\$arch(${1:Architecture}, ${2:Version})$3\n$0" ],
    "description":"  '$arch'(-Architecture, -Version) is det.\n\n   @deprecated use current_prolog_flag(arch, Architecture)",
    "prefix":"$arch"
  },
  "backward_compatibility:'$argv'/1": {
    "body": ["\\$argv(${1:Argv})$2\n$0" ],
    "description":"  '$argv'(-Argv:list) is det.\n\n   @deprecated use current_prolog_flag(os_argv, Argv) or\n   current_prolog_flag(argv, Argv)",
    "prefix":"$argv"
  },
  "backward_compatibility:'$declare_module'/3": {
    "body": ["\\$declare_module(${1:Module}, ${2:File}, ${3:Line})$4\n$0" ],
    "description":"  '$declare_module'(Module, File, Line)\n\n   Used in triple20 particle library. Should use a public interface",
    "prefix":"$declare_module"
  },
  "backward_compatibility:'$home'/1": {
    "body": ["\\$home(${1:SWIPrologDir})$2\n$0" ],
    "description":"  '$home'(-SWIPrologDir) is det.\n\n   @deprecated use current_prolog_flag(home, SWIPrologDir)\n   @see file_search_path/2, absolute_file_name/3,  The Prolog home\n        directory is available through the alias =swi=.",
    "prefix":"$home"
  },
  "backward_compatibility:'$module'/2": {
    "body": ["\\$module(${1:OldTypeIn}, ${2:NewTypeIn})$3\n$0" ],
    "description":"  '$module'(-OldTypeIn, +NewTypeIn)",
    "prefix":"$module"
  },
  "backward_compatibility:'$set_prompt'/1": {
    "body": ["\\$set_prompt(${1:Prompt})$2\n$0" ],
    "description":"  '$set_prompt'(+Prompt) is det.\n\n   Set the prompt for the toplevel\n\n   @deprecated use set_prolog_flag(toplevel_prompt, Prompt).",
    "prefix":"$set_prompt"
  },
  "backward_compatibility:'$strip_module'/3": {
    "body": ["\\$strip_module(${1:Term}, ${2:Module}, ${3:Plain})$4\n$0" ],
    "description":"  '$strip_module'(+Term, -Module, -Plain)\n\n   This used to be an internal predicate.  It was added to the XPCE\n   compatibility library without $ and  since   then  used  at many\n   places. From 5.4.1 onwards strip_module/3 is  built-in and the $\n   variation is added here for compatibility.\n\n   @deprecated Use strip_module/3.",
    "prefix":"$strip_module"
  },
  "backward_compatibility:'$version'/1": {
    "body": ["\\$version(${1:Version})$2\n$0" ],
    "description":"  '$version'(Version:integer) is det.\n\n   @deprecated use current_prolog_flag(version, Version)",
    "prefix":"$version"
  },
  "backward_compatibility:'C'/3": {
    "body": ["C(${1:List}, ${2:Head}, ${3:Tail})$4\n$0" ],
    "description":"  'C'(?List, ?Head, ?Tail) is det.\n\n   Used to be generated by DCG.  Some people appear to be using in\n   in normal code too.\n\n   @deprecated Do not use in normal code; DCG no longer generates it.",
    "prefix":"C"
  },
  "backward_compatibility:at_initialization/1": {
    "body": ["at_initialization(${1:Goal})$2\n$0" ],
    "description":"  at_initialization(:Goal) is det.\n\n   Register goal only to be run if a saved state is restored.\n\n   @deprecated Use initialization(Goal, restore)",
    "prefix":"at_initialization"
  },
  "backward_compatibility:checklist/2": {
    "body": ["checklist(${1:Goal}, ${2:List})$3\n$0" ],
    "description":"  checklist(:Goal, +List)\n\n   @deprecated Use maplist/2",
    "prefix":"checklist"
  },
  "backward_compatibility:concat/3": {
    "body": ["concat(${1:Atom1}, ${2:Atom2}, ${3:Atom})$4\n$0" ],
    "description":"  concat(+Atom1, +Atom2, -Atom) is det.\n\n   @deprecated Use ISO atom_concat/3",
    "prefix":"concat"
  },
  "backward_compatibility:concat_atom/2": {
    "body": ["concat_atom(${1:List}, ${2:Atom})$3\n$0" ],
    "description":"  concat_atom(+List, -Atom) is det.\n\n   Concatenate a list of atomic values to an atom.\n\n   @deprecated Use atomic_list_concat/2 as proposed by the prolog\n               commons initiative.",
    "prefix":"concat_atom"
  },
  "backward_compatibility:concat_atom/3": {
    "body": ["concat_atom(${1:List}, ${2:Seperator}, ${3:Atom})$4\n$0" ],
    "description":"  concat_atom(+List, +Seperator, -Atom) is det.\n\n   Concatenate a list of atomic values to an atom, inserting Seperator\n   between each consecutive elements.\n\n   @deprecated Use atomic_list_concat/3 as proposed by the prolog\n               commons initiative.",
    "prefix":"concat_atom"
  },
  "backward_compatibility:convert_time/2": {
    "body": ["convert_time(${1:Stamp}, ${2:String})$3\n$0" ],
    "description":"  convert_time(+Stamp, -String)\n\n   Convert  a time-stamp as  obtained though get_time/1 into a  textual\n   representation  using the C-library function ctime().  The  value is\n   returned  as a  SWI-Prolog string object  (see section  4.23).   See\n   also convert_time/8.\n\n   @deprecated Use format_time/3.",
    "prefix":"convert_time"
  },
  "backward_compatibility:convert_time/8": {
    "body": [
      "convert_time(${1:Stamp}, ${2:Y}, ${3:Mon}, ${4:Day}, ${5:Hour}, ${6:Min}, ${7:Sec}, ${8:MilliSec})$9\n$0"
    ],
    "description":"  convert_time(+Stamp, -Y, -Mon, -Day, -Hour, -Min, -Sec, -MilliSec)\n\n   Convert   a  time  stamp,   provided  by   get_time/1,   time_file/2,\n   etc.   Year is  unified with the year,  Month with the month  number\n   (January  is 1), Day  with the day of  the month (starting with  1),\n   Hour  with  the hour  of the  day (0--23),  Minute  with the  minute\n   (0--59).   Second with the  second (0--59) and MilliSecond with  the\n   milliseconds  (0--999).  Note that the latter might not  be accurate\n   or  might always be 0, depending  on the timing capabilities of  the\n   system.  See also convert_time/2.\n\n   @deprecated Use stamp_date_time/3.",
    "prefix":"convert_time"
  },
  "backward_compatibility:current_module/2": {
    "body": ["current_module(${1:Module}, ${2:File})$3\n$0" ],
    "description":"  current_module(?Module, ?File) is nondet.\n\n   True if Module is a module loaded from File.\n\n   @deprecated Use module_property(Module, file(File))",
    "prefix":"current_module"
  },
  "backward_compatibility:current_mutex/3": {
    "body": ["current_mutex(${1:Mutex}, ${2:Owner}, ${3:Count})$4\n$0" ],
    "description":"  current_mutex(?Mutex, ?Owner, ?Count) is nondet.\n\n   @deprecated Replaced by mutex_property/2",
    "prefix":"current_mutex"
  },
  "backward_compatibility:current_thread/2": {
    "body": ["current_thread(${1:Thread}, ${2:Status})$3\n$0" ],
    "description":"  current_thread(?Thread, ?Status) is nondet.\n\n   @deprecated Replaced by thread_property/2",
    "prefix":"current_thread"
  },
  "backward_compatibility:displayq/1": {
    "body": ["displayq(${1:Term})$2\n$0" ],
    "description":"  displayq(@Term) is det.\n  displayq(+Stream, @Term) is det.\n\n   Write term ignoring operators and quote atoms.\n\n   @deprecated Use write_term/3 or write_canonical/2.",
    "prefix":"displayq"
  },
  "backward_compatibility:displayq/2": {
    "body": ["displayq(${1:Stream}, ${2:Term})$3\n$0" ],
    "description":"  displayq(@Term) is det.\n  displayq(+Stream, @Term) is det.\n\n   Write term ignoring operators and quote atoms.\n\n   @deprecated Use write_term/3 or write_canonical/2.",
    "prefix":"displayq"
  },
  "backward_compatibility:eval_license/0": {
    "body": ["eval_license$1\n$0" ],
    "description":"  eval_license is det.\n\n   @deprecated Equivalent to license/0",
    "prefix":"eval_license"
  },
  "backward_compatibility:export_list/2": {
    "body": ["export_list(${1:Module}, ${2:List})$3\n$0" ],
    "description":"  export_list(+Module, -List) is det.\n\n   Module exports the predicates of List.\n\n   @deprecated Use module_property(Module, exports(List))",
    "prefix":"export_list"
  },
  "backward_compatibility:feature/2": {
    "body": ["feature(${1:Key}, ${2:Value})$3\n$0" ],
    "description":"  feature(?Key, ?Value) is nondet.\n  set_feature(+Key, @Term) is det.\n\n   Control Prolog flags.\n\n   @deprecated Use ISO current_prolog_flag/2 and set_prolog_flag/2.",
    "prefix":"feature"
  },
  "backward_compatibility:flush/0": {
    "body": ["flush$1\n$0" ],
    "description":"  flush is det.\n\n   @deprecated use ISO flush_output/0.",
    "prefix":"flush"
  },
  "backward_compatibility:free_variables/2": {
    "body": ["free_variables(${1:Term}, ${2:Variables})$3\n$0" ],
    "description":"  free_variables(+Term, -Variables)\n\n   Return  a  list  of  unbound  variables    in   Term.  The  name\n   term_variables/2 is more widely used.\n\n   @deprecated Use term_variables/2.",
    "prefix":"free_variables"
  },
  "backward_compatibility:hash/1": {
    "body": ["hash(${1:PredInd})$2\n$0" ],
    "description":"  hash(:PredInd) is det.\n\n   Demands PredInd to be  indexed  using   a  hash-table.  This  is\n   handled dynamically.",
    "prefix":"hash"
  },
  "backward_compatibility:hash_term/2": {
    "body": ["hash_term(${1:Term}, ${2:Hash})$3\n$0" ],
    "description":"  hash_term(+Term, -Hash) is det.\n\n   If Term is ground, Hash is unified to an integer representing\n   a hash for Term.  Otherwise Hash is left unbound.\n\n   @deprecated Use term_hash/2.",
    "prefix":"hash_term"
  },
  "backward_compatibility:index/1": {
    "body": ["index(${1:Head})$2\n$0" ],
    "description":"  index(:Head) is det.\n\n   Prepare the predicate  indicated  by   Head  for  multi-argument\n   indexing.\n\n   @deprecated     As of version 5.11.29, SWI-Prolog performs\n                   just-in-time indexing on all arguments.",
    "prefix":"index"
  },
  "backward_compatibility:lock_predicate/2": {
    "body": ["lock_predicate(${1:Name}, ${2:Arity})$3\n$0" ],
    "description":"  lock_predicate(+Name, +Arity) is det.\n  unlock_predicate(+Name, +Arity) is det.\n\n   @deprecated see lock_predicate/1 and unlock_predicate/1.",
    "prefix":"lock_predicate"
  },
  "backward_compatibility:merge/3": {
    "body": ["merge(${1:List1}, ${2:List2}, ${3:List3})$4\n$0" ],
    "description":"  merge(+List1, +List2, -List3)\n\n   Merge the ordered sets List1 and List2 into a new ordered  list.\n   Duplicates are not removed and their order is maintained.\n\n   @deprecated     The name of this predicate is far too general for\n                   a rather specific function.",
    "prefix":"merge"
  },
  "backward_compatibility:merge_set/3": {
    "body": ["merge_set(${1:Set1}, ${2:Set2}, ${3:Set3})$4\n$0" ],
    "description":"  merge_set(+Set1, +Set2, -Set3)\n\n   Merge the ordered sets Set1 and  Set2   into  a  new ordered set\n   without duplicates.\n\n   @deprecated     New code should use ord_union/3 from\n                   library(ordsets)",
    "prefix":"merge_set"
  },
  "backward_compatibility:message_queue_size/2": {
    "body": ["message_queue_size(${1:Queue}, ${2:Size})$3\n$0" ],
    "description":"  message_queue_size(+Queue, -Size) is det.\n\n   True if Queue holds Size terms.\n\n   @deprecated Please use message_queue_property(Queue, Size)",
    "prefix":"message_queue_size"
  },
  "backward_compatibility:proper_list/1": {
    "body": ["proper_list(${1:List})$2\n$0" ],
    "description":"  proper_list(+List)\n\n   Old SWI-Prolog predicate to check for a list that really ends\n   in a [].  There is not much use for the quick is_list, as in\n   most cases you want to process the list element-by-element anyway.\n\n   @deprecated Use ISO is_list/1.",
    "prefix":"proper_list"
  },
  "backward_compatibility:read_clause/1": {
    "body": ["read_clause(${1:Term})$2\n$0" ],
    "description":"  read_clause(-Term) is det.\n\n   @deprecated Use read_clause/3 or read_term/3.",
    "prefix":"read_clause"
  },
  "backward_compatibility:read_clause/2": {
    "body": ["read_clause(${1:Stream}, ${2:Term})$3\n$0" ],
    "description":"  read_clause(+Stream, -Term) is det.\n\n   @deprecated Use read_clause/3 or read_term/3.",
    "prefix":"read_clause"
  },
  "backward_compatibility:read_pending_input/3": {
    "body": ["read_pending_input(${1:Stream}, ${2:Codes}, ${3:Tail})$4\n$0" ],
    "description":"  read_pending_input(+Stream, -Codes, ?Tail) is det.\n\n   @deprecated Use read_pending_codes/3.",
    "prefix":"read_pending_input"
  },
  "backward_compatibility:read_variables/2": {
    "body": ["read_variables(${1:Term}, ${2:Bindings})$3\n$0" ],
    "description":"  read_variables(-Term, -Bindings) is det.\n  read_variables(+In:stream, -Term, -Bindings) is det.\n\n   @deprecated Use ISO read_term/2 or read_term/3.",
    "prefix":"read_variables"
  },
  "backward_compatibility:read_variables/3": {
    "body": ["read_variables(${1:In}, ${2:Term}, ${3:Bindings})$4\n$0" ],
    "description":"  read_variables(-Term, -Bindings) is det.\n  read_variables(+In:stream, -Term, -Bindings) is det.\n\n   @deprecated Use ISO read_term/2 or read_term/3.",
    "prefix":"read_variables"
  },
  "backward_compatibility:set_base_module/1": {
    "body": ["set_base_module(${1:Base})$2\n$0" ],
    "description":"  set_base_module(:Base) is det.\n\n   Set the default module from whic we inherit.\n\n   @deprecated Equivalent to set_module(base(Base)).",
    "prefix":"set_base_module"
  },
  "backward_compatibility:set_feature/2": {
    "body": ["set_feature(${1:Key}, ${2:Value})$3\n$0" ],
    "description":"  feature(?Key, ?Value) is nondet.\n  set_feature(+Key, @Term) is det.\n\n   Control Prolog flags.\n\n   @deprecated Use ISO current_prolog_flag/2 and set_prolog_flag/2.",
    "prefix":"set_feature"
  },
  "backward_compatibility:setup_and_call_cleanup/3": {
    "body": ["setup_and_call_cleanup(${1:Setup}, ${2:Goal}, ${3:Cleanup})$4\n$0" ],
    "description":"  setup_and_call_cleanup(:Setup, :Goal, :Cleanup).\n\n   Call Cleanup once after Goal is finished.\n\n   @deprecated Use setup_call_cleanup/3.",
    "prefix":"setup_and_call_cleanup"
  },
  "backward_compatibility:setup_and_call_cleanup/4": {
    "body": [
      "setup_and_call_cleanup(${1:Setup}, ${2:Goal}, ${3:Catcher}, ${4:Cleanup})$5\n$0"
    ],
    "description":"  setup_and_call_cleanup(:Setup, :Goal, Catcher, :Cleanup).\n\n   Call Cleanup once after Goal is finished, with Catcher\n   unified to the reason\n\n   @deprecated Use setup_call_cleanup/3.",
    "prefix":"setup_and_call_cleanup"
  },
  "backward_compatibility:sformat/2": {
    "body": ["sformat(${1:String}, ${2:Format})$3\n$0" ],
    "description":"  sformat(-String, +Format, +Args) is det.\n  sformat(-String, +Format) is det.\n\n   @deprecated Use format/3 as =|format(string(String), ...)|=",
    "prefix":"sformat"
  },
  "backward_compatibility:sformat/3": {
    "body": ["sformat(${1:String}, ${2:Format}, ${3:Args})$4\n$0" ],
    "description":"  sformat(-String, +Format, +Args) is det.\n  sformat(-String, +Format) is det.\n\n   @deprecated Use format/3 as =|format(string(String), ...)|=",
    "prefix":"sformat"
  },
  "backward_compatibility:string_to_atom/2": {
    "body": ["string_to_atom(${1:String}, ${2:Atom})$3\n$0" ],
    "description":"  string_to_atom(?String, ?Atom) is det.\n\n   Bi-directional conversion between string and atom.\n\n   @deprecated     Use atom_string/2. Note that the order of the\n                   arguments is reversed.",
    "prefix":"string_to_atom"
  },
  "backward_compatibility:string_to_list/2": {
    "body": ["string_to_list(${1:String}, ${2:Codes})$3\n$0" ],
    "description":"  string_to_list(?String, ?Codes) is det.\n\n   Bi-directional conversion between a string and a list of\n   character codes.\n\n   @deprecated Use string_codes/2.",
    "prefix":"string_to_list"
  },
  "backward_compatibility:sublist/3": {
    "body": ["sublist(${1:Goal}, ${2:List1}, ${3:List2})$4\n$0" ],
    "description":"  sublist(:Goal, +List1, ?List2)\n\n   Succeeds if List2 unifies with a list holding those terms for wich\n   call(Goal, Elem) succeeds.\n\n   @deprecated Use include/3 from library(apply)\n   @compat DEC10 library",
    "prefix":"sublist"
  },
  "backward_compatibility:substring/4": {
    "body": ["substring(${1:String}, ${2:Offset}, ${3:Length}, ${4:Sub})$5\n$0" ],
    "description":"  substring(+String, +Offset, +Length, -Sub)\n\n   Predecessor of sub_string using 1-based Offset.\n\n   @deprecated Use sub_string/5.",
    "prefix":"substring"
  },
  "backward_compatibility:subsumes/2": {
    "body": ["subsumes(${1:Generic}, ${2:Specific})$3\n$0" ],
    "description":"  subsumes(+Generic, @Specific)\n\n   True  if  Generic  is  unified   to  Specific  without  changing\n   Specific.\n\n   @deprecated It turns out that calls to this predicate almost\n   always should have used subsumes_term/2.  Also the name is\n   misleading.  In case this is really needed, one is adviced to\n   follow subsumes_term/2 with an explicit unification.",
    "prefix":"subsumes"
  },
  "backward_compatibility:subsumes_chk/2": {
    "body": ["subsumes_chk(${1:Generic}, ${2:Specific})$3\n$0" ],
    "description":"  subsumes_chk(@Generic, @Specific)\n\n   True if Generic can be made equivalent to Specific without\n   changing Specific.\n\n   @deprecated Replace by subsumes_term/2.",
    "prefix":"subsumes_chk"
  },
  "backward_compatibility:sumlist/2": {
    "body": ["sumlist(${1:List}, ${2:Sum})$3\n$0" ],
    "description":"  sumlist(+List, -Sum) is det.\n\n   True when Sum is the list of all numbers in List.\n\n   @deprecated Use sum_list/2",
    "prefix":"sumlist"
  },
  "backward_compatibility:unlock_predicate/2": {
    "body": ["unlock_predicate(${1:Name}, ${2:Arity})$3\n$0" ],
    "description":"  lock_predicate(+Name, +Arity) is det.\n  unlock_predicate(+Name, +Arity) is det.\n\n   @deprecated see lock_predicate/1 and unlock_predicate/1.",
    "prefix":"unlock_predicate"
  },
  "backward_compatibility:write_ln/1": {
    "body": ["write_ln(${1:X})$2\n$0" ],
    "description":"  write_ln(X) is det\n\n   @deprecated Use writeln(X).",
    "prefix":"write_ln"
  },
  "bagof/3": {
    "body":"bagof(${1:Template}, ${2:Goal}, ${3:Bag})$4\n$0",
    "description":"[ISO]bagof(+Template, :Goal, -Bag).\nUnify Bag with the alternatives of Template. If Goal  has free variables besides the one sharing with Template, bagof/3  will backtrack over the alternatives of these free variables, unifying Bag with the corresponding alternatives of Template.  The construct +Var^Goal  tells bagof/3  not to bind Var in Goal. bagof/3  fails if Goal has no solutions.  The example below illustrates bagof/3  and the ^ operator. The variable bindings  are printed together on one line to save paper. \n\n\n\n2 ?- listing(foo).\nfoo(a, b, c).\nfoo(a, b, d).\nfoo(b, c, e).\nfoo(b, c, f).\nfoo(c, c, g).\ntrue.\n\n3 ?- bagof(C, foo(A, B, C), Cs).\nA = a, B = b, C = G308, Cs = [c, d] ;\nA = b, B = c, C = G308, Cs = [e, f] ;\nA = c, B = c, C = G308, Cs = [g].\n\n4 ?- bagof(C, A^foo(A, B, C), Cs).\nA = G324, B = b, C = G326, Cs = [c, d] ;\nA = G324, B = c, C = G326, Cs = [e, f, g].\n\n5 ?-\n\n ",
    "prefix":"bagof"
  },
  "base32:base32/2": {
    "body": ["base32(${1:Plain}, ${2:Encoded})$3\n$0" ],
    "description":"  base32(+Plain, -Encoded) is det.\n  base32(-Plain, +Encoded) is det.\n\n   Translates between plaintext and base32  encoded atom or string.\n   See also base32//1.",
    "prefix":"base32"
  },
  "base32:base32/3": {
    "body": ["base32(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"base32('Param1','Param2','Param3')",
    "prefix":"base32"
  },
  "base64:base64/2": {
    "body": ["base64(${1:Plain}, ${2:Encoded})$3\n$0" ],
    "description":"  base64(+Plain, -Encoded) is det.\n  base64(-Plain, +Encoded) is det.\n\n   Translates between plaintext and base64  encoded atom or string.\n   See also base64//1.",
    "prefix":"base64"
  },
  "base64:base64/3": {
    "body": ["base64(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"base64('Param1','Param2','Param3')",
    "prefix":"base64"
  },
  "base64:base64url/2": {
    "body": ["base64url(${1:Plain}, ${2:Encoded})$3\n$0" ],
    "description":"  base64url(+Plain, -Encoded) is det.\n  base64url(-Plain, +Encoded) is det.\n\n   Translates between plaintext  and  base64url   encoded  atom  or\n   string. Base64URL encoded values can safely  be used as URLs and\n   file names. The use \"-\" instead of   \"+\", \"_\" instead of \"/\" and\n   do not use padding. This implies   that the encoded value cannot\n   be embedded inside a longer string.",
    "prefix":"base64url"
  },
  "base64:base64url/3": {
    "body": ["base64url(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"base64url('Param1','Param2','Param3')",
    "prefix":"base64url"
  },
  "bdb:bdb_close/1": {
    "body":"bdb_close(${1:DB})$2\n$0",
    "description":"[det]bdb_close(+DB).\nClose BerkeleyDB database indicated by DB. DB  becomes invalid after this operation. An attempt to access a closed  database is detected reliably and results in a permission_error  exception.",
    "prefix":"bdb_close"
  },
  "bdb:bdb_close_environment/1": {
    "body":"bdb_close_environment(${1:Environment})$2\n$0",
    "description":"[det]bdb_close_environment(+Environment).\nClose a database environment that was explicitly created using bdb_init/2.",
    "prefix":"bdb_close_environment"
  },
  "bdb:bdb_closeall/0": {
    "body": ["bdb_closeall$1\n$0" ],
    "description":"  bdb_closeall is det.\n\n   Close all currently open  databases   and  environments. This is\n   called automatically after  loading  this   library  on  process\n   terminatation using at_halt/1.",
    "prefix":"bdb_closeall"
  },
  "bdb:bdb_current/1": {
    "body":"bdb_current(${1:DB})$2\n$0",
    "description":"[nondet]bdb_current(?DB).\nTrue when DB is a handle to a currently open database.",
    "prefix":"bdb_current"
  },
  "bdb:bdb_current_environment/1": {
    "body":"bdb_current_environment(${1:Environment})$2\n$0",
    "description":"[nondet]bdb_current_environment(-Environment).\nTrue when Environment is a currently known environment.",
    "prefix":"bdb_current_environment"
  },
  "bdb:bdb_del/3": {
    "body":"bdb_del(${1:DB}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"[nondet]bdb_del(+DB, ?Key, ?Value).\nDelete the first matching key-value pair from the database. If the  database allows for duplicates, this predicate is non-deterministic,  otherwise it is semidet. The enumeration performed by this  predicate is the same as for bdb_get/3.  See also bdb_delall/3.",
    "prefix":"bdb_del"
  },
  "bdb:bdb_delall/3": {
    "body":"bdb_delall(${1:DB}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"[det]bdb_delall(+DB, +Key, ?Value).\nDelete all matching key-value pairs from the database. With unbound Value  the key and all values are removed efficiently.",
    "prefix":"bdb_delall"
  },
  "bdb:bdb_enum/3": {
    "body":"bdb_enum(${1:DB}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"bdb_enum(+DB, -Key, -Value).\nEnumerate the whole database, unifying the key-value pairs to Key and Value. Though this predicate can be used  with an instantiated Key to enumerate only the keys unifying  with Key, no indexing is used by bdb_enum/3.",
    "prefix":"bdb_enum"
  },
  "bdb:bdb_environment_property/2": {
    "body":"bdb_environment_property(${1:Environment}, ${2:Property})$3\n$0",
    "description":"[nondet]bdb_environment_property(?Environment, ?Property).\nTrue when Property is a property of Environment.  Defined properties are all boolean options defined with bdb_init/2  and the following options:  home(-Path): Path is the absolute path name for the directory used as  database environment.\n\nopen(-Boolean): True if the environment is open.\n\n ",
    "prefix":"bdb_environment_property"
  },
  "bdb:bdb_get/3": {
    "body":"bdb_get(${1:DB}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"[nondet]bdb_get(+DB, ?Key, -Value).\nQuery the database. If the database allows for duplicates this predicate  is non-deterministic, otherwise it is semidet. Note that if Key  is a term this matches stored keys that are variants of Key, not unification. See =@=/2.  Thus, after bdb_put(DB, f(X), 42), we get the following query results:  \n\nbdb_get(DB, f(Y), V) binds Value to 42,  while Y is left unbound.\nbdb_get(DB, f(a), V) fails.\nbdb_enum(DB, f(a), V) succeeds, but does not perform  any indexing, i.e., it enumerates all key-value pairs and performs the  unification.\n\n",
    "prefix":"bdb_get"
  },
  "bdb:bdb_getall/3": {
    "body":"bdb_getall(${1:DB}, ${2:Key}, ${3:Values})$4\n$0",
    "description":"[semidet]bdb_getall(+DB, +Key, -Values).\nGet all values associated with Key. Fails if the key does not  exist (as bagof/3).",
    "prefix":"bdb_getall"
  },
  "bdb:bdb_init/1": {
    "body":"bdb_init(${1:Options})$2\n$0",
    "description":"[det]bdb_init(+Options).\n",
    "prefix":"bdb_init"
  },
  "bdb:bdb_init/2": {
    "body":"bdb_init(${1:Environment}, ${2:Options})$3\n$0",
    "description":"[det]bdb_init(-Environment, +Options).\nInitialise a DB environment. The predicate bdb_init/1  initialises the default environment, while bdb_init/2  creates an explicit environment that can be passed to bdb_open/4  using the environment(+Environment) option. If bdb_init/1  is called, it must be called before the first call to bdb_open/4  that uses the default environment. If bdb_init/1  is not called, the default environment can only handle plain files and  does not support multiple threads, locking, crash recovery, etc.  Initializing a BDB environment always requires the home(+Dir)  option. If the environment contains no databases, the argument create(true) must be supplied as well. \n\nThe currently supported options are listed below. The name of the  boolean options are derived from the DB flags by dropping the =DB_=  prefix and using lowercase, e.g. DB_INIT_LOCK becomes init_lock.  For details, please refer to the DB manual. \n\ncreate(+Bool): If true, create any underlying file as required. By  default, no new files are created. This option should be set for  prograns that create new databases.\n\nfailchk(+Bool): home(+Home): Specify the DB home directory, the directory holding the database files.  The directory must exist prior to calling these predicates.\n\ninit_lock(+Bool): Enable locking (DB_INIT_LOCK). Implied if transactions are  used.\n\ninit_log(+Bool): Enable logging the DB modifications (DB_INIT_LOG). Logging  enables recovery of databases in case of system failure. Normally it is  used in combination with transactions.\n\ninit_mpool(+Bool): Initialize memory pool. Impicit if mp_size(+Size) or mp_mmapsize(+Size) is specified.\n\ninit_rep(+Bool): Init database replication. The rest of the replication logic is not yet  supported.\n\ninit_txn(+Bool): Init transactions. Implies init_log(true).\n\nlockdown(+Bool): mp_size(+Integer): mp_mmapsize(+Integer): Control memory pool handling (DB_INIT_MPOOL). The mp_size option sets the memory-pool used for caching, while  the mp_mmapsize controls the maximum size of a DB file  mapped entirely into memory.\n\nprivate(+Bool): recover(+Bool): Perform recovery before opening the database.\n\nrecover_fatal(+Bool): Perform fatal recovery before opening the database.\n\nregister(+Bool): server(+Host, [+ServerOptions]): Initialise the DB package for accessing a remote database. Host  specifies the name of the machine running berkeley_db_svc. Optionally additional options may be  specified:  server_timeout(+Seconds)Specify the timeout time the server uses to determine that the client  has gone. This implies the server will terminate the connection to this  client if this client does not issue any requests for the indicated  time.client_timeout(+Seconds)Specify the time the client waits for the server to handle a request. \n\nsystem_mem(+Bool): transactions(+Bool): Enable transactions, providing atomicy of changes and security. Implies  logging and locking. See bdb_transaction/1.\n\nthread(+Bool): Make the environment accessible from multiple threads.\n\nthread_count(+Integer): Declare an approximate number of threads in the database environment.  See DB_ENV->set_thread_count().\n\nuse_environ(+Bool): use_environ_root(+Bool): config(+ListOfConfig): Specify a list of configuration options, each option is of the form  Name(Value). Currently unused.\n\n ",
    "prefix":"bdb_init"
  },
  "bdb:bdb_open/4": {
    "body":"bdb_open(${1:File}, ${2:Mode}, ${3:DB}, ${4:Options})$5\n$0",
    "description":"[det]bdb_open(+File, +Mode, -DB, +Options).\nOpen File holding a database. Mode is one of read,  providing read-only access or update, providing read/write  access. Options is a list of options. Supported options are below.  The boolean options are passed as flags to DB->open().  The option name is derived from the flag name by stripping the DB_ prefix and converting to lower case. Consult the  Berkeley DB documentation for details.  auto_commit(+Boolean): Open the database in a transaction. Ensures no database is created in  case of failure.\n\ncreate(+Boolean): Create a new database of the database does not exist.\n\ndup(+Boolean): Do/do not allow for duplicate values on the same key. Default is not to  allow for duplicates.\n\nexcl(+Boolean): Combined with create(true), fail if the database already  exists.\n\nmultiversion(+Boolean): Open the database with support for multiversion concurrency control. The  flag is passed, but no further support is provided yet.\n\nnommap(+Boolean): Do not map this database into process memory.\n\nrdonly(+Boolean): Open the database for reading only.\n\nread_uncommitted(+Boolean): Read operations on the database may request the return of modified but  not yet committed data. This flag must be specified on all DB  handles used to perform dirty reads or database updates, otherwise  requests for dirty reads may not be honored and the read may block.\n\nthread(+Boolean): Enable access to the database handle from multiple threads. This is  default if the corresponding flag is specified for the environment.\n\ntruncate(+Boolean): When specified, truncate the underlying file, i.e., start with an empty  database.\n\ndatabase(+Name): If File contains multiple databases, address the named  database in the file. A DB file can only consist of multiple  databases if the bdb_open/4 call  that created it specified this argument. Each database in the file has  its own characteristics.\n\nenvironment(+Environment): Specify a database environment created using bdb_init/2.\n\nkey(+Type): value(+Type): Specify the type of the key or value. Allowed values are:  termKey/Value is a Prolog term (default). This type allows for representing  arbitrary Prolog data in both keys and value. The representation is  space-efficient, but Prolog specific. See PL_record_external() in the  SWI-Prolog Reference Manual for details on the representation. The other  representations are more neutral. This implies they are more stable and  sharing the DB with other languages is feasible.atomKey/Value is an atom. The text is represented as a UTF-8 string and its  length.c_blobKey/Value is a blob (sequence of bytes). On output, a Prolog string is  used. The input is either a Prolog string or an atom holding only  characters in the range [0..255].c_stringKey/Value is an atom. The text is represented as a C 0-terminated UTF-8  string.c_longKey/Value is an integer. The value is represented as a native C long in  machine byte-order. \n\n  DB is unified with a blob  of type db. Database handles are subject to atom garbage  collection.   Errors: permission_error(access, bdb_environment, Env) if an  environment is not thread-enabled and accessed from multiple threads.\n\n ",
    "prefix":"bdb_open"
  },
  "bdb:bdb_put/3": {
    "body":"bdb_put(${1:DB}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"[det]bdb_put(+DB, +Key, +Value).\nAdd a new key-value pair to the database. If the database does not allow  for duplicates the possible previous associated with Key is replaced by Value.",
    "prefix":"bdb_put"
  },
  "bdb:bdb_transaction/1": {
    "body":"bdb_transaction(${1:Goal})$2\n$0",
    "description":"[semidet]bdb_transaction(:Goal).\n",
    "prefix":"bdb_transaction"
  },
  "bdb:bdb_transaction/2": {
    "body":"bdb_transaction(${1:Environment}, ${2:Goal})$3\n$0",
    "description":"[semidet]bdb_transaction(+Environment, :Goal).\nStart a transaction, execute Goal and terminate the  transaction. Only if Goal succeeds, the transaction is  commited. If Goal fails or raises an exception, the  transaction is aborted and bdb_transaction/1 either  fails or rethrows the exception. Of special interest is the exception  \n\nerror(package(db, deadlock), _)\n\n  This exception indicates a deadlock was raised by one of the DB  predicates. Deadlocks may arise if multiple processes or threads access  the same keys in a different order. The DB infra-structure causes one of  the processes involved in the deadlock to abort its transaction. This  process may choose to restart the transaction. \n\nFor example, a DB application may define {Goal} to  realise transactions and restart these automatically is a deadlock is  raised: \n\n\n\n{Goal} :-\n    catch(bdb_transaction(Goal), E, true),\n    (   var(E)\n    ->  true\n    ;   E = error(package(db, deadlock), _)\n    ->  {Goal}\n    ;   throw(E)\n    ).\n\n  Environment defines the  environment to which the transaction applies. If omitted, the default  environment is used. See bdb_init/1  and bdb_init/2. ",
    "prefix":"bdb_transaction"
  },
  "bdb:bdb_version/1": {
    "body":"bdb_version(${1:Version})$2\n$0",
    "description":"[det]bdb_version(-Version:integer).\nTrue when Version identifies the database version. Version  is an integer defined as:  \n\nDB_VERSION_MAJOR*10000 +\nDB_VERSION_MINOR*100   +\nDB_VERSION_PATCH\n\n  \n\n",
    "prefix":"bdb_version"
  },
  "begin_tests/1": {
    "body":"begin_tests(${1:Name})$2\n$0",
    "description":"begin_tests(+Name).\nStart named test-unit. Same as begin_tests(Name, []).",
    "prefix":"begin_tests"
  },
  "begin_tests/2": {
    "body":"begin_tests(${1:Name}, ${2:Options})$3\n$0",
    "description":"begin_tests(+Name, +Options).\nStart named test-unit with options. Options provide conditional  processing, setup and cleanup similar to individual tests (second  argument of test/2  rules).  Defined options are: \n\nblocked(+Reason): Test-unit has been blocked for the given Reason.\n\ncondition(:Goal): Executed before executing any of the tests. If Goal fails,  the test of this unit is skipped.\n\nsetup(:Goal): Executed before executing any of the tests.\n\ncleanup(:Goal): Executed after completion of all tests in the unit.\n\nsto(+Terms): Specify default for subject-to-occurs-check mode. See section  2 for details on the sto option.\n\n ",
    "prefix":"begin_tests"
  },
  "between/3": {
    "body":"between(${1:Low}, ${2:High}, ${3:Value})$4\n$0",
    "description":"between(+Low, +High, ?Value).\nLow and High are integers, High >=Low.  If Value is an integer, Low =<Value  =<High. When Value is a variable it is  successively bound to all integers between Low and High.  If High is inf or infinite101We prefer infinite,  but some other Prolog systems already use inf for infinity;  we accept both for the time being. between/3  is true iff Value >=Low, a feature  that is particularly interesting for generating integers from a certain  value.",
    "prefix":"between"
  },
  "blob/2": {
    "body":"blob(${1:Term}, ${2:Type})$3\n$0",
    "description":"blob(@Term, ?Type).\nTrue if Term is a blob of type Type. See section 11.4.7.",
    "prefix":"blob"
  },
  "bounds:all_different/1": {
    "body": ["all_different(${1:'Param1'})$2\n$0" ],
    "description":"all_different('Param1')",
    "prefix":"all_different"
  },
  "bounds:check/1": {
    "body": ["check(${1:'Param1'})$2\n$0" ],
    "description":"check('Param1')",
    "prefix":"check"
  },
  "bounds:in/2": {
    "body": ["in(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"in('Param1','Param2')",
    "prefix":"in"
  },
  "bounds:indomain/1": {
    "body": ["indomain(${1:'Param1'})$2\n$0" ],
    "description":"indomain('Param1')",
    "prefix":"indomain"
  },
  "bounds:label/1": {
    "body": ["label(${1:'Param1'})$2\n$0" ],
    "description":"label('Param1')",
    "prefix":"label"
  },
  "bounds:labeling/2": {
    "body": ["labeling(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"labeling('Param1','Param2')",
    "prefix":"labeling"
  },
  "bounds:lex_chain/1": {
    "body": ["lex_chain(${1:'Param1'})$2\n$0" ],
    "description":"lex_chain('Param1')",
    "prefix":"lex_chain"
  },
  "bounds:serialized/2": {
    "body": ["serialized(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"serialized('Param1','Param2')",
    "prefix":"serialized"
  },
  "bounds:sum/3": {
    "body": ["sum(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"sum('Param1','Param2','Param3')",
    "prefix":"sum"
  },
  "bounds:tuples_in/2": {
    "body": ["tuples_in(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"tuples_in('Param1','Param2')",
    "prefix":"tuples_in"
  },
  "break/0": {
    "body":"break$1\n$0",
    "description":"break.\nRecursively start a new Prolog top level. This Prolog top level shares  everything from the environment it was started in. Debugging is switched  off on entering a break and restored on leaving one. The break  environment is terminated by typing the system's end-of-file character  (control-D). If that is somehow not functional, the term end_of_file. can be entered to return from the break  environment. If the -t toplevel command line  option is given, this goal is started instead of entering the default  interactive top level (prolog/0).  Notably the gui based versions (swipl-win on Windows and  MacOS) provide the menu Run/New thread that opens a new toplevel  that runs concurrently with the initial toplevel. The concurrent  toplevel can be used to examine the program, in particular global  dynamic predicates. It can not access global variables or  thread-local dynamic predicates (see thread_local/1)  of the main thread.\n\n",
    "prefix":"break"
  },
  "broadcast:broadcast/1": {
    "body":"broadcast(${1:Term})$2\n$0",
    "description":"broadcast(+Term).\nBroadcast Term. There are no limitations to Term,  though being a global service, it is good practice to use a descriptive  and unique principal functor. All associated goals are started and  regardless of their success or failure, broadcast/1  always succeeds. Exceptions are passed.",
    "prefix":"broadcast"
  },
  "broadcast:broadcast_request/1": {
    "body":"broadcast_request(${1:Term})$2\n$0",
    "description":"broadcast_request(+Term).\nUnlike broadcast/1,  this predicate stops if an associated goal succeeds. Backtracking causes  it to try other listeners. A broadcast request is used to fetch  information without knowing the identity of the agent providing it. C.f. ``Is  there someone who knows the age of John?'' could be asked using  \n\n        ...,\n        broadcast_request(age_of('John', Age)),\n\n  If there is an agent (listener) that registered an `age-of'  service and knows about the age of `John' this question will be  answered.\n\n",
    "prefix":"broadcast_request"
  },
  "broadcast:listen/2": {
    "body":"listen(${1:Template}, ${2:Goal})$3\n$0",
    "description":"listen(+Template, :Goal).\nRegister a listen channel. Whenever a term unifying Template is broadcasted, call Goal. The following  example traps all broadcasted messages as a variable unifies to any  message. It is commonly used to debug usage of the library.  \n\n?- listen(Term, (writeln(Term),fail)).\n?- broadcast(hello(world)).\nhello(world)\ntrue.\n\n ",
    "prefix":"listen"
  },
  "broadcast:listen/3": {
    "body":"listen(${1:Listener}, ${2:Template}, ${3:Goal})$4\n$0",
    "description":"listen(+Listener, +Template, :Goal).\nDeclare Listener as the owner of the channel. Unlike a  channel opened using listen/2,  channels that have an owner can terminate the channel. This is commonly  used if an object is listening to broadcast messages. In the example  below we define a `name-item' displaying the name of an identifier  represented by the predicate name_of/2.  \n\n:- pce_begin_class(name_item, text_item).\n\nvariable(id,    any,    get, \"Id visualised\").\n\ninitialise(NI, Id:any) :->\n        name_of(Id, Name),\n        send_super(NI, initialise, name, Name,\n                   message(NI, set_name, @arg1)),\n        send(NI, slot, id, Id),\n        listen(NI, name_of(Id, Name),\n               send(NI, selection, Name)).\n\nunlink(NI) :->\n        unlisten(NI),\n        send_super(NI, unlink).\n\nset_name(NI, Name:name) :->\n        get(NI, id, Id),\n        retractall(name_of(Id, _)),\n        assert(name_of(Id, Name)),\n        broadcast(name_of(Id, Name)).\n\n:- pce_end_class.\n\n ",
    "prefix":"listen"
  },
  "broadcast:listening/3": {
    "body":"listening(${1:Listener}, ${2:Template}, ${3:Goal})$4\n$0",
    "description":"listening(?Listener, ?Template, ?Goal).\nExamine the current listeners. This predicate is useful for debugging  purposes.",
    "prefix":"listening"
  },
  "broadcast:unlisten/1": {
    "body":"unlisten(${1:Listener})$2\n$0",
    "description":"unlisten(+Listener).\nDeregister all entries created with listen/3  whose Listener unify.",
    "prefix":"unlisten"
  },
  "broadcast:unlisten/2": {
    "body":"unlisten(${1:Listener}, ${2:Template})$3\n$0",
    "description":"unlisten(+Listener, +Template).\nDeregister all entries created with listen/3  whose Listener and Template unify.",
    "prefix":"unlisten"
  },
  "broadcast:unlisten/3": {
    "body":"unlisten(${1:Listener}, ${2:Template}, ${3:Goal})$4\n$0",
    "description":"unlisten(+Listener, +Template, :Goal).\nDeregister all entries created with listen/3  whose Listener, Template and Goal unify.",
    "prefix":"unlisten"
  },
  "byte_count/2": {
    "body":"byte_count(${1:Stream}, ${2:Count})$3\n$0",
    "description":"byte_count(+Stream, -Count).\nByte position in Stream. For binary streams this is the same  as character_count/2.  For text files the number may be different due to multi-byte encodings  or additional record separators (such as Control-M in Windows).",
    "prefix":"byte_count"
  },
  "c14n2:xml_write_canonical/3": {
    "body":"xml_write_canonical(${1:Stream}, ${2:DOM}, ${3:Options})$4\n$0",
    "description":"[det]xml_write_canonical(+Stream, +DOM, +Options).\nWrite an XML DOM using the canonical conventions as defined  by C14n2. Namespace declarations in the canonical document depend on the  original namespace declarations. For this reason the input document must  be parsed (see load_structure/3)  using the dialect xmlns and the option keep_prefix(true).",
    "prefix":"xml_write_canonical"
  },
  "c14n2:xsd_time_string/3": {
    "body":"xsd_time_string(${1:DateTime}, ${2:Type}, ${3:String})$4\n$0",
    "description":"[det]xsd_time_string(?DateTime, ?Type, ?String).\nSerialize and deserialize the XSD date and time formats. The converion  is represented by the table below.  \n\nProlog term Type XSD  string date(Y,M,D)xsd:dateYYYY-MM-DD date_time(Y,M,D,H,Mi,S)xsd:dateTimeYYYY-MM-DDTHH-MM-SS date_time(Y,M,D,H,Mi,S,0)xsd:dateTimeYYYY-MM-DDTHH-MM-SSZ date_time(Y,M,D,H,Mi,S,TZ)xsd:dateTimeYYYY-MM-DDTHH-MM-SS[+-]HH:MM time(H,M,S)xsd:timeHH:MM:SS year_month(Y,M)xsd:gYearMonthYYYY-MM month_day(M,D)xsd:gMonthDayMM-DD Dxsd:gDayDD Mxsd:gMonthMM Yxsd:gYearYYYY   For the Prolog term all variables denote integers except for S, which represents seconds as either an integer or float.  The TZ argument is the offset from UTC in seconds. The Type is written as xsd:name, but is in fact the  full URI of the XSD data type, e.g., http://www.w3.org/2001/XMLSchema#date.  In the XSD string notation, the letters YMDHS denote digits. The  notation SS is either a two-digit integer or a decimal number with two  digits before the floating point, e.g. 05.3 to denote 5.3  seconds. \n\nFor most conversions, Type may be specified unbound and is  unified with the resulting type. For ambiguous conversions, Type  must be specified or an instantiation_error is raised. When converting  from Prolog to XSD serialization, D, M and Y are ambiguous. When  convertion from XSD serialization to Prolog, only DD and MM are  ambiguous. If Type and String are both given and String  is a valid XSD date/time representation but not matching Type  a syntax error with the shape syntax_error(Type) is raised.  If DateTime and Type are both given and DateTime  does not satisfy Type a domain_error of the shape domain_error(xsd_time(Type), DateTime) is raised. \n\nThe domain of numerical values is verified and a corresponding  domain_error exception is raised if the domain is violated. There is no  test for the existence of a date and thus \"2016-02-31\",  although non-existing is accepted as valid.\n\n",
    "prefix":"xsd_time_string"
  },
  "call/1": {
    "body":"call(${1:Goal})$2\n$0",
    "description":"[ISO]call(:Goal).\nInvoke Goal as a goal. Note that clauses may have variables  as subclauses, which is identical to call/1.",
    "prefix":"call"
  },
  "call/3": {
    "body":"call(${1:Goal}, ${2:ExtraArg1}, ${3:...})$4\n$0",
    "description":"[ISO]call(:Goal, +ExtraArg1, ...).\nAppend ExtraArg1, ExtraArg2, ... to the argument list of Goal and call the result. For example, call(plus(1), 2,  X) will call plus(1, 2, X), binding X to  3.  The call/[2..] construct is handled by the compiler. The predicates call/[2-8]  are defined as real (meta-)predicates and are available to inspection  through current_predicate/1, predicate_property/2,  etc.59Arities 2..8 are demanded by  ISO/IEC 13211-1:1995/Cor.2:2012. Higher arities are handled  by the compiler and runtime system, but the predicates are not  accessible for inspection.60Future  versions of the reflective predicate may fake the presence of call/9.. .  Full logical behaviour, generating all these pseudo predicates, is  probably undesirable and will become impossible if max_arity is  removed.\n\n",
    "prefix":"call"
  },
  "call_cleanup/2": {
    "body":"call_cleanup(${1:Goal}, ${2:Cleanup})$3\n$0",
    "description":"call_cleanup(:Goal, :Cleanup).\nSame as setup_call_cleanup(true, Goal, Cleanup). This is  provided for compatibility with a number of other Prolog implementations  only. Do not use call_cleanup/2  if you perform side-effects prior to calling that will be undone by Cleanup.  Instead, use setup_call_cleanup/3  with an appropriate first argument to perform those side-effects.",
    "prefix":"call_cleanup"
  },
  "call_cleanup/3": {
    "body":"call_cleanup(${1:Goal}, ${2:Catcher}, ${3:Cleanup})$4\n$0",
    "description":"call_cleanup(:Goal, +Catcher, :Cleanup).\nSame as setup_call_catcher_cleanup(true, Goal, Catcher, Cleanup).  The same warning as for call_cleanup/2  applies.",
    "prefix":"call_cleanup"
  },
  "call_dcg/3": {
    "body":"call_dcg(${1:DCGBody}, ${2:State0}, ${3:State})$4\n$0",
    "description":"call_dcg(:DCGBody, ?State0, ?State).\nAs phrase/3,  but without type checking State0 and State. This  allows for using DCG rules for threading an arbitrary state variable.  This predicate was introduced after type checking was added to phrase/3.66After  discussion with Samer Abdallah.  A portable solution for threading state through a DCG can be  implemented by wrapping the state in a list and use the DCG semicontext  facility. Subsequently, the following predicates may be used to access  and modify the state:67This  solution was proposed by Markus Triska. \n\n\n\nstate(S), [S] --> [S].\nstate(S0, S), [S] --> [S0].\n\n  \n\n",
    "prefix":"call_dcg"
  },
  "call_residue_vars/2": {
    "body":"call_residue_vars(${1:Goal}, ${2:Vars})$3\n$0",
    "description":"call_residue_vars(:Goal, -Vars).\nFind residual attributed variables left by Goal. This  predicate is intended for reasoning about and debugging programs that  use coroutining or constraints. To see why this predicate is necessary,  consider a predicate that poses contradicting constraints on a variable,  and where that variable does not appear in any argument of the predicate  and hence does not yield any residual goals on the toplevel when the  predicate is invoked. Such programs should fail, but sometimes succeed  because the constraint solver is too weak to detect the contradiction.  Ideally, delayed goals and constraints are all executed at the end of  the computation. The meta predicate call_residue_vars/2  finds variables that are given attributes or whose attributes are  modified by Goal, regardless of whether or not these  variables are reachable from the arguments of Goal.146The  implementation of call_residue_vars/2  is completely redone in version 7.3.2 (7.2.1) after discussion with Bart  Demoen. The current implementation no longer performs full scans of the  stacks. The overhead is proportional to the number of attributed  variables on the stack, dead or alive..",
    "prefix":"call_residue_vars"
  },
  "call_with_depth_limit/3": {
    "body":"call_with_depth_limit(${1:Goal}, ${2:Limit}, ${3:Result})$4\n$0",
    "description":"call_with_depth_limit(:Goal, +Limit, -Result).\nIf Goal can be proven without recursion deeper than Limit  levels, call_with_depth_limit/3  succeeds, binding Result to the deepest recursion level used  during the proof. Otherwise, Result is unified with depth_limit_exceeded  if the limit was exceeded during the proof, or the entire predicate  fails if Goal fails without exceeding Limit.  The depth limit is guarded by the internal machinery. This may differ  from the depth computed based on a theoretical model. For example, true/0  is translated into an inline virtual machine instruction. Also, repeat/0  is not implemented as below, but as a non-deterministic foreign  predicate. \n\n\n\nrepeat.\nrepeat :-\n        repeat.\n\n  As a result, call_with_depth_limit/3  may still loop infinitely on programs that should theoretically finish  in finite time. This problem can be cured by using Prolog equivalents to  such built-in predicates. \n\nThis predicate may be used for theorem provers to realise techniques  like iterative deepening. See also call_with_inference_limit/3.  It was implemented after discussion with Steve Moyle smoyle@ermine.ox.ac.uk.\n\n",
    "prefix":"call_with_depth_limit"
  },
  "call_with_inference_limit/3": {
    "body":"call_with_inference_limit(${1:Goal}, ${2:Limit}, ${3:Result})$4\n$0",
    "description":"call_with_inference_limit(:Goal, +Limit, -Result).\nEquivalent to call(Goal), but limits the number of  inferences for each solution of Goal.61This  predicate was realised after discussion with Ulrich Neumerkel and Markus  Triska.. Execution may terminate as follows:  \n\nIf Goal does not terminate before the inference  limit is exceeded, Goal is aborted by injecting the exception inference_limit_exceeded  into its execution. After termination of Goal, Result is unified with the atom inference_limit_exceeded. Otherwise,\nIf Goal fails, call_with_inference_limit/3  fails.\nIf Goal succeeds without a choice point, Result is unified with !.\nIf Goal succeeds with a choice point, Result is unified with true.\nIf Goal throws an exception, call_with_inference_limit/3  re-throws the exception.\n\n  An inference is defined as a call or redo on a predicate. Please note  that some primitive built-in predicates are compiled to virtual machine  instructions for which inferences are not counted. The execution of  predicates defined in other languages (e.g., C, C++) count as a single  inference. This includes potentially expensive built-in predicates such  as sort/2. \n\nCalls to this predicate may be nested. An inner call that sets the  limit below the current is honoured. An inner call that would terminate  after the current limit does not change the effective limit. See also call_with_depth_limit/3  and call_with_time_limit/2.\n\n",
    "prefix":"call_with_inference_limit"
  },
  "callable/1": {
    "body":"callable(${1:Term})$2\n$0",
    "description":"[ISO]callable(@Term).\nTrue if Term is bound to an atom or a compound term. This was  intended as a type-test for arguments to call/1  and call/2..  Note that callable only tests the surface term. Terms such as  (22,true) are considered callable, but cause call/1  to raise a type error. Module-qualification of meta-argument (see meta_predicate/1)  using :/2 causes callable to succeed on any  meta-argument.52We think that callable/1  should be deprecated and there should be two new predicates, one  performing a test for callable that is minimally module aware and  possibly consistent with type-checking in call/1  and a second predicate that tests for atom or compound.  Consider the program and query below:  \n\n:- meta_predicate p(0).\n\np(G) :- callable(G), call(G).\n\n?- p(22).\nERROR: Type error: `callable' expected, found `22'\nERROR: In:\nERROR:    [6] p(user:22)\n\n ",
    "prefix":"callable"
  },
  "cancel_halt/1": {
    "body":"cancel_halt(${1:Reason})$2\n$0",
    "description":"cancel_halt(+Reason).\nIf this predicate is called from a hook registered with at_halt/1,  halting Prolog is cancelled and an informational message is printed that  includes Reason. This is used by the development tools to  cancel halting the system if the editor has unsafed data and the user  decides to cancel.",
    "prefix":"cancel_halt"
  },
  "catch/3": {
    "body":"catch(${1:Goal}, ${2:Catcher}, ${3:Recover})$4\n$0",
    "description":"[ISO]catch(:Goal, +Catcher, :Recover).\nBehaves as call/1  if no exception is raised when executing Goal. If an  exception is raised using throw/1  while Goal executes, and the Goal is the innermost  goal for which Catcher unifies with the argument of throw/1,  all choice points generated by Goal are cut, the system  backtracks to the start of catch/3  while preserving the thrown exception term, and Recover is  called as in call/1.  The overhead of calling a goal through catch/3  is comparable to call/1.  Recovery from an exception is much slower, especially if the exception  term is large due to the copying thereof.\n\n",
    "prefix":"catch"
  },
  "ceil/1": {
    "body":"ceil(${1:Expr})$2\n$0",
    "description":"ceil(+Expr).\nSame as ceiling/1  (backward compatibility).",
    "prefix":"ceil"
  },
  "ceiling/1": {
    "body":"ceiling(${1:Expr})$2\n$0",
    "description":"[ISO]ceiling(+Expr).\nEvaluate Expr and return the smallest integer larger or equal  to the result of the evaluation.",
    "prefix":"ceiling"
  },
  "cgi:cgi_get_form/1": {
    "body": ["cgi_get_form(${1:Form})$2\n$0" ],
    "description":"  cgi_get_form(-Form)\n\n   Decodes standard input and the environment variables to obtain a\n   list of arguments passed to the  CGI script. This predicate both\n   deals with the CGI *GET* method as well as the *POST* method. If\n   the data cannot be  obtained,   an  existence_error exception is\n   raised.\n\n   @param Form is a list of Name(Value) terms.",
    "prefix":"cgi_get_form"
  },
  "char_code/2": {
    "body":"char_code(${1:Atom}, ${2:Code})$3\n$0",
    "description":"[ISO]char_code(?Atom, ?Code).\nConvert between character and character code for a single character.95This  is also called atom_char/2 in older versions of SWI-Prolog as well as  some other Prolog implementations. The atom_char/2 predicate is  available from the library backcomp.pl",
    "prefix":"char_code"
  },
  "char_conversion/2": {
    "body":"char_conversion(${1:CharIn}, ${2:CharOut})$3\n$0",
    "description":"[ISO]char_conversion(+CharIn, +CharOut).\nDefine that term input (see read_term/3)  maps each character read as CharIn to the character CharOut. Character  conversion is only executed if the Prolog flag char_conversion  is set to true and not inside quoted atoms or strings. The initial  table maps each character onto itself. See also current_char_conversion/2.",
    "prefix":"char_conversion"
  },
  "char_type/2": {
    "body":"char_type(${1:Char}, ${2:Type})$3\n$0",
    "description":"char_type(?Char, ?Type).\nTests or generates alternative Types or Chars. The  character types are inspired by the standard C <ctype.h>  primitives.  alnum: Char is a letter (upper- or lowercase) or digit.\n\nalpha: Char is a letter (upper- or lowercase).\n\ncsym: Char is a letter (upper- or lowercase), digit or the  underscore (_). These are valid C and Prolog symbol  characters.\n\ncsymf: Char is a letter (upper- or lowercase) or the underscore (_).  These are valid first characters for C and Prolog symbols.\n\nascii: Char is a 7-bit ASCII character (0..127).\n\nwhite: Char is a space or tab, i.e. white space inside a line.\n\ncntrl: Char is an ASCII control character (0..31).\n\ndigit: Char is a digit.\n\ndigit(Weight): Char is a digit with value Weight. I.e. char_type(X,  digit(6) yields X = '6'. Useful for  parsing numbers.\n\nxdigit(Weight): Char is a hexadecimal digit with value Weight.  I.e. char_type(a, xdigit(X) yields X = '10'.  Useful for parsing numbers.\n\ngraph: Char produces a visible mark on a page when printed. Note  that the space is not included!\n\nlower: Char is a lowercase letter.\n\nlower(Upper): Char is a lowercase version of Upper. Only true if Char is lowercase and Upper uppercase.\n\nto_lower(Upper): Char is a lowercase version of Upper. For  non-letters, or letter without case, Char and Lower  are the same. See also upcase_atom/2  and downcase_atom/2.\n\nupper: Char is an uppercase letter.\n\nupper(Lower): Char is an uppercase version of Lower. Only true  if Char is uppercase and Lower lowercase.\n\nto_upper(Lower): Char is an uppercase version of Lower. For  non-letters, or letter without case, Char and Lower  are the same. See also upcase_atom/2  and downcase_atom/2.\n\npunct: Char is a punctuation character. This is a graph  character that is not a letter or digit.\n\nspace: Char is some form of layout character (tab, vertical tab,  newline, etc.).\n\nend_of_file: Char is -1.\n\nend_of_line: Char ends a line (ASCII: 10..13).\n\nnewline: Char is a newline character (10).\n\nperiod: Char counts as the end of a sentence (.,!,?).\n\nquote: Char is a quote character (\", ', `).\n\nparen(Close): Char is an open parenthesis and Close is the  corresponding close parenthesis.\n\nprolog_var_start: Char can start a Prolog variable name.\n\nprolog_atom_start: Char can start a unquoted Prolog atom that is not a symbol.\n\nprolog_identifier_continue: Char can continue a Prolog variable name or atom.\n\nprolog_prolog_symbol: Char is a Prolog symbol character. Sequences of Prolog symbol  characters glue together to form an unquoted atom. Examples are =.., \\=,  etc.\n\n ",
    "prefix":"char_type"
  },
  "character_count/2": {
    "body":"character_count(${1:Stream}, ${2:Count})$3\n$0",
    "description":"character_count(+Stream, -Count).\nUnify Count with the current character index. For input  streams this is the number of characters read since the open; for output  streams this is the number of characters written. Counting starts at 0.",
    "prefix":"character_count"
  },
  "charsio:atom_to_chars/2": {
    "body":"atom_to_chars(${1:Atom}, ${2:Codes})$3\n$0",
    "description":"[det]atom_to_chars(+Atom, -Codes).\nConvert Atom into a list of character codes.  deprecated: Use ISO atom_codes/2.\n\n ",
    "prefix":"atom_to_chars"
  },
  "charsio:atom_to_chars/3": {
    "body":"atom_to_chars(${1:Atom}, ${2:Codes}, ${3:Tail})$4\n$0",
    "description":"[det]atom_to_chars(+Atom, -Codes, ?Tail).\nConvert Atom into a difference list of character codes.",
    "prefix":"atom_to_chars"
  },
  "charsio:format_to_chars/3": {
    "body":"format_to_chars(${1:Format}, ${2:Args}, ${3:Codes})$4\n$0",
    "description":"[det]format_to_chars(+Format, +Args, -Codes).\nUse format/2 to write to  a list of character codes.",
    "prefix":"format_to_chars"
  },
  "charsio:format_to_chars/4": {
    "body":"format_to_chars(${1:Format}, ${2:Args}, ${3:Codes}, ${4:Tail})$5\n$0",
    "description":"[det]format_to_chars(+Format, +Args, -Codes, ?Tail).\nUse format/2 to write to  a difference list of character codes.",
    "prefix":"format_to_chars"
  },
  "charsio:number_to_chars/2": {
    "body":"number_to_chars(${1:Number}, ${2:Codes})$3\n$0",
    "description":"[det]number_to_chars(+Number, -Codes).\nConvert Atom into a list of character codes.  deprecated: Use ISO number_codes/2.\n\n ",
    "prefix":"number_to_chars"
  },
  "charsio:number_to_chars/3": {
    "body":"number_to_chars(${1:Number}, ${2:Codes}, ${3:Tail})$4\n$0",
    "description":"[det]number_to_chars(+Number, -Codes, ?Tail).\nConvert Number into a difference list of character codes.",
    "prefix":"number_to_chars"
  },
  "charsio:open_chars_stream/2": {
    "body":"open_chars_stream(${1:Codes}, ${2:Stream})$3\n$0",
    "description":"[det]open_chars_stream(+Codes, -Stream).\nOpen Codes as an input stream.  See also: open_string/2.\n\n ",
    "prefix":"open_chars_stream"
  },
  "charsio:read_from_chars/2": {
    "body":"read_from_chars(${1:Codes}, ${2:Term})$3\n$0",
    "description":"[det]read_from_chars(+Codes, -Term).\nRead Codes into Term.  Compatibility: The SWI-Prolog version does not require Codes to end in a  full-stop.\n\n ",
    "prefix":"read_from_chars"
  },
  "charsio:read_term_from_chars/3": {
    "body":"read_term_from_chars(${1:Codes}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"[det]read_term_from_chars(+Codes, -Term, +Options).\nRead Codes into Term. Options are  processed by read_term/3.  Compatibility: sicstus\n\n ",
    "prefix":"read_term_from_chars"
  },
  "charsio:with_output_to_chars/2": {
    "body":"with_output_to_chars(${1:Goal}, ${2:Codes})$3\n$0",
    "description":"[det]with_output_to_chars(:Goal, -Codes).\nRun Goal as with once/1.  Output written to current_output is collected in Codes.",
    "prefix":"with_output_to_chars"
  },
  "charsio:with_output_to_chars/3": {
    "body":"with_output_to_chars(${1:Goal}, ${2:Codes}, ${3:Tail})$4\n$0",
    "description":"[det]with_output_to_chars(:Goal, -Codes, ?Tail).\nRun Goal as with once/1.  Output written to current_output is collected in Codes\\Tail.",
    "prefix":"with_output_to_chars"
  },
  "charsio:with_output_to_chars/4": {
    "body":"with_output_to_chars(${1:Goal}, ${2:Stream}, ${3:Codes}, ${4:Tail})$5\n$0",
    "description":"[det]with_output_to_chars(:Goal, -Stream, -Codes, ?Tail).\nSame as with_output_to_chars/3  using an explicit stream. The difference list Codes\\Tail  contains the character codes that Goal has written to Stream.",
    "prefix":"with_output_to_chars"
  },
  "charsio:write_to_chars/2": {
    "body":"write_to_chars(${1:Term}, ${2:Codes})$3\n$0",
    "description":"write_to_chars(+Term, -Codes).\nWrite a term to a code list. True when Codes is a list of  character codes written by write/1  on Term.",
    "prefix":"write_to_chars"
  },
  "charsio:write_to_chars/3": {
    "body":"write_to_chars(${1:Term}, ${2:Codes}, ${3:Tail})$4\n$0",
    "description":"write_to_chars(+Term, -Codes, ?Tail).\nWrite a term to a code list. Codes\\Tail  is a difference list of character codes produced by write/1  on Term.",
    "prefix":"write_to_chars"
  },
  "chdir/1": {
    "body":"chdir(${1:Path})$2\n$0",
    "description":"chdir(+Path).\nCompatibility predicate. New code should use working_directory/2.",
    "prefix":"chdir"
  },
  "check:check/0": {
    "body": ["check$1\n$0" ],
    "description":"  check is det.\n\n   Run all consistency checks defined by checker/2. Checks enabled by\n   default are:\n\n     * list_undefined/0 reports undefined predicates\n     * list_trivial_fails/0 reports calls for which there is no\n       matching clause.\n     * list_redefined/0 reports predicates that have a local\n       definition and a global definition.  Note that these are\n       *not* errors.\n     * list_autoload/0 lists predicates that will be defined at\n       runtime using the autoloader.",
    "prefix":"check"
  },
  "check:checker/2": {
    "body":"checker(${1:Goal}, ${2:Message})$3\n$0",
    "description":"[multifile]checker(:Goal, +Message:text).\nRegister code validation routines. Each clause defines a Goal  which performs a consistency check executed by check/0. Message  is a short description of the check. For example, assuming the my_checks module defines a predicate list_format_mistakes/0:  \n\n:- multifile check:checker/2.\ncheck:checker(my_checks:list_format_mistakes,\n              \"errors with format/2 arguments\").\n\n  The predicate is dynamic, so you can disable checks with retract/1.  For example, to stop reporting redefined predicates: \n\n\n\nretract(check:checker(list_redefined,_)).\n\n  \n\n",
    "prefix":"checker"
  },
  "check:list_autoload/0": {
    "body": ["list_autoload$1\n$0" ],
    "description":"  list_autoload is det.\n\n   Report predicates that may be  auto-loaded. These are predicates\n   that  are  not  defined,  but  will   be  loaded  on  demand  if\n   referenced.\n\n   @tbd    This predicate uses an older mechanism for finding\n           undefined predicates.  Should be synchronized with\n           list undefined.\n   @see    autoload/0",
    "prefix":"list_autoload"
  },
  "check:list_redefined/0": {
    "body":"list_redefined$1\n$0",
    "description":"list_redefined.\nLists predicates that are defined in the global module user  as well as in a normal module; that is, predicates for which the local  definition overrules the global default definition.",
    "prefix":"list_redefined"
  },
  "check:list_strings/0": {
    "body": ["list_strings$1\n$0" ],
    "description":"  list_strings is det.\n  list_strings(+Options) is det.\n\n   List strings that appear in clauses.   This predicate is used to\n   find  portability  issues  for   changing    the   Prolog   flag\n   =double_quotes= from =codes= to =string=, creating packed string\n   objects.  Warnings  may  be  suppressed    using  the  following\n   multifile hooks:\n\n     - string_predicate/1 to stop checking certain predicates\n     - valid_string_goal/1 to tell the checker that a goal is\n       safe.\n\n   @see Prolog flag =double_quotes=.",
    "prefix":"list_strings"
  },
  "check:list_strings/1": {
    "body":"list_strings(${1:Options})$2\n$0",
    "description":"[det]list_strings(+Options).\nList strings that appear in clauses. This predicate is used to find  portability issues for changing the Prolog flag double_quotes from codes to string,  creating packed string objects. Warnings may be suppressed using the  following multifile hooks:  \n\nstring_predicate/1  to stop checking certain predicates\nvalid_string_goal/1  to tell the checker that a goal is safe.\n\n  See also: Prolog flag double_quotes.\n\n ",
    "prefix":"list_strings"
  },
  "check:list_trivial_fails/0": {
    "body": ["list_trivial_fails$1\n$0" ],
    "description":"  list_trivial_fails is det.\n  list_trivial_fails(+Options) is det.\n\n   List goals that trivially fail  because   there  is  no matching\n   clause.  Options:\n\n     * module_class(+Classes)\n       Process modules of the given Classes.  The default for\n       classes is =|[user]|=. For example, to include the\n       libraries into the examination, use =|[user,library]|=.",
    "prefix":"list_trivial_fails"
  },
  "check:list_trivial_fails/1": {
    "body":"list_trivial_fails(${1:Options})$2\n$0",
    "description":"[det]list_trivial_fails(+Options).\nList goals that trivially fail because there is no matching clause. Options:  module_class(+Classes): Process modules of the given Classes. The default for classes  is [user]. For example, to include the libraries into the  examination, use [user,library].\n\n ",
    "prefix":"list_trivial_fails"
  },
  "check:list_undefined/0": {
    "body": ["list_undefined$1\n$0" ],
    "description":"  list_undefined is det.\n  list_undefined(+Options) is det.\n\n   Report undefined predicates.  This   predicate  finds  undefined\n   predciates by decompiling and analyzing the body of all clauses.\n   Options:\n\n       * module_class(+Classes)\n       Process modules of the given Classes.  The default for\n       classes is =|[user]|=. For example, to include the\n       libraries into the examination, use =|[user,library]|=.\n\n   @see gxref/0 provides a graphical cross-referencer.\n   @see make/0 calls list_undefined/0",
    "prefix":"list_undefined"
  },
  "check:list_undefined/1": {
    "body":"list_undefined(${1:Options})$2\n$0",
    "description":"[det]list_undefined(+Options).\nReport undefined predicates. This predicate finds undefined predciates  by decompiling and analyzing the body of all clauses. Options:  module_class(+Classes): Process modules of the given Classes. The default for classes  is [user]. For example, to include the libraries into the  examination, use [user,library].\n\n  See also: - gxref/0 provides a  graphical cross-referencer.  - make/0 calls list_undefined/0\n\n ",
    "prefix":"list_undefined"
  },
  "check:list_void_declarations/0": {
    "body": ["list_void_declarations$1\n$0" ],
    "description":"  list_void_declarations is det.\n\n   List predicates that have declared attributes, but no clauses.",
    "prefix":"list_void_declarations"
  },
  "check:string_predicate/1": {
    "body":"string_predicate(${1:PredicateIndicator})$2\n$0",
    "description":"[multifile]string_predicate(:PredicateIndicator).\nMultifile hook to disable list_strings/0  on the given predicate. This is typically used for facts that store  strings.",
    "prefix":"string_predicate"
  },
  "check:trivial_fail_goal/1": {
    "body":"trivial_fail_goal(${1:Goal})$2\n$0",
    "description":"[multifile]trivial_fail_goal(:Goal).\nMultifile hook that tells list_trivial_fails/0  to accept Goal as valid.",
    "prefix":"trivial_fail_goal"
  },
  "check:valid_string_goal/1": {
    "body":"valid_string_goal(${1:Goal})$2\n$0",
    "description":"[semidet,multifile]valid_string_goal(+Goal).\nMultifile hook that qualifies Goal as valid for list_strings/0.  For example, format(\"Hello world~n\") is considered proper  use of string constants.",
    "prefix":"valid_string_goal"
  },
  "check_installation:check_installation/0": {
    "body": ["check_installation$1\n$0" ],
    "description":"  check_installation\n\n   Check features of the installed   system. Performs the following\n   tests:\n\n     1. Test whether features that depend on optional libraries\n        are present (e.g., unbounded arithmetic support)\n     2. Test that all standard libraries that depend on foreign\n        code are present.\n\n   If issues are found it prints a   diagnostic message with a link\n   to a wiki page with additional information about the issue.",
    "prefix":"check_installation"
  },
  "check_installation:check_installation/1": {
    "body": ["check_installation(${1:'Param1'})$2\n$0" ],
    "description":"check_installation('Param1')",
    "prefix":"check_installation"
  },
  "checklast:check_old_last/0": {
    "body": ["check_old_last$1\n$0" ],
    "description":"check_old_last",
    "prefix":"check_old_last"
  },
  "checkselect:check_old_select/0": {
    "body": ["check_old_select$1\n$0" ],
    "description":"  check_old_select\n\n   When compiling, print calls to select/3 that may use the wrong\n   argument order.  Upto version 3.3.x the argument order of select/3\n   as\n\n           select(+List, ?Element, ?RestList).\n\n   Later versions use the compatible version\n\n           select(?Element, +List, ?RestList).",
    "prefix":"check_old_select"
  },
  "chr/a_star:a_star/4": {
    "body": [
      "a_star(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"a_star('Param1','Param2','Param3','Param4')",
    "prefix":"a_star"
  },
  "chr/binomialheap:delete_min_q/3": {
    "body": ["delete_min_q(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"delete_min_q('Param1','Param2','Param3')",
    "prefix":"delete_min_q"
  },
  "chr/binomialheap:empty_q/1": {
    "body": ["empty_q(${1:'Param1'})$2\n$0" ],
    "description":"empty_q('Param1')",
    "prefix":"empty_q"
  },
  "chr/binomialheap:find_min_q/2": {
    "body": ["find_min_q(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"find_min_q('Param1','Param2')",
    "prefix":"find_min_q"
  },
  "chr/binomialheap:insert_list_q/3": {
    "body": ["insert_list_q(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"insert_list_q('Param1','Param2','Param3')",
    "prefix":"insert_list_q"
  },
  "chr/binomialheap:insert_q/3": {
    "body": ["insert_q(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"insert_q('Param1','Param2','Param3')",
    "prefix":"insert_q"
  },
  "chr/builtins:binds_b/2": {
    "body": ["binds_b(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"binds_b('Param1','Param2')",
    "prefix":"binds_b"
  },
  "chr/builtins:builtin_binds_b/2": {
    "body": ["builtin_binds_b(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"builtin_binds_b('Param1','Param2')",
    "prefix":"builtin_binds_b"
  },
  "chr/builtins:entails_b/2": {
    "body": ["entails_b(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"entails_b('Param1','Param2')",
    "prefix":"entails_b"
  },
  "chr/builtins:negate_b/2": {
    "body": ["negate_b(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"negate_b('Param1','Param2')",
    "prefix":"negate_b"
  },
  "chr/chr_compiler_errors:chr_error/3": {
    "body": ["chr_error(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"chr_error('Param1','Param2','Param3')",
    "prefix":"chr_error"
  },
  "chr/chr_compiler_errors:chr_info/3": {
    "body": ["chr_info(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"chr_info('Param1','Param2','Param3')",
    "prefix":"chr_info"
  },
  "chr/chr_compiler_errors:chr_warning/3": {
    "body": ["chr_warning(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"chr_warning('Param1','Param2','Param3')",
    "prefix":"chr_warning"
  },
  "chr/chr_compiler_errors:print_chr_error/1": {
    "body": ["print_chr_error(${1:'Param1'})$2\n$0" ],
    "description":"print_chr_error('Param1')",
    "prefix":"print_chr_error"
  },
  "chr/chr_compiler_options:chr_pp_flag/2": {
    "body": ["chr_pp_flag(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"chr_pp_flag('Param1','Param2')",
    "prefix":"chr_pp_flag"
  },
  "chr/chr_compiler_options:handle_option/2": {
    "body": ["handle_option(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"handle_option('Param1','Param2')",
    "prefix":"handle_option"
  },
  "chr/chr_compiler_options:init_chr_pp_flags/0": {
    "body": ["init_chr_pp_flags$1\n$0" ],
    "description":"init_chr_pp_flags",
    "prefix":"init_chr_pp_flags"
  },
  "chr/chr_compiler_utility:arg1/3": {
    "body": ["arg1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"arg1('Param1','Param2','Param3')",
    "prefix":"arg1"
  },
  "chr/chr_compiler_utility:atom_concat_list/2": {
    "body": ["atom_concat_list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"atom_concat_list('Param1','Param2')",
    "prefix":"atom_concat_list"
  },
  "chr/chr_compiler_utility:conj2list/2": {
    "body": ["conj2list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"conj2list('Param1','Param2')",
    "prefix":"conj2list"
  },
  "chr/chr_compiler_utility:copy_with_variable_replacement/3": {
    "body": [
      "copy_with_variable_replacement(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"copy_with_variable_replacement('Param1','Param2','Param3')",
    "prefix":"copy_with_variable_replacement"
  },
  "chr/chr_compiler_utility:disj2list/2": {
    "body": ["disj2list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"disj2list('Param1','Param2')",
    "prefix":"disj2list"
  },
  "chr/chr_compiler_utility:fold/4": {
    "body": [
      "fold(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"fold('Param1','Param2','Param3','Param4')",
    "prefix":"fold"
  },
  "chr/chr_compiler_utility:fold1/3": {
    "body": ["fold1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"fold1('Param1','Param2','Param3')",
    "prefix":"fold1"
  },
  "chr/chr_compiler_utility:identical_guarded_rules/2": {
    "body": ["identical_guarded_rules(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"identical_guarded_rules('Param1','Param2')",
    "prefix":"identical_guarded_rules"
  },
  "chr/chr_compiler_utility:identical_rules/2": {
    "body": ["identical_rules(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"identical_rules('Param1','Param2')",
    "prefix":"identical_rules"
  },
  "chr/chr_compiler_utility:init/2": {
    "body": ["init(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"init('Param1','Param2')",
    "prefix":"init"
  },
  "chr/chr_compiler_utility:instrument_goal/4": {
    "body": [
      "instrument_goal(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"instrument_goal('Param1','Param2','Param3','Param4')",
    "prefix":"instrument_goal"
  },
  "chr/chr_compiler_utility:list2conj/2": {
    "body": ["list2conj(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"list2conj('Param1','Param2')",
    "prefix":"list2conj"
  },
  "chr/chr_compiler_utility:list2disj/2": {
    "body": ["list2disj(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"list2disj('Param1','Param2')",
    "prefix":"list2disj"
  },
  "chr/chr_compiler_utility:maplist_dcg/5": {
    "body": [
      "maplist_dcg(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"maplist_dcg('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"maplist_dcg"
  },
  "chr/chr_compiler_utility:maplist_dcg/6": {
    "body": [
      "maplist_dcg(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"maplist_dcg('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"maplist_dcg"
  },
  "chr/chr_compiler_utility:member2/3": {
    "body": ["member2(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"member2('Param1','Param2','Param3')",
    "prefix":"member2"
  },
  "chr/chr_compiler_utility:my_term_copy/3": {
    "body": ["my_term_copy(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"my_term_copy('Param1','Param2','Param3')",
    "prefix":"my_term_copy"
  },
  "chr/chr_compiler_utility:my_term_copy/4": {
    "body": [
      "my_term_copy(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"my_term_copy('Param1','Param2','Param3','Param4')",
    "prefix":"my_term_copy"
  },
  "chr/chr_compiler_utility:pair_all_with/3": {
    "body": ["pair_all_with(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"pair_all_with('Param1','Param2','Param3')",
    "prefix":"pair_all_with"
  },
  "chr/chr_compiler_utility:replicate/3": {
    "body": ["replicate(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"replicate('Param1','Param2','Param3')",
    "prefix":"replicate"
  },
  "chr/chr_compiler_utility:select2/6": {
    "body": [
      "select2(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"select2('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"select2"
  },
  "chr/chr_compiler_utility:set_elems/2": {
    "body": ["set_elems(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"set_elems('Param1','Param2')",
    "prefix":"set_elems"
  },
  "chr/chr_compiler_utility:sort_by_key/3": {
    "body": ["sort_by_key(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"sort_by_key('Param1','Param2','Param3')",
    "prefix":"sort_by_key"
  },
  "chr/chr_compiler_utility:time/2": {
    "body": ["time(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"time('Param1','Param2')",
    "prefix":"time"
  },
  "chr/chr_compiler_utility:tree_set_add/3": {
    "body": ["tree_set_add(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"tree_set_add('Param1','Param2','Param3')",
    "prefix":"tree_set_add"
  },
  "chr/chr_compiler_utility:tree_set_empty/1": {
    "body": ["tree_set_empty(${1:'Param1'})$2\n$0" ],
    "description":"tree_set_empty('Param1')",
    "prefix":"tree_set_empty"
  },
  "chr/chr_compiler_utility:tree_set_memberchk/2": {
    "body": ["tree_set_memberchk(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"tree_set_memberchk('Param1','Param2')",
    "prefix":"tree_set_memberchk"
  },
  "chr/chr_compiler_utility:tree_set_merge/3": {
    "body": ["tree_set_merge(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"tree_set_merge('Param1','Param2','Param3')",
    "prefix":"tree_set_merge"
  },
  "chr/chr_compiler_utility:variable_replacement/3": {
    "body": [
      "variable_replacement(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"variable_replacement('Param1','Param2','Param3')",
    "prefix":"variable_replacement"
  },
  "chr/chr_compiler_utility:variable_replacement/4": {
    "body": [
      "variable_replacement(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"variable_replacement('Param1','Param2','Param3','Param4')",
    "prefix":"variable_replacement"
  },
  "chr/chr_compiler_utility:wrap_in_functor/3": {
    "body": [
      "wrap_in_functor(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"wrap_in_functor('Param1','Param2','Param3')",
    "prefix":"wrap_in_functor"
  },
  "chr/chr_debug:chr_show_store/1": {
    "body": ["chr_show_store(${1:Module})$2\n$0" ],
    "description":"\tchr_show_store(+Module)\n\n\tPrints all suspended constraints of module   Mod to the standard\n\toutput.",
    "prefix":"chr_show_store"
  },
  "chr/chr_debug:find_chr_constraint/1": {
    "body": ["find_chr_constraint(${1:'Param1'})$2\n$0" ],
    "description":"find_chr_constraint('Param1')",
    "prefix":"find_chr_constraint"
  },
  "chr/chr_find:find_with_var_identity/4": {
    "body": [
      "find_with_var_identity(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"find_with_var_identity('Param1','Param2','Param3','Param4')",
    "prefix":"find_with_var_identity"
  },
  "chr/chr_find:forall/3": {
    "body": ["forall(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"forall('Param1','Param2','Param3')",
    "prefix":"forall"
  },
  "chr/chr_find:forsome/3": {
    "body": ["forsome(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"forsome('Param1','Param2','Param3')",
    "prefix":"forsome"
  },
  "chr/chr_hashtable_store:delete_first_ht/3": {
    "body": [
      "delete_first_ht(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"delete_first_ht('Param1','Param2','Param3')",
    "prefix":"delete_first_ht"
  },
  "chr/chr_hashtable_store:delete_ht/3": {
    "body": ["delete_ht(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"delete_ht('Param1','Param2','Param3')",
    "prefix":"delete_ht"
  },
  "chr/chr_hashtable_store:delete_ht1/4": {
    "body": [
      "delete_ht1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"delete_ht1('Param1','Param2','Param3','Param4')",
    "prefix":"delete_ht1"
  },
  "chr/chr_hashtable_store:insert_ht/3": {
    "body": ["insert_ht(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"insert_ht('Param1','Param2','Param3')",
    "prefix":"insert_ht"
  },
  "chr/chr_hashtable_store:insert_ht/4": {
    "body": [
      "insert_ht(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"insert_ht('Param1','Param2','Param3','Param4')",
    "prefix":"insert_ht"
  },
  "chr/chr_hashtable_store:insert_ht1/4": {
    "body": [
      "insert_ht1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"insert_ht1('Param1','Param2','Param3','Param4')",
    "prefix":"insert_ht1"
  },
  "chr/chr_hashtable_store:lookup_ht/3": {
    "body": ["lookup_ht(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"lookup_ht('Param1','Param2','Param3')",
    "prefix":"lookup_ht"
  },
  "chr/chr_hashtable_store:lookup_ht1/4": {
    "body": [
      "lookup_ht1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"lookup_ht1('Param1','Param2','Param3','Param4')",
    "prefix":"lookup_ht1"
  },
  "chr/chr_hashtable_store:lookup_ht2/4": {
    "body": [
      "lookup_ht2(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"lookup_ht2('Param1','Param2','Param3','Param4')",
    "prefix":"lookup_ht2"
  },
  "chr/chr_hashtable_store:new_ht/1": {
    "body": ["new_ht(${1:'Param1'})$2\n$0" ],
    "description":"new_ht('Param1')",
    "prefix":"new_ht"
  },
  "chr/chr_hashtable_store:stats_ht/1": {
    "body": ["stats_ht(${1:'Param1'})$2\n$0" ],
    "description":"stats_ht('Param1')",
    "prefix":"stats_ht"
  },
  "chr/chr_hashtable_store:value_ht/2": {
    "body": ["value_ht(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"value_ht('Param1','Param2')",
    "prefix":"value_ht"
  },
  "chr/chr_integertable_store:delete_iht/3": {
    "body": ["delete_iht(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"delete_iht('Param1','Param2','Param3')",
    "prefix":"delete_iht"
  },
  "chr/chr_integertable_store:insert_iht/3": {
    "body": ["insert_iht(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"insert_iht('Param1','Param2','Param3')",
    "prefix":"insert_iht"
  },
  "chr/chr_integertable_store:lookup_iht/3": {
    "body": ["lookup_iht(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"lookup_iht('Param1','Param2','Param3')",
    "prefix":"lookup_iht"
  },
  "chr/chr_integertable_store:new_iht/1": {
    "body": ["new_iht(${1:'Param1'})$2\n$0" ],
    "description":"new_iht('Param1')",
    "prefix":"new_iht"
  },
  "chr/chr_integertable_store:value_iht/2": {
    "body": ["value_iht(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"value_iht('Param1','Param2')",
    "prefix":"value_iht"
  },
  "chr/chr_messages:chr_message/3": {
    "body": ["chr_message(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"chr_message('Param1','Param2','Param3')",
    "prefix":"chr_message"
  },
  "chr/chr_runtime:chr_leash/1": {
    "body": ["chr_leash(${1:'Param1'})$2\n$0" ],
    "description":"chr_leash('Param1')",
    "prefix":"chr_leash"
  },
  "chr/chr_runtime:chr_notrace/0": {
    "body": ["chr_notrace$1\n$0" ],
    "description":"chr_notrace",
    "prefix":"chr_notrace"
  },
  "chr/chr_runtime:chr_show_store/1": {
    "body": ["chr_show_store(${1:'Param1'})$2\n$0" ],
    "description":"chr_show_store('Param1')",
    "prefix":"chr_show_store"
  },
  "chr/chr_runtime:chr_trace/0": {
    "body": ["chr_trace$1\n$0" ],
    "description":"chr_trace",
    "prefix":"chr_trace"
  },
  "chr/chr_runtime:current_chr_constraint/1": {
    "body": ["current_chr_constraint(${1:Constraint})$2\n$0" ],
    "description":"\tcurrent_chr_constraint(:Constraint) is nondet.\n\n\tTrue if Constraint is a constraint associated with the qualified\n\tmodule.",
    "prefix":"current_chr_constraint"
  },
  "chr/chr_runtime:find_chr_constraint/1": {
    "body": ["find_chr_constraint(${1:Constraint})$2\n$0" ],
    "description":"\tfind_chr_constraint(-Constraint) is nondet.\n\n\tTrue when Constraint is a  currently   known  constraint  in any\n\tknown CHR module.\n\n\t@deprecated\tcurrent_chr_constraint/1 handles modules.",
    "prefix":"find_chr_constraint"
  },
  "chr/chr_translate:chr_translate/2": {
    "body": ["chr_translate(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"chr_translate('Param1','Param2')",
    "prefix":"chr_translate"
  },
  "chr/chr_translate:chr_translate_line_info/3": {
    "body": [
      "chr_translate_line_info(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"chr_translate_line_info('Param1','Param2','Param3')",
    "prefix":"chr_translate_line_info"
  },
  "chr/clean_code:clean_clauses/2": {
    "body": ["clean_clauses(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"clean_clauses('Param1','Param2')",
    "prefix":"clean_clauses"
  },
  "chr/guard_entailment:entails_guard/2": {
    "body": ["entails_guard(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"entails_guard('Param1','Param2')",
    "prefix":"entails_guard"
  },
  "chr/guard_entailment:simplify_guards/5": {
    "body": [
      "simplify_guards(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"simplify_guards('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"simplify_guards"
  },
  "chr/listmap:listmap_empty/1": {
    "body": ["listmap_empty(${1:'Param1'})$2\n$0" ],
    "description":"listmap_empty('Param1')",
    "prefix":"listmap_empty"
  },
  "chr/listmap:listmap_insert/4": {
    "body": [
      "listmap_insert(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"listmap_insert('Param1','Param2','Param3','Param4')",
    "prefix":"listmap_insert"
  },
  "chr/listmap:listmap_lookup/3": {
    "body": ["listmap_lookup(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"listmap_lookup('Param1','Param2','Param3')",
    "prefix":"listmap_lookup"
  },
  "chr/listmap:listmap_merge/5": {
    "body": [
      "listmap_merge(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"listmap_merge('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"listmap_merge"
  },
  "chr/listmap:listmap_remove/3": {
    "body": ["listmap_remove(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"listmap_remove('Param1','Param2','Param3')",
    "prefix":"listmap_remove"
  },
  "chr/pairlist:fst_of_pairs/2": {
    "body": ["fst_of_pairs(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"fst_of_pairs('Param1','Param2')",
    "prefix":"fst_of_pairs"
  },
  "chr/pairlist:lookup/3": {
    "body": ["lookup(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"lookup('Param1','Param2','Param3')",
    "prefix":"lookup"
  },
  "chr/pairlist:lookup_any/3": {
    "body": ["lookup_any(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"lookup_any('Param1','Param2','Param3')",
    "prefix":"lookup_any"
  },
  "chr/pairlist:lookup_any_eq/3": {
    "body": ["lookup_any_eq(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"lookup_any_eq('Param1','Param2','Param3')",
    "prefix":"lookup_any_eq"
  },
  "chr/pairlist:lookup_eq/3": {
    "body": ["lookup_eq(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"lookup_eq('Param1','Param2','Param3')",
    "prefix":"lookup_eq"
  },
  "chr/pairlist:pairlist_delete_eq/3": {
    "body": [
      "pairlist_delete_eq(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"pairlist_delete_eq('Param1','Param2','Param3')",
    "prefix":"pairlist_delete_eq"
  },
  "chr/pairlist:pairup/3": {
    "body": ["pairup(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"pairup('Param1','Param2','Param3')",
    "prefix":"pairup"
  },
  "chr/pairlist:snd_of_pairs/2": {
    "body": ["snd_of_pairs(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"snd_of_pairs('Param1','Param2')",
    "prefix":"snd_of_pairs"
  },
  "chr/pairlist:translate/3": {
    "body": ["translate(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"translate('Param1','Param2','Param3')",
    "prefix":"translate"
  },
  "chr:chr_leash/1": {
    "body": ["chr_leash(${1:'Param1'})$2\n$0" ],
    "description":"chr_leash('Param1')",
    "prefix":"chr_leash"
  },
  "chr:chr_notrace/0": {
    "body": ["chr_notrace$1\n$0" ],
    "description":"chr_notrace",
    "prefix":"chr_notrace"
  },
  "chr:chr_show_store/1": {
    "body": ["chr_show_store(${1:'Param1'})$2\n$0" ],
    "description":"chr_show_store('Param1')",
    "prefix":"chr_show_store"
  },
  "chr:chr_trace/0": {
    "body": ["chr_trace$1\n$0" ],
    "description":"chr_trace",
    "prefix":"chr_trace"
  },
  "chr:find_chr_constraint/1": {
    "body": ["find_chr_constraint(${1:'Param1'})$2\n$0" ],
    "description":"find_chr_constraint('Param1')",
    "prefix":"find_chr_constraint"
  },
  "chr_leash/1": {
    "body":"chr_leash(${1:Spec})$2\n$0",
    "description":"chr_leash(+Spec).\nDefine the set of CHR ports on which the CHR tracer asks for user  intervention (i.e. stops). Spec is either a list of ports as  defined in section 8.4.1 or a  predefined `alias'. Defined aliases are: full to stop at  all ports, none or off to never stop, and default  to stop at the call, exit, fail, wake and apply  ports. See also leash/1.",
    "prefix":"chr_leash"
  },
  "chr_notrace/0": {
    "body":"chr_notrace$1\n$0",
    "description":"chr_notrace.\nDeactivate the CHR tracer. By default the CHR tracer is activated and  deactivated automatically by the Prolog predicates trace/0  and notrace/0.",
    "prefix":"chr_notrace"
  },
  "chr_show_store/1": {
    "body":"chr_show_store(${1:Mod})$2\n$0",
    "description":"chr_show_store(+Mod).\nPrints all suspended constraints of module Mod to the  standard output. This predicate is automatically called by the  SWI-Prolog top level at the end of each query for every CHR module  currently loaded. The Prolog flag chr_toplevel_show_store controls whether the top level  shows the constraint stores. The value true enables it. Any  other value disables it.",
    "prefix":"chr_show_store"
  },
  "chr_trace/0": {
    "body":"chr_trace$1\n$0",
    "description":"chr_trace.\nActivate the CHR tracer. By default the CHR tracer is activated and  deactivated automatically by the Prolog predicates trace/0  and notrace/0.",
    "prefix":"chr_trace"
  },
  "clause/2": {
    "body":"clause(${1:Head}, ${2:Body})$3\n$0",
    "description":"[ISO]clause(:Head, ?Body).\nTrue if Head can be unified with a clause head and Body  with the corresponding clause body. Gives alternative clauses on  backtracking. For facts, Body is unified with the atom true.",
    "prefix":"clause"
  },
  "clause/3": {
    "body":"clause(${1:Head}, ${2:Body}, ${3:Reference})$4\n$0",
    "description":"clause(:Head, ?Body, ?Reference).\nEquivalent to clause/2,  but unifies Reference with a unique reference to the clause  (see also assert/2, erase/1).  If Reference is instantiated to a reference the clause's head  and body will be unified with Head and Body.",
    "prefix":"clause"
  },
  "clause_property/2": {
    "body":"clause_property(${1:ClauseRef}, ${2:Property})$3\n$0",
    "description":"clause_property(+ClauseRef, -Property).\nQueries properties of a clause. ClauseRef is a reference to a  clause as produced by clause/3, nth_clause/3  or prolog_frame_attribute/3.  Unlike most other predicates that access clause references, clause_property/2  may be used to get information about erased clauses that have not yet  been reclaimed. Property is one of the following:  file(FileName): Unify FileName with the name of the file from which the  clause is loaded. Fails if the clause was not created by loading a file  (e.g., clauses added using assertz/1).  See also source.\n\nline_count(LineNumber): Unify LineNumber with the line number of the clause. Fails if  the clause is not associated to a file.\n\nsize(SizeInBytes): True when SizeInBytes is the size that the clause uses in  memory in bytes. The size required by a predicate also includes the  predicate data record, a linked list of clauses, clause selection  instructions and optionally one or more clause indexes.\n\nsource(FileName): Unify FileName with the name of the source file that created  the clause. This is the same as the file property, unless  the file is loaded from a file that is textually included into source  using include/1.  In this scenario, file is the included file, while the source  property refers to the main file.\n\nfact: True if the clause has no body.\n\nerased: True if the clause has been erased, but not yet reclaimed because it is  referenced.\n\npredicate(PredicateIndicator): PredicateIndicator denotes the predicate to which this clause  belongs. This is needed to obtain information on erased clauses because  the usual way to obtain this information using clause/3  fails for erased clauses.\n\nmodule(Module): Module is the context module used to execute the body of the  clause. For normal clauses, this is the same as the module in which the  predicate is defined. However, if a clause is compiled with a module  qualified head, the clause belongs to the predicate with the  qualified head, while the body is executed in the context of the module  in which the clause was defined.\n\n ",
    "prefix":"clause_property"
  },
  "clib_rlimit:rlimit/3": {
    "body": ["rlimit(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"rlimit('Param1','Param2','Param3')",
    "prefix":"rlimit"
  },
  "close/1": {
    "body":"close(${1:Stream})$2\n$0",
    "description":"[ISO]close(+Stream).\nClose the specified stream. If Stream is not open, an  existence error is raised. See stream_pair/3  for the implications of closing a stream pair.  If the closed stream is the current input, output or error stream,  the stream alias is bound to the initial standard I/O streams of the  process. Calling close/1  on the initial standard I/O streams of the process is a no-op for an  input stream and flushes an output stream without closing it.79This  behaviour was defined with purely interactive usage of Prolog in mind.  Applications should not count on this behaviour. Future versions may  allow for closing the initial standard I/O streams.\n\n",
    "prefix":"close"
  },
  "close/2": {
    "body":"close(${1:Stream}, ${2:Options})$3\n$0",
    "description":"[ISO]close(+Stream, +Options).\nProvides close(Stream, [force(true)]) as the only option.  Called this way, any resource errors (such as write errors while  flushing the output buffer) are ignored.",
    "prefix":"close"
  },
  "close_dde_conversation/1": {
    "body":"close_dde_conversation(${1:Handle})$2\n$0",
    "description":"close_dde_conversation(+Handle).\nClose the conversation associated with Handle. All opened  conversations should be closed when they're no longer needed, although  the system will close any that remain open on process termination.",
    "prefix":"close_dde_conversation"
  },
  "close_table/1": {
    "body":"close_table(${1:Handle})$2\n$0",
    "description":"close_table(+Handle).\nClose the file and other system resources, but do not remove the  description of the table, so it can be re-opened later.",
    "prefix":"close_table"
  },
  "clp_distinct:all_distinct/1": {
    "body": ["all_distinct(${1:'Param1'})$2\n$0" ],
    "description":"all_distinct('Param1')",
    "prefix":"all_distinct"
  },
  "clp_distinct:vars_in/2": {
    "body": ["vars_in(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"vars_in('Param1','Param2')",
    "prefix":"vars_in"
  },
  "clp_distinct:vars_in/3": {
    "body": ["vars_in(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"vars_in('Param1','Param2','Param3')",
    "prefix":"vars_in"
  },
  "clp_events:notify/2": {
    "body": ["notify(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"notify('Param1','Param2')",
    "prefix":"notify"
  },
  "clp_events:subscribe/4": {
    "body": [
      "subscribe(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"subscribe('Param1','Param2','Param3','Param4')",
    "prefix":"subscribe"
  },
  "clp_events:unsubscribe/2": {
    "body": ["unsubscribe(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"unsubscribe('Param1','Param2')",
    "prefix":"unsubscribe"
  },
  "clpb:labeling/1": {
    "body":"labeling(${1:Vs})$2\n$0",
    "description":"[multi]labeling(+Vs).\nEnumerate concrete solutions. Assigns truth values to the Boolean  variables Vs such that all stated constraints are satisfied.",
    "prefix":"labeling"
  },
  "clpb:random_labeling/2": {
    "body":"random_labeling(${1:Seed}, ${2:Vs})$3\n$0",
    "description":"[det]random_labeling(+Seed, +Vs).\nSelect a single random solution. An admissible assignment of truth  values to the Boolean variables in Vs is chosen in such a way  that each admissible assignment is equally likely. Seed is an  integer, used as the initial seed for the random number generator.",
    "prefix":"random_labeling"
  },
  "clpb:sat/1": {
    "body":"sat(${1:Expr})$2\n$0",
    "description":"[semidet]sat(+Expr).\nTrue iff Expr is a satisfiable Boolean expression.",
    "prefix":"sat"
  },
  "clpb:sat_count/2": {
    "body":"sat_count(${1:Expr}, ${2:Count})$3\n$0",
    "description":"[det]sat_count(+Expr, -Count).\nCount the number of admissible assignments. Count  is the number of different assignments of truth values to the variables  in the Boolean expression Expr, such that Expr is  true and all posted constraints are satisfiable.  A common form of invocation is sat_count(+[1|Vs], Count):  This counts the number of admissible assignments to Vs  without imposing any further constraints. \n\nExamples: \n\n\n\n?- sat(A =< B), Vs = [A,B], sat_count(+[1|Vs], Count).\nVs = [A, B],\nCount = 3,\nsat(A=:=A*B).\n\n?- length(Vs, 120),\n   sat_count(+Vs, CountOr),\n   sat_count(*(Vs), CountAnd).\nVs = [...],\nCountOr = 1329227995784915872903807060280344575,\nCountAnd = 1.\n\n ",
    "prefix":"sat_count"
  },
  "clpb:taut/2": {
    "body":"taut(${1:Expr}, ${2:T})$3\n$0",
    "description":"[semidet]taut(+Expr, -T).\nTautology check. Succeeds with T = 0 if the Boolean  expression Expr cannot be satisfied, and with T =  1 if Expr is always true with respect to the current  constraints. Fails otherwise.",
    "prefix":"taut"
  },
  "clpb:weighted_maximum/3": {
    "body":"weighted_maximum(${1:Weights}, ${2:Vs}, ${3:Maximum})$4\n$0",
    "description":"[multi]weighted_maximum(+Weights, +Vs, -Maximum).\nEnumerate weighted optima over admissible assignments. Maximize a linear  objective function over Boolean variables Vs with integer  coefficients Weights. This predicate assigns 0 and 1 to the  variables in Vs such that all stated constraints are  satisfied, and Maximum is the maximum of sum(Weight_i*V_i) over  all admissible assignments. On backtracking, all admissible assignments  that attain the optimum are generated.  This predicate can also be used to minimize a linear Boolean  program, since negative integers can appear in Weights. \n\nExample: \n\n\n\n?- sat(A#B), weighted_maximum([1,2,1], [A,B,C], Maximum).\nA = 0, B = 1, C = 1, Maximum = 3.\n\n ",
    "prefix":"weighted_maximum"
  },
  "clpfd:all_different/1": {
    "body":"all_different(${1:Vars})$2\n$0",
    "description":"all_different(+Vars).\nLike all_distinct/1,  but with weaker propagation. Consider using all_distinct/1  instead, since all_distinct/1  is typically acceptably efficient and propagates much more strongly.",
    "prefix":"all_different"
  },
  "clpfd:all_distinct/1": {
    "body":"all_distinct(${1:Vars})$2\n$0",
    "description":"all_distinct(+Vars).\nTrue iff Vars are pairwise distinct. For example, all_distinct/1  can detect that not all variables can assume distinct values given the  following domains:  \n\n?- maplist(in, Vs,\n           [1\\/3..4, 1..2\\/4, 1..2\\/4, 1..3, 1..3, 1..6]),\n   all_distinct(Vs).\nfalse.\n\n ",
    "prefix":"all_distinct"
  },
  "clpfd:automaton/3": {
    "body":"automaton(${1:Vs}, ${2:Nodes}, ${3:Arcs})$4\n$0",
    "description":"automaton(+Vs, +Nodes, +Arcs).\nDescribes a list of finite domain variables with a finite automaton.  Equivalent to automaton(Vs, _, Vs, Nodes, Arcs, [], [], _),  a common use case of automaton/8.  In the following example, a list of binary finite domain variables is  constrained to contain at least two consecutive ones:  \n\ntwo_consecutive_ones(Vs) :-\n        automaton(Vs, [source(a),sink(c)],\n                  [arc(a,0,a), arc(a,1,b),\n                   arc(b,0,a), arc(b,1,c),\n                   arc(c,0,c), arc(c,1,c)]).\n\n  Example query: \n\n\n\n?- length(Vs, 3), two_consecutive_ones(Vs), label(Vs).\nVs = [0, 1, 1] ;\nVs = [1, 1, 0] ;\nVs = [1, 1, 1].\n\n ",
    "prefix":"automaton"
  },
  "clpfd:automaton/8": {
    "body":"automaton(${1:Sequence}, ${2:Template}, ${3:Signature}, ${4:Nodes}, ${5:Arcs}, ${6:Counters}, ${7:Initials}, ${8:Finals})$9\n$0",
    "description":"automaton(+Sequence, ?Template, +Signature, +Nodes, +Arcs, +Counters, +Initials, ?Finals).\nDescribes a list of finite domain variables with a finite automaton.  True iff the finite automaton induced by Nodes and Arcs  (extended with Counters) accepts Signature. Sequence  is a list of terms, all of the same shape. Additional constraints must  link Sequence to Signature, if necessary. Nodes  is a list of source(Node) and sink(Node) terms. Arcs  is a list of arc(Node,Integer,Node) and arc(Node,Integer,Node,Exprs)  terms that denote the automaton's transitions. Each node is represented  by an arbitrary term. Transitions that are not mentioned go to an  implicit failure node. Exprs is a list of arithmetic  expressions, of the same length as Counters. In each  expression, variables occurring in Counters symbolically  refer to previous counter values, and variables occurring in Template  refer to the current element of Sequence. When a transition  containing arithmetic expressions is taken, each counter is updated  according to the result of the corresponding expression. When a  transition without arithmetic expressions is taken, all counters remain  unchanged. Counters is a list of variables. Initials is a  list of finite domain variables or integers denoting, in the same order,  the initial value of each counter. These values are related to Finals  according to the arithmetic expressions of the taken transitions.  The following example is taken from Beldiceanu, Carlsson, Debruyne  and Petit: \"Reformulation of Global Constraints Based on Constraints  Checkers\", Constraints 10(4), pp 339-362 (2005). It relates a sequence  of integers and finite domain variables to its number of inflexions,  which are switches between strictly ascending and strictly descending  subsequences: \n\n\n\nsequence_inflexions(Vs, N) :-\n        variables_signature(Vs, Sigs),\n        automaton(Sigs, _, Sigs,\n                  [source(s),sink(i),sink(j),sink(s)],\n                  [arc(s,0,s), arc(s,1,j), arc(s,2,i),\n                   arc(i,0,i), arc(i,1,j,[C+1]), arc(i,2,i),\n                   arc(j,0,j), arc(j,1,j),\n                   arc(j,2,i,[C+1])],\n                  [C], [0], [N]).\n\nvariables_signature([], []).\nvariables_signature([V|Vs], Sigs) :-\n        variables_signature_(Vs, V, Sigs).\n\nvariables_signature_([], _, []).\nvariables_signature_([V|Vs], Prev, [S|Sigs]) :-\n        V #= Prev #<==> S #= 0,\n        Prev #< V #<==> S #= 1,\n        Prev #> V #<==> S #= 2,\n        variables_signature_(Vs, V, Sigs).\n\n  Example queries: \n\n\n\n?- sequence_inflexions([1,2,3,3,2,1,3,0], N).\nN = 3.\n\n?- length(Ls, 5), Ls ins 0..1,\n   sequence_inflexions(Ls, 3), label(Ls).\nLs = [0, 1, 0, 1, 0] ;\nLs = [1, 0, 1, 0, 1].\n\n ",
    "prefix":"automaton"
  },
  "clpfd:chain/2": {
    "body":"chain(${1:Zs}, ${2:Relation})$3\n$0",
    "description":"chain(+Zs, +Relation).\nZs form a chain with respect to Relation. Zs  is a list of finite domain variables that are a chain with respect to  the partial order Relation, in the order they appear in the list. Relation  must be #=, #=<, #>=, #< or #>.  For example:  \n\n?- chain([X,Y,Z], #>=).\nX#>=Y,\nY#>=Z.\n\n  \n\n",
    "prefix":"chain"
  },
  "clpfd:circuit/1": {
    "body":"circuit(${1:Vs})$2\n$0",
    "description":"circuit(+Vs).\nTrue iff the list Vs of finite domain variables induces a  Hamiltonian circuit. The k-th element of Vs denotes the  successor of node k. Node indexing starts with 1. Examples:  \n\n?- length(Vs, _), circuit(Vs), label(Vs).\nVs = [] ;\nVs = [1] ;\nVs = [2, 1] ;\nVs = [2, 3, 1] ;\nVs = [3, 1, 2] ;\nVs = [2, 3, 4, 1] .\n\n ",
    "prefix":"circuit"
  },
  "clpfd:cumulative/1": {
    "body":"cumulative(${1:Tasks})$2\n$0",
    "description":"cumulative(+Tasks).\nEquivalent to cumulative(Tasks, [limit(1)]). See cumulative/2.",
    "prefix":"cumulative"
  },
  "clpfd:cumulative/2": {
    "body":"cumulative(${1:Tasks}, ${2:Options})$3\n$0",
    "description":"cumulative(+Tasks, +Options).\nSchedule with a limited resource. Tasks is a list of tasks,  each of the form task(S_i, D_i, E_i, C_i, T_i). S_i denotes  the start time, D_i the positive duration, E_i the end time, C_i the  non-negative resource consumption, and T_i the task identifier. Each of  these arguments must be a finite domain variable with bounded domain, or  an integer. The constraint holds iff at each time slot during the start  and end of each task, the total resource consumption of all tasks  running at that time does not exceed the global resource limit. Options  is a list of options. Currently, the only supported option is:  limit(L): The integer L is the global resource limit. Default is 1.\n\n  For example, given the following predicate that relates three tasks  of durations 2 and 3 to a list containing their starting times: \n\n\n\ntasks_starts(Tasks, [S1,S2,S3]) :-\n        Tasks = [task(S1,3,_,1,_),\n                 task(S2,2,_,1,_),\n                 task(S3,2,_,1,_)].\n\n  We can use cumulative/2  as follows, and obtain a schedule: \n\n\n\n?- tasks_starts(Tasks, Starts), Starts ins 0..10,\n   cumulative(Tasks, [limit(2)]), label(Starts).\nTasks = [task(0, 3, 3, 1, _G36), task(0, 2, 2, 1, _G45), ...],\nStarts = [0, 0, 2] .\n\n ",
    "prefix":"cumulative"
  },
  "clpfd:disjoint2/1": {
    "body":"disjoint2(${1:Rectangles})$2\n$0",
    "description":"disjoint2(+Rectangles).\nTrue iff Rectangles are not overlapping. Rectangles  is a list of terms of the form F(X_i, W_i, Y_i, H_i), where F is any  functor, and the arguments are finite domain variables or integers that  denote, respectively, the X coordinate, width, Y coordinate and height  of each rectangle.",
    "prefix":"disjoint2"
  },
  "clpfd:element/3": {
    "body":"element(${1:N}, ${2:Vs}, ${3:V})$4\n$0",
    "description":"element(?N, +Vs, ?V).\nThe N-th element of the list of finite domain variables Vs  is V. Analogous to nth1/3.",
    "prefix":"element"
  },
  "clpfd:fd_dom/2": {
    "body":"fd_dom(${1:Var}, ${2:Dom})$3\n$0",
    "description":"fd_dom(+Var, -Dom).\nDom is the current domain (see in/2)  of Var. This predicate is useful if you want to reason about  domains. It is not needed if you only want to display remaining  domains; instead, separate your model from the search part and let the  toplevel display this information via residual goals.  For example, to implement a custom labeling strategy, you may need to  inspect the current domain of a finite domain variable. With the  following code, you can convert a finite domain to a list of  integers: \n\n\n\ndom_integers(D, Is) :- phrase(dom_integers_(D), Is).\n\ndom_integers_(I)      --> { integer(I) }, [I].\ndom_integers_(L..U)   --> { numlist(L, U, Is) }, Is.\ndom_integers_(D1\\/D2) --> dom_integers_(D1), dom_integers_(D2).\n\n  Example: \n\n\n\n?- X in 1..5, X #\\= 4, fd_dom(X, D), dom_integers(D, Is).\nD = 1..3\\/5,\nIs = [1,2,3,5],\nX in 1..3\\/5.\n\n  \n\n",
    "prefix":"fd_dom"
  },
  "clpfd:fd_inf/2": {
    "body":"fd_inf(${1:Var}, ${2:Inf})$3\n$0",
    "description":"fd_inf(+Var, -Inf).\nInf is the infimum of the current domain of Var.",
    "prefix":"fd_inf"
  },
  "clpfd:fd_size/2": {
    "body":"fd_size(${1:Var}, ${2:Size})$3\n$0",
    "description":"fd_size(+Var, -Size).\nReflect the current size of a domain. Size is the number of  elements of the current domain of Var, or the atom sup  if the domain is unbounded.",
    "prefix":"fd_size"
  },
  "clpfd:fd_sup/2": {
    "body":"fd_sup(${1:Var}, ${2:Sup})$3\n$0",
    "description":"fd_sup(+Var, -Sup).\nSup is the supremum of the current domain of Var.",
    "prefix":"fd_sup"
  },
  "clpfd:fd_var/1": {
    "body":"fd_var(${1:Var})$2\n$0",
    "description":"fd_var(+Var).\nTrue iff Var is a CLP(FD) variable.",
    "prefix":"fd_var"
  },
  "clpfd:global_cardinality/2": {
    "body":"global_cardinality(${1:Vs}, ${2:Pairs})$3\n$0",
    "description":"global_cardinality(+Vs, +Pairs).\nGlobal Cardinality constraint. Equivalent to global_cardinality(Vs, Pairs, []). See global_cardinality/3.  Example: \n\n\n\n?- Vs = [_,_,_], global_cardinality(Vs, [1-2,3-_]), label(Vs).\nVs = [1, 1, 3] ;\nVs = [1, 3, 1] ;\nVs = [3, 1, 1].\n\n ",
    "prefix":"global_cardinality"
  },
  "clpfd:global_cardinality/3": {
    "body":"global_cardinality(${1:Vs}, ${2:Pairs}, ${3:Options})$4\n$0",
    "description":"global_cardinality(+Vs, +Pairs, +Options).\nGlobal Cardinality constraint. Vs is a list of finite domain  variables, Pairs is a list of Key-Num pairs, where Key is an  integer and Num is a finite domain variable. The constraint holds iff  each V in Vs is equal to some key, and for each Key-Num pair  in Pairs, the number of occurrences of Key in Vs  is Num. Options is a list of options. Supported options are:  consistency(value): A weaker form of consistency is used.\n\ncost(Cost, Matrix): Matrix is a list of rows, one for each variable, in the order  they occur in Vs. Each of these rows is a list of integers,  one for each key, in the order these keys occur in Pairs.  When variable v_i is assigned the value of key k_j, then the associated  cost is Matrix_{ij}. Cost is the sum of all costs.\n\n ",
    "prefix":"global_cardinality"
  },
  "clpfd:in/2": {
    "body": ["in(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"in('Param1','Param2')",
    "prefix":"in"
  },
  "clpfd:indomain/1": {
    "body":"indomain(${1:Var})$2\n$0",
    "description":"indomain(?Var).\nBind Var to all feasible values of its domain on  backtracking. The domain of Var must be finite.",
    "prefix":"indomain"
  },
  "clpfd:ins/2": {
    "body": ["ins(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"ins('Param1','Param2')",
    "prefix":"ins"
  },
  "clpfd:label/1": {
    "body":"label(${1:Vars})$2\n$0",
    "description":"label(+Vars).\nEquivalent to labeling([], Vars). See labeling/2.",
    "prefix":"label"
  },
  "clpfd:labeling/2": {
    "body":"labeling(${1:Options}, ${2:Vars})$3\n$0",
    "description":"labeling(+Options, +Vars).\nAssign a value to each variable in Vars. Labeling means  systematically trying out values for the finite domain variables Vars  until all of them are ground. The domain of each variable in Vars  must be finite. Options is a list of options that let you exhibit some  control over the search process. Several categories of options exist:  The variable selection strategy lets you specify which variable of Vars is labeled next and is one of: \n\nleftmost: Label the variables in the order they occur in Vars. This is  the default.\n\nff: First fail. Label the leftmost variable with smallest domain  next, in order to detect infeasibility early. This is often a good  strategy.\n\nffc: Of the variables with smallest domains, the leftmost one participating  in most constraints is labeled next.\n\nmin: Label the leftmost variable whose lower bound is the lowest next.\n\nmax: Label the leftmost variable whose upper bound is the highest next.\n\n  The value order is one of: \n\nup: Try the elements of the chosen variable's domain in ascending order.  This is the default.\n\ndown: Try the domain elements in descending order.\n\n  The branching strategy is one of: \n\nstep: For each variable X, a choice is made between X = V and X #\\=  V, where V is determined by the value ordering options. This is the  default.\n\nenum: For each variable X, a choice is made between X = V_1, X = V_2 etc., for  all values V_i of the domain of X. The order is determined by the value  ordering options.\n\nbisect: For each variable X, a choice is made between X #=< M  and X #> M, where M is the midpoint of the domain of X.\n\n  At most one option of each category can be specified, and an option  must not occur repeatedly. \n\nThe order of solutions can be influenced with: \n\n\n\nmin(Expr)\nmax(Expr)\n\n  This generates solutions in ascending/descending order with respect  to the evaluation of the arithmetic expression Expr. Labeling Vars  must make Expr ground. If several such options are specified, they are  interpreted from left to right, e.g.: \n\n\n\n?- [X,Y] ins 10..20, labeling([max(X),min(Y)],[X,Y]).\n\n  This generates solutions in descending order of X, and for each  binding of X, solutions are generated in ascending order of Y. To obtain  the incomplete behaviour that other systems exhibit with \"maximize(Expr)\"  and \"minimize(Expr)\", use once/1,  e.g.: \n\n\n\nonce(labeling([max(Expr)], Vars))\n\n  Labeling is always complete, always terminates, and yields no  redundant solutions. See core relations and search (section  A.8.9) for usage advice.\n\n",
    "prefix":"labeling"
  },
  "clpfd:lex_chain/1": {
    "body":"lex_chain(${1:Lists})$2\n$0",
    "description":"lex_chain(+Lists).\nLists are lexicographically non-decreasing.",
    "prefix":"lex_chain"
  },
  "clpfd:scalar_product/4": {
    "body":"scalar_product(${1:Cs}, ${2:Vs}, ${3:Rel}, ${4:Expr})$5\n$0",
    "description":"scalar_product(+Cs, +Vs, +Rel, ?Expr).\nTrue iff the scalar product of Cs and Vs is in  relation Rel to Expr. Cs is a list of integers, Vs is a list of  variables and integers. Rel is #=, #\\=, #<, #>, #=<  or #>=.",
    "prefix":"scalar_product"
  },
  "clpfd:serialized/2": {
    "body":"serialized(${1:Starts}, ${2:Durations})$3\n$0",
    "description":"serialized(+Starts, +Durations).\nDescribes a set of non-overlapping tasks. Starts = [S_1,...,S_n], is a list of variables or integers, Durations = [D_1,...,D_n] is a list of non-negative integers.  Constrains Starts and Durations to denote a set of  non-overlapping tasks, i.e.: S_i + D_i =< S_j or S_j +  D_j =< S_i for all 1 =< i <  j =< n. Example:  \n\n?- length(Vs, 3),\n   Vs ins 0..3,\n   serialized(Vs, [1,2,3]),\n   label(Vs).\nVs = [0, 1, 3] ;\nVs = [2, 0, 3] ;\nfalse.\n\n  See also: Dorndorf et al. 2000, \"Constraint Propagation Techniques for the  Disjunctive Scheduling Problem\"\n\n ",
    "prefix":"serialized"
  },
  "clpfd:sum/3": {
    "body":"sum(${1:Vars}, ${2:Rel}, ${3:Expr})$4\n$0",
    "description":"sum(+Vars, +Rel, ?Expr).\nThe sum of elements of the list Vars is in relation Rel  to Expr. Rel is one of #=, #\\=, #<, #>, #=<  or #>=. For example:  \n\n?- [A,B,C] ins 0..sup, sum([A,B,C], #=, 100).\nA in 0..100,\nA+B+C#=100,\nB in 0..100,\nC in 0..100.\n\n ",
    "prefix":"sum"
  },
  "clpfd:transpose/2": {
    "body": ["transpose(${1:Matrix}, ${2:Transpose})$3\n$0" ],
    "description":" transpose(+Matrix, ?Transpose)\n\n  Transpose a list of lists of the same length. Example:\n\n  ==\n  ?- transpose([[1,2,3],[4,5,6],[7,8,9]], Ts).\n  Ts = [[1, 4, 7], [2, 5, 8], [3, 6, 9]].\n  ==\n\n  This predicate is useful in many constraint programs. Consider for\n  instance Sudoku:\n\n  ==\n  sudoku(Rows) :-\n          length(Rows, 9), maplist(same_length(Rows), Rows),\n          append(Rows, Vs), Vs ins 1..9,\n          maplist(all_distinct, Rows),\n          transpose(Rows, Columns),\n          maplist(all_distinct, Columns),\n          Rows = [As,Bs,Cs,Ds,Es,Fs,Gs,Hs,Is],\n          blocks(As, Bs, Cs), blocks(Ds, Es, Fs), blocks(Gs, Hs, Is).\n\n  blocks([], [], []).\n  blocks([N1,N2,N3|Ns1], [N4,N5,N6|Ns2], [N7,N8,N9|Ns3]) :-\n          all_distinct([N1,N2,N3,N4,N5,N6,N7,N8,N9]),\n          blocks(Ns1, Ns2, Ns3).\n\n  problem(1, [[_,_,_,_,_,_,_,_,_],\n              [_,_,_,_,_,3,_,8,5],\n              [_,_,1,_,2,_,_,_,_],\n              [_,_,_,5,_,7,_,_,_],\n              [_,_,4,_,_,_,1,_,_],\n              [_,9,_,_,_,_,_,_,_],\n              [5,_,_,_,_,_,_,7,3],\n              [_,_,2,_,1,_,_,_,_],\n              [_,_,_,_,4,_,_,_,9]]).\n  ==\n\n  Sample query:\n\n  ==\n  ?- problem(1, Rows), sudoku(Rows), maplist(writeln, Rows).\n  [9,8,7,6,5,4,3,2,1]\n  [2,4,6,1,7,3,9,8,5]\n  [3,5,1,9,2,8,7,4,6]\n  [1,2,8,5,3,7,6,9,4]\n  [6,3,4,8,9,2,1,5,7]\n  [7,9,5,4,6,1,8,3,2]\n  [5,1,9,2,8,6,4,7,3]\n  [4,7,2,3,1,9,5,6,8]\n  [8,6,3,7,4,5,2,1,9]\n  Rows = [[9, 8, 7, 6, 5, 4, 3, 2|...], ... , [...|...]].\n  ==",
    "prefix":"transpose"
  },
  "clpfd:tuples_in/2": {
    "body":"tuples_in(${1:Tuples}, ${2:Relation})$3\n$0",
    "description":"tuples_in(+Tuples, +Relation).\nTrue iff all Tuples are elements of Relation. Each  element of the list Tuples is a list of integers or finite  domain variables. Relation is a list of lists of integers. Arbitrary finite  relations, such as compatibility tables, can be modeled in this way. For  example, if 1 is compatible with 2 and 5, and 4 is compatible with 0 and  3:  \n\n?- tuples_in([[X,Y]], [[1,2],[1,5],[4,0],[4,3]]), X = 4.\nX = 4,\nY in 0\\/3.\n\n  As another example, consider a train schedule represented as a list  of quadruples, denoting departure and arrival places and times for each  train. In the following program, Ps is a feasible journey of length 3  from A to D via trains that are part of the given schedule. \n\n\n\ntrains([[1,2,0,1],\n        [2,3,4,5],\n        [2,3,0,1],\n        [3,4,5,6],\n        [3,4,2,3],\n        [3,4,8,9]]).\n\nthreepath(A, D, Ps) :-\n        Ps = [[A,B,_T0,T1],[B,C,T2,T3],[C,D,T4,_T5]],\n        T2 #> T1,\n        T4 #> T3,\n        trains(Ts),\n        tuples_in(Ps, Ts).\n\n  In this example, the unique solution is found without labeling: \n\n\n\n?- threepath(1, 4, Ps).\nPs = [[1, 2, 0, 1], [2, 3, 4, 5], [3, 4, 8, 9]].\n\n ",
    "prefix":"tuples_in"
  },
  "clpfd:zcompare/3": {
    "body":"zcompare(${1:Order}, ${2:A}, ${3:B})$4\n$0",
    "description":"zcompare(?Order, ?A, ?B).\nAnalogous to compare/3,  with finite domain variables A and B.  This predicate allows you to make several predicates over integers  deterministic while preserving their generality and completeness. For  example: \n\n\n\nn_factorial(N, F) :-\n        zcompare(C, N, 0),\n        n_factorial_(C, N, F).\n\nn_factorial_(=, _, 1).\nn_factorial_(>, N, F) :-\n        F #= F0*N, N1 #= N - 1,\n        n_factorial(N1, F0).\n\n  This version is deterministic if the first argument is instantiated,  because first argument indexing can distinguish the two different  clauses: \n\n\n\n?- n_factorial(30, F).\nF = 265252859812191058636308480000000.\n\n  The predicate can still be used in all directions, including the most  general query: \n\n\n\n?- n_factorial(N, F).\nN = 0,\nF = 1 ;\nN = F, F = 1 ;\nN = F, F = 2 .\n\n  \n\n",
    "prefix":"zcompare"
  },
  "clpq/bb_q:bb_inf/3": {
    "body": ["bb_inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"bb_inf('Param1','Param2','Param3')",
    "prefix":"bb_inf"
  },
  "clpq/bb_q:bb_inf/4": {
    "body": [
      "bb_inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"bb_inf('Param1','Param2','Param3','Param4')",
    "prefix":"bb_inf"
  },
  "clpq/bb_q:vertex_value/2": {
    "body": ["vertex_value(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"vertex_value('Param1','Param2')",
    "prefix":"vertex_value"
  },
  "clpq/bv_q:allvars/2": {
    "body": ["allvars(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"allvars('Param1','Param2')",
    "prefix":"allvars"
  },
  "clpq/bv_q:backsubst/3": {
    "body": ["backsubst(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"backsubst('Param1','Param2','Param3')",
    "prefix":"backsubst"
  },
  "clpq/bv_q:backsubst_delta/4": {
    "body": [
      "backsubst_delta(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"backsubst_delta('Param1','Param2','Param3','Param4')",
    "prefix":"backsubst_delta"
  },
  "clpq/bv_q:basis_add/2": {
    "body": ["basis_add(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"basis_add('Param1','Param2')",
    "prefix":"basis_add"
  },
  "clpq/bv_q:dec_step/2": {
    "body": ["dec_step(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"dec_step('Param1','Param2')",
    "prefix":"dec_step"
  },
  "clpq/bv_q:deref/2": {
    "body": ["deref(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"deref('Param1','Param2')",
    "prefix":"deref"
  },
  "clpq/bv_q:deref_var/2": {
    "body": ["deref_var(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"deref_var('Param1','Param2')",
    "prefix":"deref_var"
  },
  "clpq/bv_q:detach_bounds/1": {
    "body": ["detach_bounds(${1:'Param1'})$2\n$0" ],
    "description":"detach_bounds('Param1')",
    "prefix":"detach_bounds"
  },
  "clpq/bv_q:detach_bounds_vlv/5": {
    "body": [
      "detach_bounds_vlv(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"detach_bounds_vlv('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"detach_bounds_vlv"
  },
  "clpq/bv_q:determine_active_dec/1": {
    "body": ["determine_active_dec(${1:'Param1'})$2\n$0" ],
    "description":"determine_active_dec('Param1')",
    "prefix":"determine_active_dec"
  },
  "clpq/bv_q:determine_active_inc/1": {
    "body": ["determine_active_inc(${1:'Param1'})$2\n$0" ],
    "description":"determine_active_inc('Param1')",
    "prefix":"determine_active_inc"
  },
  "clpq/bv_q:dump_nz/5": {
    "body": [
      "dump_nz(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"dump_nz('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"dump_nz"
  },
  "clpq/bv_q:dump_var/6": {
    "body": [
      "dump_var(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"dump_var('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"dump_var"
  },
  "clpq/bv_q:export_binding/1": {
    "body": ["export_binding(${1:'Param1'})$2\n$0" ],
    "description":"export_binding('Param1')",
    "prefix":"export_binding"
  },
  "clpq/bv_q:get_or_add_class/2": {
    "body": ["get_or_add_class(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"get_or_add_class('Param1','Param2')",
    "prefix":"get_or_add_class"
  },
  "clpq/bv_q:inc_step/2": {
    "body": ["inc_step(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"inc_step('Param1','Param2')",
    "prefix":"inc_step"
  },
  "clpq/bv_q:inf/2": {
    "body": ["inf(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"inf('Param1','Param2')",
    "prefix":"inf"
  },
  "clpq/bv_q:inf/4": {
    "body": [
      "inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"inf('Param1','Param2','Param3','Param4')",
    "prefix":"inf"
  },
  "clpq/bv_q:intro_at/3": {
    "body": ["intro_at(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"intro_at('Param1','Param2','Param3')",
    "prefix":"intro_at"
  },
  "clpq/bv_q:iterate_dec/2": {
    "body": ["iterate_dec(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"iterate_dec('Param1','Param2')",
    "prefix":"iterate_dec"
  },
  "clpq/bv_q:lb/3": {
    "body": ["lb(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"lb('Param1','Param2','Param3')",
    "prefix":"lb"
  },
  "clpq/bv_q:log_deref/4": {
    "body": [
      "log_deref(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"log_deref('Param1','Param2','Param3','Param4')",
    "prefix":"log_deref"
  },
  "clpq/bv_q:maximize/1": {
    "body": ["maximize(${1:'Param1'})$2\n$0" ],
    "description":"maximize('Param1')",
    "prefix":"maximize"
  },
  "clpq/bv_q:minimize/1": {
    "body": ["minimize(${1:'Param1'})$2\n$0" ],
    "description":"minimize('Param1')",
    "prefix":"minimize"
  },
  "clpq/bv_q:pivot/5": {
    "body": [
      "pivot(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"pivot('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"pivot"
  },
  "clpq/bv_q:pivot_a/4": {
    "body": [
      "pivot_a(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"pivot_a('Param1','Param2','Param3','Param4')",
    "prefix":"pivot_a"
  },
  "clpq/bv_q:rcbl_status/6": {
    "body": [
      "rcbl_status(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"rcbl_status('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"rcbl_status"
  },
  "clpq/bv_q:reconsider/1": {
    "body": ["reconsider(${1:'Param1'})$2\n$0" ],
    "description":"reconsider('Param1')",
    "prefix":"reconsider"
  },
  "clpq/bv_q:same_class/2": {
    "body": ["same_class(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"same_class('Param1','Param2')",
    "prefix":"same_class"
  },
  "clpq/bv_q:solve/1": {
    "body": ["solve(${1:'Param1'})$2\n$0" ],
    "description":"solve('Param1')",
    "prefix":"solve"
  },
  "clpq/bv_q:solve_ord_x/3": {
    "body": ["solve_ord_x(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"solve_ord_x('Param1','Param2','Param3')",
    "prefix":"solve_ord_x"
  },
  "clpq/bv_q:sup/2": {
    "body": ["sup(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sup('Param1','Param2')",
    "prefix":"sup"
  },
  "clpq/bv_q:sup/4": {
    "body": [
      "sup(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"sup('Param1','Param2','Param3','Param4')",
    "prefix":"sup"
  },
  "clpq/bv_q:ub/3": {
    "body": ["ub(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"ub('Param1','Param2','Param3')",
    "prefix":"ub"
  },
  "clpq/bv_q:unconstrained/4": {
    "body": [
      "unconstrained(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"unconstrained('Param1','Param2','Param3','Param4')",
    "prefix":"unconstrained"
  },
  "clpq/bv_q:var_intern/2": {
    "body": ["var_intern(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"var_intern('Param1','Param2')",
    "prefix":"var_intern"
  },
  "clpq/bv_q:var_intern/3": {
    "body": ["var_intern(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"var_intern('Param1','Param2','Param3')",
    "prefix":"var_intern"
  },
  "clpq/bv_q:var_with_def_assign/2": {
    "body": ["var_with_def_assign(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"var_with_def_assign('Param1','Param2')",
    "prefix":"var_with_def_assign"
  },
  "clpq/bv_q:var_with_def_intern/4": {
    "body": [
      "var_with_def_intern(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"var_with_def_intern('Param1','Param2','Param3','Param4')",
    "prefix":"var_with_def_intern"
  },
  "clpq/fourmotz_q:fm_elim/3": {
    "body": ["fm_elim(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"fm_elim('Param1','Param2','Param3')",
    "prefix":"fm_elim"
  },
  "clpq/ineq_q:ineq/4": {
    "body": [
      "ineq(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"ineq('Param1','Param2','Param3','Param4')",
    "prefix":"ineq"
  },
  "clpq/ineq_q:ineq_one/4": {
    "body": [
      "ineq_one(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"ineq_one('Param1','Param2','Param3','Param4')",
    "prefix":"ineq_one"
  },
  "clpq/ineq_q:ineq_one_n_n_0/1": {
    "body": ["ineq_one_n_n_0(${1:'Param1'})$2\n$0" ],
    "description":"ineq_one_n_n_0('Param1')",
    "prefix":"ineq_one_n_n_0"
  },
  "clpq/ineq_q:ineq_one_n_p_0/1": {
    "body": ["ineq_one_n_p_0(${1:'Param1'})$2\n$0" ],
    "description":"ineq_one_n_p_0('Param1')",
    "prefix":"ineq_one_n_p_0"
  },
  "clpq/ineq_q:ineq_one_s_n_0/1": {
    "body": ["ineq_one_s_n_0(${1:'Param1'})$2\n$0" ],
    "description":"ineq_one_s_n_0('Param1')",
    "prefix":"ineq_one_s_n_0"
  },
  "clpq/ineq_q:ineq_one_s_p_0/1": {
    "body": ["ineq_one_s_p_0(${1:'Param1'})$2\n$0" ],
    "description":"ineq_one_s_p_0('Param1')",
    "prefix":"ineq_one_s_p_0"
  },
  "clpq/itf_q:do_checks/8": {
    "body": [
      "do_checks(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'})$9\n$0"
    ],
    "description":"do_checks('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8')",
    "prefix":"do_checks"
  },
  "clpq/nf_q:entailed/1": {
    "body": ["entailed(${1:'Param1'})$2\n$0" ],
    "description":"entailed('Param1')",
    "prefix":"entailed"
  },
  "clpq/nf_q:nf/2": {
    "body": ["nf(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"nf('Param1','Param2')",
    "prefix":"nf"
  },
  "clpq/nf_q:nf2term/2": {
    "body": ["nf2term(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"nf2term('Param1','Param2')",
    "prefix":"nf2term"
  },
  "clpq/nf_q:nf_constant/2": {
    "body": ["nf_constant(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"nf_constant('Param1','Param2')",
    "prefix":"nf_constant"
  },
  "clpq/nf_q:repair/2": {
    "body": ["repair(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"repair('Param1','Param2')",
    "prefix":"repair"
  },
  "clpq/nf_q:split/3": {
    "body": ["split(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"split('Param1','Param2','Param3')",
    "prefix":"split"
  },
  "clpq/nf_q:wait_linear/3": {
    "body": ["wait_linear(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"wait_linear('Param1','Param2','Param3')",
    "prefix":"wait_linear"
  },
  "clpq/store_q:add_linear_11/3": {
    "body": ["add_linear_11(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"add_linear_11('Param1','Param2','Param3')",
    "prefix":"add_linear_11"
  },
  "clpq/store_q:add_linear_f1/4": {
    "body": [
      "add_linear_f1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"add_linear_f1('Param1','Param2','Param3','Param4')",
    "prefix":"add_linear_f1"
  },
  "clpq/store_q:add_linear_ff/5": {
    "body": [
      "add_linear_ff(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"add_linear_ff('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"add_linear_ff"
  },
  "clpq/store_q:delete_factor/4": {
    "body": [
      "delete_factor(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"delete_factor('Param1','Param2','Param3','Param4')",
    "prefix":"delete_factor"
  },
  "clpq/store_q:indep/2": {
    "body": ["indep(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"indep('Param1','Param2')",
    "prefix":"indep"
  },
  "clpq/store_q:isolate/3": {
    "body": ["isolate(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"isolate('Param1','Param2','Param3')",
    "prefix":"isolate"
  },
  "clpq/store_q:mult_hom/3": {
    "body": ["mult_hom(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"mult_hom('Param1','Param2','Param3')",
    "prefix":"mult_hom"
  },
  "clpq/store_q:mult_linear_factor/3": {
    "body": [
      "mult_linear_factor(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"mult_linear_factor('Param1','Param2','Param3')",
    "prefix":"mult_linear_factor"
  },
  "clpq/store_q:nf2sum/3": {
    "body": ["nf2sum(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nf2sum('Param1','Param2','Param3')",
    "prefix":"nf2sum"
  },
  "clpq/store_q:nf_coeff_of/3": {
    "body": ["nf_coeff_of(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nf_coeff_of('Param1','Param2','Param3')",
    "prefix":"nf_coeff_of"
  },
  "clpq/store_q:nf_rhs_x/4": {
    "body": [
      "nf_rhs_x(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"nf_rhs_x('Param1','Param2','Param3','Param4')",
    "prefix":"nf_rhs_x"
  },
  "clpq/store_q:nf_substitute/4": {
    "body": [
      "nf_substitute(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"nf_substitute('Param1','Param2','Param3','Param4')",
    "prefix":"nf_substitute"
  },
  "clpq/store_q:normalize_scalar/2": {
    "body": ["normalize_scalar(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"normalize_scalar('Param1','Param2')",
    "prefix":"normalize_scalar"
  },
  "clpq/store_q:renormalize/2": {
    "body": ["renormalize(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"renormalize('Param1','Param2')",
    "prefix":"renormalize"
  },
  "clpq:bb_inf/3": {
    "body": ["bb_inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"bb_inf('Param1','Param2','Param3')",
    "prefix":"bb_inf"
  },
  "clpq:bb_inf/4": {
    "body": [
      "bb_inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"bb_inf('Param1','Param2','Param3','Param4')",
    "prefix":"bb_inf"
  },
  "clpq:clp_type/2": {
    "body": ["clp_type(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"clp_type('Param1','Param2')",
    "prefix":"clp_type"
  },
  "clpq:dump/3": {
    "body": ["dump(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"dump('Param1','Param2','Param3')",
    "prefix":"dump"
  },
  "clpq:entailed/1": {
    "body": ["entailed(${1:'Param1'})$2\n$0" ],
    "description":"entailed('Param1')",
    "prefix":"entailed"
  },
  "clpq:inf/2": {
    "body": ["inf(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"inf('Param1','Param2')",
    "prefix":"inf"
  },
  "clpq:inf/4": {
    "body": [
      "inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"inf('Param1','Param2','Param3','Param4')",
    "prefix":"inf"
  },
  "clpq:maximize/1": {
    "body": ["maximize(${1:'Param1'})$2\n$0" ],
    "description":"maximize('Param1')",
    "prefix":"maximize"
  },
  "clpq:minimize/1": {
    "body": ["minimize(${1:'Param1'})$2\n$0" ],
    "description":"minimize('Param1')",
    "prefix":"minimize"
  },
  "clpq:ordering/1": {
    "body": ["ordering(${1:'Param1'})$2\n$0" ],
    "description":"ordering('Param1')",
    "prefix":"ordering"
  },
  "clpq:sup/2": {
    "body": ["sup(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sup('Param1','Param2')",
    "prefix":"sup"
  },
  "clpq:sup/4": {
    "body": [
      "sup(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"sup('Param1','Param2','Param3','Param4')",
    "prefix":"sup"
  },
  "clpqr/class:arrangement/2": {
    "body": ["arrangement(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"arrangement('Param1','Param2')",
    "prefix":"arrangement"
  },
  "clpqr/class:class_allvars/2": {
    "body": ["class_allvars(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"class_allvars('Param1','Param2')",
    "prefix":"class_allvars"
  },
  "clpqr/class:class_basis/2": {
    "body": ["class_basis(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"class_basis('Param1','Param2')",
    "prefix":"class_basis"
  },
  "clpqr/class:class_basis_add/3": {
    "body": [
      "class_basis_add(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"class_basis_add('Param1','Param2','Param3')",
    "prefix":"class_basis_add"
  },
  "clpqr/class:class_basis_drop/2": {
    "body": ["class_basis_drop(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"class_basis_drop('Param1','Param2')",
    "prefix":"class_basis_drop"
  },
  "clpqr/class:class_basis_pivot/3": {
    "body": [
      "class_basis_pivot(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"class_basis_pivot('Param1','Param2','Param3')",
    "prefix":"class_basis_pivot"
  },
  "clpqr/class:class_drop/2": {
    "body": ["class_drop(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"class_drop('Param1','Param2')",
    "prefix":"class_drop"
  },
  "clpqr/class:class_get_clp/2": {
    "body": ["class_get_clp(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"class_get_clp('Param1','Param2')",
    "prefix":"class_get_clp"
  },
  "clpqr/class:class_get_prio/2": {
    "body": ["class_get_prio(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"class_get_prio('Param1','Param2')",
    "prefix":"class_get_prio"
  },
  "clpqr/class:class_new/5": {
    "body": [
      "class_new(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"class_new('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"class_new"
  },
  "clpqr/class:class_put_prio/2": {
    "body": ["class_put_prio(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"class_put_prio('Param1','Param2')",
    "prefix":"class_put_prio"
  },
  "clpqr/class:ordering/1": {
    "body": ["ordering(${1:'Param1'})$2\n$0" ],
    "description":"ordering('Param1')",
    "prefix":"ordering"
  },
  "clpqr/dump:dump/3": {
    "body": ["dump(${1:Target}, ${2:NewVars}, ${3:Constraints})$4\n$0" ],
    "description":" dump(+Target,-NewVars,-Constraints) is det.\n\n Returns in <Constraints>, the constraints that currently hold on Target where\n all variables in <Target> are copied to new variables in <NewVars> and the\n constraints are given on these new variables. In short, you can safely\n manipulate <NewVars> and <Constraints> without changing the constraints on\n <Target>.",
    "prefix":"dump"
  },
  "clpqr/dump:projecting_assert/1": {
    "body": ["projecting_assert(${1:'Param1'})$2\n$0" ],
    "description":"projecting_assert('Param1')",
    "prefix":"projecting_assert"
  },
  "clpqr/geler:collect_nonlin/3": {
    "body": ["collect_nonlin(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"collect_nonlin('Param1','Param2','Param3')",
    "prefix":"collect_nonlin"
  },
  "clpqr/geler:geler/3": {
    "body": ["geler(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"geler('Param1','Param2','Param3')",
    "prefix":"geler"
  },
  "clpqr/geler:project_nonlin/3": {
    "body": ["project_nonlin(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"project_nonlin('Param1','Param2','Param3')",
    "prefix":"project_nonlin"
  },
  "clpqr/itf:clp_type/2": {
    "body": ["clp_type(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"clp_type('Param1','Param2')",
    "prefix":"clp_type"
  },
  "clpqr/itf:dump_linear/3": {
    "body": ["dump_linear(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"dump_linear('Param1','Param2','Param3')",
    "prefix":"dump_linear"
  },
  "clpqr/itf:dump_nonzero/3": {
    "body": ["dump_nonzero(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"dump_nonzero('Param1','Param2','Param3')",
    "prefix":"dump_nonzero"
  },
  "clpqr/ordering:arrangement/2": {
    "body": ["arrangement(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"arrangement('Param1','Param2')",
    "prefix":"arrangement"
  },
  "clpqr/ordering:combine/3": {
    "body": ["combine(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"combine('Param1','Param2','Param3')",
    "prefix":"combine"
  },
  "clpqr/ordering:ordering/1": {
    "body": ["ordering(${1:'Param1'})$2\n$0" ],
    "description":"ordering('Param1')",
    "prefix":"ordering"
  },
  "clpqr/project:drop_dep/1": {
    "body": ["drop_dep(${1:'Param1'})$2\n$0" ],
    "description":"drop_dep('Param1')",
    "prefix":"drop_dep"
  },
  "clpqr/project:drop_dep_one/1": {
    "body": ["drop_dep_one(${1:'Param1'})$2\n$0" ],
    "description":"drop_dep_one('Param1')",
    "prefix":"drop_dep_one"
  },
  "clpqr/project:make_target_indep/2": {
    "body": ["make_target_indep(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"make_target_indep('Param1','Param2')",
    "prefix":"make_target_indep"
  },
  "clpqr/project:project_attributes/2": {
    "body": ["project_attributes(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"project_attributes('Param1','Param2')",
    "prefix":"project_attributes"
  },
  "clpqr/redund:redundancy_vars/1": {
    "body": ["redundancy_vars(${1:'Param1'})$2\n$0" ],
    "description":"redundancy_vars('Param1')",
    "prefix":"redundancy_vars"
  },
  "clpqr/redund:systems/3": {
    "body": ["systems(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"systems('Param1','Param2','Param3')",
    "prefix":"systems"
  },
  "clpqr:bb_inf/3": {
    "body":"bb_inf(${1:Ints}, ${2:Expression}, ${3:Inf})$4\n$0",
    "description":"bb_inf(+Ints, +Expression, -Inf).\nThe same as bb_inf/5 or bb_inf/4  but without returning the values of the integers. In CLP(R), an error  margin of 0.001 is used.",
    "prefix":"bb_inf"
  },
  "clpqr:bb_inf/4": {
    "body":"bb_inf(${1:Ints}, ${2:Expression}, ${3:Inf}, ${4:Vertex})$5\n$0",
    "description":"bb_inf(+Ints, +Expression, -Inf, -Vertex).\nThis predicate is offered in CLP(Q) only. It behaves the same as bb_inf/5 but does not use  an error margin.",
    "prefix":"bb_inf"
  },
  "clpqr:bb_inf/5": {
    "body":"bb_inf(${1:Ints}, ${2:Expression}, ${3:Inf}, ${4:Vertex}, ${5:Eps})$6\n$0",
    "description":"bb_inf(+Ints, +Expression, -Inf, -Vertex, +Eps).\nThis predicate is offered in CLP(R) only. It computes the infimum of Expression within the current constraint store, with the  additional constraint that in that infimum, all variables in Ints  have integral values. Vertex will contain the values of Ints  in the infimum. Eps denotes how much a value may differ from  an integer to be considered an integer. E.g. when Eps = 0.001, then X = 4.999 will be considered as an integer  (5 in this case). Eps should be between 0 and 0.5.",
    "prefix":"bb_inf"
  },
  "clpqr:dump/3": {
    "body":"dump(${1:Target}, ${2:Newvars}, ${3:CodedAnswer})$4\n$0",
    "description":"dump(+Target, +Newvars, -CodedAnswer).\nReturns the constraints on Target in the list CodedAnswer  where all variables of Target have been replaced by NewVars.  This operation does not change the constraint store. E.g. in  \n\ndump([X,Y,Z],[x,y,z],Cons)\n\n  Cons will contain the constraints on X, Y and Z, where  these variables have been replaced by atoms x, y and z. \n\n\n\n",
    "prefix":"dump"
  },
  "clpqr:entailed/1": {
    "body":"entailed(${1:Constraint})$2\n$0",
    "description":"entailed(+Constraint).\nSucceeds if Constraint is necessarily true within the current  constraint store. This means that adding the negation of the constraint  to the store results in failure.",
    "prefix":"entailed"
  },
  "clpqr:inf/2": {
    "body":"inf(${1:Expression}, ${2:Inf})$3\n$0",
    "description":"inf(+Expression, -Inf).\nComputes the infimum of Expression within the current state  of the constraint store and returns that infimum in Inf. This  predicate does not change the constraint store.",
    "prefix":"inf"
  },
  "clpqr:maximize/1": {
    "body":"maximize(${1:Expression})$2\n$0",
    "description":"maximize(+Expression).\nMaximizes Expression within the current constraint store.  This is the same as computing the supremum and equating the expression  to that supremum.",
    "prefix":"maximize"
  },
  "clpqr:minimize/1": {
    "body":"minimize(${1:Expression})$2\n$0",
    "description":"minimize(+Expression).\nMinimizes Expression within the current constraint store.  This is the same as computing the infimum and equating the expression to  that infimum.",
    "prefix":"minimize"
  },
  "clpqr:sup/2": {
    "body":"sup(${1:Expression}, ${2:Sup})$3\n$0",
    "description":"sup(+Expression, -Sup).\nComputes the supremum of Expression within the current state  of the constraint store and returns that supremum in Sup.  This predicate does not change the constraint store.",
    "prefix":"sup"
  },
  "clpr/bb_r:bb_inf/3": {
    "body": ["bb_inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"bb_inf('Param1','Param2','Param3')",
    "prefix":"bb_inf"
  },
  "clpr/bb_r:bb_inf/5": {
    "body": [
      "bb_inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"bb_inf('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"bb_inf"
  },
  "clpr/bb_r:vertex_value/2": {
    "body": ["vertex_value(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"vertex_value('Param1','Param2')",
    "prefix":"vertex_value"
  },
  "clpr/bv_r:allvars/2": {
    "body": ["allvars(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"allvars('Param1','Param2')",
    "prefix":"allvars"
  },
  "clpr/bv_r:backsubst/3": {
    "body": ["backsubst(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"backsubst('Param1','Param2','Param3')",
    "prefix":"backsubst"
  },
  "clpr/bv_r:backsubst_delta/4": {
    "body": [
      "backsubst_delta(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"backsubst_delta('Param1','Param2','Param3','Param4')",
    "prefix":"backsubst_delta"
  },
  "clpr/bv_r:basis_add/2": {
    "body": ["basis_add(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"basis_add('Param1','Param2')",
    "prefix":"basis_add"
  },
  "clpr/bv_r:dec_step/2": {
    "body": ["dec_step(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"dec_step('Param1','Param2')",
    "prefix":"dec_step"
  },
  "clpr/bv_r:deref/2": {
    "body": ["deref(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"deref('Param1','Param2')",
    "prefix":"deref"
  },
  "clpr/bv_r:deref_var/2": {
    "body": ["deref_var(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"deref_var('Param1','Param2')",
    "prefix":"deref_var"
  },
  "clpr/bv_r:detach_bounds/1": {
    "body": ["detach_bounds(${1:'Param1'})$2\n$0" ],
    "description":"detach_bounds('Param1')",
    "prefix":"detach_bounds"
  },
  "clpr/bv_r:detach_bounds_vlv/5": {
    "body": [
      "detach_bounds_vlv(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"detach_bounds_vlv('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"detach_bounds_vlv"
  },
  "clpr/bv_r:determine_active_dec/1": {
    "body": ["determine_active_dec(${1:'Param1'})$2\n$0" ],
    "description":"determine_active_dec('Param1')",
    "prefix":"determine_active_dec"
  },
  "clpr/bv_r:determine_active_inc/1": {
    "body": ["determine_active_inc(${1:'Param1'})$2\n$0" ],
    "description":"determine_active_inc('Param1')",
    "prefix":"determine_active_inc"
  },
  "clpr/bv_r:dump_nz/5": {
    "body": [
      "dump_nz(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"dump_nz('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"dump_nz"
  },
  "clpr/bv_r:dump_var/6": {
    "body": [
      "dump_var(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"dump_var('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"dump_var"
  },
  "clpr/bv_r:export_binding/1": {
    "body": ["export_binding(${1:'Param1'})$2\n$0" ],
    "description":"export_binding('Param1')",
    "prefix":"export_binding"
  },
  "clpr/bv_r:export_binding/2": {
    "body": ["export_binding(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"export_binding('Param1','Param2')",
    "prefix":"export_binding"
  },
  "clpr/bv_r:get_or_add_class/2": {
    "body": ["get_or_add_class(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"get_or_add_class('Param1','Param2')",
    "prefix":"get_or_add_class"
  },
  "clpr/bv_r:inc_step/2": {
    "body": ["inc_step(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"inc_step('Param1','Param2')",
    "prefix":"inc_step"
  },
  "clpr/bv_r:inf/2": {
    "body": ["inf(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"inf('Param1','Param2')",
    "prefix":"inf"
  },
  "clpr/bv_r:inf/4": {
    "body": [
      "inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"inf('Param1','Param2','Param3','Param4')",
    "prefix":"inf"
  },
  "clpr/bv_r:intro_at/3": {
    "body": ["intro_at(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"intro_at('Param1','Param2','Param3')",
    "prefix":"intro_at"
  },
  "clpr/bv_r:iterate_dec/2": {
    "body": ["iterate_dec(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"iterate_dec('Param1','Param2')",
    "prefix":"iterate_dec"
  },
  "clpr/bv_r:lb/3": {
    "body": ["lb(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"lb('Param1','Param2','Param3')",
    "prefix":"lb"
  },
  "clpr/bv_r:log_deref/4": {
    "body": [
      "log_deref(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"log_deref('Param1','Param2','Param3','Param4')",
    "prefix":"log_deref"
  },
  "clpr/bv_r:maximize/1": {
    "body": ["maximize(${1:'Param1'})$2\n$0" ],
    "description":"maximize('Param1')",
    "prefix":"maximize"
  },
  "clpr/bv_r:minimize/1": {
    "body": ["minimize(${1:'Param1'})$2\n$0" ],
    "description":"minimize('Param1')",
    "prefix":"minimize"
  },
  "clpr/bv_r:pivot/5": {
    "body": [
      "pivot(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"pivot('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"pivot"
  },
  "clpr/bv_r:pivot_a/4": {
    "body": [
      "pivot_a(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"pivot_a('Param1','Param2','Param3','Param4')",
    "prefix":"pivot_a"
  },
  "clpr/bv_r:rcbl_status/6": {
    "body": [
      "rcbl_status(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"rcbl_status('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"rcbl_status"
  },
  "clpr/bv_r:reconsider/1": {
    "body": ["reconsider(${1:'Param1'})$2\n$0" ],
    "description":"reconsider('Param1')",
    "prefix":"reconsider"
  },
  "clpr/bv_r:same_class/2": {
    "body": ["same_class(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"same_class('Param1','Param2')",
    "prefix":"same_class"
  },
  "clpr/bv_r:solve/1": {
    "body": ["solve(${1:'Param1'})$2\n$0" ],
    "description":"solve('Param1')",
    "prefix":"solve"
  },
  "clpr/bv_r:solve_ord_x/3": {
    "body": ["solve_ord_x(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"solve_ord_x('Param1','Param2','Param3')",
    "prefix":"solve_ord_x"
  },
  "clpr/bv_r:sup/2": {
    "body": ["sup(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sup('Param1','Param2')",
    "prefix":"sup"
  },
  "clpr/bv_r:sup/4": {
    "body": [
      "sup(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"sup('Param1','Param2','Param3','Param4')",
    "prefix":"sup"
  },
  "clpr/bv_r:ub/3": {
    "body": ["ub(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"ub('Param1','Param2','Param3')",
    "prefix":"ub"
  },
  "clpr/bv_r:unconstrained/4": {
    "body": [
      "unconstrained(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"unconstrained('Param1','Param2','Param3','Param4')",
    "prefix":"unconstrained"
  },
  "clpr/bv_r:var_intern/2": {
    "body": ["var_intern(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"var_intern('Param1','Param2')",
    "prefix":"var_intern"
  },
  "clpr/bv_r:var_intern/3": {
    "body": ["var_intern(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"var_intern('Param1','Param2','Param3')",
    "prefix":"var_intern"
  },
  "clpr/bv_r:var_with_def_assign/2": {
    "body": ["var_with_def_assign(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"var_with_def_assign('Param1','Param2')",
    "prefix":"var_with_def_assign"
  },
  "clpr/bv_r:var_with_def_intern/4": {
    "body": [
      "var_with_def_intern(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"var_with_def_intern('Param1','Param2','Param3','Param4')",
    "prefix":"var_with_def_intern"
  },
  "clpr/fourmotz_r:fm_elim/3": {
    "body": ["fm_elim(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"fm_elim('Param1','Param2','Param3')",
    "prefix":"fm_elim"
  },
  "clpr/ineq_r:ineq/4": {
    "body": [
      "ineq(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"ineq('Param1','Param2','Param3','Param4')",
    "prefix":"ineq"
  },
  "clpr/ineq_r:ineq_one/4": {
    "body": [
      "ineq_one(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"ineq_one('Param1','Param2','Param3','Param4')",
    "prefix":"ineq_one"
  },
  "clpr/ineq_r:ineq_one_n_n_0/1": {
    "body": ["ineq_one_n_n_0(${1:'Param1'})$2\n$0" ],
    "description":"ineq_one_n_n_0('Param1')",
    "prefix":"ineq_one_n_n_0"
  },
  "clpr/ineq_r:ineq_one_n_p_0/1": {
    "body": ["ineq_one_n_p_0(${1:'Param1'})$2\n$0" ],
    "description":"ineq_one_n_p_0('Param1')",
    "prefix":"ineq_one_n_p_0"
  },
  "clpr/ineq_r:ineq_one_s_n_0/1": {
    "body": ["ineq_one_s_n_0(${1:'Param1'})$2\n$0" ],
    "description":"ineq_one_s_n_0('Param1')",
    "prefix":"ineq_one_s_n_0"
  },
  "clpr/ineq_r:ineq_one_s_p_0/1": {
    "body": ["ineq_one_s_p_0(${1:'Param1'})$2\n$0" ],
    "description":"ineq_one_s_p_0('Param1')",
    "prefix":"ineq_one_s_p_0"
  },
  "clpr/itf_r:do_checks/8": {
    "body": [
      "do_checks(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'})$9\n$0"
    ],
    "description":"do_checks('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8')",
    "prefix":"do_checks"
  },
  "clpr/nf_r:entailed/1": {
    "body": ["entailed(${1:'Param1'})$2\n$0" ],
    "description":"entailed('Param1')",
    "prefix":"entailed"
  },
  "clpr/nf_r:nf/2": {
    "body": ["nf(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"nf('Param1','Param2')",
    "prefix":"nf"
  },
  "clpr/nf_r:nf2term/2": {
    "body": ["nf2term(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"nf2term('Param1','Param2')",
    "prefix":"nf2term"
  },
  "clpr/nf_r:nf_constant/2": {
    "body": ["nf_constant(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"nf_constant('Param1','Param2')",
    "prefix":"nf_constant"
  },
  "clpr/nf_r:repair/2": {
    "body": ["repair(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"repair('Param1','Param2')",
    "prefix":"repair"
  },
  "clpr/nf_r:split/3": {
    "body": ["split(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"split('Param1','Param2','Param3')",
    "prefix":"split"
  },
  "clpr/nf_r:wait_linear/3": {
    "body": ["wait_linear(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"wait_linear('Param1','Param2','Param3')",
    "prefix":"wait_linear"
  },
  "clpr/store_r:add_linear_11/3": {
    "body": ["add_linear_11(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"add_linear_11('Param1','Param2','Param3')",
    "prefix":"add_linear_11"
  },
  "clpr/store_r:add_linear_f1/4": {
    "body": [
      "add_linear_f1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"add_linear_f1('Param1','Param2','Param3','Param4')",
    "prefix":"add_linear_f1"
  },
  "clpr/store_r:add_linear_ff/5": {
    "body": [
      "add_linear_ff(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"add_linear_ff('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"add_linear_ff"
  },
  "clpr/store_r:delete_factor/4": {
    "body": [
      "delete_factor(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"delete_factor('Param1','Param2','Param3','Param4')",
    "prefix":"delete_factor"
  },
  "clpr/store_r:indep/2": {
    "body": ["indep(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"indep('Param1','Param2')",
    "prefix":"indep"
  },
  "clpr/store_r:isolate/3": {
    "body": ["isolate(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"isolate('Param1','Param2','Param3')",
    "prefix":"isolate"
  },
  "clpr/store_r:mult_hom/3": {
    "body": ["mult_hom(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"mult_hom('Param1','Param2','Param3')",
    "prefix":"mult_hom"
  },
  "clpr/store_r:mult_linear_factor/3": {
    "body": [
      "mult_linear_factor(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"mult_linear_factor('Param1','Param2','Param3')",
    "prefix":"mult_linear_factor"
  },
  "clpr/store_r:nf2sum/3": {
    "body": ["nf2sum(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nf2sum('Param1','Param2','Param3')",
    "prefix":"nf2sum"
  },
  "clpr/store_r:nf_coeff_of/3": {
    "body": ["nf_coeff_of(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nf_coeff_of('Param1','Param2','Param3')",
    "prefix":"nf_coeff_of"
  },
  "clpr/store_r:nf_rhs_x/4": {
    "body": [
      "nf_rhs_x(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"nf_rhs_x('Param1','Param2','Param3','Param4')",
    "prefix":"nf_rhs_x"
  },
  "clpr/store_r:nf_substitute/4": {
    "body": [
      "nf_substitute(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"nf_substitute('Param1','Param2','Param3','Param4')",
    "prefix":"nf_substitute"
  },
  "clpr/store_r:normalize_scalar/2": {
    "body": ["normalize_scalar(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"normalize_scalar('Param1','Param2')",
    "prefix":"normalize_scalar"
  },
  "clpr/store_r:renormalize/2": {
    "body": ["renormalize(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"renormalize('Param1','Param2')",
    "prefix":"renormalize"
  },
  "clpr:bb_inf/3": {
    "body": ["bb_inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"bb_inf('Param1','Param2','Param3')",
    "prefix":"bb_inf"
  },
  "clpr:bb_inf/5": {
    "body": [
      "bb_inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"bb_inf('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"bb_inf"
  },
  "clpr:clp_type/2": {
    "body": ["clp_type(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"clp_type('Param1','Param2')",
    "prefix":"clp_type"
  },
  "clpr:dump/3": {
    "body": ["dump(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"dump('Param1','Param2','Param3')",
    "prefix":"dump"
  },
  "clpr:entailed/1": {
    "body": ["entailed(${1:'Param1'})$2\n$0" ],
    "description":"entailed('Param1')",
    "prefix":"entailed"
  },
  "clpr:inf/2": {
    "body": ["inf(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"inf('Param1','Param2')",
    "prefix":"inf"
  },
  "clpr:inf/4": {
    "body": [
      "inf(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"inf('Param1','Param2','Param3','Param4')",
    "prefix":"inf"
  },
  "clpr:maximize/1": {
    "body": ["maximize(${1:'Param1'})$2\n$0" ],
    "description":"maximize('Param1')",
    "prefix":"maximize"
  },
  "clpr:minimize/1": {
    "body": ["minimize(${1:'Param1'})$2\n$0" ],
    "description":"minimize('Param1')",
    "prefix":"minimize"
  },
  "clpr:ordering/1": {
    "body": ["ordering(${1:'Param1'})$2\n$0" ],
    "description":"ordering('Param1')",
    "prefix":"ordering"
  },
  "clpr:sup/2": {
    "body": ["sup(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sup('Param1','Param2')",
    "prefix":"sup"
  },
  "clpr:sup/4": {
    "body": [
      "sup(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"sup('Param1','Param2','Param3','Param4')",
    "prefix":"sup"
  },
  "code_type/2": {
    "body":"code_type(${1:Code}, ${2:Type})$3\n$0",
    "description":"code_type(?Code, ?Type).\nAs char_type/2,  but uses character codes rather than one-character atoms. Please note  that both predicates are as flexible as possible. They handle either  representation if the argument is instantiated and will instantiate only  with an integer code or a one-character atom, depending of the version  used. See also the Prolog flag double_quotes, atom_chars/2  and atom_codes/2.",
    "prefix":"code_type"
  },
  "codesio:format_to_codes/3": {
    "body": ["format_to_codes(${1:Format}, ${2:Args}, ${3:Codes})$4\n$0" ],
    "description":"  format_to_codes(+Format, +Args, -Codes) is det.\n\n   Use format/2 to write to a list of character codes.",
    "prefix":"format_to_codes"
  },
  "codesio:format_to_codes/4": {
    "body": [
      "format_to_codes(${1:Format}, ${2:Args}, ${3:Codes}, ${4:Tail})$5\n$0"
    ],
    "description":"  format_to_codes(+Format, +Args, -Codes, ?Tail) is det.\n\n   Use format/2 to write to a difference list of character codes.",
    "prefix":"format_to_codes"
  },
  "codesio:open_codes_stream/2": {
    "body": ["open_codes_stream(${1:Codes}, ${2:Stream})$3\n$0" ],
    "description":"  open_codes_stream(+Codes, -Stream) is det.\n\n   Open Codes as an input stream.\n\n   @see open_string/2.",
    "prefix":"open_codes_stream"
  },
  "codesio:read_from_codes/2": {
    "body": ["read_from_codes(${1:Codes}, ${2:Term})$3\n$0" ],
    "description":"  read_from_codes(+Codes, -Term) is det.\n\n   Read Codes into Term.\n\n   @compat The SWI-Prolog version does not require Codes to end\n           in a full-stop.",
    "prefix":"read_from_codes"
  },
  "codesio:read_term_from_codes/3": {
    "body": ["read_term_from_codes(${1:Codes}, ${2:Term}, ${3:Options})$4\n$0" ],
    "description":"  read_term_from_codes(+Codes, -Term, +Options) is det.\n\n   Read Codes into Term.  Options are processed by read_term/3.\n\n   @compat sicstus",
    "prefix":"read_term_from_codes"
  },
  "codesio:with_output_to_codes/2": {
    "body": ["with_output_to_codes(${1:Goal}, ${2:Codes})$3\n$0" ],
    "description":"  with_output_to_codes(:Goal, Codes) is det.\n\n   Run Goal with as once/1.  Output written to =current_output=\n   is collected in Codes.",
    "prefix":"with_output_to_codes"
  },
  "codesio:with_output_to_codes/3": {
    "body": ["with_output_to_codes(${1:Goal}, ${2:Codes}, ${3:Tail})$4\n$0" ],
    "description":"  with_output_to_codes(:Goal, -Codes, ?Tail) is det.\n\n   Run Goal with as once/1.  Output written to =current_output=\n   is collected in Codes\\Tail.",
    "prefix":"with_output_to_codes"
  },
  "codesio:with_output_to_codes/4": {
    "body": [
      "with_output_to_codes(${1:Goal}, ${2:Stream}, ${3:Codes}, ${4:Tail})$5\n$0"
    ],
    "description":"  with_output_to_codes(:Goal, -Stream, -Codes, ?Tail) is det.\n\n   As  with_output_to_codes/3,  but  Stream  is  unified  with  the\n   temporary  stream.  This  predicate   exists  for  compatibility\n   reasons. In SWI-Prolog, the temporary   stream is also available\n   as `current_output`.",
    "prefix":"with_output_to_codes"
  },
  "codesio:write_term_to_codes/3": {
    "body": ["write_term_to_codes(${1:Term}, ${2:Codes}, ${3:Options})$4\n$0" ],
    "description":"  write_term_to_codes(+Term, -Codes, +Options) is det.\n\n   True  when  Codes  is  a  string  that  matches  the  output  of\n   write_term/3 using Options.",
    "prefix":"write_term_to_codes"
  },
  "codesio:write_term_to_codes/4": {
    "body": [
      "write_term_to_codes(${1:Term}, ${2:Codes}, ${3:Tail}, ${4:Options})$5\n$0"
    ],
    "description":"  write_term_to_codes(+Term, -Codes, ?Tail, +Options) is det.\n\n   True  when  Codes\\Tail  is  a  difference  list  containing  the\n   character codes that matches the   output  of write_term/3 using\n   Options.",
    "prefix":"write_term_to_codes"
  },
  "codesio:write_to_codes/2": {
    "body": ["write_to_codes(${1:Term}, ${2:Codes})$3\n$0" ],
    "description":"  write_to_codes(+Term, -Codes)\n\n   Codes is a list of character codes produced by write/1 on Term.",
    "prefix":"write_to_codes"
  },
  "codesio:write_to_codes/3": {
    "body": ["write_to_codes(${1:Term}, ${2:Codes}, ${3:Tail})$4\n$0" ],
    "description":"  write_to_codes(+Term, -Codes, ?Tail)\n\n   Codes is a difference-list of character codes produced by write/1 on Term.",
    "prefix":"write_to_codes"
  },
  "coinduction:coinductive/1": {
    "body": ["coinductive(${1:Spec})$2\n$0" ],
    "description":"  coinductive(:Spec)\n\n   The  declaration  :-   coinductive    name/arity,   ...  defines\n   predicates as _coinductive_. The predicate definition is wrapped\n   such that goals unify with their  ancestors. This directive must\n   preceed all clauses of the predicate.",
    "prefix":"coinductive"
  },
  "collation_key/2": {
    "body":"collation_key(${1:Atom}, ${2:Key})$3\n$0",
    "description":"collation_key(+Atom, -Key).\nCreate a Key from Atom for locale-specific  comparison. The key is defined such that if the key of atom A  precedes the key of atom B in the standard order of terms, A  is alphabetically smaller than B using the sort order of the  current locale.  The predicate collation_key/2  is used by locale_sort/2  from library(sort). Please examine the implementation of locale_sort/2  as an example of using this call. \n\nThe Key is an implementation-defined and generally  unreadable string. On systems that do not support locale handling, Key  is simply unified with Atom.\n\n",
    "prefix":"collation_key"
  },
  "compare/3": {
    "body":"compare(${1:Order}, ${2:Term1}, ${3:Term2})$4\n$0",
    "description":"[ISO]compare(?Order, @Term1, @Term2).\nDetermine or test the Order between two terms in the standard  order of terms. Order is one of <, >  or =, with the obvious meaning.",
    "prefix":"compare"
  },
  "compare_strings/4": {
    "body":"compare_strings(${1:Table}, ${2:S1}, ${3:S2}, ${4:Result})$5\n$0",
    "description":"compare_strings(+Table, +S1, +S2, -Result).\nCompare two strings using the named Table. S1 and S2 may be atoms, strings or code-lists. Result is  one of the atoms <, = or >.",
    "prefix":"compare_strings"
  },
  "compile_aux_clauses/1": {
    "body":"compile_aux_clauses(${1:Clauses})$2\n$0",
    "description":"compile_aux_clauses(+Clauses).\nCompile clauses on behalf of goal_expansion/2.  This predicate compiles the argument clauses into static predicates,  associating the predicates with the current file but avoids changing the  notion of current predicate and therefore discontiguous warnings.  Note that in some cases multiple expansions of similar goals can  share the same compiled auxiliary predicate. In such cases, the  implementation of goal_expansion/2  can use predicate_property/2  using the property defined to test whether the predicate is already defined in  the current context.\n\n",
    "prefix":"compile_aux_clauses"
  },
  "compile_predicates/1": {
    "body":"compile_predicates(${1:ListOfPredicateIndicators})$2\n$0",
    "description":"compile_predicates(:ListOfPredicateIndicators).\nCompile a list of specified dynamic predicates (see dynamic/1  and assert/1)  into normal static predicates. This call tells the Prolog environment  the definition will not change anymore and further calls to assert/1  or retract/1  on the named predicates raise a permission error. This predicate is  designed to deal with parts of the program that are generated at runtime  but do not change during the remainder of the program execution.73The  specification of this predicate is from Richard O'Keefe. The  implementation is allowed to optimise the predicate. This is not yet  implemented. In multithreaded Prolog, however, static code runs faster  as it does not require synchronisation. This is particularly true on SMP  hardware.",
    "prefix":"compile_predicates"
  },
  "compiling/0": {
    "body":"compiling$1\n$0",
    "description":"compiling.\nTrue if the system is compiling source files with the -c  option or qcompile/1  into an intermediate code file. Can be used to perform conditional code  optimisations in term_expansion/2  (see also the -O option) or to omit execution of directives during  compilation.",
    "prefix":"compiling"
  },
  "compound/1": {
    "body":"compound(${1:Term})$2\n$0",
    "description":"[ISO]compound(@Term).\nTrue if Term is bound to a compound term. See also functor/3  =../2, compound_name_arity/3  and compound_name_arguments/3.",
    "prefix":"compound"
  },
  "compound_name_arguments/3": {
    "body":"compound_name_arguments(${1:Compound}, ${2:Name}, ${3:Arguments})$4\n$0",
    "description":"compound_name_arguments(?Compound, ?Name, ?Arguments).\nRationalized version of =../2  that can compose and decompose compound terms with zero arguments. See  also compound_name_arity/3.",
    "prefix":"compound_name_arguments"
  },
  "compound_name_arity/3": {
    "body":"compound_name_arity(${1:Compound}, ${2:Name}, ${3:Arity})$4\n$0",
    "description":"compound_name_arity(?Compound, ?Name, ?Arity).\nRationalized version of functor/3  that only works for compound terms and can examine and create compound  terms with zero arguments (e.g, name(). See also compound_name_arguments/3.",
    "prefix":"compound_name_arity"
  },
  "consult/1": {
    "body":"consult(${1:File})$2\n$0",
    "description":"consult(:File).\nRead File as a Prolog source file. Calls to consult/1  may be abbreviated by just typing a number of filenames in a list.  Examples: ?- consult(load). % consult load  or load.pl ?- [library(lists)]. % load  library lists ?- [user]. % Type program on  the terminal   The predicate consult/1  is equivalent to load_files(File, []), except for handling  the special file user, which reads clauses from the  terminal. See also the stream(Input) option of load_files/2.  Abbreviation using ?- [file1,file2]. does not work for the empty list ([]). This facility is  implemented by defining the list as a predicate. Applications may only  rely on using the list abbreviation at the Prolog toplevel and in  directives.\n\n",
    "prefix":"consult"
  },
  "context_module/1": {
    "body":"context_module(${1:Module})$2\n$0",
    "description":"context_module(-Module).\nUnify Module with the context module of the current goal. context_module/1  itself is, of course, transparent.",
    "prefix":"context_module"
  },
  "copy_predicate_clauses/2": {
    "body":"copy_predicate_clauses(${1:From}, ${2:To})$3\n$0",
    "description":"copy_predicate_clauses(:From, :To).\nCopy all clauses of predicate From to To. The  predicate To must be dynamic or undefined. If To is  undefined, it is created as a dynamic predicate holding a copy of the  clauses of From. If To is a dynamic predicate, the clauses of From are added (as in assertz/1)  to the clauses of To. To and From must have the same arity. Acts as if  defined by the program below, but at a much better performance by  avoiding decompilation and compilation.  \n\ncopy_predicate_clauses(From, To) :-\n        head(From, MF:FromHead),\n        head(To, MT:ToHead),\n        FromHead =.. [_|Args],\n        ToHead =.. [_|Args],\n        forall(clause(MF:FromHead, Body),\n               assertz(MT:ToHead, Body)).\n\nhead(From, M:Head) :-\n        strip_module(From, M, Name/Arity),\n        functor(Head, Name, Arity).\n\n ",
    "prefix":"copy_predicate_clauses"
  },
  "copy_stream_data/2": {
    "body":"copy_stream_data(${1:StreamIn}, ${2:StreamOut})$3\n$0",
    "description":"copy_stream_data(+StreamIn, +StreamOut).\nCopy all (remaining) data from StreamIn to StreamOut.",
    "prefix":"copy_stream_data"
  },
  "copy_stream_data/3": {
    "body":"copy_stream_data(${1:StreamIn}, ${2:StreamOut}, ${3:Len})$4\n$0",
    "description":"copy_stream_data(+StreamIn, +StreamOut, +Len).\nCopy Len codes from StreamIn to StreamOut.  Note that the copy is done using the semantics of get_code/2  and put_code/2,  taking care of possibly recoding that needs to take place between two  text files. See section 2.18.1.",
    "prefix":"copy_stream_data"
  },
  "copy_term/2": {
    "body":"copy_term(${1:In}, ${2:Out})$3\n$0",
    "description":"[ISO]copy_term(+In, -Out).\nCreate a version of In with renamed (fresh) variables and  unify it to Out. Attributed variables (see section  7.1) have their attributes copied. The implementation of copy_term/2  can deal with infinite trees (cyclic terms). As pure Prolog cannot  distinguish a ground term from another ground term with exactly the same  structure, ground sub-terms are shared between In  and Out. Sharing ground terms does affect setarg/3.  SWI-Prolog provides duplicate_term/2  to create a true copy of a term.",
    "prefix":"copy_term"
  },
  "copy_term/3": {
    "body":"copy_term(${1:Term}, ${2:Copy}, ${3:Gs})$4\n$0",
    "description":"copy_term(+Term, -Copy, -Gs).\nCreate a regular term Copy as a copy of Term  (without any attributes), and a list Gs of goals that  represents the attributes. The goal maplist(call, Gs)  recreates the attributes for Copy. The nonterminal attribute_goals/3,  as defined in the modules the attributes stem from, is used to convert  attributes to lists of goals.  This building block is used by the top level to report pending  attributes in a portable and understandable fashion. This predicate is  the preferred way to reason about and communicate terms with  constraints. \n\nThe form copy_term(Term, Term, Gs) can be used to reason  about the constraints in which Term is involved.\n\n",
    "prefix":"copy_term"
  },
  "copy_term_nat/2": {
    "body":"copy_term_nat(${1:Term}, ${2:Copy})$3\n$0",
    "description":"copy_term_nat(+Term, -Copy).\nAs copy_term/2.  Attributes, however, are not copied but replaced by fresh  variables.",
    "prefix":"copy_term_nat"
  },
  "copysign/2": {
    "body":"copysign(${1:Expr1}, ${2:Expr2})$3\n$0",
    "description":"[ISO]copysign(+Expr1, +Expr2).\nEvaluate to X, where the absolute value of X  equals the absolute value of Expr1 and the sign of X  matches the sign of Expr2. This function is based on  copysign() from C99, which works on double precision floats and deals  with handling the sign of special floating point values such as -0.0.  Our implementation follows C99 if both arguments are floats. Otherwise, copysign/2  evaluates to Expr1 if the sign of both expressions matches or  -Expr1 if the signs do not match. Here, we use the extended  notion of signs for floating point numbers, where the sign of -0.0 and  other special floats is negative.",
    "prefix":"copysign"
  },
  "cos/1": {
    "body":"cos(${1:Expr})$2\n$0",
    "description":"[ISO]cos(+Expr).\nResult = cos(Expr). Expr is  the angle in radians.",
    "prefix":"cos"
  },
  "cosh/1": {
    "body":"cosh(${1:Expr})$2\n$0",
    "description":"cosh(+Expr).\nResult = cosh(Expr). The hyperbolic  cosine of X is defined as e ** X + e ** -X / 2.",
    "prefix":"cosh"
  },
  "cputime/0": {
    "body":"cputime$1\n$0",
    "description":"cputime.\nEvaluate to a floating point number expressing the CPU  time (in seconds) used by Prolog up till now. See also statistics/2  and time/1.",
    "prefix":"cputime"
  },
  "cql/cql:attribute_domain/4": {
    "body":"attribute_domain(${1:Schema}, ${2:TableName}, ${3:ColumnName}, ${4:Domain})$5\n$0",
    "description":"attribute_domain(+Schema, +TableName, +ColumnName, -Domain).\n",
    "prefix":"attribute_domain"
  },
  "cql/cql:cql_access_token_to_user_id/2": {
    "body": ["cql_access_token_to_user_id(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"cql_access_token_to_user_id('Param1','Param2')",
    "prefix":"cql_access_token_to_user_id"
  },
  "cql/cql:cql_data_type/10": {
    "body": [
      "cql_data_type(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'}, ${9:'Param9'}, ${10:'Param10'})$11\n$0"
    ],
    "description":"cql_data_type('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8','Param9','Param10')",
    "prefix":"cql_data_type"
  },
  "cql/cql:cql_error/3": {
    "body": ["cql_error(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"cql_error('Param1','Param2','Param3')",
    "prefix":"cql_error"
  },
  "cql/cql:cql_event_notification_table/2": {
    "body":"cql_event_notification_table(${1:Schema}, ${2:TableName})$3\n$0",
    "description":"[multifile]cql_event_notification_table(+Schema, +TableName).\n",
    "prefix":"cql_event_notification_table"
  },
  "cql/cql:cql_execute/1": {
    "body": ["cql_execute(${1:'Param1'})$2\n$0" ],
    "description":"cql_execute('Param1')",
    "prefix":"cql_execute"
  },
  "cql/cql:cql_get_module_default_schema/2": {
    "body":"cql_get_module_default_schema(${1:Module}, ${2:ModuleDefaultSchema})$3\n$0",
    "description":"cql_get_module_default_schema(+Module, ?ModuleDefaultSchema).\n",
    "prefix":"cql_get_module_default_schema"
  },
  "cql/cql:cql_goal_expansion/3": {
    "body":"cql_goal_expansion(${1:Schema}, ${2:Cql}, ${3:GoalExpansion})$4\n$0",
    "description":"cql_goal_expansion(?Schema, ?Cql, ?GoalExpansion).\nExpand at compile time if the first term is a list of unbound input  variables  Expand at runtime if the first term is compile_at_runtime\n\n",
    "prefix":"cql_goal_expansion"
  },
  "cql/cql:cql_history_attribute/3": {
    "body":"cql_history_attribute(${1:Schema}, ${2:TableName}, ${3:ColumnName})$4\n$0",
    "description":"[multifile]cql_history_attribute(+Schema, +TableName, +ColumnName).\n",
    "prefix":"cql_history_attribute"
  },
  "cql/cql:cql_identity/3": {
    "body": ["cql_identity(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"cql_identity('Param1','Param2','Param3')",
    "prefix":"cql_identity"
  },
  "cql/cql:cql_log/4": {
    "body": [
      "cql_log(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"cql_log('Param1','Param2','Param3','Param4')",
    "prefix":"cql_log"
  },
  "cql/cql:cql_normalize_name/3": {
    "body":"cql_normalize_name(${1:DBMS}, ${2:Name}, ${3:NormalizedName})$4\n$0",
    "description":"cql_normalize_name(+DBMS, +Name, -NormalizedName).\nNormalize a name which is potentially longer than the DBMS  allows to a unique truncation",
    "prefix":"cql_normalize_name"
  },
  "cql/cql:cql_odbc_select_statement/4": {
    "body": [
      "cql_odbc_select_statement(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"cql_odbc_select_statement('Param1','Param2','Param3','Param4')",
    "prefix":"cql_odbc_select_statement"
  },
  "cql/cql:cql_odbc_state_change_statement/7": {
    "body": [
      "cql_odbc_state_change_statement(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'})$8\n$0"
    ],
    "description":"cql_odbc_state_change_statement('Param1','Param2','Param3','Param4','Param5','Param6','Param7')",
    "prefix":"cql_odbc_state_change_statement"
  },
  "cql/cql:cql_portray/2": {
    "body": ["cql_portray(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"cql_portray('Param1','Param2')",
    "prefix":"cql_portray"
  },
  "cql/cql:cql_post_state_change_select_sql/4": {
    "body": [
      "cql_post_state_change_select_sql(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"cql_post_state_change_select_sql('Param1','Param2','Param3','Param4')",
    "prefix":"cql_post_state_change_select_sql"
  },
  "cql/cql:cql_pre_state_change_select_sql/7": {
    "body": [
      "cql_pre_state_change_select_sql(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'})$8\n$0"
    ],
    "description":"cql_pre_state_change_select_sql('Param1','Param2','Param3','Param4','Param5','Param6','Param7')",
    "prefix":"cql_pre_state_change_select_sql"
  },
  "cql/cql:cql_runtime/7": {
    "body":"cql_runtime(${1:Schema}, ${2:IgnoreIfNullVariables}, ${3:CqlA}, ${4:CqlB}, ${5:VariableMap}, ${6:FileName}, ${7:LineNumber})$8\n$0",
    "description":"cql_runtime(+Schema, +IgnoreIfNullVariables, +CqlA, +CqlB, +VariableMap, +FileName, +LineNumber).\n",
    "prefix":"cql_runtime"
  },
  "cql/cql:cql_set_module_default_schema/1": {
    "body":"cql_set_module_default_schema(${1:Schema})$2\n$0",
    "description":"cql_set_module_default_schema(+Schema).\nSet the Schema for a module",
    "prefix":"cql_set_module_default_schema"
  },
  "cql/cql:cql_show/2": {
    "body":"cql_show(${1:Goal}, ${2:Mode})$3\n$0",
    "description":"cql_show(:Goal, +Mode).\nCalled when ?/1, ??/1,  and ???/1 applied to CQL Goal goal term Mode minimal ; explicit ; full ",
    "prefix":"cql_show"
  },
  "cql/cql:cql_sql_clause/3": {
    "body": ["cql_sql_clause(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"cql_sql_clause('Param1','Param2','Param3')",
    "prefix":"cql_sql_clause"
  },
  "cql/cql:cql_state_change_statistics_sql/8": {
    "body": [
      "cql_state_change_statistics_sql(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'})$9\n$0"
    ],
    "description":"cql_state_change_statistics_sql('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8')",
    "prefix":"cql_state_change_statistics_sql"
  },
  "cql/cql:cql_statement_location/2": {
    "body": ["cql_statement_location(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"cql_statement_location('Param1','Param2')",
    "prefix":"cql_statement_location"
  },
  "cql/cql:cql_temporary_column_name/4": {
    "body":"cql_temporary_column_name(${1:Schema}, ${2:DataType}, ${3:ColumnName}, ${4:Type})$5\n$0",
    "description":"cql_temporary_column_name(?Schema, ?DataType, ?ColumnName, ?Type).\n",
    "prefix":"cql_temporary_column_name"
  },
  "cql/cql:cql_transaction/3": {
    "body": [
      "cql_transaction(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"cql_transaction('Param1','Param2','Param3')",
    "prefix":"cql_transaction"
  },
  "cql/cql:cql_update_history_hook/14": {
    "body": [
      "cql_update_history_hook(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'}, ${9:'Param9'}, ${10:'Param10'}, ${11:'Param11'}, ${12:'Param12'}, ${13:'Param13'}, ${14:'Param14'})$15\n$0"
    ],
    "description":"cql_update_history_hook('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8','Param9','Param10','Param11','Param12','Param13','Param14')",
    "prefix":"cql_update_history_hook"
  },
  "cql/cql:cql_var_check/1": {
    "body": ["cql_var_check(${1:'Param1'})$2\n$0" ],
    "description":"cql_var_check('Param1')",
    "prefix":"cql_var_check"
  },
  "cql/cql:database_attribute/8": {
    "body":"database_attribute(${1:EntityType}, ${2:Schema}, ${3:EntityName}, ${4:ColumnName}, ${5:DomainOrNativeType}, ${6:AllowsNulls}, ${7:IsIdentity}, ${8:ColumnDefault})$9\n$0",
    "description":"[nondet,multifile]database_attribute(?EntityType:table/view, ?Schema:atom, ?EntityName:atom, ?ColumnName:atom, ?DomainOrNativeType:atom, ?AllowsNulls:allows_nulls(true/false), ?IsIdentity:is_identity(true/false), ?ColumnDefault).\nCan be autoconfigured.",
    "prefix":"database_attribute"
  },
  "cql/cql:database_constraint/4": {
    "body":"database_constraint(${1:Schema}, ${2:EntityName}, ${3:ConstraintName}, ${4:Constraint})$5\n$0",
    "description":"[nondet,multifile]database_constraint(?Schema:atom, ?EntityName:atom, ?ConstraintName:atom, ?Constraint).\nConstraint is one of:  \n\nprimary_key(ColumnNames:list)\nforeign_key(ForeignTableName:atom, ForeignColumnNames:list, ColumnNames:list)\nunique(ColumnNames:list)\ncheck(CheckClause)\n\n  In theory this can be autoconfigured too, but I have not written the  code for it yet\n\n",
    "prefix":"database_constraint"
  },
  "cql/cql:database_domain/2": {
    "body": ["database_domain(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"database_domain('Param1','Param2')",
    "prefix":"database_domain"
  },
  "cql/cql:database_identity/3": {
    "body":"database_identity(${1:Schema}, ${2:EntityName}, ${3:ColumnName})$4\n$0",
    "description":"database_identity(?Schema:atom, ?EntityName:atom, ?ColumnName:atom).\n",
    "prefix":"database_identity"
  },
  "cql/cql:database_key/5": {
    "body":"database_key(${1:Schema}, ${2:EntityName}, ${3:ConstraintName}, ${4:KeyColumnNames}, ${5:KeyType})$6\n$0",
    "description":"database_key(?Schema:atom, ?EntityName:atom, ?ConstraintName:atom, ?KeyColumnNames:list, ?KeyType).\nKeyColumnNames list of atom  in database-supplied order KeyType identity ; 'primary  key' ; unique ",
    "prefix":"database_key"
  },
  "cql/cql:dbms/2": {
    "body":"dbms(${1:Schema}, ${2:DBMSName})$3\n$0",
    "description":"[multifile]dbms(+Schema, -DBMSName).\nDetermine the DBMS for a given Schema. Can be autoconfigured.",
    "prefix":"dbms"
  },
  "cql/cql:default_schema/1": {
    "body": ["default_schema(${1:'Param1'})$2\n$0" ],
    "description":"default_schema('Param1')",
    "prefix":"default_schema"
  },
  "cql/cql:domain_database_data_type/2": {
    "body": ["domain_database_data_type(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"domain_database_data_type('Param1','Param2')",
    "prefix":"domain_database_data_type"
  },
  "cql/cql:in_line_format/4": {
    "body": [
      "in_line_format(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"in_line_format('Param1','Param2','Param3','Param4')",
    "prefix":"in_line_format"
  },
  "cql/cql:odbc_data_type/4": {
    "body":"odbc_data_type(${1:Schema}, ${2:TableSpec}, ${3:ColumnName}, ${4:OdbcDataType})$5\n$0",
    "description":"[multifile]odbc_data_type(+Schema, +TableSpec, +ColumnName, ?OdbcDataType).\nOdbcDataType must be a native SQL datatype, such as varchar(30)  or decimal(10, 5) Can be autoconfigured.",
    "prefix":"odbc_data_type"
  },
  "cql/cql:odbc_execute_with_statistics/4": {
    "body": [
      "odbc_execute_with_statistics(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"odbc_execute_with_statistics('Param1','Param2','Param3','Param4')",
    "prefix":"odbc_execute_with_statistics"
  },
  "cql/cql:primary_key_column_name/3": {
    "body":"primary_key_column_name(${1:Schema}, ${2:TableName}, ${3:PrimaryKeyAttributeName})$4\n$0",
    "description":"[multifile]primary_key_column_name(+Schema, +TableName, -PrimaryKeyAttributeName).\nCan be autoconfigured.",
    "prefix":"primary_key_column_name"
  },
  "cql/cql:register_database_connection_details/2": {
    "body":"register_database_connection_details(${1:Schema}, ${2:ConnectionDetails})$3\n$0",
    "description":"[det]register_database_connection_details(+Schema:atom, +ConnectionDetails).\nThis should be called once to register the database connection details. ConnectionDetails driver_string(DriverString)  or dsn(Dsn, Username, Password) ",
    "prefix":"register_database_connection_details"
  },
  "cql/cql:routine_return_type/3": {
    "body":"routine_return_type(${1:Schema}, ${2:EntityName}, ${3:OdbcType})$4\n$0",
    "description":"[multifile]routine_return_type(?Schema:atom, ?EntityName:atom, ?OdbcType).\nCan be autoconfigured",
    "prefix":"routine_return_type"
  },
  "cql/cql:row_count/2": {
    "body": ["row_count(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"row_count('Param1','Param2')",
    "prefix":"row_count"
  },
  "cql/cql:sql_gripe/3": {
    "body": ["sql_gripe(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"sql_gripe('Param1','Param2','Param3')",
    "prefix":"sql_gripe"
  },
  "cql/cql:sql_gripe_hook/3": {
    "body":"sql_gripe_hook(${1:Level}, ${2:Format}, ${3:Args})$4\n$0",
    "description":"[multifile]sql_gripe_hook(+Level, +Format, +Args).\nCalled when something dubious is found by the SQL parser.",
    "prefix":"sql_gripe_hook"
  },
  "cql/cql:statistic_monitored_attribute/3": {
    "body":"statistic_monitored_attribute(${1:Schema}, ${2:TableName}, ${3:ColumnName})$4\n$0",
    "description":"statistic_monitored_attribute(+Schema, +TableName, +ColumnName).\n",
    "prefix":"statistic_monitored_attribute"
  },
  "cql/cql_database:application_value_to_odbc_value/7": {
    "body": [
      "application_value_to_odbc_value(${1:ApplicationValue}, ${2:OdbcDataType}, ${3:Schema}, ${4:TableName}, ${5:ColumnName}, ${6:Qualifiers}, ${7:OdbcValue})$8\n$0"
    ],
    "description":"      application_value_to_odbc_value(+ApplicationValue, +OdbcDataType, +Schema, +TableName, +ColumnName, +Qualifiers, -OdbcValue).",
    "prefix":"application_value_to_odbc_value"
  },
  "cql/cql_database:cql_transaction/3": {
    "body": [
      "cql_transaction(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"cql_transaction('Param1','Param2','Param3')",
    "prefix":"cql_transaction"
  },
  "cql/cql_database:current_transaction_id/1": {
    "body": ["current_transaction_id(${1:TransactionId})$2\n$0" ],
    "description":"      current_transaction_id(-TransactionId).",
    "prefix":"current_transaction_id"
  },
  "cql/cql_database:database_connection_details/2": {
    "body": ["database_connection_details(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"database_connection_details('Param1','Param2')",
    "prefix":"database_connection_details"
  },
  "cql/cql_database:database_transaction_query_info/3": {
    "body": [
      "database_transaction_query_info(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"database_transaction_query_info('Param1','Param2','Param3')",
    "prefix":"database_transaction_query_info"
  },
  "cql/cql_database:get_transaction_context/5": {
    "body": [
      "get_transaction_context(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"get_transaction_context('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"get_transaction_context"
  },
  "cql/cql_database:odbc_cleanup_and_disconnect/1": {
    "body": ["odbc_cleanup_and_disconnect(${1:Connection})$2\n$0" ],
    "description":"      odbc_cleanup_and_disconnect(+Connection) is det.\n\n       Rollback the current transaction, retract and free prepared statements, then disconnect.\n\n       To avoid leaks, all exiting threads with database connections should call this.  See odbc_connection_call/2 (thread_at_exit/1)\n\n       Note that any exception inside odbc_cleanup_and_disconnect/1 will result in it not going on to the next step.\n\n       We log exceptions to the event log because exceptions at this level are associated with the server process crashing\n       and the SE log is unlikely to capture anything useful.",
    "prefix":"odbc_cleanup_and_disconnect"
  },
  "cql/cql_database:odbc_connection_call/3": {
    "body": [
      "odbc_connection_call(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"odbc_connection_call('Param1','Param2','Param3')",
    "prefix":"odbc_connection_call"
  },
  "cql/cql_database:odbc_execute_with_statement_cache/7": {
    "body": [
      "odbc_execute_with_statement_cache(${1:Connection}, ${2:FileName}, ${3:LineNumber}, ${4:Sql}, ${5:OdbcParameters}, ${6:OdbcParameterDataTypes}, ${7:Row})$8\n$0"
    ],
    "description":"      odbc_execute_with_statement_cache(+Connection, +FileName, +LineNumber, +Sql, +OdbcParameters, +OdbcParameterDataTypes, -Row)",
    "prefix":"odbc_execute_with_statement_cache"
  },
  "cql/cql_database:odbc_value_to_application_value/5": {
    "body": [
      "odbc_value_to_application_value(${1:Schema}, ${2:TableSpec}, ${3:ColumnName}, ${4:OdbcValue}, ${5:ApplicationValue})$6\n$0"
    ],
    "description":"      odbc_value_to_application_value(+Schema, +TableSpec, +ColumnName, +OdbcValue, ?ApplicationValue).",
    "prefix":"odbc_value_to_application_value"
  },
  "cql/cql_database:register_database_connection_details/2": {
    "body": [
      "register_database_connection_details(${1:Schema}, ${2:ConnectionDetails})$3\n$0"
    ],
    "description":"      register_database_connection_details(+Schema:atom, +ConnectionDetails) is det.\n\n       This should be called once to register the database connection details.\n\n       @param ConnectionDetails driver_string(DriverString) or dsn(Dsn, Username, Password)",
    "prefix":"register_database_connection_details"
  },
  "cql/cql_database:resolve_deadlock/1": {
    "body": ["resolve_deadlock(${1:Goal})$2\n$0" ],
    "description":"      resolve_deadlock(:Goal)\n\n       Call Goal as in catch/3.  If a deadlock ('40001') error occurs then Goal is *|called again|* immediately if another transaction has completed in the\n       time since Goal was called, since that transaction may well have been the reason for the deadlock.\n       If no other transaction has completed Goal is *|called again|* after a random delay of 0.0 to 2.0 seconds.  The maximum number of retries\n       is specified by maximum_deadlock_retries/1.  It is important to note that the deadlock mechanism actually *|retries|* Goal, i.e. it calls it\n       *|again|*.\n\n       *|Use this only when you are sure Goal has no non-database side effects (assert/retract, file operations etc)|*\n\n       Originally developed for use inside cql_transaction/3, resolve_deadlock/1 can also be used to ensure non-transactional\n       operations can resolve deadlocks.",
    "prefix":"resolve_deadlock"
  },
  "cql/cql_database:save_database_event/6": {
    "body": [
      "save_database_event(${1:AccessToken}, ${2:\n%%}, ${3:\n%%}, ${4:\n%%}, ${5:\n%%}, ${6:\n%%})$7\n$0"
    ],
    "description":"      save_database_event(+AccessToken,\n                          +EventType,\n                          +Schema,\n                          +TableName,\n                          +PrimaryKeyColumnName,\n                          +PrimaryKey).\n\n       Need this because its called from the caller's module and we want the fact asserted\n       in this module",
    "prefix":"save_database_event"
  },
  "cql/cql_database:transaction_active/0": {
    "body": ["transaction_active$1\n$0" ],
    "description":"transaction_active",
    "prefix":"transaction_active"
  },
  "cql/cql_database:update_history/14": {
    "body": [
      "update_history(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'}, ${9:'Param9'}, ${10:'Param10'}, ${11:'Param11'}, ${12:'Param12'}, ${13:'Param13'}, ${14:'Param14'})$15\n$0"
    ],
    "description":"update_history('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8','Param9','Param10','Param11','Param12','Param13','Param14')",
    "prefix":"update_history"
  },
  "cql/cql_hooks:application_value_to_odbc_value_hook/7": {
    "body": [
      "application_value_to_odbc_value_hook(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'})$8\n$0"
    ],
    "description":"application_value_to_odbc_value_hook('Param1','Param2','Param3','Param4','Param5','Param6','Param7')",
    "prefix":"application_value_to_odbc_value_hook"
  },
  "cql/cql_hooks:cql_update_history_hook/16": {
    "body": [
      "cql_update_history_hook(${1:Schema}, ${2:\n%%}, ${3:\n%%}, ${4:\n%%}, ${5:\n%%}, ${6:\n%%}, ${7:\n%%}, ${8:\n%%}, ${9:\n%%}, ${10:\n%%}, ${11:\n%%}, ${12:\n%%}, ${13:\n%%}, ${14:\n%%}, ${15:\n%%}, ${16:\n%%})$17\n$0"
    ],
    "description":"      cql_update_history_hook(+Schema,\n                              +TableName,\n                              +AttributeName,\n                              +PrimaryKeyAttributeName,\n                              +PrimaryKeyValue,\n                              +ApplicationValueBefore,\n                              +ApplicationValueAfter,\n                              +AccessToken,\n                              +UserId,\n                              +UserIpAddress,\n                              +TransactionId,\n                              +TransactionTimestamp,\n                              +ThreadId,\n                              +Spid,\n                              +Connection,\n                              +Goal).\n\n       Use this hook predicate to actually record database attribute value changes.\n\n       You are free to let this predicate fail or raise an exception - the\n       database layer will ignore both of these eventualities.\n\n       @param Schema <atom>\n       @param TableName <atom> (lower case)\n       @param AttributeName <atom> (lower case)\n       @param PrimaryKeyAttributeName <atom> (lower case)\n       @param PrimaryKeyValue <int>\n       @param ApplicationValueBefore <domain dependent>\n       @param ApplicationValueAfter <domain dependent>\n       @param AccessToken <atom>\n       @param UserId <atom>\n       @param UserIpAddress <atom>\n       @param TransactionId <atom>\n       @param TransactionTimestamp <t7/7>\n       @param ThreadId <atom>\n       @param Spid <int>\n       @param Connection <opaque>\n       @param Goal <goal term> The goal passed to pri_db_trans",
    "prefix":"cql_update_history_hook"
  },
  "cql/cql_hooks:odbc_value_to_application_value_hook/7": {
    "body": [
      "odbc_value_to_application_value_hook(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'})$8\n$0"
    ],
    "description":"odbc_value_to_application_value_hook('Param1','Param2','Param3','Param4','Param5','Param6','Param7')",
    "prefix":"odbc_value_to_application_value_hook"
  },
  "cql/sql_keywords:reserved_sql_keyword/1": {
    "body": ["reserved_sql_keyword(${1:'Param1'})$2\n$0" ],
    "description":"reserved_sql_keyword('Param1')",
    "prefix":"reserved_sql_keyword"
  },
  "cql/sql_parser:sql_gripe_level/1": {
    "body": ["sql_gripe_level(${1:'Param1'})$2\n$0" ],
    "description":"sql_gripe_level('Param1')",
    "prefix":"sql_gripe_level"
  },
  "cql/sql_parser:sql_parse/4": {
    "body": [
      "sql_parse(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"sql_parse('Param1','Param2','Param3','Param4')",
    "prefix":"sql_parse"
  },
  "cql/sql_parser:strip_sql_comments/2": {
    "body": ["strip_sql_comments(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"strip_sql_comments('Param1','Param2')",
    "prefix":"strip_sql_comments"
  },
  "cql/sql_tokenizer:sql_tokens/3": {
    "body": ["sql_tokens(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"sql_tokens('Param1','Param2','Param3')",
    "prefix":"sql_tokens"
  },
  "cql/sql_write:format_sql_error/3": {
    "body": [
      "format_sql_error(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"format_sql_error('Param1','Param2','Param3')",
    "prefix":"format_sql_error"
  },
  "cql/sql_write:sql_quote_codes/3": {
    "body": [
      "sql_quote_codes(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"sql_quote_codes('Param1','Param2','Param3')",
    "prefix":"sql_quote_codes"
  },
  "cql/sql_write:sql_write/3": {
    "body": ["sql_write(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"sql_write('Param1','Param2','Param3')",
    "prefix":"sql_write"
  },
  "create_prolog_flag/3": {
    "body":"create_prolog_flag(${1:Key}, ${2:Value}, ${3:Options})$4\n$0",
    "description":"[YAP]create_prolog_flag(+Key, +Value, +Options).\nCreate a new Prolog flag. The ISO standard does not foresee creation of  new flags, but many libraries introduce new flags. Options is  a list of the options below. See also user_flags.  access(+Access): Define access rights for the flag. Values are read_write  and read_only. The default is read_write.\n\ntype(+Atom): Define a type restriction. Possible values are boolean, atom, integer, float  and term. The default is determined from the initial value.  Note that term restricts the term to be ground.\n\nkeep(+Boolean): If true, do not modify the flag if it already exists.  Otherwise (default), this predicate behaves as set_prolog_flag/2  if the flag already exists.\n\n ",
    "prefix":"create_prolog_flag"
  },
  "crypt:crypt/2": {
    "body": ["crypt(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"crypt('Param1','Param2')",
    "prefix":"crypt"
  },
  "crypto:cert_accept_any/5": {
    "body":"cert_accept_any(${1:SSL}, ${2:ProblemCertificate}, ${3:AllCertificates}, ${4:FirstCertificate}, ${5:Error})$6\n$0",
    "description":"[det]cert_accept_any(+SSL, +ProblemCertificate, +AllCertificates, +FirstCertificate, +Error).\nImplementation for the hook `cert_verify_hook(:Hook)` that accepts any  certificate. This is intended for http_open/3  if no certificate verification is desired as illustrated below.  \n\n  http_open('https:/...', In,\n            [ cert_verify_hook(cert_accept_any)\n            ])\n\n  \n\n",
    "prefix":"cert_accept_any"
  },
  "crypto:crypto_context_hash/2": {
    "body":"crypto_context_hash(${1:Context}, ${2:Hash})$3\n$0",
    "description":"crypto_context_hash(+Context, -Hash).\nObtain the hash code of Context. Hash is an atom  representing the hash code that is associated with the current state of  the computation context Context.",
    "prefix":"crypto_context_hash"
  },
  "crypto:crypto_context_new/2": {
    "body":"crypto_context_new(${1:Context}, ${2:Options})$3\n$0",
    "description":"[det]crypto_context_new(-Context, +Options).\nContext is unified with the empty context, taking into  account Options. The context can be used in crypto_data_context/3.  For Options, see crypto_data_hash/3. Context is an opaque pure  Prolog term that is subject to garbage collection. ",
    "prefix":"crypto_context_new"
  },
  "crypto:crypto_data_context/3": {
    "body":"crypto_data_context(${1:Data}, ${2:Context0}, ${3:Context})$4\n$0",
    "description":"[det]crypto_data_context(+Data, +Context0, -Context).\nContext0 is an existing computation context, and Context  is the new context after hashing Data in addition to the  previously hashed data. Context0 may be produced by a prior  invocation of either crypto_context_new/2  or crypto_data_context/3  itself.  This predicate allows a hash to be computed in chunks, which may be  important while working with Metalink (RFC 5854), BitTorrent or similar  technologies, or simply with big files.\n\n",
    "prefix":"crypto_data_context"
  },
  "crypto:crypto_data_hash/3": {
    "body":"crypto_data_hash(${1:Data}, ${2:Hash}, ${3:Options})$4\n$0",
    "description":"[det]crypto_data_hash(+Data, -Hash, +Options).\nHash is the hash of Data. The conversion is  controlled by Options:  algorithm(+Algorithm): One of md5, sha1, sha224, sha256  (default), sha384, sha512, blake2s256 or blake2b512.  The BLAKE digest algorithms require OpenSSL 1.1.0 or  greater.\n\nencoding(+Encoding): If Data is a sequence of character codes, this must be  translated into a sequence of bytes, because that is what the  hashing requires. The default encoding is utf8. The other  meaningful value is octet, claiming that Data  contains raw bytes.\n\nhmac(+Key): If this option is specified, a hash-based message authentication code  (HMAC) is computed, using the specified Key which is either  an atom or string. Any of the available digest algorithms can be used  with this option. The cryptographic strength of the HMAC depends on that  of the chosen algorithm and also on the key. This option requires  OpenSSL 1.1.0 or greater.\n\n  Data is either an atom, string  or code-list Hash is an atom that represents  the hash.   See also: hex_bytes/2 for conversion  between hashes and lists.\n\n ",
    "prefix":"crypto_data_hash"
  },
  "crypto:crypto_file_hash/3": {
    "body":"crypto_file_hash(${1:File}, ${2:Hash}, ${3:Options})$4\n$0",
    "description":"[det]crypto_file_hash(+File, -Hash, +Options).\nTrue if Hash is the hash of the content of File.  For Options, see crypto_data_hash/3.",
    "prefix":"crypto_file_hash"
  },
  "crypto:crypto_open_hash_stream/3": {
    "body":"crypto_open_hash_stream(${1:OrgStream}, ${2:HashStream}, ${3:Options})$4\n$0",
    "description":"[det]crypto_open_hash_stream(+OrgStream, -HashStream, +Options).\nOpen a filter stream on OrgStream that maintains a hash. The  hash can be retrieved at any time using crypto_stream_hash/2.  Available Options in addition to those of crypto_data_hash/3  are:  close_parent(+Bool): If true (default), closing the filter stream also closes  the original (parent) stream.\n\n ",
    "prefix":"crypto_open_hash_stream"
  },
  "crypto:crypto_stream_hash/2": {
    "body":"crypto_stream_hash(${1:HashStream}, ${2:Hash})$3\n$0",
    "description":"[det]crypto_stream_hash(+HashStream, -Hash).\nUnify Hash with a hash for the bytes sent to or read from HashStream. Note that the hash is computed on the stream  buffers. If the stream is an output stream, it is first flushed and the  Digest represents the hash at the current location. If the stream is an  input stream the Digest represents the hash of the processed input  including the already buffered data.",
    "prefix":"crypto_stream_hash"
  },
  "crypto:ecdsa_sign/4": {
    "body":"ecdsa_sign(${1:Key}, ${2:Data}, ${3:Signature}, ${4:Options})$5\n$0",
    "description":"ecdsa_sign(+Key, +Data, -Signature, +Options).\nCreate an ECDSA signature for Data with EC private key Key.  Among the most common cases is signing a hash that was created with crypto_data_hash/3  or other predicates of this library. For this reason, the default  encoding (hex) assumes that Data is an atom,  string, character list or code list representing the data in hexadecimal  notation. See rsa_sign/4 for an  example.  Options: \n\nencoding(+Encoding): Encoding to use for Data. Default is hex.  Alternatives are octet, utf8 and text.\n\n ",
    "prefix":"ecdsa_sign"
  },
  "crypto:ecdsa_verify/4": {
    "body":"ecdsa_verify(${1:Key}, ${2:Data}, ${3:Signature}, ${4:Options})$5\n$0",
    "description":"[semidet]ecdsa_verify(+Key, +Data, +Signature, +Options).\nTrue iff Signature can be verified as the ECDSA signature for Data, using the EC public key Key.  Options: \n\nencoding(+Encoding): Encoding to use for Data. Default is hex.  Alternatives are octet, utf8 and text.\n\n ",
    "prefix":"ecdsa_verify"
  },
  "crypto:evp_decrypt/6": {
    "body":"evp_decrypt(${1:CipherText}, ${2:Algorithm}, ${3:Key}, ${4:IV}, ${5:PlainText}, ${6:Options})$7\n$0",
    "description":"evp_decrypt(+CipherText, +Algorithm, +Key, +IV, -PlainText, +Options).\nDecrypt the given CipherText, using the symmetric algorithm Algorithm, key Key, and iv IV, to give PlainText. CipherText, Key  and IV should all be strings, and PlainText is  created as a string as well. Algorithm should be an algorithm  which your copy of OpenSSL knows about. Examples are:  \n\naes-128-cbc\naes-256-cbc\ndes3\n\n  If the IV is not needed for your decryption algorithm  (such as aes-128-ecb) then any string can be provided as it will be  ignored by the underlying implementation \n\nOptions: \n\nencoding(+Encoding): Encoding to use for Data. Default is utf8.  Alternatives are utf8 and octet.\n\npadding(+PaddingScheme): Padding scheme to use. Default is block. You can disable  padding by supplying none here.\n\n  Example of aes-128-cbc encryption: \n\n\n\n?- evp_encrypt(\"this is some input\", 'aes-128-cbc', \"sixteenbyteofkey\",\n               \"sixteenbytesofiv\", CipherText, []),\n   evp_decrypt(CipherText, 'aes-128-cbc',\n               \"sixteenbyteofkey\", \"sixteenbytesofiv\",\n               RecoveredText, []).\nCipherText = <binary string>\nRecoveredText = \"this is some input\".\n\n ",
    "prefix":"evp_decrypt"
  },
  "crypto:evp_encrypt/6": {
    "body":"evp_encrypt(${1:PlainText}, ${2:Algorithm}, ${3:Key}, ${4:IV}, ${5:CipherTExt}, ${6:Options})$7\n$0",
    "description":"evp_encrypt(+PlainText, +Algorithm, +Key, +IV, -CipherTExt, +Options).\nEncrypt the given PlainText, using the symmetric algorithm Algorithm, key Key, and iv IV, to give  CipherText. See evp_decrypt/6.",
    "prefix":"evp_encrypt"
  },
  "crypto:hex_bytes/2": {
    "body":"hex_bytes(${1:Hex}, ${2:List})$3\n$0",
    "description":"[det]hex_bytes(?Hex, ?List).\nRelation between a hexadecimal sequence and a list of bytes. Hex  is an atom, string, list of characters or list of codes in hexadecimal  encoding. This is the format that is used by crypto_data_hash/3 and  related predicates to represent hashes. Bytes is a list of integers  between 0 and 255 that represent the sequence as a list of bytes. At  least one of the arguments must be instantiated. When converting List to Hex,  an atom is used to represent the sequence of hexadecimal digits.  Example: \n\n\n\n?- hex_bytes('501ACE', Bs).\nBs = [80, 26, 206].\n\n  \n\n",
    "prefix":"hex_bytes"
  },
  "crypto:rsa_private_decrypt/4": {
    "body":"rsa_private_decrypt(${1:PrivateKey}, ${2:CipherText}, ${3:PlainText}, ${4:Options})$5\n$0",
    "description":"[det]rsa_private_decrypt(+PrivateKey, +CipherText, -PlainText, +Options).\n",
    "prefix":"rsa_private_decrypt"
  },
  "crypto:rsa_private_encrypt/4": {
    "body":"rsa_private_encrypt(${1:PrivateKey}, ${2:PlainText}, ${3:CipherText}, ${4:Options})$5\n$0",
    "description":"[det]rsa_private_encrypt(+PrivateKey, +PlainText, -CipherText, +Options).\n",
    "prefix":"rsa_private_encrypt"
  },
  "crypto:rsa_public_decrypt/4": {
    "body":"rsa_public_decrypt(${1:PublicKey}, ${2:CipherText}, ${3:PlainText}, ${4:Options})$5\n$0",
    "description":"[det]rsa_public_decrypt(+PublicKey, +CipherText, -PlainText, +Options).\n",
    "prefix":"rsa_public_decrypt"
  },
  "crypto:rsa_public_encrypt/4": {
    "body":"rsa_public_encrypt(${1:PublicKey}, ${2:PlainText}, ${3:CipherText}, ${4:Options})$5\n$0",
    "description":"[det]rsa_public_encrypt(+PublicKey, +PlainText, -CipherText, +Options).\nRSA Public key encryption and decryption primitives. A string can be  safely communicated by first encrypting it and have the peer decrypt it  with the matching key and predicate. The length of the string is limited  by the key length.  Options: \n\nencoding(+Encoding): Encoding to use for Data. Default is utf8.  Alternatives are utf8 and octet.\n\npadding(+PaddingScheme): Padding scheme to use. Default is pkcs1. Alternatives are pkcs1_oaep, sslv23  and none. Note that none should only be used  if you implement cryptographically sound padding modes in your  application code as encrypting unpadded data with RSA is insecure\n\n  Errors: ssl_error(Code, LibName, FuncName, Reason) is raised if  there is an error, e.g., if the text is too long for the key.\n\nSee also: load_private_key/3, load_public_key/2  can be use to load keys from a file. The predicate load_certificate/2  can be used to obtain the public key from a certificate.\n\n ",
    "prefix":"rsa_public_encrypt"
  },
  "crypto:rsa_sign/4": {
    "body":"rsa_sign(${1:Key}, ${2:Data}, ${3:Signature}, ${4:Options})$5\n$0",
    "description":"[det]rsa_sign(+Key, +Data, -Signature, +Options).\nCreate an RSA signature for Data with private key Key. Options:  type(+Type): SHA algorithm used to compute the digest. Values are sha1 (default), sha224, sha256, sha384  or sha512.\n\nencoding(+Encoding): Encoding to use for Data. Default is hex.  Alternatives are octet, utf8 and text.\n\n  This predicate can be used to compute a sha256WithRSAEncryption  signature as follows: \n\n\n\nsha256_with_rsa(PemKeyFile, Password, Data, Signature) :-\n    Algorithm = sha256,\n    read_key(PemKeyFile, Password, Key),\n    crypto_data_hash(Data, Hash, [algorithm(Algorithm),\n                                  encoding(octet)]),\n    rsa_sign(Key, Hash, Signature, [type(Algorithm)]).\n\nread_key(File, Password, Key) :-\n    setup_call_cleanup(\n        open(File, read, In, [type(binary)]),\n        load_private_key(In, Password, Key),\n        close(In)).\n\n  Note that a hash that is computed by crypto_data_hash/3  can be directly used in rsa_sign/4  as well as ecdsa_sign/4.\n\n",
    "prefix":"rsa_sign"
  },
  "crypto:rsa_verify/4": {
    "body":"rsa_verify(${1:Key}, ${2:Data}, ${3:Signature}, ${4:Options})$5\n$0",
    "description":"[semidet]rsa_verify(+Key, +Data, +Signature, +Options).\nVerify an RSA signature for Data with public key Key.  Options: \n\ntype(+Type): SHA algorithm used to compute the digest. Values are sha1 (default), sha224, sha256, sha384  or sha512.\n\nencoding(+Encoding): Encoding to use for Data. Default is hex.  Alternatives are octet, utf8 and text.\n\n ",
    "prefix":"rsa_verify"
  },
  "crypto_hash:file_sha1/2": {
    "body": ["file_sha1(${1:File}, ${2:SHA1})$3\n$0" ],
    "description":"  file_sha1(+File, -SHA1:atom) is det.\n\n   True when SHA1 is the SHA1 hash for the content of File. Options\n   is passed to open/4 and typically used to control whether binary\n   or text encoding must be used. The   output is compatible to the\n   =sha1sum= program found in many systems.",
    "prefix":"file_sha1"
  },
  "crypto_hash:hash_atom/2": {
    "body": ["hash_atom(${1:HashCodes}, ${2:HexAtom})$3\n$0" ],
    "description":"  hash_atom(+HashCodes, -HexAtom) is det.\n\n   Convert a list of bytes (integers 0..255) into the usual\n   hexadecimal notation.  E.g.\n\n     ==\n     ?- sha_hash('SWI-Prolog', Hash, []),\n        hash_atom(Hash, Hex).\n     Hash = [61, 128, 252, 38, 121, 69, 229, 85, 199|...],\n     Hex = '3d80fc267945e555c730403bd0ab0716e2a68c68'.\n     ==",
    "prefix":"hash_atom"
  },
  "crypto_hash:hmac_sha/4": {
    "body": ["hmac_sha(${1:Key}, ${2:Data}, ${3:Hash}, ${4:Options})$5\n$0" ],
    "description":"  hmac_sha(+Key, +Data, -Hash, +Options) is det\n\n   For Options, see sha_hash/3.",
    "prefix":"hmac_sha"
  },
  "crypto_hash:sha_hash/3": {
    "body": ["sha_hash(${1:Data}, ${2:Hash}, ${3:Options})$4\n$0" ],
    "description":"  sha_hash(+Data, -Hash, +Options) is det\n\n   Hash is the SHA hash of Data, The conversion is controlled\n   by Options:\n\n     * algorithm(+Algorithm)\n     One of =sha1= (default), =sha224=, =sha256=, =sha384= or\n     =sha512=\n     * encoding(+Encoding)\n     If Data is a sequence of character _codes_, this must be\n     translated into a sequence of _bytes_, because that is what\n     the hashing requires.  The default encoding is =utf8=.  The\n     other meaningful value is =octet=, claiming that Data contains\n     raw bytes.\n\n   @param  Data is either an atom, string or code-list\n   @param  Hash is a packed string",
    "prefix":"sha_hash"
  },
  "crypto_hash:sha_hash_ctx/4": {
    "body": [
      "sha_hash_ctx(${1:OldContext}, ${2:Data}, ${3:NewContext}, ${4:Hash})$5\n$0"
    ],
    "description":"  sha_hash_ctx(+OldContext, +Data, -NewContext, -Hash) is det\n\n   Hash is the SHA hash of Data.  NewContext is the new SHA\n   computation context, while OldContext is the old.  OldContext\n   may be produced by a prior invocation of either sha_new_ctx/3 or\n   sha_hash_ctx/4 itself.\n\n   This predicate allows a SHA function to be computed in chunks,\n   which may be important while working with Metalink (RFC 5854),\n   BitTorrent or similar technologies, or simply with big files.",
    "prefix":"sha_hash_ctx"
  },
  "crypto_hash:sha_new_ctx/2": {
    "body": ["sha_new_ctx(${1:NewContext}, ${2:Options})$3\n$0" ],
    "description":"  sha_new_ctx(-NewContext, +Options) is det\n\n   NewContext is unified with the empty SHA computation context\n   (which includes the Options.)  It could later be passed to\n   sha_hash_ctx/4. For Options, see sha_hash/3.\n\n   @param  NewContext is an opaque pure Prolog term that is\n           subject to garbage collection.",
    "prefix":"sha_new_ctx"
  },
  "csv:csv/1": {
    "body":"csv(${1:Rows})$2\n$0",
    "description":"[det]csv(?Rows)//.\n",
    "prefix":"csv"
  },
  "csv:csv/2": {
    "body":"csv(${1:Rows}, ${2:Options})$3\n$0",
    "description":"[det]csv(?Rows, +Options)//.\nProlog DCG to `read/write' CSV data. Options:  separator(+Code): The comma-separator. Must be a character code. Default is (of course)  the comma. Character codes can be specified using the 0' notion. E.g.,  using separator(0';) parses a semicolon separated file.\n\nignore_quotes(+Boolean): If true (default false), threat double quotes as a normal  character.\n\nstrip(+Boolean): If true (default false), strip leading and  trailing blank space. RFC4180 says that blank space is part of the data.\n\nconvert(+Boolean): If true (default), use name/2  on the field data. This translates the field into a number if possible.\n\nfunctor(+Atom): Functor to use for creating row terms. Default is row.\n\narity(?Arity): Number of fields in each row. This predicate raises a domain_error(row_arity(Expected), Found)  if a row is found with different arity.\n\nmatch_arity(+Boolean): If false (default true), do not reject CSV  files where lines provide a varying number of fields (columns). This can  be a work-around to use some incorrect CSV files.\n\n ",
    "prefix":"csv"
  },
  "csv:csv_read_file/2": {
    "body":"csv_read_file(${1:File}, ${2:Rows})$3\n$0",
    "description":"[det]csv_read_file(+File, -Rows).\n",
    "prefix":"csv_read_file"
  },
  "csv:csv_read_file/3": {
    "body":"csv_read_file(${1:File}, ${2:Rows}, ${3:Options})$4\n$0",
    "description":"[det]csv_read_file(+File, -Rows, +Options).\nRead a CSV file into a list of rows. Each row is a Prolog term with the  same arity. Options is handed to csv/4.  Remaining options are processed by phrase_from_file/3.  The default separator depends on the file name extension and is \\t  for .tsv files and , otherwise.  Suppose we want to create a predicate table/6  from a CSV file that we know contains 6 fields per record. This can be  done using the code below. Without the option arity(6),  this would generate a predicate table/N, where N is the number of fields  per record in the data. \n\n\n\n?- csv_read_file(File, Rows, [functor(table), arity(6)]),\n   maplist(assert, Rows).\n\n ",
    "prefix":"csv_read_file"
  },
  "csv:csv_read_file_row/3": {
    "body":"csv_read_file_row(${1:File}, ${2:Row}, ${3:Options})$4\n$0",
    "description":"[nondet]csv_read_file_row(+File, -Row, +Options).\nTrue when Row is a row in File. First unifies Row  with the first row in File. Backtracking yields the second,  ... row. This interface is an alternative to csv_read_file/3  that avoids loading all rows in memory. Note that this interface does  not guarantee that all rows in File have the same arity.  In addition to the options of csv_read_file/3,  this predicate processes the option: \n\nline(-Line): Line is unified with the 1-based line-number from which Row  is read. Note that Line is not the physical line, but rather  the logical record number.\n\n  To be done: Input is read line by line. If a record separator is embedded in a  quoted field, parsing the record fails and another line is added to the  input. This does not nicely deal with other reasons why parsing the row  may fail.\n\n ",
    "prefix":"csv_read_file_row"
  },
  "csv:csv_write_file/2": {
    "body":"csv_write_file(${1:File}, ${2:Data})$3\n$0",
    "description":"[det]csv_write_file(+File, +Data).\n",
    "prefix":"csv_write_file"
  },
  "csv:csv_write_file/3": {
    "body":"csv_write_file(${1:File}, ${2:Data}, ${3:Options})$4\n$0",
    "description":"[det]csv_write_file(+File, +Data, +Options).\nWrite a list of Prolog terms to a CSV file. Options are given  to csv/4. Remaining options are given to open/4.  The default separator depends on the file name extension and is \\t  for .tsv files and , otherwise.",
    "prefix":"csv_write_file"
  },
  "csv:csv_write_stream/3": {
    "body":"csv_write_stream(${1:Stream}, ${2:Data}, ${3:Options})$4\n$0",
    "description":"[det]csv_write_stream(+Stream, +Data, +Options).\nWrite the rows in Data to Stream. This is similar  to csv_write_file/3,  but can deal with data that is produced incrementally. The example below  saves all answers from the predicate data/3  to File.  \n\nsave_data(File) :-\n   setup_call_cleanup(\n       open(File, write, Out),\n       forall(data(C1,C2,C3),\n              csv_write_stream(Out, [row(C1,C2,C3)], [])),\n       close(Out)),\n\n  \n\n",
    "prefix":"csv_write_stream"
  },
  "ctypes:is_alnum/1": {
    "body": ["is_alnum(${1:'Param1'})$2\n$0" ],
    "description":"is_alnum('Param1')",
    "prefix":"is_alnum"
  },
  "ctypes:is_alpha/1": {
    "body": ["is_alpha(${1:'Param1'})$2\n$0" ],
    "description":"is_alpha('Param1')",
    "prefix":"is_alpha"
  },
  "ctypes:is_ascii/1": {
    "body": ["is_ascii(${1:'Param1'})$2\n$0" ],
    "description":"is_ascii('Param1')",
    "prefix":"is_ascii"
  },
  "ctypes:is_cntrl/1": {
    "body": ["is_cntrl(${1:'Param1'})$2\n$0" ],
    "description":"is_cntrl('Param1')",
    "prefix":"is_cntrl"
  },
  "ctypes:is_csym/1": {
    "body": ["is_csym(${1:'Param1'})$2\n$0" ],
    "description":"is_csym('Param1')",
    "prefix":"is_csym"
  },
  "ctypes:is_csymf/1": {
    "body": ["is_csymf(${1:'Param1'})$2\n$0" ],
    "description":"is_csymf('Param1')",
    "prefix":"is_csymf"
  },
  "ctypes:is_digit/1": {
    "body": ["is_digit(${1:'Param1'})$2\n$0" ],
    "description":"is_digit('Param1')",
    "prefix":"is_digit"
  },
  "ctypes:is_digit/3": {
    "body": ["is_digit(${1:C}, ${2:Base}, ${3:Weight})$4\n$0" ],
    "description":"  is_digit(+C, +Base, -Weight) is det.\n  is_digit(-C, +Base, +Weight) is det.\n\n   Succeeds if `C' is a digit using `Base'  as  base  and  `Weight'\n   represents its value.  Only the base-10 case is handled by code_type.",
    "prefix":"is_digit"
  },
  "ctypes:is_endfile/1": {
    "body": ["is_endfile(${1:'Param1'})$2\n$0" ],
    "description":"is_endfile('Param1')",
    "prefix":"is_endfile"
  },
  "ctypes:is_endline/1": {
    "body": ["is_endline(${1:'Param1'})$2\n$0" ],
    "description":"is_endline('Param1')",
    "prefix":"is_endline"
  },
  "ctypes:is_graph/1": {
    "body": ["is_graph(${1:'Param1'})$2\n$0" ],
    "description":"is_graph('Param1')",
    "prefix":"is_graph"
  },
  "ctypes:is_lower/1": {
    "body": ["is_lower(${1:'Param1'})$2\n$0" ],
    "description":"is_lower('Param1')",
    "prefix":"is_lower"
  },
  "ctypes:is_newline/1": {
    "body": ["is_newline(${1:'Param1'})$2\n$0" ],
    "description":"is_newline('Param1')",
    "prefix":"is_newline"
  },
  "ctypes:is_newpage/1": {
    "body": ["is_newpage(${1:'Param1'})$2\n$0" ],
    "description":"is_newpage('Param1')",
    "prefix":"is_newpage"
  },
  "ctypes:is_paren/2": {
    "body": ["is_paren(${1:Open}, ${2:Close})$3\n$0" ],
    "description":"  is_paren(?Open, ?Close) is semidet.\n\n   True if Open is the open-parenthesis of Close.",
    "prefix":"is_paren"
  },
  "ctypes:is_period/1": {
    "body": ["is_period(${1:'Param1'})$2\n$0" ],
    "description":"is_period('Param1')",
    "prefix":"is_period"
  },
  "ctypes:is_print/1": {
    "body": ["is_print(${1:'Param1'})$2\n$0" ],
    "description":"is_print('Param1')",
    "prefix":"is_print"
  },
  "ctypes:is_punct/1": {
    "body": ["is_punct(${1:'Param1'})$2\n$0" ],
    "description":"is_punct('Param1')",
    "prefix":"is_punct"
  },
  "ctypes:is_quote/1": {
    "body": ["is_quote(${1:'Param1'})$2\n$0" ],
    "description":"is_quote('Param1')",
    "prefix":"is_quote"
  },
  "ctypes:is_space/1": {
    "body": ["is_space(${1:'Param1'})$2\n$0" ],
    "description":"is_space('Param1')",
    "prefix":"is_space"
  },
  "ctypes:is_upper/1": {
    "body": ["is_upper(${1:'Param1'})$2\n$0" ],
    "description":"is_upper('Param1')",
    "prefix":"is_upper"
  },
  "ctypes:is_white/1": {
    "body": ["is_white(${1:'Param1'})$2\n$0" ],
    "description":"is_white('Param1')",
    "prefix":"is_white"
  },
  "ctypes:to_lower/2": {
    "body": ["to_lower(${1:U}, ${2:L})$3\n$0" ],
    "description":"  to_lower(+U, -L) is det.\n\n   Downcase a character code. If U  is   the  character  code of an\n   uppercase character, unify L with  the   character  code  of the\n   lowercase version. Else unify L with U.",
    "prefix":"to_lower"
  },
  "ctypes:to_upper/2": {
    "body": ["to_upper(${1:L}, ${2:U})$3\n$0" ],
    "description":"  to_upper(+L, -U) is det.\n\n   Upcase a character code.  If  L  is   the  character  code  of a\n   lowercase character, unify L with  the   character  code  of the\n   uppercase version. Else unify U with L.",
    "prefix":"to_upper"
  },
  "ctypes:upper_lower/2": {
    "body": ["upper_lower(${1:U}, ${2:L})$3\n$0" ],
    "description":"  upper_lower(?U, ?L) is det.\n\n   True when U is the character code  of an uppercase character and\n   L  is  the  character  code    of  the  corresponding  lowercase\n   character.",
    "prefix":"upper_lower"
  },
  "current_arithmetic_function/1": {
    "body":"current_arithmetic_function(${1:Head})$2\n$0",
    "description":"current_arithmetic_function(?Head).\nTrue when Head is an evaluable function. For example:  \n\n?- current_arithmetic_function(sin(_)).\ntrue.\n\n  \n\n",
    "prefix":"current_arithmetic_function"
  },
  "current_atom/1": {
    "body":"current_atom(${1:Atom})$2\n$0",
    "description":"current_atom(-Atom).\nSuccessively unifies Atom with all atoms known to the system.  Note that current_atom/1  always succeeds if Atom is instantiated to an atom.",
    "prefix":"current_atom"
  },
  "current_blob/2": {
    "body":"current_blob(${1:Blob}, ${2:Type})$3\n$0",
    "description":"current_blob(?Blob, ?Type).\nExamine the type or enumerate blobs of the given Type. Typed  blobs are supported through the foreign language interface for storing  arbitrary BLOBs (Binary Large Object) or handles to external entities.  See section 11.4.7 for  details.",
    "prefix":"current_blob"
  },
  "current_char_conversion/2": {
    "body":"current_char_conversion(${1:CharIn}, ${2:CharOut})$3\n$0",
    "description":"[ISO]current_char_conversion(?CharIn, ?CharOut).\nQueries the current character conversion table. See char_conversion/2  for details.",
    "prefix":"current_char_conversion"
  },
  "current_engine/1": {
    "body":"current_engine(${1:Engine})$2\n$0",
    "description":"[nondet]current_engine(-Engine).\nTrue when Engine is an existing engine.",
    "prefix":"current_engine"
  },
  "current_flag/1": {
    "body":"current_flag(${1:FlagKey})$2\n$0",
    "description":"current_flag(-FlagKey).\nSuccessively unifies FlagKey with all keys used for flags  (see flag/3).",
    "prefix":"current_flag"
  },
  "current_format_predicate/2": {
    "body":"current_format_predicate(${1:Code}, ${2:Head})$3\n$0",
    "description":"current_format_predicate(?Code, ?:Head).\nTrue when ~Code is handled by the  user-defined predicate specified by Head.",
    "prefix":"current_format_predicate"
  },
  "current_functor/2": {
    "body":"current_functor(${1:Name}, ${2:Arity})$3\n$0",
    "description":"current_functor(?Name, ?Arity).\nSuccessively unifies Name with the name and Arity  with the arity of functors known to the system.",
    "prefix":"current_functor"
  },
  "current_input/1": {
    "body":"current_input(${1:Stream})$2\n$0",
    "description":"[ISO]current_input(-Stream).\nGet the current input stream. Useful for getting access to the status  predicates associated with streams.",
    "prefix":"current_input"
  },
  "current_key/1": {
    "body":"current_key(${1:Key})$2\n$0",
    "description":"current_key(-Key).\nSuccessively unifies Key with all keys used for records (see recorda/3,  etc.).",
    "prefix":"current_key"
  },
  "current_locale/1": {
    "body":"current_locale(${1:Locale})$2\n$0",
    "description":"current_locale(-Locale).\nTrue when Locale is the locale of the calling thread.",
    "prefix":"current_locale"
  },
  "current_module/1": {
    "body":"current_module(${1:Module})$2\n$0",
    "description":"[nondet]current_module(?Module).\nTrue if Module is a currently defined module. This predicate  enumerates all modules, whether loaded from a file or created  dynamically. Note that modules cannot be destroyed in the current  version of SWI-Prolog.",
    "prefix":"current_module"
  },
  "current_op/3": {
    "body":"current_op(${1:Precedence}, ${2:Type}, ${3:Name})$4\n$0",
    "description":"[ISO]current_op(?Precedence, ?Type, ?:Name).\nTrue if Name is currently defined as an operator of type Type  with precedence Precedence. See also op/3.",
    "prefix":"current_op"
  },
  "current_output/1": {
    "body":"current_output(${1:Stream})$2\n$0",
    "description":"[ISO]current_output(-Stream).\nGet the current output stream.",
    "prefix":"current_output"
  },
  "current_predicate/1": {
    "body":"current_predicate(${1:PredicateIndicator})$2\n$0",
    "description":"[ISO]current_predicate(:PredicateIndicator).\nTrue if PredicateIndicator is a currently defined predicate.  A predicate is considered defined if it exists in the specified module,  is imported into the module or is defined in one of the modules from  which the predicate will be imported if it is called (see section 6.9). Note that current_predicate/1  does not succeed for predicates that can be autoloaded.  See also current_predicate/2  and predicate_property/2.  If PredicateIndicator is not fully specified, the  predicate only generates values that are defined in or already imported  into the target module. Generating all callable predicates therefore  requires enumerating modules using current_module/1.  Generating predicates callable in a given module requires enumerating  the import modules using import_module/2  and the autoloadable predicates using the predicate_property/2 autoload.\n\n",
    "prefix":"current_predicate"
  },
  "current_predicate/2": {
    "body":"current_predicate(${1:Name}, ${2:Head})$3\n$0",
    "description":"current_predicate(?Name, :Head).\nClassical pre-ISO implementation of current_predicate/1,  where the predicate is represented by the head term. The advantage is  that this can be used for checking the existence of a predicate before  calling it without the need for functor/3:  \n\ncall_if_exists(G) :-\n        current_predicate(_, G),\n        call(G).\n\n  Because of this intended usage, current_predicate/2  also succeeds if the predicate can be autoloaded. Unfortunately,  checking the autoloader makes this predicate relatively slow, in  particular because a failed lookup of the autoloader will cause the  autoloader to verify that its index is up-to-date.\n\n",
    "prefix":"current_predicate"
  },
  "current_prolog_flag/2": {
    "body":"current_prolog_flag(${1:Key}, ${2:Value})$3\n$0",
    "description":"[ISO]current_prolog_flag(?Key, -Value).\nThe predicate current_prolog_flag/2  defines an interface to installation features: options compiled in,  version, home, etc. With both arguments unbound, it will generate all  defined Prolog flags. With Key instantiated, it unifies Value  with the value of the Prolog flag or fails if the Key is not  a Prolog flag.  Flags marked rw can be modified by the user using set_prolog_flag/2.  Flag values are typed. Flags marked as bool can have the  values true or false. The predicate create_prolog_flag/3  may be used to create flags that describe or control behaviour of  libraries and applications. The library library(settings) provides an alternative interface for  managing notably application parameters. \n\nSome Prolog flags are not defined in all versions, which is normally  indicated in the documentation below as ``if present and true''.  A boolean Prolog flag is true iff the Prolog flag is present and the Value is the atom true. Tests for  such flags should be written as below: \n\n\n\n        (   current_prolog_flag(windows, true)\n        ->  <Do MS-Windows things>\n        ;   <Do normal things>\n        )\n\n  Some Prolog flags are scoped to a source file. This implies that if  they are set using a directive inside a file, the flag value encountered  when loading of the file started is restored when loading of the file is  completed. Currently, the following flags are scoped to the source file: generate_debug_info  and optimise. \n\nA new thread (see section 9) copies  all flags from the thread that created the new thread (its parent).15This  is implemented using the copy-on-write tecnhnique. As a  consequence, modifying a flag inside a thread does not affect other  threads. \n\naccess_level(atom, changeable): This flag defines a normal `user' view (user, default) or a  `system' view. In system view all system code is fully accessible as if  it was normal user code. In user view, certain operations are not  permitted and some details are kept invisible. We leave the exact  consequences undefined, but, for example, system code can be traced  using system access and system predicates can be redefined.\n\naddress_bits(integer): Address size of the hosting machine. Typically 32 or 64. Except for the  maximum stack limit, this has few implications to the user. See also the  Prolog flag arch.\n\nagc_margin(integer, changeable): If this amount of atoms possible garbage atoms exist perform atom  garbage collection at the first opportunity. Initial value is 10,000.  May be changed. A value of 0 (zero) disables atom garbage collection.  See also PL_register_atom().16Given  that SWI-Prolog has no limit on the length of atoms, 10,000 atoms may  still occupy a lot of memory. Applications using extremely large atoms  may wish to call garbage_collect_atoms/0  explicitly or lower the margin.\n\napple(bool): If present and true, the  operating system is MacOSX. Defined if the C compiler used to compile  this version of SWI-Prolog defines __APPLE__. Note that the unix  is also defined for MacOSX.\n\nallow_dot_in_atom(bool, changeable): If true (default false), dots may be embedded  into atoms that are not quoted and start with a letter. The embedded dot must be followed by an identifier continuation character (i.e.,  letter, digit or underscore). The dot is allowed in identifiers in many  languages, which can make this a useful flag for defining DSLs. Note  that this conflicts with cascading functional notation. For example, Post.meta.author is read as .(Post, 'meta.author'  if this flag is set to true.\n\nallow_variable_name_as_functor(bool, changeable): If true (default is false), Functor(arg) is read as if it  were written 'Functor'(arg). Some applications use the  Prolog read/1  predicate for reading an application-defined script language. In these  cases, it is often difficult to explain to non-Prolog users of the  application that constants and functions can only start with a lowercase  letter. Variables can be turned into atoms starting with an uppercase  atom by calling read_term/2  using the option variable_names and binding the variables  to their name. Using this feature, F(x) can be turned into valid syntax  for such script languages. Suggested by Robert van Engelen. SWI-Prolog  specific.\n\nargv(list, changeable): List is a list of atoms representing the application command line  arguments. Application command line arguments are those that have not been processed by Prolog during its initialization. Note  that Prolog's argument processing stops at -- or the first  non-option argument. See also os_argv.17Prior  to version 6.5.2, argv  was defined as os_argv  is now. The change was made for compatibility reasone and because the  current definition is more practical.\n\narch(atom): Identifier for the hardware and operating system SWI-Prolog is running  on. Used to select foreign files for the right architecture. See also section 11.2.3 and file_search_path/2.\n\nassociated_file(atom): Set if Prolog was started with a prolog file as argument. Used by e.g., edit/0  to edit the initial file.\n\nautoload(bool, changeable): If true (default) autoloading of library functions is  enabled.\n\nback_quotes(codes,chars,string,symbol_char, changeable): Defines the term-representation for back-quoted material. The default is codes.  If --traditional is given, the default is symbol_char,  which allows using ` in operators composed of symbols.18Older  versions had a boolean flag backquoted_strings, which  toggled between string and symbol_char.  See also section 5.2.\n\nbacktrace(bool, changeable): If true (default), print a backtrace on an uncaught  exception.\n\nbacktrace_depth(integer, changeable): If backtraces on errors are enabled, this flag defines the maximum  number of frames that is printed (default20).\n\nbacktrace_goal_depth(integer, changeable): The frame of a backtrace is printed after making a shallow copy of the  goal. This flag determines the depth to which the goal term is copied.  Default is `3'.\n\nbacktrace_show_lines(bool, changeable): If true (default), try to reconstruct the line number at  which the exception happened.\n\nbounded(bool): ISO Prolog flag. If true, integer representation is bound  by min_integer and max_integer.  If false integers can be arbitrarily large and the min_integer  and max_integer are  not present. See section 4.27.2.1.\n\nbreak_level(integer): Current break-level. The initial top level (started with -t) has value 0. See break/0.  This flag is absent from threads that are not running a top-level loop.\n\nc_cc(atom, changeable): Name of the C compiler used to compile SWI-Prolog. Normally either gcc  or cc. See section 11.5.\n\nc_cflags(atom, changeable): CFLAGS used to compile SWI-Prolog. See section  11.5.\n\nc_ldflags(atom, changeable): LDFLAGS used to link SWI-Prolog. See section  11.5.\n\nc_libs(atom, changeable): Libraries needed to link executables that embed SWI-Prolog. Typically -lswipl if the SWI-Prolog kernel is a shared (DLL). If the  SWI-Prolog kernel is in a static library, this flag also contains the  dependencies.\n\nc_libplso(atom, changeable): Libraries needed to link extensions (shared object, DLL) to SWI-Prolog.  Typically empty on ELF systems and -lswipl on COFF-based  systems. See section 11.5.\n\nchar_conversion(bool, changeable): Determines whether character conversion takes place while reading terms.  See also char_conversion/2.\n\ncharacter_escapes(bool, changeable): If true (default), read/1  interprets \\ escape sequences in quoted atoms and strings.  May be changed. This flag is local to the module in which it is changed.  See section 2.15.1.3.\n\ncolon_sets_calling_context(bool, changeable): Using the construct <module>:<goal>  sets the calling context for executing <goal>.  This flag is defined by ISO/IEC 13211-2 (Prolog modules standard). See section  6.\n\ncolor_term(bool, changeable): This flag is managed by library library(ansi_term), which  is loaded at startup if the two conditions below are both true. Note  that this implies that setting this flag to false from the  system or personal initialization file (see section  2.2 disables colored output. The predicate message_property/2  can be used to control the actual color scheme depending in the message  type passed to print_message/2.  stream_property(current_output, tty(true))\n\\+ current_prolog_flag(color_term, false)\n\n\n\ncompile_meta_arguments(atom, changeable): Experimental flag that controls compilation of arguments passed to  meta-calls marked `0' or `^' (see meta_predicate/1).  Supported values are:  false(default). Meta-arguments are passed verbatim.controlCompile meta-arguments that contain control structures ((A,B), (A;B),  (A->B;C), etc.). If not compiled at compile time, such arguments are  compiled to a temporary clause before execution. Using this option  enhances performance of processing complex meta-goals that are known at  compile time.trueAlso compile references to normal user predicates. This harms  performance (a little), but enhances the power of poor-mens consistency  check used by make/0  and implemented by list_undefined/0.alwaysAlways create an intermediate clause, even for system predicates. This  prepares for replacing the normal head of the generated predicate with a  special reference (similar to database references as used by, e.g., assert/2)  that provides direct access to the executable code, thus avoiding  runtime lookup of predicates for meta-calling. \n\ncompiled_at(atom): Describes when the system has been compiled. Only available if the C  compiler used to compile SWI-Prolog provides the __DATE__ and __TIME__  macros.\n\nconsole_menu(bool): Set to true in swipl-win.exe to indicate that the  console supports menus. See also section  4.35.3.\n\ncpu_count(integer, changeable): Number of physical CPUs or cores in the system. The flag is marked  read-write both to allow pretending the system has more or less  processors. See also thread_setconcurrency/2  and the library library(thread). This flag is not available on systems  where we do not know how to get the number of CPUs. This flag is not  included in a saved state (see qsave_program/1).\n\ndde(bool): Set to true if this instance of Prolog supports DDE as  described in section 4.43.\n\ndebug(bool, changeable): Switch debugging mode on/off. If debug mode is activated the system  traps encountered spy points (see spy/1)  and trace points (see trace/1).  In addition, last-call optimisation is disabled and the system is more  conservative in destroying choice points to simplify debugging.  Disabling these optimisations can cause the system to run out of  memory on programs that behave correctly if debug mode is off.\n\ndebug_on_error(bool, changeable): If true, start the tracer after an error is detected.  Otherwise just continue execution. The goal that raised the error will  normally fail. See also the Prolog flag report_error.  Default is true.\n\ndebugger_write_options(term, changeable): This argument is given as option-list to write_term/2  for printing goals by the debugger. Modified by the `w', `p' and `<N>  d' commands of the debugger. Default is [quoted(true),  portray(true), max_depth(10), attributes(portray)].\n\ndebugger_show_context(bool, changeable): If true, show the context module while printing a  stack-frame in the tracer. Normally controlled using the `C' option of  the tracer.\n\ndialect(atom): Fixed to swi. The code below is a reliable and portable way  to detect SWI-Prolog.  \n\nis_dialect(swi) :-\n        catch(current_prolog_flag(dialect, swi), _, fail).\n\n \n\ndouble_quotes(codes,chars,atom,string, changeable): This flag determines how double quoted strings are read by Prolog and is  ---like character_escapes  and back_quotes---  maintained for each module. The default is string, which  produces a string as described in section  5.2. If --traditional is given, the default is codes,  which produces a list of character codes, integers that represent a  Unicode code-point. The value chars produces a list of  one-character atoms and the value atom makes double quotes  the same as single quotes, creating a atom. See also section  5.\n\neditor(atom, changeable): Determines the editor used by edit/1.  See section 4.4.1 for details on  selecting the editor used.\n\nemacs_inferior_process(bool): If true, SWI-Prolog is running as an inferior process of  (GNU/X-)Emacs. SWI-Prolog assumes this is the case if the environment  variable EMACS is t and INFERIOR  is yes.\n\nencoding(atom, changeable): Default encoding used for opening files in text mode. The  initial value is deduced from the environment. See section  2.18.1 for details.\n\nexecutable(atom): Pathname of the running executable. Used by qsave_program/2  as default emulator.\n\nexit_status(integer): Set by halt/1  to its argument, making the exit status available to hooks registered  with at_halt/1.\n\nfile_name_case_handling(atom, changeable): This flag defines how Prolog handles the case of file names. The flag is  used for case normalization and to determine whether two names refer to  the same file.bugNote that file  name case handling is typically a properly of the filesystem, while  Prolog only has a global flag to determine its file handling.  It has one of the following values:  case_sensitiveThe filesystem is fully case sensitive. Prolog does not perform any case  modification or case insensitive matching. This is the default on Unix  systems.case_preservingThe filesystem is case insensitive, but it preserves the case with which  the user jas created a file. This is the default on Windows systems.case_insensitiveThe filesystem doesn't store or match case. In this scenario Prolog maps  all file names to lower case. \n\nfile_name_variables(bool, changeable): If true (default false), expand $varname  and ~ in arguments of built-in predicates that  accept a file name (open/3, exists_file/1, access_file/2,  etc.). The predicate expand_file_name/2  can be used to expand environment variables and wildcard patterns. This  Prolog flag is intended for backward compatibility with older versions  of SWI-Prolog.\n\nfile_search_cache_time(number, changeable): Time in seconds for which search results from absolute_file_name/3  are cached. Within this time limit, the system will first check that the  old search result satisfies the conditions. Default is 10 seconds, which  typically avoids most repetitive searches for (library) files during  compilation. Setting this value to 0 (zero) disables the cache.\n\ngc(bool, changeable): If true (default), the garbage collector is active. If false, neither  garbage collection, nor stack shifts will take place, even not on  explicit request. May be changed.\n\ngenerate_debug_info(bool, changeable): If true (default) generate code that can be debugged using trace/0, spy/1,  etc. Can be set to false using the -nodebug. This flag is scoped within a source file.  Many of the libraries have :- set_prolog_flag(generate_debug_info, false) to hide  their details from a normal trace.19In  the current implementation this only causes a flag to be set on the  predicate that causes children to be hidden from the debugger. The name  anticipates further changes to the compiler.\n\ngmp_version(integer): If Prolog is linked with GMP, this flag gives the major version of the  GMP library used. See also section  11.4.8.\n\ngui(bool): Set to true if XPCE is around and can be used for graphics.\n\nhistory(integer, changeable): If integer> 0, support Unix csh(1)-like  history as described in section 2.7.  Otherwise, only support reusing commands through the command line  editor. The default is to set this Prolog flag to 0 if a command line  editor is provided (see Prolog flag readline) and 15  otherwise.\n\nhome(atom): SWI-Prolog's notion of the home directory. SWI-Prolog uses its home  directory to find its startup file as <home>/boot32.prc (32-bit machines) or <home>/boot64.prc (64-bit machines) and to  find its library as <home>/library.\n\nhwnd(integer): In swipl-win.exe, this refers to the MS-Windows window handle of  the console window.\n\ninteger_rounding_function(down,toward_zero): ISO Prolog flag describing rounding by // and rem  arithmetic functions. Value depends on the C compiler used.\n\niso(bool, changeable): Include some weird ISO compatibility that is incompatible with normal  SWI-Prolog behaviour. Currently it has the following effect: The //2 (float division) always  returns a float, even if applied to integers that can be divided.\nIn the standard order of terms (see section  4.7.1), all floats are before all integers.\natom_length/2  yields a type error if the first argument is a number.\nclause/[2,3]  raises a permission error when accessing static predicates.\nabolish/[1,2]  raises a permission error when accessing static predicates.\nSyntax is closer to the ISO standard: Unquoted commas and bars appearing as atoms are not allowed. Instead  of f(,,a) now write f(',',a). Unquoted commas can  only be used to separate arguments in functional notation and list  notation, and as a conjunction operator. Unquoted bars can only appear  within lists to separate head and tail, like [Head|Tail],  and as infix operator for alternation in grammar rules, like a -->  b | c.Within functional notation and list notation terms must have  priority below 1000. That means that rules and control constructs  appearing as arguments need bracketing. A term like [a :- b, c].  must now be disambiguated to mean [(a :- b), c]. or [(a  :- b, c)].Operators appearing as operands must be bracketed. Instead of X  == -, true. write X == (-), true. Currently, this is  not entirely enforced.Backslash-escaped newlines are interpreted according to the ISO  standard. See section 2.15.1.3.\n\n\n\nlarge_files(bool): If present and true, SWI-Prolog has been compiled with large file support (LFS) and is capable of accessing files  larger than 2GB on 32-bit hardware. Large file support is default on  installations built using configure that support it and may be  switched off using the configure option --disable-largefile.\n\nlast_call_optimisation(bool, changeable): Determines whether or not last-call optimisation is enabled. Normally  the value of this flag is the negation of the debug  flag. As programs may run out of stack if last-call optimisation is  omitted, it is sometimes necessary to enable it during debugging.\n\nmax_arity(unbounded): ISO Prolog flag describing there is no maximum arity to compound terms.\n\nmax_integer(integer): Maximum integer value if integers are bounded. See also the  flag bounded and section  4.27.2.1.\n\nmax_tagged_integer(integer): Maximum integer value represented as a `tagged' value. Tagged integers  require one word storage. Larger integers are represented as `indirect  data' and require significantly more space.\n\nmin_integer(integer): Minimum integer value if integers are bounded. See also the  flag bounded and section  4.27.2.1.\n\nmin_tagged_integer(integer): Start of the tagged-integer value range.\n\noccurs_check(atom, changeable): This flag controls unification that creates an infinite tree (also  called cyclic term) and can have three values. Using false (default), unification succeeds, creating an infinite  tree. Using true, unification behaves as unify_with_occurs_check/2,  failing silently. Using error, an attempt to create a  cyclic term results in an occurs_check exception. The  latter is intended for debugging unintentional creations of cyclic  terms. Note that this flag is a global flag modifying fundamental  behaviour of Prolog. Changing the flag from its default may cause  libraries to stop functioning properly.\n\nopen_shared_object(bool): If true, open_shared_object/2  and friends are implemented, providing access to shared libraries (.so  files) or dynamic link libraries (.DLL files).\n\noptimise(bool, changeable): If true, compile in optimised mode. The initial value is true if Prolog was started with the -O  command line option. The optimise  flag is scoped to a source file.  Currently optimised compilation implies compilation of arithmetic,  and deletion of redundant true/0  that may result from expand_goal/2. Later versions might imply various other optimisations such as  integrating small predicates into their callers, eliminating constant  expressions and other predictable constructs. Source code optimisation  is never applied to predicates that are declared dynamic (see dynamic/1).\n\nos_argv(list, changeable): List is a list of atoms representing the command line arguments used to  invoke SWI-Prolog. Please note that all arguments are included in  the list returned. See argv  to get the application options.\n\npid(int): Process identifier of the running Prolog process. Existence of this flag  is implementation-defined.\n\npipe(bool, changeable): If true, open(pipe(command), mode, Stream), etc. are  supported. Can be changed to disable the use of pipes in applications  testing this feature. Not recommended.\n\nprint_write_options(term, changeable): Specifies the options for write_term/2  used by print/1  and print/2.\n\nprompt_alternatives_on(atom, changeable): Determines prompting for  alternatives in the Prolog top level. Default is determinism, which implies the system prompts for  alternatives if the goal succeeded while leaving choice points. Many  classical Prolog systems behave as groundness: they prompt  for alternatives if and only if the query contains variables.\n\nprotect_static_code(bool, changeable): If true (default false), clause/2  does not operate on static code, providing some basic protection from  hackers that wish to list the static code of your Prolog program. Once  the flag is true, it cannot be changed back to false.  Protection is default in ISO mode (see Prolog flag iso).  Note that many parts of the development environment require clause/2  to work on static code, and enabling this flag should thus only be used  for production code.\n\nqcompile(atom, changeable): This option provides the default for the qcompile(+Atom)  option of load_files/2.\n\nreadline(atom, changeable): Specifies which form of command line editing is provided. Possible  values are below. The flag may be set from the user's init file (see section 2.3) to one of false, readline  or editline. This causes the toplevel not to load a command  line editor (false) or load the specified one. If loading  fails the flag is set to false.  falseNo command line editing is available.readlineThe library library(readline) is loaded, providing line  editing based on the GNU readline library.editlineThe library library(editline) is loaded, providing line  editing based on the BSD libedit. This is the default if library(editline)  is available and can be loaded.swipl_winSWI-Prolog uses its own console (swipl-win.exe on Windows, the Qt  based swipl-win on MacOS) which provides line editing. \n\nresource_database(atom): Set to the absolute filename of the attached state. Typically this is  the file boot32.prc, the file specified with -x  or the running executable. See also resource/3.\n\nreport_error(bool, changeable): If true, print error messages; otherwise suppress them. May  be changed. See also the debug_on_error  Prolog flag. Default is true, except for the runtime  version.\n\nruntime(bool): If present and true, SWI-Prolog is compiled with  -DO_RUNTIME, disabling various useful development features (currently  the tracer and profiler).\n\nsandboxed_load(bool, changeable): If true (default false), load_files/2  calls hooks to allow library(sandbox) to verify the safety of  directives.\n\nsaved_program(bool): If present and true, Prolog has been started from a state  saved with qsave_program/[1,2].\n\nshared_object_extension(atom): Extension used by the operating system for shared objects. .so  for most Unix systems and .dll for Windows. Used for  locating files using the file_type executable.  See also absolute_file_name/3.\n\nshared_object_search_path(atom): Name of the environment variable used by the system to search for shared  objects.\n\nsignals(bool): Determine whether Prolog is handling signals (software interrupts). This  flag is false if the hosting OS does not support signal  handling or the command line option -nosignals is  active. See section 11.4.21.1 for  details.\n\nstream_type_check(atom, changeable): Defines whether and how strictly the system validates that byte I/O  should not be applied to text streams and text I/O should not be applied  to binary streams. Values are false (no checking), true  (full checking) and loose. Using checking mode loose  (default), the system accepts byte I/O from text stream that use ISO  Latin-1 encoding and accepts writing text to binary streams.\n\nsystem_thread_id(int): Available in multithreaded version (see section  9) where the operating system provides system-wide integer thread  identifiers. The integer is the thread identifier used by the operating  system for the calling thread. See also thread_self/1.\n\ntable_space(integer, changeable): Space reserved for storing answer tables for tabled predicates  (see table/1).bugCurrently  only counts the space occupied by the nodes in the answer tries.  When exceeded a resource_error(table_space) exception is raised.\n\ntimezone(integer): Offset in seconds west of GMT of the current time zone. Set at  initialization time from the timezone variable associated  with the POSIX tzset() function. See also format_time/3.\n\ntoplevel_mode(atom, changeable): If backtracking (default), the toplevel backtracks after  completing a query. If recursive, the toplevel is  implemented as a recursive loop. This implies that global variables set  using b_setval/2  are maintained between queries. In recursive mode, answers to  toplevel variables (see section 2.8)  are kept in backtrackable global variables and thus not copied.  In backtracking mode answers to toplevel variables are kept in the  recorded database (see section 4.14.2).  The recursive mode has been added for interactive usage of CHR (see section 8),20Suggested  by Falco Nogatz which maintains the global constraint store  in backtrackable global variables.\n\ntoplevel_print_anon(bool, changeable): If true, top-level variables starting with an underscore (_)  are printed normally. If false they are hidden. This may be  used to hide bindings in complex queries from the top level.\n\ntoplevel_print_factorized(bool, changeable): If true (default false) show the internal  sharing of subterms in the answer substitution. The example below  reveals internal sharing of leaf nodes in red-black trees as  implemented by the library(rbtrees) predicate rb_new1:  \n\n?- set_prolog_flag(toplevel_print_factorized, true).\n?- rb_new(X).\nX = t(_S1, _S1), % where\n    _S1 = black('', _G387, _G388, '').\n\n  If this flag is false, the % where notation  is still used to indicate cycles as illustrated below. This example also  shows that the implementation reveals the internal cycle length, and not  the minimal cycle length. Cycles of different length are  indistinguishable in Prolog (as illustrated by S == R). \n\n?- S = s(S), R = s(s(R)), S == R.\nS = s(S),\nR = s(s(R)).\n\n \n\nanswer_write_options(term, changeable): This argument is given as option-list to write_term/2  for printing results of queries. Default is [quoted(true),  portray(true), max_depth(10), attributes(portray)].\n\ntoplevel_prompt(atom, changeable): Define the prompt that is used by the interactive top level. The  following ~ (tilde) sequences are replaced:  ~mType in  module if not user (see module/1) ~lBreak  level if not 0 (see break/0) ~dDebugging  state if not normal execution (see debug/0, trace/0) ~!History  event if history is enabled (see flag history) \n\ntoplevel_var_size(int, changeable): Maximum size counted in literals of a term returned as a binding for a  variable in a top-level query that is saved for re-use using the $ variable reference. See section  2.8.\n\ntrace_gc(bool, changeable): If true (default false), garbage collections  and stack-shifts will be reported on the terminal. May be changed.  Values are reported in bytes as G+T, where G  is the global stack value and T the trail stack value.  `Gained' describes the number of bytes reclaimed. `used' the number of  bytes on the stack after GC and `free' the number of bytes allocated,  but not in use. Below is an example output.  \n\n% GC: gained 236,416+163,424 in 0.00 sec;\n      used 13,448+5,808; free 72,568+47,440\n\n \n\ntraditional(bool): Available in SWI-Prolog version7. If true,  `traditional' mode has been selected using --traditional.  Notice that some SWI7 features, like the functional notation on dicts,  do not work in this mode. See also section  5.\n\ntty_control(bool, changeable): Determines whether the terminal is switched to raw mode for get_single_char/1,  which also reads the user actions for the trace. May be set. If this  flag is false at startup, command line editing is disabled.  See also the +/-tty command line option.\n\nunix(bool): If present and true, the  operating system is some version of Unix. Defined if the C compiler used  to compile this version of SWI-Prolog either defines __unix__  or unix. On other systems this flag is not available. See  also apple and windows.\n\nunknown(fail,warning,error, changeable): Determines the behaviour if an undefined procedure is encountered. If fail, the predicate fails silently. If warn, a  warning is printed, and execution continues as if the predicate was not  defined, and if error (default), an existence_error  exception is raised. This flag is local to each module and inherited  from the module's import-module. Using default setup, this  implies that normal modules inherit the flag from user,  which in turn inherit the value error from system.  The user may change the flag for module user to change the  default for all application modules or for a specific module. It is  strongly advised to keep the error default and use dynamic/1  and/or multifile/1  to specify possible non-existence of a predicate.\n\nunload_foreign_libraries(bool, changeable): If true (default false), unload all loaded  foreign libraries. Default is false because modern OSes  reclaim the resources anyway and unloading the foreign code may cause  registered hooks to point to no longer existing data or code.\n\nuser_flags(Atom, changeable): Define the behaviour of set_prolog_flag/2  if the flag is not known. Values are silent, warning  and error. The first two create the flag on-the-fly, where warning  prints a message. The value error is consistent with ISO:  it raises an existence error and does not create the flag. See also create_prolog_flag/3.  The default is silent, but future versions may change that.  Developers are encouraged to use another value and ensure proper use of create_prolog_flag/3  to create flags for their library.\n\nvar_prefix(bool, changeable): If true (default false), variables must start  with an underscore (_). May be changed. This flag is local  to the module in which it is changed. See section  2.15.1.7.\n\nverbose(atom, changeable): This flag is used by print_message/2.  If its value is silent, messages of type informational  and banner are suppressed. The -q switches  the value from the initial normal to silent.\n\nverbose_autoload(bool, changeable): If true the normal consult message will be printed if a  library is autoloaded. By default this message is suppressed. Intended  to be used for debugging purposes.\n\nverbose_load(atom, changeable): Determines messages printed for loading (compiling) Prolog files.  Current values are full (print a message at the start and  end of each file loaded), normal (print a message at the  end of each file loaded), brief (print a message at end of  loading the toplevel file), and silent (no messages are  printed, default). The value of this flag is normally controlled by the  option silent(Bool) provided by load_files/2.\n\nverbose_file_search(bool, changeable): If true (default false), print messages  indicating the progress of absolute_file_name/[2,3]  in locating files. Intended for debugging complicated file-search paths.  See also file_search_path/2.\n\nversion(integer): The version identifier is an integer with value:  10000  Major + 100  Minor  + Patch\n\nversion_data(swi(Major, Minor, Patch, Extra)): Part of the dialect compatibility layer; see also the Prolog flag dialect and section  C. Extra provides platform-specific version information  as a list. Extra is used for tagged versions such as ``7.4.0-rc1'', in which case Extra contains a term tag(rc1).\n\nversion_git(atom): Available if created from a git repository. See git-describe for  details.\n\nwarn_override_implicit_import(bool, changeable): If true (default), a warning is printed if an implicitly  imported predicate is clobbered by a local definition. See use_module/1  for details.\n\nwin_file_access_check(atom, changeable): Controls the behaviour or access_file/2  under Windows. There is no reliable way to check access to files and  directories on Windows. This flag allows for switching between three  alternative approximations.  accessUse Windows _waccess() function. This ignores ACLs (Access Control List)  and thus may indicate that access is allowed while it is not.filesecurityUse the Windows GetFileSecurity() function. This does not work on all  file systems, but is probably the best choice on file systems that do  support it, notably local NTFS volumes.opencloseTry to open the file and close it. This works reliable for files, but  not for directories. Currently directories are checked using _waccess().  This is the default. \n\nwindows(bool): If present and true, the  operating system is an implementation of Microsoft Windows. This flag is  only available on MS-Windows based versions. See also unix.\n\nwrite_attributes(atom, changeable): Defines how write/1  and friends write attributed variables. The option values are described  with the attributes option of write_term/3.  Default is ignore.\n\nwrite_help_with_overstrike(bool): Internal flag used by help/1  when writing to a terminal. If present and true it prints  bold and underlined text using overstrike.\n\nxpce(bool): Available and set to true if the XPCE graphics system is  loaded.\n\nxpce_version(atom): Available and set to the version of the loaded XPCE system.\n\nxref(bool, changeable): If true, source code is being read for analysis  purposes such as cross-referencing. Otherwise (default) it is being read  to be compiled. This flag is used at several places by term_expansion/2  and goal_expansion/2  hooks, notably if these hooks use side effects. See also the libraries library(prolog_source)  and library(prolog_xref).\n\n ",
    "prefix":"current_prolog_flag"
  },
  "current_signal/3": {
    "body":"current_signal(${1:Name}, ${2:Id}, ${3:Handler})$4\n$0",
    "description":"current_signal(?Name, ?Id, ?Handler).\nEnumerate the currently defined signal handling. Name is the  signal name, Id is the numerical identifier and Handler  is the currently defined handler (see on_signal/3).",
    "prefix":"current_signal"
  },
  "current_stream/3": {
    "body":"current_stream(${1:Object}, ${2:Mode}, ${3:Stream})$4\n$0",
    "description":"current_stream(?Object, ?Mode, ?Stream).\nThe predicate current_stream/3  is used to access the status of a stream as well as to generate all open  streams. Object is the name of the file opened if the stream  refers to an open file, an integer file descriptor if the stream  encapsulates an operating system stream, or the atom [] if  the stream refers to some other object. Mode is one of read or write.",
    "prefix":"current_stream"
  },
  "current_trie/1": {
    "body":"current_trie(${1:Trie})$2\n$0",
    "description":"[nondet]current_trie(-Trie).\nTrue if Trie is a currently existing trie. As this enumerates  and then filters all known atoms this predicate is slow and should only  be used for debugging purposes.",
    "prefix":"current_trie"
  },
  "cyclic_term/1": {
    "body":"cyclic_term(${1:Term})$2\n$0",
    "description":"cyclic_term(@Term).\nTrue if Term contains cycles, i.e. is an infinite term. See  also acyclic_term/1  and section 2.16.53The  predicates cyclic_term/1  and acyclic_term/1  are compatible with SICStus Prolog. Some Prolog systems supporting  cyclic terms use is_cyclic/1 .",
    "prefix":"cyclic_term"
  },
  "date:date_time_value/3": {
    "body": ["date_time_value(${1:Field}, ${2:Struct}, ${3:Value})$4\n$0" ],
    "description":"  date_time_value(?Field:atom, +Struct:datime, -Value) is nondet.\n\n   Extract values from a date-time structure.  Provided fields are\n\n           | year | integer | |\n           | month | 1..12 | |\n           | day | 1..31 | |\n           | hour | 0..23 | |\n           | minute | 0..59 | |\n           | second | 0.0..60.0 | |\n           | utc_offset | integer | Offset to UTC in seconds (positive is west) |\n           | daylight_saving | bool | Name of timezone; fails if unknown |\n           | date | date(Y,M,D) | |\n           | time | time(H,M,S) | |",
    "prefix":"date_time_value"
  },
  "date:day_of_the_week/2": {
    "body": ["day_of_the_week(${1:Date}, ${2:DayOfTheWeek})$3\n$0" ],
    "description":"  day_of_the_week(+Date, -DayOfTheWeek) is det.\n\n   Computes the day of the week for a  given date. Days of the week\n   are numbered from one to seven: monday   =  1, tuesday = 2, ...,\n   sunday = 7.\n\n   @param Date is a term of the form date(+Year, +Month, +Day)",
    "prefix":"day_of_the_week"
  },
  "date:day_of_the_year/2": {
    "body": ["day_of_the_year(${1:Date}, ${2:DayOfTheYear})$3\n$0" ],
    "description":"  day_of_the_year(+Date, -DayOfTheYear) is det.\n\n   Computes the day of the year for a  given date. Days of the year\n   are numbered from 1 to 365 (366 for a leap year).\n\n   @param Date is a term of the form date(+Year, +Month, +Day)",
    "prefix":"day_of_the_year"
  },
  "date:parse_time/2": {
    "body": ["parse_time(${1:Text}, ${2:Stamp})$3\n$0" ],
    "description":"  parse_time(+Text, -Stamp) is semidet.\n  parse_time(+Text, ?Format, -Stamp) is semidet.\n\n   Stamp is a  timestamp  created  from   parsing  Text  using  the\n   representation Format. Currently supported formats are:\n\n       * rfc_1123\n       Used for the HTTP protocol to represent time-stamps\n       * iso_8601\n       Commonly used in XML documents.",
    "prefix":"parse_time"
  },
  "date:parse_time/3": {
    "body": ["parse_time(${1:Text}, ${2:Format}, ${3:Stamp})$4\n$0" ],
    "description":"  parse_time(+Text, -Stamp) is semidet.\n  parse_time(+Text, ?Format, -Stamp) is semidet.\n\n   Stamp is a  timestamp  created  from   parsing  Text  using  the\n   representation Format. Currently supported formats are:\n\n       * rfc_1123\n       Used for the HTTP protocol to represent time-stamps\n       * iso_8601\n       Commonly used in XML documents.",
    "prefix":"parse_time"
  },
  "date_time_stamp/2": {
    "body":"date_time_stamp(${1:DateTime}, ${2:TimeStamp})$3\n$0",
    "description":"date_time_stamp(+DateTime, -TimeStamp).\nCompute the timestamp from a date/9 term. Values for month, day, hour,  minute or second need not be normalized. This flexibility allows for  easy computation of the time at any given number of these units from a  given timestamp. Normalization can be achieved following this call with stamp_date_time/3.  This example computes the date 200 days after 2006-7-14:  \n\n?- date_time_stamp(date(2006,7,214,0,0,0,0,-,-), Stamp),\n   stamp_date_time(Stamp, D, 0),\n   date_time_value(date, D, Date).\nDate = date(2007, 1, 30)\n\n  When computing a time stamp from a local time specification, the UTC  offset (arg7), TZ (arg8) and DST (arg9) argument may  be left unbound and are unified with the proper information. The example  below, executed in Amsterdam, illustrates this behaviour. On the 25th of  March at 01:00, DST does not apply. At 02.00, the clock is advanced by  one hour and thus both 02:00 and 03:00 represent the same time stamp. \n\n\n\n1 ?- date_time_stamp(date(2012,3,25,1,0,0,UTCOff,TZ,DST),\n                     Stamp).\nUTCOff = -3600,\nTZ = 'CET',\nDST = false,\nStamp = 1332633600.0.\n\n2 ?- date_time_stamp(date(2012,3,25,2,0,0,UTCOff,TZ,DST),\n                     Stamp).\nUTCOff = -7200,\nTZ = 'CEST',\nDST = true,\nStamp = 1332637200.0.\n\n3 ?- date_time_stamp(date(2012,3,25,3,0,0,UTCOff,TZ,DST),\n                     Stamp).\nUTCOff = -7200,\nTZ = 'CEST',\nDST = true,\nStamp = 1332637200.0.\n\n  Note that DST and offset calculation are based on the POSIX function  mktime(). If mktime() returns an error, a representation_error dst is generated.\n\n",
    "prefix":"date_time_stamp"
  },
  "date_time_value/3": {
    "body":"date_time_value(${1:Key}, ${2:DateTime}, ${3:Value})$4\n$0",
    "description":"date_time_value(?Key, +DateTime, ?Value).\nExtract values from a date/9 term. Provided keys are:  \n\nkeyvalue year Calendar year as an  integer month Calendar month as an  integer 1..12 day Calendar day as an  integer 1..31 hour Clock hour as an integer  0..23 minute Clock minute as an  integer 0..59 second Clock second as a  float 0.0..60.0 utc_offset Offset to UTC in  seconds (positive is west) time_zone Name of timezone;  fails if unknown daylight_saving Bool daylight_savingtrue)  if dst is in effect date Term date(Y,M,D) time Term time(H,M,S) ",
    "prefix":"date_time_value"
  },
  "day_of_the_week/2": {
    "body":"day_of_the_week(${1:Date}, ${2:DayOfTheWeek})$3\n$0",
    "description":"day_of_the_week(+Date,-DayOfTheWeek).\nComputes the day of the week for a given date. Date = date(Year,Month,Day).  Days of the week are numbered from one to seven: Monday = 1, Tuesday =  2, ... , Sunday = 7.",
    "prefix":"day_of_the_week"
  },
  "dcg/dcg_basics:alpha_to_lower/3": {
    "body": ["alpha_to_lower(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"alpha_to_lower('Param1','Param2','Param3')",
    "prefix":"alpha_to_lower"
  },
  "dcg/dcg_basics:atom/3": {
    "body": ["atom(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"atom('Param1','Param2','Param3')",
    "prefix":"atom"
  },
  "dcg/dcg_basics:blank/2": {
    "body": ["blank(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"blank('Param1','Param2')",
    "prefix":"blank"
  },
  "dcg/dcg_basics:blanks/2": {
    "body": ["blanks(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"blanks('Param1','Param2')",
    "prefix":"blanks"
  },
  "dcg/dcg_basics:blanks_to_nl/2": {
    "body": ["blanks_to_nl(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"blanks_to_nl('Param1','Param2')",
    "prefix":"blanks_to_nl"
  },
  "dcg/dcg_basics:digit/3": {
    "body": ["digit(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"digit('Param1','Param2','Param3')",
    "prefix":"digit"
  },
  "dcg/dcg_basics:digits/3": {
    "body": ["digits(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"digits('Param1','Param2','Param3')",
    "prefix":"digits"
  },
  "dcg/dcg_basics:eos/2": {
    "body": ["eos(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"eos('Param1','Param2')",
    "prefix":"eos"
  },
  "dcg/dcg_basics:float/3": {
    "body": ["float(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"float('Param1','Param2','Param3')",
    "prefix":"float"
  },
  "dcg/dcg_basics:integer/3": {
    "body": ["integer(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"integer('Param1','Param2','Param3')",
    "prefix":"integer"
  },
  "dcg/dcg_basics:nonblank/3": {
    "body": ["nonblank(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nonblank('Param1','Param2','Param3')",
    "prefix":"nonblank"
  },
  "dcg/dcg_basics:nonblanks/3": {
    "body": ["nonblanks(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nonblanks('Param1','Param2','Param3')",
    "prefix":"nonblanks"
  },
  "dcg/dcg_basics:number/3": {
    "body": ["number(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"number('Param1','Param2','Param3')",
    "prefix":"number"
  },
  "dcg/dcg_basics:prolog_var_name/3": {
    "body": [
      "prolog_var_name(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"prolog_var_name('Param1','Param2','Param3')",
    "prefix":"prolog_var_name"
  },
  "dcg/dcg_basics:remainder/3": {
    "body": ["remainder(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"remainder('Param1','Param2','Param3')",
    "prefix":"remainder"
  },
  "dcg/dcg_basics:string/3": {
    "body": ["string(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"string('Param1','Param2','Param3')",
    "prefix":"string"
  },
  "dcg/dcg_basics:string_without/4": {
    "body": [
      "string_without(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"string_without('Param1','Param2','Param3','Param4')",
    "prefix":"string_without"
  },
  "dcg/dcg_basics:white/2": {
    "body": ["white(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"white('Param1','Param2')",
    "prefix":"white"
  },
  "dcg/dcg_basics:whites/2": {
    "body": ["whites(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"whites('Param1','Param2')",
    "prefix":"whites"
  },
  "dcg/dcg_basics:xdigit/3": {
    "body": ["xdigit(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"xdigit('Param1','Param2','Param3')",
    "prefix":"xdigit"
  },
  "dcg/dcg_basics:xdigits/3": {
    "body": ["xdigits(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"xdigits('Param1','Param2','Param3')",
    "prefix":"xdigits"
  },
  "dcg/dcg_basics:xinteger/3": {
    "body": ["xinteger(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"xinteger('Param1','Param2','Param3')",
    "prefix":"xinteger"
  },
  "dcg_translate_rule/2": {
    "body":"dcg_translate_rule(${1:In}, ${2:Out})$3\n$0",
    "description":"dcg_translate_rule(+In, -Out).\nThis predicate performs the translation of a term Head-->Body  into a normal Prolog clause. Normally this functionality should be  accessed using expand_term/2.",
    "prefix":"dcg_translate_rule"
  },
  "dcg_translate_rule/4": {
    "body":"dcg_translate_rule(${1:In}, ${2:LayoutIn}, ${3:Out}, ${4:LayoutOut})$5\n$0",
    "description":"dcg_translate_rule(+In, ?LayoutIn, -Out, -LayoutOut).\nThese versions are called before their 2-argument counterparts.  The input layout term is either a variable (if no layout information is  available) or a term carrying detailed layout information as returned by  the subterm_positions of read_term/2.",
    "prefix":"dcg_translate_rule"
  },
  "dde_current_connection/2": {
    "body":"dde_current_connection(${1:Service}, ${2:Topic})$3\n$0",
    "description":"dde_current_connection(-Service, -Topic).\nFind currently open conversations.",
    "prefix":"dde_current_connection"
  },
  "dde_current_service/2": {
    "body":"dde_current_service(${1:Service}, ${2:Topic})$3\n$0",
    "description":"dde_current_service(-Service, -Topic).\nFind currently registered services and the topics served on them.",
    "prefix":"dde_current_service"
  },
  "dde_execute/2": {
    "body":"dde_execute(${1:Handle}, ${2:Command})$3\n$0",
    "description":"dde_execute(+Handle, +Command).\nRequest the DDE server to execute the given command string. Succeeds if  the command could be executed and fails with an error message otherwise.",
    "prefix":"dde_execute"
  },
  "dde_poke/3": {
    "body":"dde_poke(${1:Handle}, ${2:Item}, ${3:Command})$4\n$0",
    "description":"dde_poke(+Handle, +Item, +Command).\nIssue a POKE command to the server on the specified Item. command is passed as data of type CF_TEXT.",
    "prefix":"dde_poke"
  },
  "dde_register_service/2": {
    "body":"dde_register_service(${1:Template}, ${2:Goal})$3\n$0",
    "description":"dde_register_service(+Template, +Goal).\nRegister a server to handle DDE request or DDE execute  requests from other applications. To register a service for a DDE  request, Template is of the form:  +Service(+Topic, +Item, +Value) Service is the name of the DDE service provided (like progman in the client example above). Topic is either  an atom, indicating Goal only handles requests on this topic,  or a variable that also appears in Goal. Item and Value  are variables that also appear in Goal. Item  represents the request data as a Prolog atom.135Up  to version 3.4.5 this was a list of character codes. As recent versions  have atom garbage collection there is no need for this anymore.  The example below registers the Prolog current_prolog_flag/2  predicate to be accessible from other applications. The request may be  given from the same Prolog as well as from another application. \n\n\n\n?- dde_register_service(prolog(current_prolog_flag, F, V),\n                        current_prolog_flag(F, V)).\n\n?- open_dde_conversation(prolog, current_prolog_flag, Handle),\n   dde_request(Handle, home, Home),\n   close_dde_conversation(Handle).\n\nHome = '/usr/local/lib/pl-2.0.6/'\n\n  Handling DDE execute requests is very similar. In this  case the template is of the form:\n\n +Service(+Topic, +Item)  Passing a Value argument is not needed as execute  requests either succeed or fail. If Goal fails, a `not  processed' is passed back to the caller of the DDE request.\n\n",
    "prefix":"dde_register_service"
  },
  "dde_request/3": {
    "body":"dde_request(${1:Handle}, ${2:Item}, ${3:Value})$4\n$0",
    "description":"dde_request(+Handle, +Item, -Value).\nRequest a value from the server. Item is an atom that  identifies the requested data, and Value will be a string (CF_TEXT  data in DDE parlance) representing that data, if the request is  successful.",
    "prefix":"dde_request"
  },
  "dde_unregister_service/1": {
    "body":"dde_unregister_service(${1:Service})$2\n$0",
    "description":"dde_unregister_service(+Service).\nStop responding to Service. If Prolog is halted, it will  automatically call this on all open services.",
    "prefix":"dde_unregister_service"
  },
  "debug/0": {
    "body":"debug$1\n$0",
    "description":"debug.\nStart debugger. In debug mode, Prolog stops at spy and trace points,  disables last-call optimisation and aggressive destruction of choice  points to make debugging information accessible. Implemented by the  Prolog flag debug.  Note that the min_free parameter of all stacks is  enlarged to 8K cells if debugging is switched off in order to  avoid excessive GC. GC complicates tracing because it renames the _G<NNN>  variables and replaces unreachable variables with the atom <garbage_collected>. Calling nodebug/0  does not reset the initial free-margin because several parts of  the top level and debugger disable debugging of system code regions. See  also set_prolog_stack/2.\n\n",
    "prefix":"debug"
  },
  "debug:assertion/1": {
    "body":"assertion(${1:Goal})$2\n$0",
    "description":"[det]assertion(:Goal).\nActs similar to C assert() macro. It has no effect if Goal  succeeds. If Goal fails or throws an exception, the following  steps are taken:  \n\ncall prolog:assertion_failed/2.  If prolog:assertion_failed/2  fails, then:  If this is an interactive toplevel thread, print a message, the  stack-trace, and finally trap the debugger.Otherwise, throw error(assertion_error(Reason, G),_)  where Reason is one of fail or the exception raised.\n\n",
    "prefix":"assertion"
  },
  "debug:debug/1": {
    "body":"debug(${1:Topic})$2\n$0",
    "description":"[det]debug(+Topic).\n",
    "prefix":"debug"
  },
  "debug:debug/3": {
    "body":"debug(${1:Topic}, ${2:Format}, ${3:Args})$4\n$0",
    "description":"[det]debug(+Topic, +Format, :Args).\nFormat a message if debug topic is enabled. Similar to format/3  to user_error, but only prints if Topic is  activated through debug/1. Args  is a meta-argument to deal with goal for the @-command. Output is first  handed to the hook prolog:debug_print_hook/3.  If this fails, Format+Args is translated to text  using the message-translation (see print_message/2)  for the term debug(Format, Args) and then printed to every  matching destination (controlled by debug/1)  using print_message_lines/3.  The message is preceded by '% ' and terminated with a newline. \n\nSee also: format/3.\n\n ",
    "prefix":"debug"
  },
  "debug:debug_message_context/1": {
    "body":"debug_message_context(${1:What})$2\n$0",
    "description":"[det]debug_message_context(+What).\nSpecify additional context for debug messages. What is one of  +Context or -Context, and Context is one of thread, time  or time(Format), where Format is a format specification for format_time/3  (default is %T.%3f). Initially, debug/3  shows only thread information.",
    "prefix":"debug_message_context"
  },
  "debug:debugging/1": {
    "body":"debugging(${1:Topic})$2\n$0",
    "description":"[nondet]debugging(-Topic).\n",
    "prefix":"debugging"
  },
  "debug:debugging/2": {
    "body":"debugging(${1:Topic}, ${2:Bool})$3\n$0",
    "description":"[nondet]debugging(?Topic, ?Bool).\nExamine debug topics. The form debugging(+Topic) may be  used to perform more complex debugging tasks. A typical usage skeleton  is:  \n\n      (   debugging(mytopic)\n      ->  <perform debugging actions>\n      ;   true\n      ),\n      ...\n\n  The other two calls are intended to examine existing and enabled  debugging tokens and are typically not used in user programs.\n\n",
    "prefix":"debugging"
  },
  "debug:nodebug/1": {
    "body":"nodebug(${1:Topic})$2\n$0",
    "description":"[det]nodebug(+Topic).\nAdd/remove a topic from being printed. nodebug(_) removes  all topics. Gives a warning if the topic is not defined unless it is  used from a directive. The latter allows placing debug topics at the  start of a (load-)file without warnings.  For debug/1, Topic  can be a term Topic > Out, where Out is either  a stream or stream-alias or a filename (atom). This redirects debug  information on this topic to the given output.\n\n",
    "prefix":"nodebug"
  },
  "debugging/0": {
    "body":"debugging$1\n$0",
    "description":"debugging.\nPrint debug status and spy points on current output stream. See also the  Prolog flag debug.",
    "prefix":"debugging"
  },
  "default_module/2": {
    "body":"default_module(${1:Module}, ${2:Default})$3\n$0",
    "description":"[multi]default_module(+Module, -Default).\nTrue if predicates and operators in Default are visible in Module. Modules are returned in the same search order used  for predicates and operators. That is, Default is first  unified with Module, followed by the depth-first transitive  closure of import_module/2.",
    "prefix":"default_module"
  },
  "del_attr/2": {
    "body":"del_attr(${1:Var}, ${2:Module})$3\n$0",
    "description":"del_attr(+Var, +Module).\nDelete the named attribute. If Var loses its last attribute  it is transformed back into a traditional Prolog variable. If Module  is not an atom, a type error is raised. In all other cases this  predicate succeeds regardless of whether or not the named attribute is  present.",
    "prefix":"del_attr"
  },
  "del_attrs/1": {
    "body":"del_attrs(${1:Var})$2\n$0",
    "description":"del_attrs(+Var).\nIf Var is an attributed variable, delete all its  attributes. In all other cases, this predicate succeeds without  side-effects.",
    "prefix":"del_attrs"
  },
  "del_dict/4": {
    "body":"del_dict(${1:Key}, ${2:DictIn}, ${3:Value}, ${4:DictOut})$5\n$0",
    "description":"del_dict(+Key, +DictIn, ?Value, -DictOut).\nTrue when Key-Value is in DictIn and DictOut  contains all associations of DictIn except for Key.",
    "prefix":"del_dict"
  },
  "delete_directory/1": {
    "body":"delete_directory(${1:Directory})$2\n$0",
    "description":"delete_directory(+Directory).\nDelete directory (folder) from the filesystem. Raises an exception on  failure. Please note that in general it will not be possible to delete a  non-empty directory.",
    "prefix":"delete_directory"
  },
  "delete_file/1": {
    "body":"delete_file(${1:File})$2\n$0",
    "description":"delete_file(+File).\nRemove File from the file system.",
    "prefix":"delete_file"
  },
  "delete_import_module/2": {
    "body":"delete_import_module(${1:Module}, ${2:Import})$3\n$0",
    "description":"delete_import_module(+Module, +Import).\nDelete Import from the list of import modules for Module.  Fails silently if Import is not in the list.",
    "prefix":"delete_import_module"
  },
  "deterministic/1": {
    "body":"deterministic(${1:Boolean})$2\n$0",
    "description":"deterministic(-Boolean).\nUnifies its argument with true if no choice point exists  that is more recent than the entry of the clause in which it appears.  There are few realistic situations for using this predicate. It is used  by the prolog/0  top level to check whether Prolog should prompt the user for  alternatives. Similar results can be achieved in a more portable fashion  using call_cleanup/2.",
    "prefix":"deterministic"
  },
  "dia_main:dialog/0": {"body": ["dialog$1\n$0" ], "description":"dialog", "prefix":"dialog"},
  "dialect/bim:atomconcat/3": {
    "body": ["atomconcat(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"atomconcat('Param1','Param2','Param3')",
    "prefix":"atomconcat"
  },
  "dialect/bim:bim_erase/1": {
    "body": ["bim_erase(${1:'Param1'})$2\n$0" ],
    "description":"bim_erase('Param1')",
    "prefix":"bim_erase"
  },
  "dialect/bim:bim_erase/2": {
    "body": ["bim_erase(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"bim_erase('Param1','Param2')",
    "prefix":"bim_erase"
  },
  "dialect/bim:bim_random/1": {
    "body": ["bim_random(${1:'Param1'})$2\n$0" ],
    "description":"bim_random('Param1')",
    "prefix":"bim_random"
  },
  "dialect/bim:bim_recorded/3": {
    "body": ["bim_recorded(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"bim_recorded('Param1','Param2','Param3')",
    "prefix":"bim_recorded"
  },
  "dialect/bim:bindVariables/1": {
    "body": ["bindVariables(${1:'Param1'})$2\n$0" ],
    "description":"bindVariables('Param1')",
    "prefix":"bindVariables"
  },
  "dialect/bim:cputime/1": {
    "body": ["cputime(${1:'Param1'})$2\n$0" ],
    "description":"cputime('Param1')",
    "prefix":"cputime"
  },
  "dialect/bim:erase_all/1": {
    "body": ["erase_all(${1:'Param1'})$2\n$0" ],
    "description":"erase_all('Param1')",
    "prefix":"erase_all"
  },
  "dialect/bim:index/2": {
    "body": ["index(${1:PI}, ${2:Indices})$3\n$0" ],
    "description":"\tindex(+PI, +Indices) is det.\n\n\tIndex in the given arguments.  SWI-Prolog performs JIT indexing.",
    "prefix":"index"
  },
  "dialect/bim:inttoatom/2": {
    "body": ["inttoatom(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"inttoatom('Param1','Param2')",
    "prefix":"inttoatom"
  },
  "dialect/bim:please/2": {
    "body": ["please(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"please('Param1','Param2')",
    "prefix":"please"
  },
  "dialect/bim:predicate_type/2": {
    "body": ["predicate_type(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"predicate_type('Param1','Param2')",
    "prefix":"predicate_type"
  },
  "dialect/bim:printf/2": {
    "body": ["printf(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"printf('Param1','Param2')",
    "prefix":"printf"
  },
  "dialect/bim:record/3": {
    "body": ["record(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"record('Param1','Param2','Param3')",
    "prefix":"record"
  },
  "dialect/bim:rerecord/2": {
    "body": ["rerecord(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rerecord('Param1','Param2')",
    "prefix":"rerecord"
  },
  "dialect/bim:setdebug/0": {
    "body": ["setdebug$1\n$0" ],
    "description":"setdebug",
    "prefix":"setdebug"
  },
  "dialect/bim:update/1": {
    "body": ["update(${1:'Param1'})$2\n$0" ],
    "description":"update('Param1')",
    "prefix":"update"
  },
  "dialect/bim:vread/2": {
    "body": ["vread(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"vread('Param1','Param2')",
    "prefix":"vread"
  },
  "dialect/bim:writeClause/2": {
    "body": ["writeClause(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"writeClause('Param1','Param2')",
    "prefix":"writeClause"
  },
  "dialect/commons:feature/1": {
    "body": ["feature(${1:Feature})$2\n$0" ],
    "description":"\tfeature(+Feature) is semidet.\n\n\tProvide the condition for :- if(feature(...)).",
    "prefix":"feature"
  },
  "dialect/eclipse/test_util_iso:test/1": {
    "body": ["test(${1:TestFile})$2\n$0" ],
    "description":"\ttest(+TestFile) is det.\n\n\tRuns all the test patterns in TestFile.",
    "prefix":"test"
  },
  "dialect/eclipse/test_util_iso:test/2": {
    "body": ["test(${1:TestFile}, ${2:ResultFile})$3\n$0" ],
    "description":"\ttest(+TestFile, +ResultFile) is det.\n\n\tRuns all the test patterns  in   TestFile,  and  logs results in\n\tResultFile.",
    "prefix":"test"
  },
  "dialect/hprolog/format:format/2": {
    "body": ["format(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"format('Param1','Param2')",
    "prefix":"format"
  },
  "dialect/hprolog/format:format/3": {
    "body": ["format(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"format('Param1','Param2','Param3')",
    "prefix":"format"
  },
  "dialect/hprolog:bounded_sublist/3": {
    "body": ["bounded_sublist(${1:Sub}, ${2:List}, ${3:Bound})$4\n$0" ],
    "description":"\tbounded_sublist(?Sub, +List, +Bound:integer)\n\n\tAs sublist/2, but Sub has at most  Bound elements. E.g. the call\n\tbelow generates all 21 sublists of length   =< 2 from the second\n\targument.\n\n\t==\n\t?- bounded_sublist(List, [a,b,c,d], 2).\n\tX = [] ;\n\tX = [a] ;\n\tX = [a, b] ;\n\tX = [a] ;\n\t...\n\t==",
    "prefix":"bounded_sublist"
  },
  "dialect/hprolog:chr_delete/3": {
    "body": ["chr_delete(${1:List}, ${2:Element}, ${3:Rest})$4\n$0" ],
    "description":"\tchr_delete(+List, +Element, -Rest) is det.\n\n\tRest is a copy of List   without elements matching Element using\n\t==.",
    "prefix":"chr_delete"
  },
  "dialect/hprolog:drop/3": {
    "body": ["drop(${1:N}, ${2:List}, ${3:ListMinFirstN})$4\n$0" ],
    "description":"\tdrop(+N, +List, -ListMinFirstN) is semidet.\n\n\tDrop the first N elements from List and unify the remainder with\n\tLastElements.",
    "prefix":"drop"
  },
  "dialect/hprolog:ds_to_list/2": {
    "body": ["ds_to_list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"ds_to_list('Param1','Param2')",
    "prefix":"ds_to_list"
  },
  "dialect/hprolog:empty_ds/1": {
    "body": ["empty_ds(${1:'Param1'})$2\n$0" ],
    "description":"empty_ds('Param1')",
    "prefix":"empty_ds"
  },
  "dialect/hprolog:get_ds/3": {
    "body": ["get_ds(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"get_ds('Param1','Param2','Param3')",
    "prefix":"get_ds"
  },
  "dialect/hprolog:get_store/2": {
    "body": ["get_store(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"get_store('Param1','Param2')",
    "prefix":"get_store"
  },
  "dialect/hprolog:init_store/2": {
    "body": ["init_store(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"init_store('Param1','Param2')",
    "prefix":"init_store"
  },
  "dialect/hprolog:intersect_eq/3": {
    "body": ["intersect_eq(${1:List1}, ${2:List2}, ${3:Intersection})$4\n$0" ],
    "description":"\tintersect_eq(+List1, +List2, -Intersection)\n\n\tDetermine the intersection of two lists without unifying values.",
    "prefix":"intersect_eq"
  },
  "dialect/hprolog:list_difference_eq/3": {
    "body": ["list_difference_eq(${1:List}, ${2:Subtract}, ${3:Rest})$4\n$0" ],
    "description":"\tlist_difference_eq(+List, -Subtract, -Rest)\n\n\tDelete all elements of Subtract from List and unify the result\n\twith Rest.  Element comparision is done using ==/2.",
    "prefix":"list_difference_eq"
  },
  "dialect/hprolog:make_get_store_goal/3": {
    "body": [
      "make_get_store_goal(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"make_get_store_goal('Param1','Param2','Param3')",
    "prefix":"make_get_store_goal"
  },
  "dialect/hprolog:make_get_store_goal_no_error/3": {
    "body": [
      "make_get_store_goal_no_error(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"make_get_store_goal_no_error('Param1','Param2','Param3')",
    "prefix":"make_get_store_goal_no_error"
  },
  "dialect/hprolog:make_init_store_goal/3": {
    "body": [
      "make_init_store_goal(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"make_init_store_goal('Param1','Param2','Param3')",
    "prefix":"make_init_store_goal"
  },
  "dialect/hprolog:make_update_store_goal/3": {
    "body": [
      "make_update_store_goal(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"make_update_store_goal('Param1','Param2','Param3')",
    "prefix":"make_update_store_goal"
  },
  "dialect/hprolog:max_go_list/2": {
    "body": ["max_go_list(${1:List}, ${2:Max})$3\n$0" ],
    "description":"\tmax_go_list(+List, -Max)\n\n\tReturn the maximum of List in the standard order of terms.",
    "prefix":"max_go_list"
  },
  "dialect/hprolog:memberchk_eq/2": {
    "body": ["memberchk_eq(${1:Val}, ${2:List})$3\n$0" ],
    "description":"\tmemberchk_eq(+Val, +List)\n\n\tDeterministic check of membership using == rather than\n\tunification.",
    "prefix":"memberchk_eq"
  },
  "dialect/hprolog:or_list/2": {
    "body": ["or_list(${1:ListOfInts}, ${2:BitwiseOr})$3\n$0" ],
    "description":"\tor_list(+ListOfInts, -BitwiseOr)\n\n\tDo a bitwise disjuction over all integer members of ListOfInts.",
    "prefix":"or_list"
  },
  "dialect/hprolog:put_ds/4": {
    "body": [
      "put_ds(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"put_ds('Param1','Param2','Param3','Param4')",
    "prefix":"put_ds"
  },
  "dialect/hprolog:split_at/4": {
    "body": ["split_at(${1:N}, ${2:List}, ${3:FirstN}, ${4:Rest})$5\n$0" ],
    "description":"\tsplit_at(+N, +List, +FirstN, -Rest) is semidet.\n\n\tCombines take/3 and drop/3.",
    "prefix":"split_at"
  },
  "dialect/hprolog:sublist/2": {
    "body": ["sublist(${1:Sub}, ${2:List})$3\n$0" ],
    "description":"\tsublist(?Sub, +List) is nondet.\n\n\tTrue if all elements of Sub appear in List in the same order.",
    "prefix":"sublist"
  },
  "dialect/hprolog:substitute_eq/4": {
    "body": [
      "substitute_eq(${1:OldVal}, ${2:OldList}, ${3:NewVal}, ${4:NewList})$5\n$0"
    ],
    "description":"\tsubstitute_eq(+OldVal, +OldList, +NewVal, -NewList)\n\n\tSubstitute OldVal by NewVal in OldList and unify the result\n\twith NewList.",
    "prefix":"substitute_eq"
  },
  "dialect/hprolog:take/3": {
    "body": ["take(${1:N}, ${2:List}, ${3:FirstElements})$4\n$0" ],
    "description":"\ttake(+N, +List, -FirstElements)\n\n\tTake the first  N  elements  from   List  and  unify  this  with\n\tFirstElements. The definition is based   on the GNU-Prolog lists\n\tlibrary. Implementation by Jan Wielemaker.",
    "prefix":"take"
  },
  "dialect/hprolog:time/3": {
    "body": ["time(${1:Goal}, ${2:CPU}, ${3:Wall})$4\n$0" ],
    "description":"\ttime(:Goal, -CPU, -Wall)\n\n\thProlog compatible predicate to for statistical purposes",
    "prefix":"time"
  },
  "dialect/hprolog:update_store/2": {
    "body": ["update_store(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"update_store('Param1','Param2')",
    "prefix":"update_store"
  },
  "dialect/ifprolog:asserta_with_names/2": {
    "body": ["asserta_with_names(${1:Clause}, ${2:VarNames})$3\n$0" ],
    "description":"\tasserta_with_names(@Clause, +VarNames) is det.\n\tassertz_with_names(@Clause, +VarNames) is det.\n\tclause_with_names(?Head, ?Body, -VarNames) is det.\n\tretract_with_names(?Clause, -VarNames) is det.\n\n\tPredicates that manage  the  database   while  keeping  track of\n\tvariable names.",
    "prefix":"asserta_with_names"
  },
  "dialect/ifprolog:assertz_with_names/2": {
    "body": ["assertz_with_names(${1:Clause}, ${2:VarNames})$3\n$0" ],
    "description":"\tasserta_with_names(@Clause, +VarNames) is det.\n\tassertz_with_names(@Clause, +VarNames) is det.\n\tclause_with_names(?Head, ?Body, -VarNames) is det.\n\tretract_with_names(?Clause, -VarNames) is det.\n\n\tPredicates that manage  the  database   while  keeping  track of\n\tvariable names.",
    "prefix":"assertz_with_names"
  },
  "dialect/ifprolog:assign_alias/2": {
    "body": ["assign_alias(${1:Alias}, ${2:Stream})$3\n$0" ],
    "description":"\tassign_alias(+Alias, @Stream) is det.\n",
    "prefix":"assign_alias"
  },
  "dialect/ifprolog:atom_part/4": {
    "body": ["atom_part(${1:Atom}, ${2:Pos}, ${3:Len}, ${4:Sub})$5\n$0" ],
    "description":"\tatom_part(+Atom, +Pos, +Len, -Sub) is det.\n\n\tTrue when Sub is part  of   the  atom [Pos,Pos+Len). Unifies Sub\n\twith '' if Pos or Len is out of range!?",
    "prefix":"atom_part"
  },
  "dialect/ifprolog:atom_prefix/3": {
    "body": ["atom_prefix(${1:Atom}, ${2:Len}, ${3:Sub})$4\n$0" ],
    "description":"\tatom_prefix(+Atom, +Len, -Sub) is det.\n\n\tUnifies Sub with the atom formed by  the first Len characters in\n\tatom.\n\n\t - If Len < 1, Sub is unified with the null atom ''.\n\t - If Len > length of Atom, Sub is unified with Atom.",
    "prefix":"atom_prefix"
  },
  "dialect/ifprolog:atom_split/3": {
    "body": ["atom_split(${1:Atom}, ${2:Delimiter}, ${3:Subatoms})$4\n$0" ],
    "description":"\tatom_split( +Atom, +Delimiter, ?Subatoms )\n\n\tSplit Atom over Delimiter and unify the parts with Subatoms.",
    "prefix":"atom_split"
  },
  "dialect/ifprolog:atom_suffix/3": {
    "body": ["atom_suffix(${1:Atom}, ${2:Len}, ${3:Sub})$4\n$0" ],
    "description":"\tatom_suffix(+Atom, +Len, -Sub) is det.\n\n\tUnifies Sub with the atom formed by   the last Len characters in\n\tatom.\n\n\t  - If Len < 1, Sub is unified with the null atom ''.\n\t  - If Len > length of Atom, Sub is unified with Atom.",
    "prefix":"atom_suffix"
  },
  "dialect/ifprolog:block/3": {
    "body": ["block(${1:Goal}, ${2:Tag}, ${3:Recovery})$4\n$0" ],
    "description":"\tblock(:Goal, +Tag, :Recovery).\n\texit_block(+Tag).\n\tcut_block(+Tag) is semidet.\n\n\tThe control construct block/3 runs Goal in a block labelled Tag.\n\tIf Goal calls exit_block/1 using a   matching Tag, the execution\n\tof Goal is abandoned  using   exception  handling  and execution\n\tcontinues by running Recovery.  Goal   can  call cut_block/1. If\n\tthere is a block with matching   Tag,  all choice points created\n\tsince the block was started are destroyed.\n\n\t@bug\tThe block control structure is implemented on top of\n\t\tcatch/3 and throw/1.  If catch/3 is used inside Goal,\n\t\tthe user must ensure that either (1) the protected\n\t\tgoal does not call exit_block/1 or cut_block/1 or (2)\n\t\tthe _Catcher_ of the catch/3 call does *not* unify with\n\t\ta term block(_,_).",
    "prefix":"block"
  },
  "dialect/ifprolog:calling_context/1": {
    "body": ["calling_context(${1:Context})$2\n$0" ],
    "description":"\tcalling_context(-Context)\n\n\tMapped to context_module/1.",
    "prefix":"calling_context"
  },
  "dialect/ifprolog:clause_with_names/3": {
    "body": ["clause_with_names(${1:Head}, ${2:Body}, ${3:VarNames})$4\n$0" ],
    "description":"\tasserta_with_names(@Clause, +VarNames) is det.\n\tassertz_with_names(@Clause, +VarNames) is det.\n\tclause_with_names(?Head, ?Body, -VarNames) is det.\n\tretract_with_names(?Clause, -VarNames) is det.\n\n\tPredicates that manage  the  database   while  keeping  track of\n\tvariable names.",
    "prefix":"clause_with_names"
  },
  "dialect/ifprolog:context/2": {
    "body": ["context(${1:Goal}, ${2:Mapping})$3\n$0" ],
    "description":"\tcontext(:Goal, +Mapping)\n\n\tIF/Prolog context/2 construct. This is  the true predicate. This\n\tis normally mapped by goal-expansion.\n\n\t@bug\tDoes not deal with IF/Prolog signal mapping",
    "prefix":"context"
  },
  "dialect/ifprolog:current_default_module/1": {
    "body": ["current_default_module(${1:Module})$2\n$0" ],
    "description":"\tcurrent_default_module(-Module) is det.\n\n\tName of the toplevel typein module.",
    "prefix":"current_default_module"
  },
  "dialect/ifprolog:current_error/1": {
    "body": ["current_error(${1:Stream})$2\n$0" ],
    "description":"\tcurrent_error(-Stream)\n\n\tDoesn't exist in SWI-Prolog, but =user_error= is always an alias\n\tto the current error stream.",
    "prefix":"current_error"
  },
  "dialect/ifprolog:current_global/1": {
    "body": ["current_global(${1:Name})$2\n$0" ],
    "description":"\tcurrent_global(+Name) is semidet.\n\tget_global(+Name, ?Value) is det.\n\tset_global(+Name, ?Value) is det.\n\tunset_global(+Name) is det.\n\n\tIF/Prolog  global  variables,  mapped    to   SWI-Prolog's  nb_*\n\tpredicates.",
    "prefix":"current_global"
  },
  "dialect/ifprolog:current_signal/2": {
    "body": ["current_signal(${1:Signal}, ${2:Mode})$3\n$0" ],
    "description":"\tcurrent_signal(?Signal, ?Mode) is nondet.\n\n\tTrue when Mode is the current   mode  for handling Signal. Modes\n\tare =on=, =off=,  =default=,  =ignore=.   Signals  are  =abort=,\n\t=alarm=, =interrupt=, =pipe=, =quit=,   =termination=,  =user_1=\n\tand =user_2=.\n\n\t@tbd\tImplement",
    "prefix":"current_signal"
  },
  "dialect/ifprolog:current_visible/2": {
    "body": ["current_visible(${1:Module}, ${2:PredicateIndicator})$3\n$0" ],
    "description":"\tcurrent_visible(@Module, @PredicateIndicator).\n\n\tFIXME check with documentation",
    "prefix":"current_visible"
  },
  "dialect/ifprolog:cut_block/1": {
    "body": ["cut_block(${1:Tag})$2\n$0" ],
    "description":"\tblock(:Goal, +Tag, :Recovery).\n\texit_block(+Tag).\n\tcut_block(+Tag) is semidet.\n\n\tThe control construct block/3 runs Goal in a block labelled Tag.\n\tIf Goal calls exit_block/1 using a   matching Tag, the execution\n\tof Goal is abandoned  using   exception  handling  and execution\n\tcontinues by running Recovery.  Goal   can  call cut_block/1. If\n\tthere is a block with matching   Tag,  all choice points created\n\tsince the block was started are destroyed.\n\n\t@bug\tThe block control structure is implemented on top of\n\t\tcatch/3 and throw/1.  If catch/3 is used inside Goal,\n\t\tthe user must ensure that either (1) the protected\n\t\tgoal does not call exit_block/1 or cut_block/1 or (2)\n\t\tthe _Catcher_ of the catch/3 call does *not* unify with\n\t\ta term block(_,_).",
    "prefix":"cut_block"
  },
  "dialect/ifprolog:debug_config/3": {
    "body": ["debug_config(${1:Key}, ${2:Current}, ${3:Value})$4\n$0" ],
    "description":"\tdebug_config(+Key, -Current, +Value)\n\n\tIgnored.  Prints a message.",
    "prefix":"debug_config"
  },
  "dialect/ifprolog:debug_mode/3": {
    "body": ["debug_mode(${1:PI}, ${2:Old}, ${3:New})$4\n$0" ],
    "description":"\tdebug_mode(:PI, -Old, +New)\n\n\tOld is not unified.  Only  New  ==   off  is  mapped  to disable\n\tdebugging of a predicate.",
    "prefix":"debug_mode"
  },
  "dialect/ifprolog:digit/1": {
    "body": ["digit(${1:A})$2\n$0" ],
    "description":"\tdigit(+A).\n\n\tIs the character A a digit [0-9]",
    "prefix":"digit"
  },
  "dialect/ifprolog:exit_block/1": {
    "body": ["exit_block(${1:Tag})$2\n$0" ],
    "description":"\tblock(:Goal, +Tag, :Recovery).\n\texit_block(+Tag).\n\tcut_block(+Tag) is semidet.\n\n\tThe control construct block/3 runs Goal in a block labelled Tag.\n\tIf Goal calls exit_block/1 using a   matching Tag, the execution\n\tof Goal is abandoned  using   exception  handling  and execution\n\tcontinues by running Recovery.  Goal   can  call cut_block/1. If\n\tthere is a block with matching   Tag,  all choice points created\n\tsince the block was started are destroyed.\n\n\t@bug\tThe block control structure is implemented on top of\n\t\tcatch/3 and throw/1.  If catch/3 is used inside Goal,\n\t\tthe user must ensure that either (1) the protected\n\t\tgoal does not call exit_block/1 or cut_block/1 or (2)\n\t\tthe _Catcher_ of the catch/3 call does *not* unify with\n\t\ta term block(_,_).",
    "prefix":"exit_block"
  },
  "dialect/ifprolog:file_test/2": {
    "body": ["file_test(${1:File}, ${2:Mode})$3\n$0" ],
    "description":"\tfile_test(+File, +Mode)\n\n\tMapped to access_file/2 (which understand more modes). Note that\n\tthis predicate is defined in the   module  =system= to allow for\n\tdirect calling.",
    "prefix":"file_test"
  },
  "dialect/ifprolog:filepos/2": {
    "body": ["filepos(${1:Stream}, ${2:Line})$3\n$0" ],
    "description":"\tfilepos(@Stream, -Line)\n\n\tfrom  the  IF/Prolog  documentation    The  predicate  filepos/2\n\tdetermines the current line  position   of  the  specified input\n\tstream and unifies the  result  with   Line.  The  current  line\n\tposition is the number of line processed + 1",
    "prefix":"filepos"
  },
  "dialect/ifprolog:filepos/3": {
    "body": ["filepos(${1:Stream}, ${2:Line}, ${3:Column})$4\n$0" ],
    "description":"\tfilepos(@Stream, -Line, -Column)\n\n\tfrom  the  IF/Prolog  documentation    The  predicate  filepos/2\n\tdetermines the current line  position   of  the  specified input\n\tstream and unifies the  result  with   Line.  The  current  line\n\tposition is the number of line processed + 1",
    "prefix":"filepos"
  },
  "dialect/ifprolog:float_format/2": {
    "body": ["float_format(${1:Old}, ${2:New})$3\n$0" ],
    "description":"\tfloat_format(-Old, +New)\n\n\tIgnored. Prints a message. Cannot   be emulated. Printing floats\n\twith a specified precision can only be done using format/2.",
    "prefix":"float_format"
  },
  "dialect/ifprolog:for/3": {
    "body": ["for(${1:Start}, ${2:Count}, ${3:End})$4\n$0" ],
    "description":"\tfor(+Start, ?Count, +End) is nondet.\n\n\tSimilar to between/3, but can count down if Start > End.",
    "prefix":"for"
  },
  "dialect/ifprolog:get_global/2": {
    "body": ["get_global(${1:Name}, ${2:Value})$3\n$0" ],
    "description":"\tcurrent_global(+Name) is semidet.\n\tget_global(+Name, ?Value) is det.\n\tset_global(+Name, ?Value) is det.\n\tunset_global(+Name) is det.\n\n\tIF/Prolog  global  variables,  mapped    to   SWI-Prolog's  nb_*\n\tpredicates.",
    "prefix":"get_global"
  },
  "dialect/ifprolog:get_until/3": {
    "body": ["get_until(${1:SearchChar}, ${2:Text}, ${3:EndChar})$4\n$0" ],
    "description":"\tget_until(+SearchChar, -Text, -EndChar) is det.\n\tget_until(@Stream, +SearchChar, -Text, -EndChar) is det.\n\n\tRead input from Stream  until   SearchChar.  Unify  EndChar with\n\teither SearchChar or the atom =end_of_file=.",
    "prefix":"get_until"
  },
  "dialect/ifprolog:get_until/4": {
    "body": [
      "get_until(${1:Stream}, ${2:SearchChar}, ${3:Text}, ${4:EndChar})$5\n$0"
    ],
    "description":"\tget_until(+SearchChar, -Text, -EndChar) is det.\n\tget_until(@Stream, +SearchChar, -Text, -EndChar) is det.\n\n\tRead input from Stream  until   SearchChar.  Unify  EndChar with\n\teither SearchChar or the atom =end_of_file=.",
    "prefix":"get_until"
  },
  "dialect/ifprolog:getchar/3": {
    "body": ["getchar(${1:Atom}, ${2:Pos}, ${3:Char})$4\n$0" ],
    "description":"\tgetchar(+Atom, +Pos, -Char)\n\n\tUnifies Char with the Position-th character in Atom\n\tIf Pos < 1 or Pos > length of Atom, then fail.",
    "prefix":"getchar"
  },
  "dialect/ifprolog:getcwd/1": {
    "body": ["getcwd(${1:Dir})$2\n$0" ],
    "description":"\tgetcwd(-Dir)\n\n\tThe predicate getcwd/1 unifies Dir with the full pathname of the\n\tcurrent working directory.",
    "prefix":"getcwd"
  },
  "dialect/ifprolog:if_concat_atom/2": {
    "body": ["if_concat_atom(${1:List}, ${2:Atom})$3\n$0" ],
    "description":"\tif_concat_atom(+List, -Atom) is det.\n\n\tTrue when Atom is the concatenation of   the lexical form of all\n\telements  from  List.  Same  as  if_concat_atom/3  using  ''  as\n\tdelimiter.",
    "prefix":"if_concat_atom"
  },
  "dialect/ifprolog:if_concat_atom/3": {
    "body": ["if_concat_atom(${1:List}, ${2:Delimiter}, ${3:Atom})$4\n$0" ],
    "description":"\tif_concat_atom(+List, +Delimiter, -Atom) is det.\n\n\tTrue when Atom is the concatenation of   the lexical form of all\n\telements from List, using Delimiter to delimit the elements.\n\n\tThe behavior of this  ifprolog   predicate  is  different w.r.t.\n\tSWI-Prolog in two respect: it supports   arbitrary terms in List\n\trather than only atomic and it does _not_ work in mode -,+,+.",
    "prefix":"if_concat_atom"
  },
  "dialect/ifprolog:ifprolog_debug/1": {
    "body": ["ifprolog_debug(${1:Goal})$2\n$0" ],
    "description":"\tifprolog_debug(:Goal)\n\n\tMap IF/Prolog debug(Goal)@Module. This should  run Goal in debug\n\tmode. We rarely needs this type of measures in SWI-Prolog.",
    "prefix":"ifprolog_debug"
  },
  "dialect/ifprolog:index/3": {
    "body": ["index(${1:Atom}, ${2:String}, ${3:Position})$4\n$0" ],
    "description":"\tindex(+Atom, +String, -Position) is semidet.\n\n\tTrue when Position is the first   occurrence  of String in Atom.\n\tPosition is 1-based.",
    "prefix":"index"
  },
  "dialect/ifprolog:letter/1": {
    "body": ["letter(${1:A})$2\n$0" ],
    "description":"\tletter(+A).\n\n\tIs the character A a letter [A-Za-z]",
    "prefix":"letter"
  },
  "dialect/ifprolog:list_length/2": {
    "body": ["list_length(${1:List}, ${2:Length})$3\n$0" ],
    "description":"\tlist_length(+List, ?Length) is det.\n\n\tDeterministic version of length/2. Current implementation simply\n\tcalls length/2.",
    "prefix":"list_length"
  },
  "dialect/ifprolog:load/1": {
    "body": ["load(${1:File})$2\n$0" ],
    "description":"\tload(File)\n\n\tMapped to consult.  I think that the compatible version should\n\tonly load .qlf (compiled) code.",
    "prefix":"load"
  },
  "dialect/ifprolog:localtime/9": {
    "body": [
      "localtime(${1:Time}, ${2:Year}, ${3:Month}, ${4:Day}, ${5:DoW}, ${6:DoY}, ${7:Hour}, ${8:Min}, ${9:Sec})$10\n$0"
    ],
    "description":"\tlocaltime(+Time, ?Year, ?Month, ?Day, ?DoW, ?DoY, ?Hour, ?Min, ?Sec)\n\n\tBreak system time into its components.  Deefines components:\n\n\t  | Year    | Year number    | 4 digits        |\n\t  | Month   | Month number   | 1..12           |\n\t  | Day\t    | Day of month   | 1..31           |\n\t  | DoW\t    | Day of week    | 1..7 (Mon-Sun)  |\n\t  | DoY\t    | Day in year    | 1..366          |\n\t  | Hour    | Hours\t     | 0..23           |\n\t  | Min\t    | Minutes\t     | 0..59           |\n\t  | Sec\t    | Seconds\t     | 0..59           |\n\n\tNote that in IF/Prolog  V4,  Year  is   0..99,  while  it  is  a\n\tfour-digit number in IF/Prolog V5.  We emulate IF/Prolog V5.",
    "prefix":"localtime"
  },
  "dialect/ifprolog:lower_upper/2": {
    "body": ["lower_upper(${1:Lower}, ${2:Upper})$3\n$0" ],
    "description":"\tlower_upper(+Lower, -Upper) is det.\n\tlower_upper(-Lower, +Upper) is det.\n\n\tMulti-moded combination of upcase_atom/2 and downcase_atom/2.",
    "prefix":"lower_upper"
  },
  "dialect/ifprolog:match/2": {
    "body": ["match(${1:Mask}, ${2:Atom})$3\n$0" ],
    "description":"\tmatch(+Mask, +Atom) is semidet.\n\n\tSame as once(match(Mask, Atom, _Replacements)).",
    "prefix":"match"
  },
  "dialect/ifprolog:match/3": {
    "body": ["match(${1:Mask}, ${2:Atom}, ${3:Replacements})$4\n$0" ],
    "description":"\tmatch(+Mask, +Atom, ?Replacements) is nondet.\n\n\tPattern matching. This emulation  should   be  complete.  Can be\n\toptimized using caching of  the   pattern-analysis  or doing the\n\tanalysis at compile-time.",
    "prefix":"match"
  },
  "dialect/ifprolog:modify_mode/3": {
    "body": ["modify_mode(${1:PI}, ${2:OldMode}, ${3:NewMode})$4\n$0" ],
    "description":"\tmodify_mode(+PI, -OldMode, +NewMode) is det.\n\n\tSwitch between static and  dynamic   code.  Fully supported, but\n\tnotably changing static to dynamic code   is  not allowed if the\n\tpredicate has clauses.",
    "prefix":"modify_mode"
  },
  "dialect/ifprolog:parse_atom/6": {
    "body": [
      "parse_atom(${1:Atom}, ${2:StartPos}, ${3:EndPos}, ${4:Term}, ${5:VarList}, ${6:Error})$7\n$0"
    ],
    "description":"\tparse_atom(+Atom, +StartPos, ?EndPos, ?Term, ?VarList, ?Error)\n\n\tRead from an atom.\n\n\t@param StartPos is 1-based position to start reading\n\t@param Error is the 1-based position of a syntax error or 0 if\n\t       there is no error.",
    "prefix":"parse_atom"
  },
  "dialect/ifprolog:predicate_type/2": {
    "body": ["predicate_type(${1:PI}, ${2:Type})$3\n$0" ],
    "description":"\tpredicate_type(:PI, -Type) is det.\n\n\tTrue when Type describes the type  of   PI.  Note that the value\n\t=linear= seems to mean you can use clause/2 on it, which is true\n\tfor any SWI-Prolog predicate that is  defined. Therefore, we use\n\tit for any predicate that is defined.",
    "prefix":"predicate_type"
  },
  "dialect/ifprolog:program_parameters/1": {
    "body": ["program_parameters(${1:List})$2\n$0" ],
    "description":"\tprogram_parameters(-List:atom)\n\n\tAll command-line argument, including the executable,",
    "prefix":"program_parameters"
  },
  "dialect/ifprolog:prolog_version/1": {
    "body": ["prolog_version(${1:Version})$2\n$0" ],
    "description":"\tprolog_version(-Version)\n\n\tReturn IF/Prolog simulated version string",
    "prefix":"prolog_version"
  },
  "dialect/ifprolog:proroot/1": {
    "body": ["proroot(${1:Path})$2\n$0" ],
    "description":"\tproroot(-Path)\n\n\tTrue when Path is  the  installation   location  of  the  Prolog\n\tsystem.",
    "prefix":"proroot"
  },
  "dialect/ifprolog:retract_with_names/2": {
    "body": ["retract_with_names(${1:Clause}, ${2:VarNames})$3\n$0" ],
    "description":"\tasserta_with_names(@Clause, +VarNames) is det.\n\tassertz_with_names(@Clause, +VarNames) is det.\n\tclause_with_names(?Head, ?Body, -VarNames) is det.\n\tretract_with_names(?Clause, -VarNames) is det.\n\n\tPredicates that manage  the  database   while  keeping  track of\n\tvariable names.",
    "prefix":"retract_with_names"
  },
  "dialect/ifprolog:set_default_module/1": {
    "body": ["set_default_module(${1:Module})$2\n$0" ],
    "description":"\tset_default_module(+Module) is det.\n\n\tSet the default toplevel module.",
    "prefix":"set_default_module"
  },
  "dialect/ifprolog:set_global/2": {
    "body": ["set_global(${1:Name}, ${2:Value})$3\n$0" ],
    "description":"\tcurrent_global(+Name) is semidet.\n\tget_global(+Name, ?Value) is det.\n\tset_global(+Name, ?Value) is det.\n\tunset_global(+Name) is det.\n\n\tIF/Prolog  global  variables,  mapped    to   SWI-Prolog's  nb_*\n\tpredicates.",
    "prefix":"set_global"
  },
  "dialect/ifprolog:system_name/1": {
    "body": ["system_name(${1:SystemName})$2\n$0" ],
    "description":"\tsystem_name(-SystemName)\n\n\tTrue when SystemName identifies the  operating system. Note that\n\tthis returns the SWI-Prolog =arch= flag,   and not the IF/Prolog\n\tidentifiers.",
    "prefix":"system_name"
  },
  "dialect/ifprolog:unset_global/1": {
    "body": ["unset_global(${1:Name})$2\n$0" ],
    "description":"\tcurrent_global(+Name) is semidet.\n\tget_global(+Name, ?Value) is det.\n\tset_global(+Name, ?Value) is det.\n\tunset_global(+Name) is det.\n\n\tIF/Prolog  global  variables,  mapped    to   SWI-Prolog's  nb_*\n\tpredicates.",
    "prefix":"unset_global"
  },
  "dialect/ifprolog:user_parameters/1": {
    "body": ["user_parameters(${1:List})$2\n$0" ],
    "description":"\tuser_parameters(-List:atom)\n\n\tParameters after =|--|=.",
    "prefix":"user_parameters"
  },
  "dialect/ifprolog:write_atom/2": {
    "body": ["write_atom(${1:Term}, ${2:Atom})$3\n$0" ],
    "description":"\twrite_atom(+Term, -Atom)\n\n\tUse write/1 to write Term to Atom.",
    "prefix":"write_atom"
  },
  "dialect/ifprolog:write_formatted/2": {
    "body": ["write_formatted(${1:Format}, ${2:ArgList})$3\n$0" ],
    "description":"\twrite_formatted_atom(-Atom, +Format, +ArgList) is det.\n\twrite_formatted(+Format, +ArgList) is det.\n\twrite_formatted(@Stream, +Format, +ArgList) is det.\n\n\tEmulation of IF/Prolog formatted write.   The  emulation is very\n\tincomplete. Notable asks for dealing with aligned fields, etc.\n\n\t@bug\tNot all format characters are processed\n\t@bug    Incomplete processing of modifiers, fieldwidth and precision\n\t@tbd\tThis should become goal-expansion based to process\n\t\tformat specifiers at compile-time.",
    "prefix":"write_formatted"
  },
  "dialect/ifprolog:write_formatted/3": {
    "body": ["write_formatted(${1:Atom}, ${2:Format}, ${3:ArgList})$4\n$0" ],
    "description":"\twrite_formatted_atom(-Atom, +Format, +ArgList) is det.\n\twrite_formatted(+Format, +ArgList) is det.\n\twrite_formatted(@Stream, +Format, +ArgList) is det.\n\n\tEmulation of IF/Prolog formatted write.   The  emulation is very\n\tincomplete. Notable asks for dealing with aligned fields, etc.\n\n\t@bug\tNot all format characters are processed\n\t@bug    Incomplete processing of modifiers, fieldwidth and precision\n\t@tbd\tThis should become goal-expansion based to process\n\t\tformat specifiers at compile-time.",
    "prefix":"write_formatted"
  },
  "dialect/ifprolog:write_formatted_atom/3": {
    "body": ["write_formatted_atom(${1:Atom}, ${2:Format}, ${3:ArgList})$4\n$0" ],
    "description":"\twrite_formatted_atom(-Atom, +Format, +ArgList) is det.\n\twrite_formatted(+Format, +ArgList) is det.\n\twrite_formatted(@Stream, +Format, +ArgList) is det.\n\n\tEmulation of IF/Prolog formatted write.   The  emulation is very\n\tincomplete. Notable asks for dealing with aligned fields, etc.\n\n\t@bug\tNot all format characters are processed\n\t@bug    Incomplete processing of modifiers, fieldwidth and precision\n\t@tbd\tThis should become goal-expansion based to process\n\t\tformat specifiers at compile-time.",
    "prefix":"write_formatted_atom"
  },
  "dialect/ifprolog:writeq_atom/2": {
    "body": ["writeq_atom(${1:Term}, ${2:Atom})$3\n$0" ],
    "description":"\twriteq_atom(+Term, -Atom)\n\n\tUse writeq/1 to write Term to Atom.",
    "prefix":"writeq_atom"
  },
  "dialect/iso/iso_predicates:iso_builtin_function/1": {
    "body": ["iso_builtin_function(${1:Head})$2\n$0" ],
    "description":"\tiso_builtin_function(?Head:callable) is nondet.\n\n\tTrue if Head describes a builtin  arithmetic function as defined\n\tby the ISO Prolog standard (ISO/IEC 1321 l-l).",
    "prefix":"iso_builtin_function"
  },
  "dialect/iso/iso_predicates:iso_builtin_predicate/1": {
    "body": ["iso_builtin_predicate(${1:Head})$2\n$0" ],
    "description":"\tiso_builtin_predicate(?Head:callable) is nondet.\n\n\tTrue if Head describes  a  builtin   defined  by  the ISO Prolog\n\tstandard (ISO/IEC 1321 l-l).",
    "prefix":"iso_builtin_predicate"
  },
  "dialect/sicstus/arrays:aref/3": {
    "body": ["aref(${1:Index}, ${2:Array}, ${3:Element})$4\n$0" ],
    "description":"\taref(+Index, +Array, -Element) is semidet.\n\n\tTrue if Element is the current element in Array at Index.\n\n\t@compat SICStus-3",
    "prefix":"aref"
  },
  "dialect/sicstus/arrays:arefa/3": {
    "body": ["arefa(${1:Index}, ${2:Array}, ${3:ArrayElement})$4\n$0" ],
    "description":"\tarefa(+Index, +Array, -ArrayElement) is det.\n\n\tAs aref/3, but succeeds with an empty   array  of the element is\n\tnot set.\n\n\t@compat SICStus-3",
    "prefix":"arefa"
  },
  "dialect/sicstus/arrays:arefl/3": {
    "body": ["arefl(${1:Index}, ${2:Array}, ${3:ListElement})$4\n$0" ],
    "description":"\tarefl(+Index, +Array, -ListElement) is det.\n\n\tAs aref/3, but succeeds with an empty list of the element is not\n\tset.\n\n\t@compat SICStus-3",
    "prefix":"arefl"
  },
  "dialect/sicstus/arrays:array_to_list/2": {
    "body": ["array_to_list(${1:Array}, ${2:Pairs})$3\n$0" ],
    "description":"\tarray_to_list(+Array, -Pairs) is det.\n\n\t@compat SICStus-3",
    "prefix":"array_to_list"
  },
  "dialect/sicstus/arrays:aset/4": {
    "body": ["aset(${1:Index}, ${2:Array}, ${3:Element}, ${4:NewArray})$5\n$0" ],
    "description":"\taset(+Index, +Array, +Element, -NewArray) is det.\n\n\tNewArray is Array with Element added/updated at Index.\n\n\t@compat SICStus-3",
    "prefix":"aset"
  },
  "dialect/sicstus/arrays:is_array/1": {
    "body": ["is_array(${1:Term})$2\n$0" ],
    "description":"\tis_array(@Term) is semidet.\n\n\tTrue if Term is an array\n\n\t@compat SICStus-3",
    "prefix":"is_array"
  },
  "dialect/sicstus/arrays:new_array/1": {
    "body": ["new_array(${1:Array})$2\n$0" ],
    "description":"\tnew_array(-Array) is det.\n\n\t@compat SICStus-3",
    "prefix":"new_array"
  },
  "dialect/sicstus/block_directive:block/1": {
    "body": ["block(${1:Heads})$2\n$0" ],
    "description":"\tblock(+Heads).\n\n\tDeclare predicates to suspend on certain modes. The argument is,\n\tlike  meta_predicate/1,  a   comma-separated    list   of  modes\n\t(_BlockSpecs_). Calls to the predicate is  suspended if at least\n\tone of the conditions  implies  by   a  blockspec  evaluated  to\n\t=true=. A blockspec  evaluated  to   =true=  iff  all  arguments\n\tspecified as `-' are unbound.\n\n\tMultiple BlockSpecs for a single predicate  can appear in one or\n\tmore :- block declarations. The   predicate  is suspended untill\n\tall mode patterns that apply to it are satisfied.\n\n\tThe implementation is realised by creating   a wrapper that uses\n\twhen/2 to realize suspension of the renamed predicate.\n\n\t@compat SICStus Prolog\n\t@compat If the predicate is blocked on multiple conditions, it\n\t\twill not unblock before _all_ conditions are satisfied.\n\t\tSICStus unblocks when one arbitrary condition is\n\t\tsatisfied.\n\t@bug\tIt is not possible to block on a dynamic predicate\n\t\tbecause we cannot wrap assert/1.  Likewise, we cannot\n\t\tblock foreign predicates, although it would be easier\n\t\tto support this.",
    "prefix":"block"
  },
  "dialect/sicstus/sicstus_lists:append/2": {
    "body": ["append(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"append('Param1','Param2')",
    "prefix":"append"
  },
  "dialect/sicstus/sicstus_lists:append/3": {
    "body": ["append(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"append('Param1','Param2','Param3')",
    "prefix":"append"
  },
  "dialect/sicstus/sicstus_lists:delete/3": {
    "body": ["delete(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"delete('Param1','Param2','Param3')",
    "prefix":"delete"
  },
  "dialect/sicstus/sicstus_lists:flatten/2": {
    "body": ["flatten(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"flatten('Param1','Param2')",
    "prefix":"flatten"
  },
  "dialect/sicstus/sicstus_lists:intersection/3": {
    "body": ["intersection(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"intersection('Param1','Param2','Param3')",
    "prefix":"intersection"
  },
  "dialect/sicstus/sicstus_lists:is_set/1": {
    "body": ["is_set(${1:'Param1'})$2\n$0" ],
    "description":"is_set('Param1')",
    "prefix":"is_set"
  },
  "dialect/sicstus/sicstus_lists:last/2": {
    "body": ["last(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"last('Param1','Param2')",
    "prefix":"last"
  },
  "dialect/sicstus/sicstus_lists:list_to_set/2": {
    "body": ["list_to_set(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"list_to_set('Param1','Param2')",
    "prefix":"list_to_set"
  },
  "dialect/sicstus/sicstus_lists:max_list/2": {
    "body": ["max_list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"max_list('Param1','Param2')",
    "prefix":"max_list"
  },
  "dialect/sicstus/sicstus_lists:max_member/2": {
    "body": ["max_member(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"max_member('Param1','Param2')",
    "prefix":"max_member"
  },
  "dialect/sicstus/sicstus_lists:member/2": {
    "body": ["member(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"member('Param1','Param2')",
    "prefix":"member"
  },
  "dialect/sicstus/sicstus_lists:min_list/2": {
    "body": ["min_list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"min_list('Param1','Param2')",
    "prefix":"min_list"
  },
  "dialect/sicstus/sicstus_lists:min_member/2": {
    "body": ["min_member(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"min_member('Param1','Param2')",
    "prefix":"min_member"
  },
  "dialect/sicstus/sicstus_lists:nextto/3": {
    "body": ["nextto(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nextto('Param1','Param2','Param3')",
    "prefix":"nextto"
  },
  "dialect/sicstus/sicstus_lists:nth/3": {
    "body": ["nth(${1:Index}, ${2:List}, ${3:Element})$4\n$0" ],
    "description":"\tnth(?Index, ?List, ?Element) is nondet.\n\n\tTrue if Element is the N-th element  in List. Counting starts at\n\t1.\n\n\t@deprecated use nth1/3.",
    "prefix":"nth"
  },
  "dialect/sicstus/sicstus_lists:nth0/3": {
    "body": ["nth0(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nth0('Param1','Param2','Param3')",
    "prefix":"nth0"
  },
  "dialect/sicstus/sicstus_lists:nth0/4": {
    "body": [
      "nth0(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"nth0('Param1','Param2','Param3','Param4')",
    "prefix":"nth0"
  },
  "dialect/sicstus/sicstus_lists:nth1/3": {
    "body": ["nth1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nth1('Param1','Param2','Param3')",
    "prefix":"nth1"
  },
  "dialect/sicstus/sicstus_lists:nth1/4": {
    "body": [
      "nth1(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"nth1('Param1','Param2','Param3','Param4')",
    "prefix":"nth1"
  },
  "dialect/sicstus/sicstus_lists:numlist/3": {
    "body": ["numlist(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"numlist('Param1','Param2','Param3')",
    "prefix":"numlist"
  },
  "dialect/sicstus/sicstus_lists:permutation/2": {
    "body": ["permutation(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"permutation('Param1','Param2')",
    "prefix":"permutation"
  },
  "dialect/sicstus/sicstus_lists:prefix/2": {
    "body": ["prefix(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"prefix('Param1','Param2')",
    "prefix":"prefix"
  },
  "dialect/sicstus/sicstus_lists:proper_length/2": {
    "body": ["proper_length(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"proper_length('Param1','Param2')",
    "prefix":"proper_length"
  },
  "dialect/sicstus/sicstus_lists:reverse/2": {
    "body": ["reverse(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"reverse('Param1','Param2')",
    "prefix":"reverse"
  },
  "dialect/sicstus/sicstus_lists:same_length/2": {
    "body": ["same_length(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"same_length('Param1','Param2')",
    "prefix":"same_length"
  },
  "dialect/sicstus/sicstus_lists:select/3": {
    "body": ["select(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"select('Param1','Param2','Param3')",
    "prefix":"select"
  },
  "dialect/sicstus/sicstus_lists:select/4": {
    "body": [
      "select(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"select('Param1','Param2','Param3','Param4')",
    "prefix":"select"
  },
  "dialect/sicstus/sicstus_lists:selectchk/3": {
    "body": ["selectchk(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"selectchk('Param1','Param2','Param3')",
    "prefix":"selectchk"
  },
  "dialect/sicstus/sicstus_lists:selectchk/4": {
    "body": [
      "selectchk(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"selectchk('Param1','Param2','Param3','Param4')",
    "prefix":"selectchk"
  },
  "dialect/sicstus/sicstus_lists:sublist/2": {
    "body": ["sublist(${1:Sub}, ${2:List})$3\n$0" ],
    "description":"\tsublist(?Sub, +List)\n\n\tTrue when all members of Sub  are   members  of List in the same\n\torder.\n\n\t@compat sicstus.  The order of generating sublists differs.\n\t@compat This predicate is known in many Prolog implementations,\n\t\tbut the semantics differ. E.g. In YAP it is a continuous\n\t\tsub-list.",
    "prefix":"sublist"
  },
  "dialect/sicstus/sicstus_lists:subset/2": {
    "body": ["subset(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"subset('Param1','Param2')",
    "prefix":"subset"
  },
  "dialect/sicstus/sicstus_lists:substitute/4": {
    "body": [
      "substitute(${1:OldElem}, ${2:List}, ${3:NewElem}, ${4:NewList})$5\n$0"
    ],
    "description":"\tsubstitute(+OldElem, +List, +NewElem, -NewList) is det.\n\n\tNewList is as List with all value that are identical (==) to OldElem\n\treplaced by NewList.",
    "prefix":"substitute"
  },
  "dialect/sicstus/sicstus_lists:subtract/3": {
    "body": ["subtract(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"subtract('Param1','Param2','Param3')",
    "prefix":"subtract"
  },
  "dialect/sicstus/sicstus_lists:sum_list/2": {
    "body": ["sum_list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sum_list('Param1','Param2')",
    "prefix":"sum_list"
  },
  "dialect/sicstus/sicstus_lists:union/3": {
    "body": ["union(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"union('Param1','Param2','Param3')",
    "prefix":"union"
  },
  "dialect/sicstus/sicstus_sockets:current_host/1": {
    "body": ["current_host(${1:Host})$2\n$0" ],
    "description":"\tcurrent_host(-Host) is det.\n\n\tTrue when Host is an atom that denotes the name of the host.\n",
    "prefix":"current_host"
  },
  "dialect/sicstus/sicstus_sockets:hostname_address/2": {
    "body": ["hostname_address(${1:Host}, ${2:Address})$3\n$0" ],
    "description":"\thostname_address(+Host:atom, -Address:atom) is det.\n\n\tTrue when Address is the IP address of Host.",
    "prefix":"hostname_address"
  },
  "dialect/sicstus/sicstus_sockets:socket/2": {
    "body": ["socket(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"socket('Param1','Param2')",
    "prefix":"socket"
  },
  "dialect/sicstus/sicstus_sockets:socket_accept/2": {
    "body": ["socket_accept(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"socket_accept('Param1','Param2')",
    "prefix":"socket_accept"
  },
  "dialect/sicstus/sicstus_sockets:socket_accept/3": {
    "body": ["socket_accept(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"socket_accept('Param1','Param2','Param3')",
    "prefix":"socket_accept"
  },
  "dialect/sicstus/sicstus_sockets:socket_bind/2": {
    "body": ["socket_bind(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"socket_bind('Param1','Param2')",
    "prefix":"socket_bind"
  },
  "dialect/sicstus/sicstus_sockets:socket_close/1": {
    "body": ["socket_close(${1:'Param1'})$2\n$0" ],
    "description":"socket_close('Param1')",
    "prefix":"socket_close"
  },
  "dialect/sicstus/sicstus_sockets:socket_connect/3": {
    "body": ["socket_connect(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"socket_connect('Param1','Param2','Param3')",
    "prefix":"socket_connect"
  },
  "dialect/sicstus/sicstus_sockets:socket_listen/2": {
    "body": ["socket_listen(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"socket_listen('Param1','Param2')",
    "prefix":"socket_listen"
  },
  "dialect/sicstus/sicstus_sockets:socket_select/5": {
    "body": [
      "socket_select(${1:TermsSockets}, ${2:NewTermsStreams}, ${3:\n%%\t\t}, ${4:Streams}, ${5:ReadStreams})$6\n$0"
    ],
    "description":"\tsocket_select(+TermsSockets, -NewTermsStreams,\n\t\t      +TimeOut, +Streams, -ReadStreams) is det.\n\n\tThe  list  of  streams  in  Streams   is  checked  for  readable\n\tcharacters. A stream can be any   stream  associated with an I/O\n\tdescriptor.  The  list  ReadStreams  returns  the  streams  with\n\treadable data. socket_select/5 also waits for connections to the\n\tsockets specified by TermsSockets.  This   argument  should be a\n\tlist of Term-Socket pairs, where Term, which can be any term, is\n\tused  as  an  identifier.   NewTermsStreams    is   a   list  of\n\tTerm-connection(Client,Stream) pairs, where  Stream   is  a  new\n\tstream open for communicating with a   process connecting to the\n\tsocket identified with Term, Client is   the client host address\n\t(see socket_accept/3). If TimeOut is   instantiated  to off, the\n\tpredicate waits until something is available.  If TimeOut is S:U\n\tthe predicate waits at most S seconds and U microseconds. Both S\n\tand U must be integers >=0. If   there is a timeout, ReadStreams\n\tand NewTermsStreams are [].",
    "prefix":"socket_select"
  },
  "dialect/sicstus/sicstus_system:datime/1": {
    "body": ["datime(${1:Datime})$2\n$0" ],
    "description":"\tdatime(-Datime) is det.\n\n\tUnifies Datime with the current  date   and  time  as a datime/6\n\trecord  of  the  form  datime(Year,Month,Day,Hour,Min,Sec).  All\n\tfields are integers.\n\n\t@compat sicstus",
    "prefix":"datime"
  },
  "dialect/sicstus/sicstus_system:datime/2": {
    "body": ["datime(${1:When}, ${2:Datime})$3\n$0" ],
    "description":"\tdatime(+When, -Datime) is det.\n\n\tTrue when Datime is a  datime/6   record  that reflects the time\n\tstamp When.\n\n\t@compat sicstus",
    "prefix":"datime"
  },
  "dialect/sicstus/sicstus_system:delete_file/1": {
    "body": ["delete_file(${1:'Param1'})$2\n$0" ],
    "description":"delete_file('Param1')",
    "prefix":"delete_file"
  },
  "dialect/sicstus/sicstus_system:environ/2": {
    "body": ["environ(${1:Name}, ${2:Value})$3\n$0" ],
    "description":"\tenviron(?Name, ?Value) is nondet.\n\n\tTrue if Value an atom associated   with the environment variable\n\tName.\n\n\t@tbd\tMode -Name is not supported",
    "prefix":"environ"
  },
  "dialect/sicstus/sicstus_system:exec/3": {
    "body": ["exec(${1:Command}, ${2:Streams}, ${3:PID})$4\n$0" ],
    "description":"\texec(+Command, +Streams, -PID)\n\n\tSICStus 3 compatible implementation of  exec/3   on  top  of the\n\tSICStus 4 compatible process_create/3.\n\n\t@bug\tThe SICStus version for Windows seems to hand Command\n\t\tdirectly to CreateProcess(). We hand it to\n\n\t\t  ==\n\t\t  %COMSPEC% /s /c \"Command\"\n\t\t  ==\n\n\t\tIn case of conflict, it is adviced to use\n\t\tprocess_create/3",
    "prefix":"exec"
  },
  "dialect/sicstus/sicstus_system:file_exists/1": {
    "body": ["file_exists(${1:FileName})$2\n$0" ],
    "description":"\tfile_exists(+FileName) is semidet.\n\n\tTrue if a file named FileName exists.\n\n\t@compat sicstus",
    "prefix":"file_exists"
  },
  "dialect/sicstus/sicstus_system:host_name/1": {
    "body": ["host_name(${1:HostName})$2\n$0" ],
    "description":"\thost_name(-HostName)\n\n\t@compat sicstus\n\t@see gethostname/1",
    "prefix":"host_name"
  },
  "dialect/sicstus/sicstus_system:make_directory/1": {
    "body": ["make_directory(${1:'Param1'})$2\n$0" ],
    "description":"make_directory('Param1')",
    "prefix":"make_directory"
  },
  "dialect/sicstus/sicstus_system:mktemp/2": {
    "body": ["mktemp(${1:Template}, ${2:File})$3\n$0" ],
    "description":"\tmktemp(+Template, -File) is det.\n\n\tInterface to the Unix function.  This emulation uses\n\ttmp_file/2 and ignores Template.\n\n\t@compat sicstus\n\t@deprecated This interface is a security-risc.  Use\n\ttmp_file_stream/3.",
    "prefix":"mktemp"
  },
  "dialect/sicstus/sicstus_system:now/1": {
    "body": ["now(${1:When})$2\n$0" ],
    "description":"\tnow(-When) is det.\n\n\tUnify when with the current time-stamp\n\n\t@compat sicstus",
    "prefix":"now"
  },
  "dialect/sicstus/sicstus_system:pid/1": {
    "body": ["pid(${1:PID})$2\n$0" ],
    "description":"\tpid(-PID)\n\n\tProcess ID of the current process.\n\n\t@compat sicstus.",
    "prefix":"pid"
  },
  "dialect/sicstus/sicstus_system:popen/3": {
    "body": ["popen(${1:Command}, ${2:Mode}, ${3:Stream})$4\n$0" ],
    "description":"\tpopen(+Command, +Mode, ?Stream)\n\n\t@compat sicstus",
    "prefix":"popen"
  },
  "dialect/sicstus/sicstus_system:rename_file/2": {
    "body": ["rename_file(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rename_file('Param1','Param2')",
    "prefix":"rename_file"
  },
  "dialect/sicstus/sicstus_system:shell/0": {"body": ["shell$1\n$0" ], "description":"shell", "prefix":"shell"},
  "dialect/sicstus/sicstus_system:shell/1": {
    "body": ["shell(${1:'Param1'})$2\n$0" ],
    "description":"shell('Param1')",
    "prefix":"shell"
  },
  "dialect/sicstus/sicstus_system:shell/2": {
    "body": ["shell(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"shell('Param1','Param2')",
    "prefix":"shell"
  },
  "dialect/sicstus/sicstus_system:sleep/1": {
    "body": ["sleep(${1:'Param1'})$2\n$0" ],
    "description":"sleep('Param1')",
    "prefix":"sleep"
  },
  "dialect/sicstus/sicstus_system:system/0": {
    "body": ["system$1\n$0" ],
    "description":"\tsystem.\n\tsystem(+Command).\n\tsystem(+Command, -Status).\n\n\tSynomyms for shell/0, shell/1 and shell/2.\n\n\t@compat sicstus.",
    "prefix":"system"
  },
  "dialect/sicstus/sicstus_system:system/1": {
    "body": ["system(${1:Command})$2\n$0" ],
    "description":"\tsystem.\n\tsystem(+Command).\n\tsystem(+Command, -Status).\n\n\tSynomyms for shell/0, shell/1 and shell/2.\n\n\t@compat sicstus.",
    "prefix":"system"
  },
  "dialect/sicstus/sicstus_system:system/2": {
    "body": ["system(${1:Command}, ${2:Status})$3\n$0" ],
    "description":"\tsystem.\n\tsystem(+Command).\n\tsystem(+Command, -Status).\n\n\tSynomyms for shell/0, shell/1 and shell/2.\n\n\t@compat sicstus.",
    "prefix":"system"
  },
  "dialect/sicstus/sicstus_system:tmpnam/1": {
    "body": ["tmpnam(${1:FileName})$2\n$0" ],
    "description":"\ttmpnam(-FileName)\n\n\tInterface to tmpnam(). This emulation uses tmp_file/2.\n\n\t@compat sicstus\n\t@deprecated This interface is a security-risc.  Use\n\ttmp_file_stream/3.",
    "prefix":"tmpnam"
  },
  "dialect/sicstus/sicstus_system:wait/2": {
    "body": ["wait(${1:PID}, ${2:Status})$3\n$0" ],
    "description":"\twait(+PID, -Status)\n\n\tWait for processes created using exec/3.\n\n\t@see exec/3",
    "prefix":"wait"
  },
  "dialect/sicstus/sicstus_system:working_directory/2": {
    "body": ["working_directory(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"working_directory('Param1','Param2')",
    "prefix":"working_directory"
  },
  "dialect/sicstus/sicstus_terms:acyclic_term/1": {
    "body": ["acyclic_term(${1:'Param1'})$2\n$0" ],
    "description":"acyclic_term('Param1')",
    "prefix":"acyclic_term"
  },
  "dialect/sicstus/sicstus_terms:cyclic_term/1": {
    "body": ["cyclic_term(${1:'Param1'})$2\n$0" ],
    "description":"cyclic_term('Param1')",
    "prefix":"cyclic_term"
  },
  "dialect/sicstus/sicstus_terms:subsumes/2": {
    "body": ["subsumes(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"subsumes('Param1','Param2')",
    "prefix":"subsumes"
  },
  "dialect/sicstus/sicstus_terms:subsumes_chk/2": {
    "body": ["subsumes_chk(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"subsumes_chk('Param1','Param2')",
    "prefix":"subsumes_chk"
  },
  "dialect/sicstus/sicstus_terms:term_factorized/3": {
    "body": [
      "term_factorized(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"term_factorized('Param1','Param2','Param3')",
    "prefix":"term_factorized"
  },
  "dialect/sicstus/sicstus_terms:term_hash/2": {
    "body": ["term_hash(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"term_hash('Param1','Param2')",
    "prefix":"term_hash"
  },
  "dialect/sicstus/sicstus_terms:term_hash/4": {
    "body": [
      "term_hash(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"term_hash('Param1','Param2','Param3','Param4')",
    "prefix":"term_hash"
  },
  "dialect/sicstus/sicstus_terms:term_size/2": {
    "body": ["term_size(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"term_size('Param1','Param2')",
    "prefix":"term_size"
  },
  "dialect/sicstus/sicstus_terms:term_subsumer/3": {
    "body": ["term_subsumer(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"term_subsumer('Param1','Param2','Param3')",
    "prefix":"term_subsumer"
  },
  "dialect/sicstus/sicstus_terms:term_variables/2": {
    "body": ["term_variables(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"term_variables('Param1','Param2')",
    "prefix":"term_variables"
  },
  "dialect/sicstus/sicstus_terms:term_variables/3": {
    "body": ["term_variables(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"term_variables('Param1','Param2','Param3')",
    "prefix":"term_variables"
  },
  "dialect/sicstus/sicstus_terms:term_variables_bag/2": {
    "body": ["term_variables_bag(${1:Term}, ${2:Variables})$3\n$0" ],
    "description":"\tterm_variables_bag(+Term, -Variables) is det.\n\n\tVariables is a list  of  variables   that  appear  in  Term. The\n\tvariables are ordered according to depth-first lef-right walking\n\tof the term. Variables contains no  duplicates. This is the same\n\tas SWI-Prolog's term_variables.",
    "prefix":"term_variables_bag"
  },
  "dialect/sicstus/sicstus_terms:variant/2": {
    "body": ["variant(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"variant('Param1','Param2')",
    "prefix":"variant"
  },
  "dialect/sicstus/timeout:time_out/3": {
    "body": ["time_out(${1:Goal}, ${2:Time_ms}, ${3:Result})$4\n$0" ],
    "description":"\ttime_out(:Goal, +Time_ms, -Result) is nondet.\n\n\tThis library provides a  SICStus   compatible  implementation of\n\ttime-outs. Unfortunately, it is not fully compatible:\n\n\t    * Time is measured in wall-time instead of virtual CPU.\n\n\tVirtual CPU time  is  hard   in  threaded-environments.  On most\n\tsystems, you probably need a thread  that measures the CPU usage\n\tof the monitored thread.",
    "prefix":"time_out"
  },
  "dialect/sicstus:bb_delete/2": {
    "body": ["bb_delete(${1:Name}, ${2:Value})$3\n$0" ],
    "description":"\tbb_put(:Name, +Value) is det.\n\tbb_get(:Name, -Value) is semidet.\n\tbb_delete(:Name, -Value) is semidet.\n\tbb_update(:Name, -Old, +New) is semidet.\n\n\tSICStus compatible blackboard routines. The implementations only\n\tdeal with cases where the module-sensitive   key  is unknown and\n\tmeta-calling. Simple cases are  directly   mapped  to SWI-Prolog\n\tnon-backtrackable global variables.",
    "prefix":"bb_delete"
  },
  "dialect/sicstus:bb_get/2": {
    "body": ["bb_get(${1:Name}, ${2:Value})$3\n$0" ],
    "description":"\tbb_put(:Name, +Value) is det.\n\tbb_get(:Name, -Value) is semidet.\n\tbb_delete(:Name, -Value) is semidet.\n\tbb_update(:Name, -Old, +New) is semidet.\n\n\tSICStus compatible blackboard routines. The implementations only\n\tdeal with cases where the module-sensitive   key  is unknown and\n\tmeta-calling. Simple cases are  directly   mapped  to SWI-Prolog\n\tnon-backtrackable global variables.",
    "prefix":"bb_get"
  },
  "dialect/sicstus:bb_put/2": {
    "body": ["bb_put(${1:Name}, ${2:Value})$3\n$0" ],
    "description":"\tbb_put(:Name, +Value) is det.\n\tbb_get(:Name, -Value) is semidet.\n\tbb_delete(:Name, -Value) is semidet.\n\tbb_update(:Name, -Old, +New) is semidet.\n\n\tSICStus compatible blackboard routines. The implementations only\n\tdeal with cases where the module-sensitive   key  is unknown and\n\tmeta-calling. Simple cases are  directly   mapped  to SWI-Prolog\n\tnon-backtrackable global variables.",
    "prefix":"bb_put"
  },
  "dialect/sicstus:bb_update/3": {
    "body": ["bb_update(${1:Name}, ${2:Old}, ${3:New})$4\n$0" ],
    "description":"\tbb_put(:Name, +Value) is det.\n\tbb_get(:Name, -Value) is semidet.\n\tbb_delete(:Name, -Value) is semidet.\n\tbb_update(:Name, -Old, +New) is semidet.\n\n\tSICStus compatible blackboard routines. The implementations only\n\tdeal with cases where the module-sensitive   key  is unknown and\n\tmeta-calling. Simple cases are  directly   mapped  to SWI-Prolog\n\tnon-backtrackable global variables.",
    "prefix":"bb_update"
  },
  "dialect/sicstus:block/1": {
    "body": ["block(${1:'Param1'})$2\n$0" ],
    "description":"block('Param1')",
    "prefix":"block"
  },
  "dialect/sicstus:create_mutable/2": {
    "body": ["create_mutable(${1:Value}, ${2:Mutable})$3\n$0" ],
    "description":"\tcreate_mutable(?Value, -Mutable) is det.\n\n\tCreate a mutable term with the given initial Value.\n\n\t@compat sicstus",
    "prefix":"create_mutable"
  },
  "dialect/sicstus:get_mutable/2": {
    "body": ["get_mutable(${1:Value}, ${2:Mutable})$3\n$0" ],
    "description":"\tget_mutable(?Value, +Mutable) is semidet.\n\n\tTrue if Value unifies with the current value of Mutable.\n\n\t@compat sicstus",
    "prefix":"get_mutable"
  },
  "dialect/sicstus:if/3": {
    "body": ["if(${1:If}, ${2:Then}, ${3:Else})$4\n$0" ],
    "description":"\tif(:If, :Then, :Else)\n\n\tSame  as  SWI-Prolog  soft-cut  construct.   Normally,  this  is\n\ttranslated using goal-expansion. If either term contains a !, we\n\tuse meta-calling for full compatibility (i.e., scoping the cut).",
    "prefix":"if"
  },
  "dialect/sicstus:prolog_flag/2": {
    "body": ["prolog_flag(${1:Flag}, ${2:Value})$3\n$0" ],
    "description":"\tprolog_flag(+Flag, -Value) is semidet.\n\n\tQuery a Prolog flag, mapping SICSTus flags to SWI-Prolog flags",
    "prefix":"prolog_flag"
  },
  "dialect/sicstus:prolog_flag/3": {
    "body": ["prolog_flag(${1:Flag}, ${2:Old}, ${3:New})$4\n$0" ],
    "description":"\tprolog_flag(+Flag, -Old, +New) is semidet.\n\n\tQuery and set a Prolog flag. Use the debug/1 topic =prolog_flag=\n\tto find the flags accessed using this predicate.",
    "prefix":"prolog_flag"
  },
  "dialect/sicstus:read_line/1": {
    "body": ["read_line(${1:Codes})$2\n$0" ],
    "description":"\tread_line(-Codes) is det.\n\tread_line(+Stream, -Codes) is det.\n\n\tRead a line from the given or  current input. The line read does\n\t_not_ include the line-termination character. Unifies Codes with\n\t=end_of_file= if the end of the input is reached.\n\n\t@compat sicstus\n\t@see\tThe SWI-Prolog primitive is read_line_to_codes/2.",
    "prefix":"read_line"
  },
  "dialect/sicstus:read_line/2": {
    "body": ["read_line(${1:Stream}, ${2:Codes})$3\n$0" ],
    "description":"\tread_line(-Codes) is det.\n\tread_line(+Stream, -Codes) is det.\n\n\tRead a line from the given or  current input. The line read does\n\t_not_ include the line-termination character. Unifies Codes with\n\t=end_of_file= if the end of the input is reached.\n\n\t@compat sicstus\n\t@see\tThe SWI-Prolog primitive is read_line_to_codes/2.",
    "prefix":"read_line"
  },
  "dialect/sicstus:trimcore/0": {
    "body": ["trimcore$1\n$0" ],
    "description":"\ttrimcore\n\n\tTrims the stacks.  Other tasks of the SICStus trimcore/0 are\n\tautomatically scheduled by SWI-Prolog.",
    "prefix":"trimcore"
  },
  "dialect/sicstus:update_mutable/2": {
    "body": ["update_mutable(${1:Value}, ${2:Mutable})$3\n$0" ],
    "description":"\tupdate_mutable(?Value, !Mutable) is det.\n\n\tSet the value of Mutable to Value.  The old binding is\n\trestored on backtracking.\n\n\t@see setarg/3.\n\t@compat sicstus",
    "prefix":"update_mutable"
  },
  "dialect/sicstus:use_module/3": {
    "body": ["use_module(${1:Module}, ${2:File}, ${3:Imports})$4\n$0" ],
    "description":"\tuse_module(+Module, -File, +Imports) is det.\n\tuse_module(-Module, +File, +Imports) is det.\n\n\tThis predicate can be used to import   from a named module while\n\tthe file-location of the module is unknown   or to get access to\n\tthe module-name loaded from a file.\n\n\tIf both Module and File are  given,   we  use  Module and try to\n\tunify File with the absolute  canonical   path  to the file from\n\twhich Module was loaded. However, we   succeed regardless of the\n\tsuccess of this unification.",
    "prefix":"use_module"
  },
  "dialect/yap:assert_static/1": {
    "body": ["assert_static(${1:Term})$2\n$0" ],
    "description":"\tassert_static(:Term)\n\n\tAssert    as    static    predicate.      SWI-Prolog    provides\n\tcompile_predicates/1 to achieve this. The   emulation  is a mere\n\talias for assert/1, as  immediate   compilation  would  prohibit\n\tfurther calls to this predicate.\n\n\t@compat yap\n\t@deprecated Use assert/1 and compile_predicates/1 after\n\tcompleting the predicate definition.",
    "prefix":"assert_static"
  },
  "dialect/yap:depth_bound_call/2": {
    "body": ["depth_bound_call(${1:Goal}, ${2:Limit})$3\n$0" ],
    "description":"\tdepth_bound_call(:Goal, :Limit)\n\n\tEquivalent to call_with_depth_limit(Goal, Limit, _Reached)\n\n\t@compat yap",
    "prefix":"depth_bound_call"
  },
  "dialect/yap:exists/1": {
    "body": ["exists(${1:File})$2\n$0" ],
    "description":"\texists(+File)\n\n\tEquivalent to exists_file(File).\n\n\t@compat yap",
    "prefix":"exists"
  },
  "dialect/yap:gc/0": {
    "body": ["gc$1\n$0" ],
    "description":"\tgc\n\n\tGarbage collect.\n\n\t@compat yap",
    "prefix":"gc"
  },
  "dialect/yap:source/0": {
    "body": ["source$1\n$0" ],
    "description":"\tsource is det.\n\n\tYAP directive to  maintain  source-information.   We  have  that\n\talways.",
    "prefix":"source"
  },
  "dialect/yap:system/1": {
    "body": ["system(${1:Command})$2\n$0" ],
    "description":"\tsystem(+Command)\n\n\tEquivalent to shell(Command).\n\n\t@compat yap",
    "prefix":"system"
  },
  "dialect/yap:yap_flag/2": {
    "body": ["yap_flag(${1:Key}, ${2:Value})$3\n$0" ],
    "description":"\tyap_flag(+Key, +Value) is det.\n\n\tMap some YAP flags to SWI-Prolog.  Supported flags:\n\n\t    * write_strings: Bool\n\t    If =on=, writes strings as \"...\" instead of a list of\n\t    integers.  In SWI-Prolog this only affects write routines\n\t    that use portray.",
    "prefix":"yap_flag"
  },
  "dialect/yap:yap_style_check/1": {
    "body": ["yap_style_check(${1:Style})$2\n$0" ],
    "description":"\tyap_style_check(+Style) is det.\n\n\tMap YAP style-check options onto the SWI-Prolog ones.",
    "prefix":"yap_style_check"
  },
  "dict_create/3": {
    "body":"dict_create(${1:Dict}, ${2:Tag}, ${3:Data})$4\n$0",
    "description":"dict_create(-Dict, +Tag, +Data).\nCreate a dict in Tag from Data. Data is  a list of attribute-value pairs using the syntax Key:Value, Key=Value, Key-Value or Key(Value).  An exception is raised if Data is not a proper list, one of  the elements is not of the shape above, a key is neither an atom nor a  small integer or there is a duplicate key.",
    "prefix":"dict_create"
  },
  "dict_pairs/3": {
    "body":"dict_pairs(${1:Dict}, ${2:Tag}, ${3:Pairs})$4\n$0",
    "description":"dict_pairs(?Dict, ?Tag, ?Pairs).\nBi-directional mapping between a dict and an ordered list of pairs (see section  A.21).",
    "prefix":"dict_pairs"
  },
  "dicts:dict_fill/4": {
    "body": ["dict_fill(${1:ValueIn}, ${2:Key}, ${3:Dict}, ${4:Value})$5\n$0" ],
    "description":"  dict_fill(+ValueIn, +Key, +Dict, -Value) is det.\n\n   Implementation for the dicts_to_same_keys/3   `OnEmpty`  closure\n   that  fills  new  cells  with  a  copy  of  ValueIn.  Note  that\n   copy_term/2 does not really copy  ground   terms.  Below are two\n   examples. Note that when filling empty   cells  with a variable,\n   each empty cell is bound to a new variable.\n\n     ==\n     ?- dicts_to_same_keys([r{x:1}, r{y:2}], dict_fill(null), L).\n     L = [r{x:1, y:null}, r{x:null, y:2}].\n     ?- dicts_to_same_keys([r{x:1}, r{y:2}], dict_fill(_), L).\n     L = [r{x:1, y:_G2005}, r{x:_G2036, y:2}].\n     ==\n\n   Use dict_no_fill/3 to raise an error if a dict is missing a key.",
    "prefix":"dict_fill"
  },
  "dicts:dict_keys/2": {
    "body": ["dict_keys(${1:Dict}, ${2:Keys})$3\n$0" ],
    "description":"  dict_keys(+Dict, -Keys) is det.\n\n   True when Keys is an ordered set of the keys appearing in Dict.",
    "prefix":"dict_keys"
  },
  "dicts:dict_no_fill/3": {
    "body": ["dict_no_fill(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"dict_no_fill('Param1','Param2','Param3')",
    "prefix":"dict_no_fill"
  },
  "dicts:dicts_join/3": {
    "body": ["dicts_join(${1:Key}, ${2:DictsIn}, ${3:Dicts})$4\n$0" ],
    "description":"  dicts_join(+Key, +DictsIn, -Dicts) is semidet.\n\n   Join dicts in Dicts that have the   same value for Key, provided\n   they do not have conflicting values on other keys.  For example:\n\n   ==\n   ?- dicts_join(x, [r{x:1, y:2}, r{x:1, z:3}, r{x:2,y:4}], L).\n   L = [r{x:1, y:2, z:3}, r{x:2, y:4}].\n   ==\n\n   @error  existence_error(key, Key, Dict) if a dict in Dicts1\n           or Dicts2 does not contain Key.",
    "prefix":"dicts_join"
  },
  "dicts:dicts_join/4": {
    "body": ["dicts_join(${1:Key}, ${2:Dicts1}, ${3:Dicts2}, ${4:Dicts})$5\n$0" ],
    "description":"  dicts_join(+Key, +Dicts1, +Dicts2, -Dicts) is semidet.\n\n   Join two lists of dicts (Dicts1 and   Dicts2)  on Key. Each pair\n   D1-D2 from Dicts1 and Dicts2 that have   the same (==) value for\n   Key creates a new dict D with the  union of the keys from D1 and\n   D2, provided D1 and D2 to not   have conflicting values for some\n   key.  For example:\n\n     ==\n     ?- DL1 = [r{x:1,y:1},r{x:2,y:4}],\n        DL2 = [r{x:1,z:2},r{x:3,z:4}],\n        dicts_join(x, DL1, DL2, DL).\n        DL = [r{x:1, y:1, z:2}, r{x:2, y:4}, r{x:3, z:4}].\n     ==\n\n   @error  existence_error(key, Key, Dict) if a dict in Dicts1\n           or Dicts2 does not contain Key.",
    "prefix":"dicts_join"
  },
  "dicts:dicts_same_keys/2": {
    "body": ["dicts_same_keys(${1:List}, ${2:Keys})$3\n$0" ],
    "description":"  dicts_same_keys(+List, -Keys) is semidet.\n\n   True if List is a list of dicts  that all have the same keys and\n   Keys is an ordered set of these keys.",
    "prefix":"dicts_same_keys"
  },
  "dicts:dicts_same_tag/2": {
    "body": ["dicts_same_tag(${1:List}, ${2:Tag})$3\n$0" ],
    "description":"  dicts_same_tag(+List, -Tag) is semidet.\n\n   True when List is a list of dicts that all have the tag Tag.",
    "prefix":"dicts_same_tag"
  },
  "dicts:dicts_slice/3": {
    "body": ["dicts_slice(${1:Keys}, ${2:DictsIn}, ${3:DictsOut})$4\n$0" ],
    "description":"  dicts_slice(+Keys, +DictsIn, -DictsOut) is det.\n\n   DictsOut is a list of Dicts only containing values for Keys.",
    "prefix":"dicts_slice"
  },
  "dicts:dicts_to_compounds/4": {
    "body": [
      "dicts_to_compounds(${1:Dicts}, ${2:Keys}, ${3:OnEmpty}, ${4:Compounds})$5\n$0"
    ],
    "description":"  dicts_to_compounds(?Dicts, +Keys, :OnEmpty, ?Compounds) is semidet.\n\n   True when Dicts and Compounds are lists   of the same length and\n   each element of Compounds is  a   compound  term whose arguments\n   represent the values associated with   the corresponding keys in\n   Keys. When converting from  dict  to   row,  OnEmpty  is used to\n   compute missing values. The functor for the compound is the same\n   as the tag of the pair. When converting from dict to row and the\n   dict has no tag, the functor `row` is used. For example:\n\n     ==\n     ?- Dicts = [_{x:1}, _{x:2, y:3}],\n        dicts_to_compounds(Dicts, [x], dict_fill(null), Compounds).\n     Compounds = [row(1), row(2)].\n     ?- Dicts = [_{x:1}, _{x:2, y:3}],\n        dicts_to_compounds(Dicts, [x,y], dict_fill(null), Compounds).\n     Compounds = [row(1, null), row(2, 3)].\n     ?- Compounds = [point(1,1), point(2,4)],\n        dicts_to_compounds(Dicts, [x,y], dict_fill(null), Compounds).\n     Dicts = [point{x:1, y:1}, point{x:2, y:4}].\n     ==\n\n   When converting from Dicts to  Compounds   Keys  may be computed by\n   dicts_same_keys/2.",
    "prefix":"dicts_to_compounds"
  },
  "dicts:dicts_to_same_keys/3": {
    "body": [
      "dicts_to_same_keys(${1:DictsIn}, ${2:OnEmpty}, ${3:DictsOut})$4\n$0"
    ],
    "description":"  dicts_to_same_keys(+DictsIn, :OnEmpty, -DictsOut)\n\n   DictsOut is a copy of DictsIn, where each dict contains all keys\n   appearing in all dicts of  DictsIn.   Values  for  keys that are\n   added to a dict are produced by   calling  OnEmpty as below. The\n   predicate dict_fill/4 provides an implementation  that fills all\n   new cells with a predefined value.\n\n     ==\n     call(:OnEmpty, +Key, +Dict, -Value)\n     ==",
    "prefix":"dicts_to_same_keys"
  },
  "dif/2": {
    "body":"dif(${1:A}, ${2:B})$3\n$0",
    "description":"dif(@A, @B).\nThe dif/2  predicate is a constraint that is true if and only if A  and B are different terms. If A and B  can never unify, dif/2  succeeds deterministically. If A and B are  identical, it fails immediately. Finally, if A and B  can unify, goals are delayed that prevent A and B  to become equal. It is this last property that makes dif/2  a more general and more declarative alternative for \\=/2  and related predicates.  This predicate behaves as if defined by dif(X, Y) :- when(?=(X,Y), X \\== Y). See also ?=/2.  The implementation can deal with cyclic terms. \n\nThe dif/2  predicate is realised using attributed variables associated with the  module dif. It is an autoloaded predicate that is defined  in the library library(dif).\n\n",
    "prefix":"dif"
  },
  "dif:dif/2": {
    "body": ["dif(${1:Term1}, ${2:Term2})$3\n$0" ],
    "description":"  dif(+Term1, +Term2) is semidet.\n\n   Constraint that expresses that  Term1   and  Term2  never become\n   identical (==/2). Fails if `Term1 ==   Term2`. Succeeds if Term1\n   can  never  become  identical  to  Term2.  In  other  cases  the\n   predicate succeeds after attaching constraints   to the relevant\n   parts of Term1 and Term2 that prevent   the  two terms to become\n   identical.",
    "prefix":"dif"
  },
  "directory_files/2": {
    "body":"directory_files(${1:Directory}, ${2:Entries})$3\n$0",
    "description":"directory_files(+Directory, -Entries).\nUnify Entries with a list of entries in Directory.  Each member of Entries is an atom denoting an entry relative  to Directory. Entries contains all entries,  including hidden files and, if supplied by the OS, the special entries .  and ... See also expand_file_name/2.129This  predicate should be considered a misnomer because it returns entries  rather than files. We stick to this name for compatibility with, e.g.,  SICStus, Ciao and YAP.",
    "prefix":"directory_files"
  },
  "divmod/4": {
    "body":"divmod(${1:Dividend}, ${2:Divisor}, ${3:Quotient}, ${4:Remainder})$5\n$0",
    "description":"divmod(+Dividend, +Divisor, -Quotient, -Remainder).\nThis predicate is a shorthand for computing both the Quotient  and Remainder of two integers in a single operation. This allows  for exploiting the fact that the low level implementation for computing  the quotient also produces the remainder. Timing confirms that this  predicate is almost twice as fast as performing the steps independently.  Semantically, divmod/4  is defined as below.  \n\ndivmod(Dividend, Divisor, Quotient, Remainder) :-\n        Quotient  is Dividend div Divisor,\n        Remainder is Dividend mod Divisor.\n\n  Note that this predicate is only available if SWI-Prolog is compiled  with unbounded integer support. This is the case for all packaged  versions.\n\n",
    "prefix":"divmod"
  },
  "doc_browser/0": {
    "body":"doc_browser$1\n$0",
    "description":"doc_browser.\nOpen the user's default browser on the running documentation server.  Fails if no server is running.",
    "prefix":"doc_browser"
  },
  "doc_browser/1": {
    "body":"doc_browser(${1:Spec})$2\n$0",
    "description":"doc_browser(+Spec).\nOpen the user's default browser on the specified page. Spec  is handled similar to edit/1,  resolving anything that relates somehow to the given specification and  ask the user to select.bugThis  flexibility is not yet implemented.",
    "prefix":"doc_browser"
  },
  "doc_collect/1": {
    "body":"doc_collect(${1:Bool})$2\n$0",
    "description":"doc_collect(+Bool).\nEnable/disable collecting structured comments into the Prolog database.  See doc_server/1  or doc_browser/0  for the normal way to deploy the server in your application. All these  predicates must be called before loading your program.",
    "prefix":"doc_collect"
  },
  "doc_files:doc_latex/3": {
    "body":"doc_latex(${1:Spec}, ${2:OutFile}, ${3:Options})$4\n$0",
    "description":"[det]doc_latex(+Spec, +OutFile, +Options).\nProcess one or more objects, writing the LaTeX output to OutFile. Spec is one of:  Name / Arity: Generate documentation for predicate\n\nName // Arity: Generate documentation for DCG rule\n\nFile: If File is a prolog file (as defined by user:prolog_file_type/2), process using latex_for_file/3, otherwise  process using latex_for_wiki_file/3.\n\n  Typically Spec is either a list of filenames or a list of  predicate indicators. Defined options are: \n\nstand_alone(+Bool): If true (default), create a document that can be run  through LaTeX. If false, produce a document to be included  in another LaTeX document.\n\npublic_only(+Bool): If true (default), only emit documentation for exported  predicates.\n\nsection_level(+Level): Outermost section level produced. Level is the name of a  LaTeX section command. Default is section.\n\nsummary(+File): Write summary declarations to the named File.\n\n ",
    "prefix":"doc_latex"
  },
  "doc_files:doc_load_library/0": {
    "body":"doc_load_library$1\n$0",
    "description":"doc_load_library.\nLoad all library files. This is intended to set up a local documentation  server. A typical scenario, making the server available at port 4000 of  the hosting machine from all locations in a domain is given below.  \n\n:- doc_server(4000,\n              [ allow('.my.org')\n              ]).\n:- use_module(library(pldoc/doc_library)).\n:- doc_load_library.\n\n  Example code can be found in $PLBASE/doc/packages/examples/pldoc.\n\n",
    "prefix":"doc_load_library"
  },
  "doc_files:doc_pack/1": {
    "body":"doc_pack(${1:Pack})$2\n$0",
    "description":"doc_pack(+Pack).\nGenerate stand-alone documentation for the package Pack. The  documentation is generated in a directory doc inside the  pack. The index page consists of the content of readme or readme.txt in the main directory of the pack and an index  of all files and their public predicates.",
    "prefix":"doc_pack"
  },
  "doc_files:doc_save/2": {
    "body":"doc_save(${1:FileOrDir}, ${2:Options})$3\n$0",
    "description":"doc_save(+FileOrDir, +Options).\nSave documentation for FileOrDir to file(s). Options  include  format(+Format): Currently only supports html.\n\ndoc_root(+Dir): Save output to the given directory. Default is to save the documentation  for a file in the same directory as the file and for a directory in a  subdirectory doc.\n\ntitle(+Title): Title is an atom that provides the HTML title of the main  (index) page. Only meaningful when generating documentation for a  directory.\n\nman_server(+RootURL): Root of a manual server used for references to built-in predicates.  Default is http://www.swi-prolog.org/pldoc/\n\nindex_file(+Base): Filename for directory indices. Default is index.\n\nif(Condition): What to do with files in a directory. loaded (default) only  documents files loaded into the Prolog image. true  documents all files.\n\nrecursive(+Bool): If true, recurse into subdirectories.\n\ncss(+Mode): If copy, copy the CSS file to created directories. Using inline,  include the CSS file into the created files. Currently, only the default copy  is supported.\n\n  The typical use-case is to document the Prolog files that belong to a  project in the current directory. To do this load the Prolog files and  run the goal below. This creates a sub-directory doc with  an index file index.html. It replicates the directory  structure of the source directory, creating an HTML file for each Prolog  file and an index file for each sub-directory. A copy of the required  CSS and image resources is copied to the doc directory. \n\n\n\n?- doc_save(., [recursive(true)]).\n\n ",
    "prefix":"doc_save"
  },
  "doc_files:latex_for_file/3": {
    "body":"latex_for_file(${1:File}, ${2:Out}, ${3:Options})$4\n$0",
    "description":"[det]latex_for_file(+File, +Out, +Options).\nGenerate a LaTeX description of all commented predicates in File, writing the LaTeX text to the stream Out.  Supports the options stand_alone, public_only  and section_level. See doc_latex/3  for a description of the options.",
    "prefix":"latex_for_file"
  },
  "doc_files:latex_for_predicates/3": {
    "body":"latex_for_predicates(${1:PI}, ${2:Out}, ${3:Options})$4\n$0",
    "description":"[det]latex_for_predicates(+PI:list, +Out, +Options).\nGenerate LaTeX for a list of predicate indicators. This does not produce the \\begin{description}...\\end{description}  environment, just a plain list of \\predicate, etc.  statements. The current implementation ignores Options.",
    "prefix":"latex_for_predicates"
  },
  "doc_files:latex_for_wiki_file/3": {
    "body":"latex_for_wiki_file(${1:File}, ${2:Out}, ${3:Options})$4\n$0",
    "description":"[det]latex_for_wiki_file(+File, +Out, +Options).\nWrite a LaTeX translation of a Wiki file to the steam Out.  Supports the options stand_alone, public_only  and section_level. See doc_latex/3  for a description of the options.",
    "prefix":"latex_for_wiki_file"
  },
  "doc_load_library/0": {
    "body":"doc_load_library$1\n$0",
    "description":"doc_load_library.\nLoad all library files. This is intended to set up a local documentation  server. A typical scenario, making the server available at port 4000 of  the hosting machine from all locations in a domain is given below.  \n\n:- doc_server(4000,\n              [ allow('.my.org')\n              ]).\n:- use_module(library(pldoc/doc_library)).\n:- doc_load_library.\n\n  Example code can be found in $PLBASE/doc/packages/examples/pldoc.\n\n",
    "prefix":"doc_load_library"
  },
  "doc_server/1": {
    "body":"doc_server(${1:Port})$2\n$0",
    "description":"doc_server(?Port).\nStart documentation server at Port. Same as doc_server(Port, [allow(localhost), workers(1)]). This  predicate must be called before loading the program for which  you consult the documentation. It calls doc_collect/1  to start collecting documentation while (re-)loading your program.",
    "prefix":"doc_server"
  },
  "doc_server/2": {
    "body":"doc_server(${1:Port}, ${2:Options})$3\n$0",
    "description":"doc_server(?Port, +Options).\nStart documentation server at Port using Options.  Provided options are:  root(+Path): Defines the root of all locations served by the HTTP server. Default is /. Path  must be an absolute URL location, starting with /  and ending in /. Intented for public services  behind a reverse proxy. See documentation of the HTTP package for  details on using reverse proxies.\n\nedit(+Bool): If false, do not allow editing, even if the connection  comes from localhost. Intended together with the root  option to make pldoc available from behind a reverse proxy. See the HTTP  package for configuring a Prolog server behind an Apache  reverse proxy.\n\nallow(+HostOrIP): Allow connections from HostOrIP. If Host is an  atom starting with a '.', suffix matching is preformed. I.e. allow('.uva.nl')  grants access to all machines in this domain. IP addresses are specified  using the library(socket) ip/4  term. I.e. to allow access from the 10.0.0.X domain, specify allow(ip(10,0,0,_)).\n\ndeny(+HostOrIP): Deny access from the given location. Matching is equal to the allow option.\n\n  Access is granted iff \n\n\n\nBoth deny and allow match\nallow exists and matches\nallow does not exist and deny does not match.\n\n",
    "prefix":"doc_server"
  },
  "double_metaphone/2": {
    "body":"double_metaphone(${1:In}, ${2:MetaPhone})$3\n$0",
    "description":"double_metaphone(+In, -MetaPhone).\nSame as double_metaphone/3,  but only returning the primary metaphone.",
    "prefix":"double_metaphone"
  },
  "double_metaphone/3": {
    "body":"double_metaphone(${1:In}, ${2:MetaPhone}, ${3:AltMetaphone})$4\n$0",
    "description":"double_metaphone(+In, -MetaPhone, -AltMetaphone).\nCreate metaphone and alternative metaphone from In. The  primary metaphone is based on english, while the secondary deals with  common alternative pronounciation in other languages. In is  either and atom, string object, code- or character list. The metaphones  are always returned as atoms.",
    "prefix":"double_metaphone"
  },
  "double_metaphone:double_metaphone/2": {
    "body": ["double_metaphone(${1:In}, ${2:MetaPhone})$3\n$0" ],
    "description":"  double_metaphone(+In, -MetaPhone) is det.\n\n   Same as double_metaphone/3,  but  only   returning  the  primary\n   metaphone.",
    "prefix":"double_metaphone"
  },
  "double_metaphone:double_metaphone/3": {
    "body": [
      "double_metaphone(${1:In}, ${2:MetaPhone}, ${3:AltMetaphone})$4\n$0"
    ],
    "description":"  double_metaphone(+In, -MetaPhone, -AltMetaphone) is det.\n\n   Create metaphone and alternative metaphone  from In. The primary\n   metaphone is based on english, while   the  secondary deals with\n   common alternative pronounciation in  other   languages.  In  is\n   either and atom, string object,  code-   or  character list. The\n   metaphones are always returned as atoms.",
    "prefix":"double_metaphone"
  },
  "downcase_atom/2": {
    "body":"downcase_atom(${1:AnyCase}, ${2:LowerCase})$3\n$0",
    "description":"downcase_atom(+AnyCase, -LowerCase).\nConverts the characters of AnyCase into lowercase as char_type/2  does (i.e. based on the defined locale if Prolog provides  locale support on the hosting platform) and unifies the lowercase atom  with LowerCase.",
    "prefix":"downcase_atom"
  },
  "draw_extend:draw_begin_shape/4": {
    "body": [
      "draw_begin_shape(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"draw_begin_shape('Param1','Param2','Param3','Param4')",
    "prefix":"draw_begin_shape"
  },
  "draw_extend:draw_end_shape/0": {
    "body": ["draw_end_shape$1\n$0" ],
    "description":"draw_end_shape",
    "prefix":"draw_end_shape"
  },
  "dtd/2": {
    "body":"dtd(${1:DocType}, ${2:DTD})$3\n$0",
    "description":"dtd(+DocType, -DTD).\nFind the DTD representing the indicated doctype. This predicate  uses a cache of DTD objects. If a doctype has no associated dtd, it  searches for a file using the file search path dtd using  the call:  \n\n...,\nabsolute_file_name(dtd(Type),\n                   [ extensions([dtd]),\n                     access(read)\n                   ], DtdFile),\n...\n\n  Note that DTD objects may be modified while processing errornous  documents. For example, loading an SGML document starting with <?xml ...?> switches the DTD to XML mode and  encountering unknown elements adds these elements to the DTD object.  Re-using a DTD object to parse multiple documents should be restricted  to situations where the documents processed are known to be error-free. \n\nThe DTD html is handled seperately. The Prolog flag html_dialect specifies the default html dialect, which is  either html4 or html5 (default).3Note  that HTML5 has no DTD. The loaded DTD is an informal DTD that includes  most of the HTML5 extensions (http://www.cs.tut.fi/~jkorpela/html5-dtd.html).  In addition, the parser sets the dialect flag of the DTD  object. This is used by the parser to accept HTML extensions.  Next, the corresponding DTD is loaded.\n\n",
    "prefix":"dtd"
  },
  "dtd_property/2": {
    "body":"dtd_property(${1:DTD}, ${2:Property})$3\n$0",
    "description":"dtd_property(+DTD, ?Property).\nThis predicate is used to examine the content of a DTD. Property is one  of:  doctype(DocType): An atom representing the document-type defined by this DTD.\n\nelements(ListOfElements): A list of atoms representing the names of the elements in this DTD.\n\nelement(Name, Omit, Content): The DTD contains an element with the given name. Omit is a  term of the format omit(OmitOpen, OmitClose), where both  arguments are booleans (true or false  representing whether the open- or close-tag may be omitted. Content  is the content-model of the element represented as a Prolog term. This  term takes the following form:  emptyThe element has no content.cdataThe element contains non-parsed character data. All data up to the  matching end-tag is included in the data (declared content).rcdataAs cdata, but entity-references are expanded.anyThe element may contain any number of any element from the DTD in any  order.#pcdataThe element contains parsed character data .element(element)n element with this name.*(SubModel)0 or more appearances.?(SubModel)0 or one appearance.+(SubModel)1 or more appearances.,(SubModel1, SubModel2)SubModel1 followed by SubModel2.&(SubModel1, SubModel2)SubModel1 and SubModel2 in any order.|(SubModel1,  SubModel2)SubModel1 or SubModel2. \n\nattributes(Element, ListOfAttributes): ListOfAttributes is a list of atoms representing the  attributes of the element Element.\n\nattribute(Element, Attribute, Type, Default): Query an element. Type is one of cdata, entity, id, idref, name, nmtoken, notation, number or nutoken. For  DTD types that allow for a list, the notation list(Type) is  used. Finally, the DTD construct (a|b|...) is mapped to the  term nameof(ListOfValues).  Default describes the sgml default. It is one required, current, conref or implied. If a  real default is present, it is one of default(Value) or fixed(Value).\n\nentities(ListOfEntities): ListOfEntities is a list of atoms representing the names of  the defined entities.\n\nentity(Name, Value): Name is the name of an entity with given value. Value is one  of  AtomIf the value is atomic, it represents the literal value of the entity.system(Url)Url is the URL of the system external entity.public(Id, Url)For external public entities, Id is the identifier. If an URL  is provided this is returned in Url. Otherwise this argument  is unbound. \n\nnotations(ListOfNotations): Returns a list holding the names of all NOTATION  declarations.\n\nnotation(Name, Decl): Unify Decl with a list if system(+File) and/or public(+PublicId).\n\n ",
    "prefix":"dtd_property"
  },
  "duplicate_term/2": {
    "body":"duplicate_term(${1:In}, ${2:Out})$3\n$0",
    "description":"duplicate_term(+In, -Out).\nVersion of copy_term/2  that also copies ground terms and therefore ensures that destructive  modification using setarg/3  does not affect the copy. See also nb_setval/2, nb_linkval/2, nb_setarg/3  and nb_linkarg/3.",
    "prefix":"duplicate_term"
  },
  "dwim_match/2": {
    "body":"dwim_match(${1:Atom1}, ${2:Atom2})$3\n$0",
    "description":"dwim_match(+Atom1, +Atom2).\nTrue if Atom1 matches Atom2 in the `Do What I  Mean' sense. Both Atom1 and Atom2 may also be  integers or floats. The two atoms match if: They are identical\nThey differ by one character (spy == spu)\nOne character is inserted/deleted (debug == deug)\nTwo characters are transposed (trace == tarce)\n`Sub-words' are glued differently (existsfile ==  existsFile == exists_file)\nTwo adjacent sub-words are transposed (existsFile ==  fileExists)\n\n",
    "prefix":"dwim_match"
  },
  "dwim_match/3": {
    "body":"dwim_match(${1:Atom1}, ${2:Atom2}, ${3:Difference})$4\n$0",
    "description":"dwim_match(+Atom1, +Atom2, -Difference).\nEquivalent to dwim_match/2,  but unifies Difference with an atom identifying the  difference between Atom1 and Atom2. The return  values are (in the same order as above): equal, mismatched_char, inserted_char, transposed_char, separated and transposed_word.",
    "prefix":"dwim_match"
  },
  "dwim_predicate/2": {
    "body":"dwim_predicate(${1:Term}, ${2:Dwim})$3\n$0",
    "description":"dwim_predicate(+Term, -Dwim).\n`Do What I Mean' (`dwim') support predicate. Term is a term,  whose name and arity are used as a predicate specification. Dwim  is instantiated with the most general term built from Name  and the arity of a defined predicate that matches the predicate  specified by Term in the `Do What I Mean' sense. See dwim_match/2  for `Do What I Mean' string matching. Internal system predicates are not  generated, unless the access level is system (see access_level).  Backtracking provides all alternative matches.",
    "prefix":"dwim_predicate"
  },
  "e/0": {
    "body":"e$1\n$0",
    "description":"e.\nEvaluate to the mathematical constant e (2.71828 ... ).",
    "prefix":"e"
  },
  "edinburgh:debug/0": {
    "body": ["debug$1\n$0" ],
    "description":"  debug is det.\n  nodebug is det.\n\n   Switch on/off debug mode.  Note that nodebug/0 has been defined\n   such that is is not traced itself.",
    "prefix":"debug"
  },
  "edinburgh:display/1": {
    "body": ["display(${1:Term})$2\n$0" ],
    "description":"  display(+Term) is det.\n  display(+Stream, +Term) is det.\n\n   Write a term, ignoring operators.\n\n   @deprecated     New code must use write_term/3 using the option\n                   ignore_ops(true).",
    "prefix":"display"
  },
  "edinburgh:display/2": {
    "body": ["display(${1:Stream}, ${2:Term})$3\n$0" ],
    "description":"  display(+Term) is det.\n  display(+Stream, +Term) is det.\n\n   Write a term, ignoring operators.\n\n   @deprecated     New code must use write_term/3 using the option\n                   ignore_ops(true).",
    "prefix":"display"
  },
  "edinburgh:fileerrors/2": {
    "body": ["fileerrors(${1:Old}, ${2:New})$3\n$0" ],
    "description":"  fileerrors(-Old, +New) is det.\n\n   Query and change the  fileerrors  flag.   Default  it  is set to\n   =true=, causing file operations to   raise an exception. Setting\n   it to =false=  activates  the  old   Edinburgh  mode  of  silent\n   failure.\n\n   @deprecated     New code should use catch/3 to handle file errors\n                   silently",
    "prefix":"fileerrors"
  },
  "edinburgh:nodebug/0": {
    "body": ["nodebug$1\n$0" ],
    "description":"  debug is det.\n  nodebug is det.\n\n   Switch on/off debug mode.  Note that nodebug/0 has been defined\n   such that is is not traced itself.",
    "prefix":"nodebug"
  },
  "edinburgh:reconsult/1": {
    "body": ["reconsult(${1:FileOrList})$2\n$0" ],
    "description":"  reconsult(+FileOrList) is det.\n\n   Load source file(s), wiping the  old content first. SWI-Prolog's\n   consult/1 and related predicates always do this.\n\n   @deprecated The Edinburgh Prolog consult/reconsult distinction\n   is no longer used throughout most of the Prolog world.",
    "prefix":"reconsult"
  },
  "edinburgh:unknown/2": {
    "body": ["unknown(${1:Old}, ${2:New})$3\n$0" ],
    "description":"  unknown(-Old, +New) is det.\n\n   Edinburgh Prolog predicate for dealing dealing with undefined\n   procedures",
    "prefix":"unknown"
  },
  "edit/0": {
    "body":"edit$1\n$0",
    "description":"edit.\nEdit the `default' file using edit/1.  The default file is the file loaded with the command line option -s  or, in Windows, the file loaded by double-clicking from the Windows  shell.",
    "prefix":"edit"
  },
  "edit/1": {
    "body":"edit(${1:Specification})$2\n$0",
    "description":"edit(+Specification).\nFirst, exploit prolog_edit:locate/3  to translate Specification into a list of Locations. If there is  more than one `hit', the user is asked to select from the locations  found. Finally, prolog_edit:edit_source/1  is used to invoke the user's preferred editor. Typically, edit/1  can be handed the name of a predicate, module, basename of a file, XPCE  class, XPCE method, etc.",
    "prefix":"edit"
  },
  "editline:el_add_history/2": {
    "body":"el_add_history(${1:In}, ${2:Line})$3\n$0",
    "description":"[det]el_add_history(+In:stream, +Line:text).\nAdd a line to the command line history.",
    "prefix":"el_add_history"
  },
  "editline:el_addfn/4": {
    "body":"el_addfn(${1:Input}, ${2:Command}, ${3:Help}, ${4:Goal})$5\n$0",
    "description":"[det]el_addfn(+Input:stream, +Command, +Help, :Goal).\nAdd a new command to the command line editor associated with Input. Command is the name of the command, Help is the  help string printed with e.g. bind -a (see el_bind/2)  and Goal is called of the associated key-binding is  activated. Goal is called as  \n\ncall(:Goal, +Input, +Char, -Continue)\n\n  where Input is the input stream providing access to the  editor, Char the activating character and Continue must be instantated  with one of the known continuation codes as defined by libedit: norm, newline, eof, arghack, refresh, refresh_beep, cursor, redisplay, error or fatal. In  addition, the following Continue code is provided. \n\nelectric(Move, TimeOut, Continue): Show electric caret at Move positions to the left of  the normal cursor positions for the given TimeOut. Continue  as defined by the Continue value.\n\n  The registered Goal typically used el_line/2  to fetch the input line and el_cursor/2, el_insertstr/2  and/or el_deletestr/2 to  manipulate the input line. \n\nNormally el_bind/2 is used to  associate the defined command with a keyboard sequence. \n\nSee also: el_set(3) EL_ADDFN for details.\n\n ",
    "prefix":"el_addfn"
  },
  "editline:el_bind/2": {
    "body":"el_bind(${1:In}, ${2:Args})$3\n$0",
    "description":"[det]el_bind(+In:stream, +Args).\nInvoke the libedit bind command with the given arguments.  The example below lists the current key bindings.  \n\n?- el_bind(user_input, ['-a']).\n\n  The predicate el_bind/2 is  typically used to bind commands defined using el_addfn/4.  Note that the C proxy function has only the last character of the  command as context to find the Prolog binding. This implies we cannot  both bind e.g., \"^[?\" *and \"?\" to a Prolog function. \n\nSee also: editrc(5) for more information.\n\n ",
    "prefix":"el_bind"
  },
  "editline:el_cursor/2": {
    "body":"el_cursor(${1:Input}, ${2:Move})$3\n$0",
    "description":"[det]el_cursor(+Input:stream, +Move:integer).\nMove the cursor Move character forwards (positive)  or backwards (negative).",
    "prefix":"el_cursor"
  },
  "editline:el_deletestr/2": {
    "body":"el_deletestr(${1:Input}, ${2:Count})$3\n$0",
    "description":"[det]el_deletestr(+Input:stream, +Count).\nDelete Count characters before the cursor.",
    "prefix":"el_deletestr"
  },
  "editline:el_history/2": {
    "body":"el_history(${1:In}, ${2:Action})$3\n$0",
    "description":"[det]el_history(+In:stream, ?Action).\nPerform a generic action on the history. This provides an incomplete  interface to history() from libedit. Supported actions are:  clear: Clear the history.\n\nsetsize(+Integer): Set size of history to size elements.\n\nsetunique(+Boolean): Set flag that adjacent identical event strings should not be entered  into the history.\n\n ",
    "prefix":"el_history"
  },
  "editline:el_history_events/2": {
    "body":"el_history_events(${1:In}, ${2:Events})$3\n$0",
    "description":"[det]el_history_events(+In:stream, -Events:list(pair)).\nUnify Events with a list of pairs of the form Num-String,  where Num is the event number and String is the  associated string without terminating newline.",
    "prefix":"el_history_events"
  },
  "editline:el_insertstr/2": {
    "body":"el_insertstr(${1:Input}, ${2:Text})$3\n$0",
    "description":"[det]el_insertstr(+Input:stream, +Text).\nInsert Text at the cursor.",
    "prefix":"el_insertstr"
  },
  "editline:el_line/2": {
    "body":"el_line(${1:Input}, ${2:Line})$3\n$0",
    "description":"[det]el_line(+Input:stream, -Line).\nFetch the currently buffered input line. Line is a term line(Before, After),  where Before is a string holding the text before the cursor  and After is a string holding the text after the cursor.",
    "prefix":"el_line"
  },
  "editline:el_read_history/2": {
    "body":"el_read_history(${1:In}, ${2:File})$3\n$0",
    "description":"[det]el_read_history(+In:stream, +File:file).\nRead the history saved using el_write_history/2. File is a file specification  for absolute_file_name/3. ",
    "prefix":"el_read_history"
  },
  "editline:el_setup/1": {
    "body":"el_setup(${1:In})$2\n$0",
    "description":"[nondet,multifile]el_setup(+In:stream).\nThis hooks is called as forall(el_setup(Input), true) after  the input stream has been wrapped, the default Prolog commands have been  added and the default user setup file has been sourced using el_source/2. It can be used to  define and bind additional commands.",
    "prefix":"el_setup"
  },
  "editline:el_source/2": {
    "body":"el_source(${1:In}, ${2:File})$3\n$0",
    "description":"[det]el_source(+In:stream, +File).\nInitialise editline by reading the contents of File. If File  is unbound try $HOME/.editrc",
    "prefix":"el_source"
  },
  "editline:el_unwrap/1": {
    "body":"el_unwrap(${1:In})$2\n$0",
    "description":"[det]el_unwrap(+In:stream).\nRemove the libedit wrapper for In and the related output and  error streams.  bug: The wrapper creates FILE* handles that cannot be closed and  thus wrapping and unwrapping implies a (modest) memory leak.\n\n ",
    "prefix":"el_unwrap"
  },
  "editline:el_wrap/4": {
    "body":"el_wrap(${1:ProgName}, ${2:In}, ${3:Out}, ${4:Error})$5\n$0",
    "description":"[det]el_wrap(+ProgName:atom, +In:stream, +Out:stream, +Error:stream).\nEnable editline on the stream-triple <In,Out,Error>.  From this moment on In is a handle to the command line  editor. ProgName is the name of the  invoking program, used when reading the editrc(5) file to  determine which settings to use. ",
    "prefix":"el_wrap"
  },
  "editline:el_wrapped/1": {
    "body":"el_wrapped(${1:In})$2\n$0",
    "description":"[semidet]el_wrapped(+In:stream).\nTrue if In is a stream wrapped by el_wrap/3.",
    "prefix":"el_wrapped"
  },
  "editline:el_write_history/2": {
    "body":"el_write_history(${1:In}, ${2:File})$3\n$0",
    "description":"[det]el_write_history(+In:stream, +File:file).\nSave editline history to File. The history may be reloaded  using el_read_history/2. File is a file specification  for absolute_file_name/3. ",
    "prefix":"el_write_history"
  },
  "emacs_extend:declare_emacs_mode/2": {
    "body": ["declare_emacs_mode(${1:ModeName}, ${2:FileSpec})$3\n$0" ],
    "description":"  declare_emacs_mode(+ModeName, +FileSpec).\n\n   Specifies that PceEmacs mode `ModeName' may be defined by\n   (auto)loading `FileSpec'.",
    "prefix":"declare_emacs_mode"
  },
  "emacs_extend:declare_emacs_mode/3": {
    "body": [
      "declare_emacs_mode(${1:ModeName}, ${2:FileSpec}, ${3:ListOfPatterns})$4\n$0"
    ],
    "description":"  declare_emacs_mode(+ModeName, +FileSpec, +ListOfPatterns)\n\n   Sames as declare_emacs_mode/2.  `ListOfPatterns' is a list of\n   regular expressions that will automatically start this mode.",
    "prefix":"declare_emacs_mode"
  },
  "emacs_tags:emacs_complete_tag/3": {
    "body": ["emacs_complete_tag(${1:Prefix}, ${2:Directory}, ${3:Goal})$4\n$0" ],
    "description":"  emacs_complete_tag(+Prefix, ?Directory, :Goal) is semidet.\n\n   Call call(Goal, Symbol) for  each  symbol   that  has  the given\n   Prefix.\n\n   @see    Used by class emacs_tag_item (defined in this file)",
    "prefix":"emacs_complete_tag"
  },
  "emacs_tags:emacs_init_tags/1": {
    "body": ["emacs_init_tags(${1:FileOrDir})$2\n$0" ],
    "description":"  emacs_init_tags(+FileOrDir) is semidet.\n\n   Load tags from the given GNU-Emacs TAGS  file. If FileOrDir is a\n   directory, see whether <dir>/TAGS exists.",
    "prefix":"emacs_init_tags"
  },
  "emacs_tags:emacs_tag/4": {
    "body": ["emacs_tag(${1:Symbol}, ${2:Dir}, ${3:File}, ${4:Line})$5\n$0" ],
    "description":"  emacs_tag(+Symbol, ?Dir, -File, -Line)\n\n   Symbol is defined in File at Line.\n\n   @param  Dir is the directory in which the tag-file resides,\n           represented as a canonical file-name.",
    "prefix":"emacs_tag"
  },
  "emacs_tags:emacs_tag_file/1": {
    "body": ["emacs_tag_file(${1:File})$2\n$0" ],
    "description":"  emacs_tag_file(?File) is nondet.\n\n   True if File is a loaded Emacs tag-file.",
    "prefix":"emacs_tag_file"
  },
  "emacs_tags:emacs_update_tags/0": {
    "body": ["emacs_update_tags$1\n$0" ],
    "description":"  emacs_update_tags is det.\n\n   Reload all modified tag-files.",
    "prefix":"emacs_update_tags"
  },
  "encoding/1": {
    "body":"encoding(${1:Encoding})$2\n$0",
    "description":"encoding(+Encoding).\nThis directive can appear anywhere in a source file to define how  characters are encoded in the remainder of the file. It can be used in  files that are encoded with a superset of US-ASCII, currently UTF-8 and  ISO Latin-1. See also section  2.18.1.",
    "prefix":"encoding"
  },
  "engine_create/3": {
    "body":"engine_create(${1:Template}, ${2:Goal}, ${3:Engine})$4\n$0",
    "description":"[det]engine_create(+Template, :Goal, ?Engine).\n",
    "prefix":"engine_create"
  },
  "engine_create/4": {
    "body":"engine_create(${1:Template}, ${2:Goal}, ${3:Engine}, ${4:Options})$5\n$0",
    "description":"[det]engine_create(+Template, :Goal, -Engine, +Options).\nCreate a new engine and unify Engine with a handle to it. Template and Goal form a pair similar to findall/3:  the instantiation of Template becomes available though engine_next/2  after Goal succeeds. Options is a list of the  following options. See thread_create/3  for details.  alias(+Name): Give the engine a name. Name must be an atom. If this option  is provided, Engine is unified with Name. The name  space for engines is shared with threads and mutexes.\n\nglobal(KBytes): Set the limit for the global stack in KBytes.\n\nlocal(KBytes): Set the limit for the local stack in KBytes.\n\ntrail(KBytes): Set the limit for the trail stack in KBytes.\n\n  The Engine argument of engine_create/3  may be instantiated to an atom, creating an engine with the given alias.",
    "prefix":"engine_create"
  },
  "engine_fetch/1": {
    "body":"engine_fetch(${1:Term})$2\n$0",
    "description":"[det]engine_fetch(-Term).\nCalled from within the engine to fetch the term made available through engine_post/2  or engine_post/3.  If no term is available an existence_error exception is raised.",
    "prefix":"engine_fetch"
  },
  "engine_next/2": {
    "body":"engine_next(${1:Engine}, ${2:Term})$3\n$0",
    "description":"[semidet]engine_next(+Engine, -Term).\nAsk the engine Engine to produce a next answer. On this first  call on a specific engine, the Goal of the engine is started.  If a previous call returned an answer through completion, this causes  the engine to backtrack and finally, if the engine produces a previous  result using engine_yield/1,  execution proceeds after the engine_yield/1  call.",
    "prefix":"engine_next"
  },
  "engine_next_reified/2": {
    "body":"engine_next_reified(${1:Engine}, ${2:Term})$3\n$0",
    "description":"[det]engine_next_reified(+Engine, -Term).\nSimilar to engine_next/2,  but instead of success, failure or or raising an exception, Term  is unified with one of terms below. This predicate is provided primarily  for compatibility with LeanProlog.  the(Answer): Goal succeeded with Template bound to Answer or  Goal yielded with a term Answer.\n\nno: Goal failed.\n\nexception(Exception): Goal raises the error Exception.\n\n ",
    "prefix":"engine_next_reified"
  },
  "engine_post/2": {
    "body":"engine_post(${1:Engine}, ${2:Term})$3\n$0",
    "description":"[det]engine_post(+Engine, +Term).\nMake Term available to engine_fetch/1  inside the Engine. This call must be followed by a call to engine_next/2  and the engine must call engine_fetch/1.",
    "prefix":"engine_post"
  },
  "engine_post/3": {
    "body":"engine_post(${1:Engine}, ${2:Term}, ${3:Reply})$4\n$0",
    "description":"[det]engine_post(+Engine, +Term, -Reply).\nCombines engine_post/2  and engine_next/2.",
    "prefix":"engine_post"
  },
  "engine_self/1": {
    "body":"engine_self(${1:Engine})$2\n$0",
    "description":"[det]engine_self(-Engine).\nCalled from within the engine to get access to the handle to the engine  itself.",
    "prefix":"engine_self"
  },
  "engine_yield/1": {
    "body":"engine_yield(${1:Term})$2\n$0",
    "description":"[det]engine_yield(+Term).\nCalled from within the engine, causing engine_next/2  in the caller to return with Term. A subsequent call to engine_next/2  causes engine_yield/1  to `return'. This predicate can only be called if the engine is not  involved in a callback from C, i.e., when the engine calls a predicate  defined in C that calls back Prolog it is not possible to use this  predicate. Trying to do so results in a permission_error exception.",
    "prefix":"engine_yield"
  },
  "ensure_loaded/1": {
    "body":"ensure_loaded(${1:File})$2\n$0",
    "description":"ensure_loaded(:File).\nIf the file is not already loaded, this is equivalent to consult/1.  Otherwise, if the file defines a module, import all public predicates.  Finally, if the file is already loaded, is not a module file, and the  context module is not the global user module, ensure_loaded/1  will call consult/1.  With this semantics, we hope to get as close as possible to the clear  semantics without the presence of a module system. Applications using  modules should consider using use_module/[1,2]. \n\nEquivalent to load_files(Files, [if(not_loaded)]).44On  older versions the condition used to be if(changed). Poor  time management on some machines or copying often caused problems. The make/0  predicate deals with updating the running system after changing the  source code.\n\n",
    "prefix":"ensure_loaded"
  },
  "epsilon/0": {
    "body":"epsilon$1\n$0",
    "description":"epsilon.\nEvaluate to the difference between the float 1.0 and the first larger  floating point number.",
    "prefix":"epsilon"
  },
  "erase/1": {
    "body":"erase(${1:Reference})$2\n$0",
    "description":"erase(+Reference).\nErase a record or clause from the database. Reference is a  db-reference returned by recorda/3, recordz/3  or recorded/3, clause/3, assert/2, asserta/2  or assertz/2.  Fail silently if the referenced object no longer exists. Notably, if  multiple threads attempt to erase the same clause one will succeed and  the others will fail.",
    "prefix":"erase"
  },
  "erf/1": {
    "body":"erf(${1:Expr})$2\n$0",
    "description":"erf(+Expr).\nhttp://en.wikipedia.org/wiki/Error_functionWikipediA: ``In mathematics,  the error function (also called the Gauss error function) is a special  function (non-elementary) of sigmoid shape which occurs in probability,  statistics and partial differential equations.''",
    "prefix":"erf"
  },
  "erfc/1": {
    "body":"erfc(${1:Expr})$2\n$0",
    "description":"erfc(+Expr).\nhttp://en.wikipedia.org/wiki/Error_functionWikipediA: ``The  complementary error function.''",
    "prefix":"erfc"
  },
  "error:current_type/3": {
    "body":"current_type(${1:Type}, ${2:Var}, ${3:Body})$4\n$0",
    "description":"[nondet]current_type(?Type, @Var, -Body).\nTrue when Type is a currently defined type and Var  satisfies Type of the body term Body succeeds.",
    "prefix":"current_type"
  },
  "error:domain_error/2": {
    "body":"domain_error(${1:Type}, ${2:Term})$3\n$0",
    "description":"domain_error(+Type, +Term).\nThe argument is of the proper type, but has a value that is outside the  supported values. See type_error/2  for a more elaborate discussion of the distinction between type- and  domain-errors.",
    "prefix":"domain_error"
  },
  "error:existence_error/2": {
    "body":"existence_error(${1:Type}, ${2:Term})$3\n$0",
    "description":"existence_error(+Type, +Term).\nTerm is of the correct type and correct domain, but there is  no existing (external) resource that is represented by it.",
    "prefix":"existence_error"
  },
  "error:has_type/2": {
    "body":"has_type(${1:Type}, ${2:Term})$3\n$0",
    "description":"[semidet,multifile]has_type(+Type, @Term).\nTrue if Term satisfies Type.",
    "prefix":"has_type"
  },
  "error:instantiation_error/1": {
    "body":"instantiation_error(${1:Term})$2\n$0",
    "description":"instantiation_error(+Term).\nAn argument is under-instantiated. I.e. it is not acceptable as it is,  but if some variables are bound to appropriate values it would be  acceptable. Term is the term that needs  (further) instantiation. Unfortunately, the ISO error does not allow for  passing this term along with the error, but we pass it to this predicate  for documentation purposes and to allow for future enhancement. ",
    "prefix":"instantiation_error"
  },
  "error:is_of_type/2": {
    "body":"is_of_type(${1:Type}, ${2:Term})$3\n$0",
    "description":"[semidet]is_of_type(+Type, @Term).\nTrue if Term satisfies Type.",
    "prefix":"is_of_type"
  },
  "error:must_be/2": {
    "body":"must_be(${1:Type}, ${2:Term})$3\n$0",
    "description":"[det]must_be(+Type, @Term).\nTrue if Term satisfies the type constraints for Type.  Defined types are atom, atomic, between, boolean, callable, chars, codes, text, compound, constant, float, integer, nonneg, positive_integer, negative_integer, nonvar, number, oneof, list, list_or_partial_list, symbol, var, rational, encoding, dict  and string.  Most of these types are defined by an arity-1 built-in predicate of  the same name. Below is a brief definition of the other types.\n\nbooleanone of true or false charAtom of length 1 codeRepresentation Unicode code point charsProper list of 1-character atoms codesProper list of Unicode character  codes textOne of atom, string, chars  or codes between(IntL,IntU) Integer  [IntL..IntU] between(FloatL,FloatU) Number  [FloatL..FloatU] nonnegInteger >= 0 positive_integerInteger > 0 negative_integerInteger < 0 oneof(L) Ground term that is  member of L encodingValid name for a character  encoding cyclicCyclic term (rational tree) acyclicAcyclic term (tree) list(Type) Proper list with  elements of Type list_or_partial_listA list or an open list  (ending in a variable   Note: The Windows version can only represent Unicode code points up  to 2^16-1. Higher values cause a representation error on  most text handling predicates. \n\nthrows: instantiation_error if Term is insufficiently instantiated  and type_error(Type, Term) if Term is not of Type.\n\n ",
    "prefix":"must_be"
  },
  "error:permission_error/3": {
    "body":"permission_error(${1:Action}, ${2:Type}, ${3:Term})$4\n$0",
    "description":"permission_error(+Action, +Type, +Term).\nIt is not allowed to perform Action on the object Term  that is of the given Type.",
    "prefix":"permission_error"
  },
  "error:representation_error/1": {
    "body":"representation_error(${1:Reason})$2\n$0",
    "description":"representation_error(+Reason).\nA representation error indicates a limitation of the implementation.  SWI-Prolog has no such limits that are not covered by other errors, but  an example of a representation error in another Prolog implementation  could be an attempt to create a term with an arity higher than supported  by the system.",
    "prefix":"representation_error"
  },
  "error:resource_error/1": {
    "body":"resource_error(${1:Culprit})$2\n$0",
    "description":"resource_error(+Culprit).\nA goal cannot be completed due to lack of resources.",
    "prefix":"resource_error"
  },
  "error:syntax_error/1": {
    "body":"syntax_error(${1:Culprit})$2\n$0",
    "description":"syntax_error(+Culprit).\nA text has invalid syntax. The error is described by Culprit.  To be done: Deal with proper description of the location of the error. For short  texts, we allow for Type(Text), meaning Text is not a valid Type. E.g. syntax_error(number('1a'))  means that 1a is not a valid number.\n\n ",
    "prefix":"syntax_error"
  },
  "error:type_error/2": {
    "body":"type_error(${1:Type}, ${2:Term})$3\n$0",
    "description":"type_error(+Type, +Term).\nTell the user that Term is not of the expected Type.  This error is closely related to domain_error/2  because the notion of types is not really set in stone in Prolog. We  introduce the difference using a simple example.  Suppose an argument must be a non-negative integer. If the actual  argument is not an integer, this is a type_error. If it is a  negative integer, it is a domain_error. \n\nTypical borderline cases are predicates accepting a compound term,  e.g., point(X,Y). One could argue that the basic type is a  compound-term and any other compound term is a domain error. Most Prolog  programmers consider each compound as a type and would consider a  compoint that is not point(_,_) a type_error.\n\n",
    "prefix":"type_error"
  },
  "error:uninstantiation_error/1": {
    "body":"uninstantiation_error(${1:Term})$2\n$0",
    "description":"uninstantiation_error(+Term).\nAn argument is over-instantiated. This error is used for output  arguments whose value cannot be known upfront. For example, the goal open(File, read, input)  cannot succeed because the system will allocate a new unique stream  handle that will never unify with input.",
    "prefix":"uninstantiation_error"
  },
  "eval/1": {
    "body":"eval(${1:Expr})$2\n$0",
    "description":"eval(+Expr).\nEvaluate Expr. Although ISO standard dictates that `A=1+2, B  is A' works and unifies B to 3, it is widely felt  that source level variables in arithmetic expressions should have been  limited to numbers. In this view the eval function can be used to  evaluate arbitrary expressions.109The eval/1  function was first introduced by ECLiPSe and is under consideration for  YAP.",
    "prefix":"eval"
  },
  "exception/3": {
    "body":"exception(${1:Exception}, ${2:Context}, ${3:Action})$4\n$0",
    "description":"exception(+Exception, +Context, -Action).\nDynamic predicate, normally not defined. Called by the Prolog system on  run-time exceptions that can be repaired `just-in-time'. The values for Exception  are described below. See also catch/3  and throw/1.  If this hook predicate succeeds it must instantiate the Action  argument to the atom fail to make the operation fail  silently, retry to tell Prolog to retry the operation or error  to make the system generate an exception. The action retry  only makes sense if this hook modified the environment such that the  operation can now succeed without error. \n\nundefined_predicate: Context is instantiated to a predicate indicator ([module]:<name>/<arity>).  If the predicate fails, Prolog will generate an existence_error  exception. The hook is intended to implement alternatives to the  built-in autoloader, such as autoloading code from a database. Do not  use this hook to suppress existence errors on predicates. See also unknown  and section 2.13.\n\nundefined_global_variable: Context is instantiated to the name of the missing global  variable. The hook must call nb_setval/2  or b_setval/2  before returning with the action retry.\n\n ",
    "prefix":"exception"
  },
  "exists_directory/1": {
    "body":"exists_directory(${1:Directory})$2\n$0",
    "description":"exists_directory(+Directory).\nTrue if Directory exists and is a directory. This does not  imply the user has read, search or write permission for the directory.",
    "prefix":"exists_directory"
  },
  "exists_file/1": {
    "body":"exists_file(${1:File})$2\n$0",
    "description":"exists_file(+File).\nTrue if File exists and is a regular file. This does not  imply the user has read and/or write permission for the file. This is  the same as access_file(File, exist).",
    "prefix":"exists_file"
  },
  "exists_source/1": {
    "body":"exists_source(${1:Spec})$2\n$0",
    "description":"exists_source(+Spec).\nIs true if Spec exists as a Prolog source. Spec  uses the same conventions as load_files/2.  Fails without error if Spec cannot be found.",
    "prefix":"exists_source"
  },
  "exp/1": {
    "body":"exp(${1:Expr})$2\n$0",
    "description":"[ISO]exp(+Expr).\nResult = e **Expr",
    "prefix":"exp"
  },
  "expand_answer/2": {
    "body":"expand_answer(${1:Bindings}, ${2:ExpandedBindings})$3\n$0",
    "description":"expand_answer(+Bindings, -ExpandedBindings).\nHook in module user, normally not defined. Expand the  result of a successfully executed top-level query. Bindings  is the query <Name>=<Value> binding list from the  query. ExpandedBindings must be unified with the bindings the  top level should print.",
    "prefix":"expand_answer"
  },
  "expand_file_name/2": {
    "body":"expand_file_name(${1:WildCard}, ${2:List})$3\n$0",
    "description":"expand_file_name(+WildCard, -List).\nUnify List with a sorted list of files or directories  matching WildCard. The normal Unix wildcard constructs `?',  `*', `[ ... ]' and `{...}'  are recognised. The interpretation of `{...}' is slightly  different from the C shell (csh(1)). The comma-separated argument can be  arbitrary patterns, including `{...}' patterns. The empty  pattern is legal as well: `{.pl,}' matches either `.pl'  or the empty string.  If the pattern contains wildcard characters, only existing files and  directories are returned. Expanding a `pattern' without wildcard  characters returns the argument, regardless of whether or not it exists. \n\nBefore expanding wildcards, the construct $var  is expanded to the value of the environment variable var, and  a possible leading ~ character is expanded to the user's  home directory.130On Windows, the  home directory is determined as follows: if the environment variable HOME  exists, this is used. If the variables HOMEDRIVE and HOMEPATH  exist (Windows-NT), these are used. At initialisation, the system will  set the environment variable HOME to point to the  SWI-Prolog home directory if neither HOME nor HOMEPATH  and HOMEDRIVE are defined.\n\n",
    "prefix":"expand_file_name"
  },
  "expand_file_search_path/2": {
    "body":"expand_file_search_path(${1:Spec}, ${2:Path})$3\n$0",
    "description":"[nondet]expand_file_search_path(+Spec, -Path).\nUnifies Path with all possible expansions of the filename  specification Spec. See also absolute_file_name/3.",
    "prefix":"expand_file_search_path"
  },
  "expand_goal/2": {
    "body":"expand_goal(${1:Goal1}, ${2:Goal2})$3\n$0",
    "description":"expand_goal(+Goal1, -Goal2).\nThis predicate is normally called by the compiler to perform  preprocessing using goal_expansion/2.  The predicate computes a fixed-point by applying transformations until  there are no more changes. If optimisation is enabled (see -O  and optimise), expand_goal/2  simplifies the result by removing unneeded calls to true/0  and fail/0  as well as unreachable branches.",
    "prefix":"expand_goal"
  },
  "expand_goal/4": {
    "body":"expand_goal(${1:Goal1}, ${2:Layout1}, ${3:Goal2}, ${4:Layout2})$5\n$0",
    "description":"expand_goal(+Goal1, ?Layout1, -Goal2, -Layout2).\n",
    "prefix":"expand_goal"
  },
  "expand_query/4": {
    "body":"expand_query(${1:Query}, ${2:Expanded}, ${3:Bindings}, ${4:ExpandedBindings})$5\n$0",
    "description":"expand_query(+Query, -Expanded, +Bindings, -ExpandedBindings).\nHook in module user, normally not defined. Query  and Bindings represents the query read from the user and the  names of the free variables as obtained using read_term/3.  If this predicate succeeds, it should bind Expanded and ExpandedBindings  to the query and bindings to be executed by the top level. This  predicate is used by the top level (prolog/0).  See also expand_answer/2  and term_expansion/2.",
    "prefix":"expand_query"
  },
  "expand_term/2": {
    "body":"expand_term(${1:Term1}, ${2:Term2})$3\n$0",
    "description":"expand_term(+Term1, -Term2).\nThis predicate is normally called by the compiler on terms read from the  input to perform preprocessing. It consists of four steps, where each  step processes the output of the previous step.  \n\nTest conditional compilation directives and translate all input to []  if we are in a `false branch' of the conditional compilation. See section  4.3.1.2.  \nCall term_expansion/2.  This predicate is first tried in the module that is being compiled and  then in the module user.  \nCall DCG expansion (dcg_translate_rule/2).  \nCall expand_goal/2  on each body term that appears in the output of the previous steps.\n\n",
    "prefix":"expand_term"
  },
  "expand_term/4": {
    "body":"expand_term(${1:Term1}, ${2:Layout1}, ${3:Term2}, ${4:Layout2})$5\n$0",
    "description":"expand_term(+Term1, ?Layout1, -Term2, -Layout2).\n",
    "prefix":"expand_term"
  },
  "explain/1": {
    "body":"explain(${1:ToExplain})$2\n$0",
    "description":"explain(+ToExplain).\nGive an explanation on the given `object'. The argument may be any  Prolog data object. If the argument is an atom, a term of the form Name/Arity or a term of the form Module:Name/Arity, explain/1  describes the predicate as well as possible references to it. See also gxref/0.",
    "prefix":"explain"
  },
  "explain/2": {
    "body":"explain(${1:ToExplain}, ${2:Explanation})$3\n$0",
    "description":"explain(+ToExplain, -Explanation).\nUnify Explanation with an explanation for ToExplain.  Backtracking yields further explanations.",
    "prefix":"explain"
  },
  "export/2": {
    "body":"export(${1:PredicateIndicator}, ${2:...})$3\n$0",
    "description":"export(+PredicateIndicator, ...).\nAdd predicates to the public list of the context module. This implies  the predicate will be imported into another module if this module is  imported with use_module/[1,2].  Note that predicates are normally exported using the directive module/2. export/1  is meant to handle export from dynamically created modules.",
    "prefix":"export"
  },
  "fast_read/2": {
    "body":"fast_read(${1:Input}, ${2:Term})$3\n$0",
    "description":"fast_read(+Input, -Term).\nRead Term using the fast serialization format from the Input stream. Input must be a binary  stream.bugThe predicate fast_read/2  may crash on arbitrary input.",
    "prefix":"fast_read"
  },
  "fast_term_serialized/2": {
    "body":"fast_term_serialized(${1:Term}, ${2:String})$3\n$0",
    "description":"fast_term_serialized(?Term, ?String).\n(De-)serialize Term to/from String.",
    "prefix":"fast_term_serialized"
  },
  "fast_write/2": {
    "body":"fast_write(${1:Output}, ${2:Term})$3\n$0",
    "description":"fast_write(+Output, +Term).\nWrite Term using the fast serialization format to the Output stream. Output must be a binary  stream.",
    "prefix":"fast_write"
  },
  "fastrw:fast_read/1": {
    "body": ["fast_read(${1:Term})$2\n$0" ],
    "description":"  fast_read(-Term)\n\n   The next term is read from current standard input and is unified\n   with Term. The syntax of the term   must  agree with fast_read /\n   fast_write format. If the end  of   the  input has been reached,\n   Term is unified with the term =end_of_file=.",
    "prefix":"fast_read"
  },
  "fastrw:fast_read/2": {
    "body": ["fast_read(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"fast_read('Param1','Param2')",
    "prefix":"fast_read"
  },
  "fastrw:fast_write/1": {
    "body": ["fast_write(${1:Term})$2\n$0" ],
    "description":"  fast_write(+Term)\n\n   Output Term in a way that   fast_read/1  and fast_read/2 will be\n   able to read it back.",
    "prefix":"fast_write"
  },
  "fastrw:fast_write/2": {
    "body": ["fast_write(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"fast_write('Param1','Param2')",
    "prefix":"fast_write"
  },
  "fastrw:fast_write_to_string/3": {
    "body": ["fast_write_to_string(${1:Term}, ${2:String}, ${3:Tail})$4\n$0" ],
    "description":"  fast_write_to_string(+Term, -String, ?Tail)\n\n   Perform a fast-write to the difference-slist String\\Tail.",
    "prefix":"fast_write_to_string"
  },
  "file_base_name/2": {
    "body":"file_base_name(${1:File}, ${2:BaseName})$3\n$0",
    "description":"file_base_name(+File, -BaseName).\nExtracts the filename part from a path specification. If File  does not contain any directory separators, File is returned  in BaseName. See also file_directory_name/2.  If the File arguments ends with a /,  e.g., '/hello/', BaseName is unified with the  empty atom ('').",
    "prefix":"file_base_name"
  },
  "file_directory_name/2": {
    "body":"file_directory_name(${1:File}, ${2:Directory})$3\n$0",
    "description":"file_directory_name(+File, -Directory).\nExtracts the directory part of File. The returned Directory  name does not end in /. There are two special  cases. The directory name of / is /  itself, and the directory name is . if File  does not contain any / characters. If the File  argument ends with a /, e.g., '/hello/',  it is not a valid file name. In this case the final /  is removed from File, e.g., '/hello'.  See also directory_file_path/3  from library(filesex). The system ensures that for every  valid Path using the Prolog (POSIX) directory separators,  following is true on systems with a sound implementation of same_file/2.127On  some systems, Path and Path2 refer to the same  entry in the file system, but same_file/2  may fail. See also prolog_to_os_filename/2. \n\n\n\n        ...,\n        file_directory_name(Path, Dir),\n        file_base_name(Path, File),\n        directory_file_path(Dir, File, Path2),\n        same_file(Path, Path2).\n\n ",
    "prefix":"file_directory_name"
  },
  "file_name_extension/3": {
    "body":"file_name_extension(${1:Base}, ${2:Extension}, ${3:Name})$4\n$0",
    "description":"file_name_extension(?Base, ?Extension, ?Name).\nThis predicate is used to add, remove or test filename extensions. The  main reason for its introduction is to deal with different filename  properties in a portable manner. If the file system is case-insensitive,  testing for an extension will also be done case-insensitive. Extension  may be specified with or without a leading dot (.).  If an Extension is generated, it will not have a leading dot.",
    "prefix":"file_name_extension"
  },
  "file_search_path/2": {
    "body":"file_search_path(${1:Alias}, ${2:Path})$3\n$0",
    "description":"file_search_path(+Alias, -Path).\nDynamic multifile hook predicate used to specify `path aliases'. This  hook is called by absolute_file_name/3  to search files specified as Alias(Name), e.g., library(lists). This  feature is best described using an example. Given the definition:  \n\nfile_search_path(demo, '/usr/lib/prolog/demo').\n\n  the file specification demo(myfile) will be expanded to /usr/lib/prolog/demo/myfile. The second argument of file_search_path/2  may be another alias. \n\nBelow is the initial definition of the file search path. This path  implies swi(<Path>) and refers to a file  in the SWI-Prolog home directory. The alias foreign(<Path>)  is intended for storing shared libraries (.so or .DLL  files). See also use_foreign_library/1. \n\n\n\nuser:file_search_path(library, X) :-\n        library_directory(X).\nuser:file_search_path(swi, Home) :-\n        current_prolog_flag(home, Home).\nuser:file_search_path(foreign, swi(ArchLib)) :-\n        current_prolog_flag(arch, Arch),\n        atom_concat('lib/', Arch, ArchLib).\nuser:file_search_path(foreign, swi(lib)).\nuser:file_search_path(path, Dir) :-\n        getenv('PATH', Path),\n        (   current_prolog_flag(windows, true)\n        ->  atomic_list_concat(Dirs, (;), Path)\n        ;   atomic_list_concat(Dirs, :, Path)\n        ),\n        member(Dir, Dirs).\n\n  The file_search_path/2  expansion is used by all loading predicates as well as by absolute_file_name/[2,3]. \n\nThe Prolog flag verbose_file_search  can be set to true to help debugging Prolog's search for  files.\n\n",
    "prefix":"file_search_path"
  },
  "files:can_open_file/2": {
    "body": ["can_open_file(${1:Path}, ${2:Mode})$3\n$0" ],
    "description":"  can_open_file(+Path, +Mode)\n\n   Succeeds if the user has access to `File' in mode `Mode'.  Fails\n   silently if this is not the  case.   `Mode'  is  one  of  {read,\n   write, both}.  This used to be difficult.  Since we have\n   access_file/2 it is merely a Quintus compatibility predicate\n   and should be in quintus.pl.  We will leave it here for compatibility\n   reasons.\n\n   @deprecated Use access_file/2.",
    "prefix":"can_open_file"
  },
  "files:chdir/1": {
    "body": ["chdir(${1:Dir})$2\n$0" ],
    "description":"  chdir(+Dir) is det.\n\n   Change Working Directory.\n\n   @deprecated     Use using working_directory/2.",
    "prefix":"chdir"
  },
  "files_ex:copy_directory/2": {
    "body": ["copy_directory(${1:From}, ${2:To})$3\n$0" ],
    "description":"  copy_directory(+From, +To) is det.\n\n   Copy the contents of the directory  From to To (recursively). If\n   To is the name of an existing  directory, the _contents_ of From\n   are copied into To. I.e., no  subdirectory using the basename of\n   From is created.",
    "prefix":"copy_directory"
  },
  "files_ex:copy_file/2": {
    "body": ["copy_file(${1:From}, ${2:To})$3\n$0" ],
    "description":"  copy_file(From, To) is det.\n\n   Copy a file into a new file or  directory. The data is copied as\n   binary data.",
    "prefix":"copy_file"
  },
  "files_ex:delete_directory_and_contents/1": {
    "body": ["delete_directory_and_contents(${1:Dir})$2\n$0" ],
    "description":"  delete_directory_and_contents(+Dir) is det.\n\n   Recursively remove the directory Dir and its contents. If Dir is\n   a symbolic link or symbolic links   inside  Dir are encountered,\n   the links are removed rather than their content. Use with care!",
    "prefix":"delete_directory_and_contents"
  },
  "files_ex:delete_directory_contents/1": {
    "body": ["delete_directory_contents(${1:Dir})$2\n$0" ],
    "description":"  delete_directory_contents(+Dir) is det.\n\n   Remove all content from  directory   Dir,  without  removing Dir\n   itself. Similar to delete_directory_and_contents/2,  if symbolic\n   links are encountered in Dir, the  links are removed rather than\n   their content.",
    "prefix":"delete_directory_contents"
  },
  "files_ex:directory_file_path/3": {
    "body": ["directory_file_path(${1:Directory}, ${2:File}, ${3:Path})$4\n$0" ],
    "description":"  directory_file_path(+Directory, +File, -Path) is det.\n  directory_file_path(?Directory, ?File, +Path) is det.\n\n   True when Path is the full path-name   for  File in Dir. This is\n   comparable to atom_concat(Directory, File, Path), but it ensures\n   there is exactly one / between the two parts.  Notes:\n\n     * In mode (+,+,-), if File is given and absolute, Path\n     is unified to File.\n     * Mode (-,-,+) uses file_directory_name/2 and file_base_name/2",
    "prefix":"directory_file_path"
  },
  "files_ex:link_file/3": {
    "body": ["link_file(${1:OldPath}, ${2:NewPath}, ${3:Type})$4\n$0" ],
    "description":"  link_file(+OldPath, +NewPath, +Type) is det.\n\n   Create a link in the filesystem   from  NewPath to OldPath. Type\n   defines the type of link and is one of =hard= or =symbolic=.\n\n   With some limitations, these  functions   also  work on Windows.\n   First of all, the unerlying filesystem  must support links. This\n   requires NTFS. Second, symbolic  links   are  only  supported in\n   Vista and later.\n\n   @error  domain_error(link_type, Type) if the requested link-type\n           is unknown or not supported on the target OS.",
    "prefix":"link_file"
  },
  "files_ex:make_directory_path/1": {
    "body": ["make_directory_path(${1:Dir})$2\n$0" ],
    "description":"  make_directory_path(+Dir) is det.\n\n   Create Dir and all required  components   (like  mkdir  -p). Can\n   raise various file-specific exceptions.",
    "prefix":"make_directory_path"
  },
  "files_ex:relative_file_name/3": {
    "body": ["relative_file_name(${1:Path}, ${2:RelTo}, ${3:RelPath})$4\n$0" ],
    "description":"  relative_file_name(+Path:atom, +RelTo:atom, -RelPath:atom) is det.\n  relative_file_name(-Path:atom, +RelTo:atom, +RelPath:atom) is det.\n\n   True when RelPath is Path, relative to RelTo. Path and RelTo are\n   first handed to absolute_file_name/2, which   makes the absolute\n   *and* canonical. Below are two examples:\n\n   ==\n   ?- relative_file_name('/home/janw/nice',\n                         '/home/janw/deep/dir/file', Path).\n   Path = '../../nice'.\n\n   ?- relative_file_name(Path, '/home/janw/deep/dir/file', '../../nice').\n   Path = '/home/janw/nice'.\n   ==\n\n   @param  All paths must be in canonical POSIX notation, i.e.,\n           using / to separate segments in the path.  See\n           prolog_to_os_filename/2.\n   @bug    This predicate is defined as a _syntactical_ operation.",
    "prefix":"relative_file_name"
  },
  "files_ex:set_time_file/3": {
    "body": ["set_time_file(${1:File}, ${2:OldTimes}, ${3:NewTimes})$4\n$0" ],
    "description":"  set_time_file(+File, -OldTimes, +NewTimes) is det.\n\n   Query and set POSIX time attributes of a file. Both OldTimes and\n   NewTimes are lists of  option-terms.   Times  are represented in\n   SWI-Prolog's standard floating point numbers.   New times may be\n   specified as =now= to indicate the current time. Defined options\n   are:\n\n       * access(Time)\n       Describes the time of last access   of  the file. This value\n       can be read and written.\n\n       * modified(Time)\n       Describes the time  the  contents  of   the  file  was  last\n       modified. This value can be read and written.\n\n       * changed(Time)\n       Describes the time the file-structure  itself was changed by\n       adding (link()) or removing (unlink()) names.\n\n   Below  are  some  example  queries.   The  first  retrieves  the\n   access-time, while the second sets the last-modified time to the\n   current time.\n\n       ==\n       ?- set_time_file(foo, [access(Access)], []).\n       ?- set_time_file(foo, [], [modified(now)]).\n       ==",
    "prefix":"set_time_file"
  },
  "filesex:copy_directory/2": {
    "body":"copy_directory(${1:From}, ${2:To})$3\n$0",
    "description":"[det]copy_directory(+From, +To).\nCopy the contents of the directory From to To  (recursively). If To is the name of an existing directory, the contents  of From are copied into To. I.e., no subdirectory  using the basename of From is created.",
    "prefix":"copy_directory"
  },
  "filesex:copy_file/2": {
    "body":"copy_file(${1:From}, ${2:To})$3\n$0",
    "description":"[det]copy_file(From, To).\nCopy a file into a new file or directory. The data is copied as binary  data.",
    "prefix":"copy_file"
  },
  "filesex:delete_directory_and_contents/1": {
    "body":"delete_directory_and_contents(${1:Dir})$2\n$0",
    "description":"[det]delete_directory_and_contents(+Dir).\nRecursively remove the directory Dir and its contents. If Dir  is a symbolic link or symbolic links inside Dir are  encountered, the links are removed rather than their content. Use with  care!",
    "prefix":"delete_directory_and_contents"
  },
  "filesex:delete_directory_contents/1": {
    "body":"delete_directory_contents(${1:Dir})$2\n$0",
    "description":"[det]delete_directory_contents(+Dir).\nRemove all content from directory Dir, without removing Dir  itself. Similar to delete_directory_and_contents/2,  if symbolic links are encountered in Dir, the links are  removed rather than their content.",
    "prefix":"delete_directory_contents"
  },
  "filesex:directory_file_path/3": {
    "body":"directory_file_path(${1:Directory}, ${2:File}, ${3:Path})$4\n$0",
    "description":"[det]directory_file_path(?Directory, ?File, +Path).\nTrue when Path is the full path-name for File in  Dir. This is comparable to atom_concat(Directory, File, Path),  but it ensures there is exactly one / between the two parts. Notes:  \n\nIn mode (+,+,-), if File is given and absolute, Path  is unified to File.\nMode (-,-,+) uses file_directory_name/2  and file_base_name/2\n\n",
    "prefix":"directory_file_path"
  },
  "filesex:link_file/3": {
    "body":"link_file(${1:OldPath}, ${2:NewPath}, ${3:Type})$4\n$0",
    "description":"[det]link_file(+OldPath, +NewPath, +Type).\nCreate a link in the filesystem from NewPath to OldPath. Type  defines the type of link and is one of hard or symbolic.  With some limitations, these functions also work on Windows. First of  all, the unerlying filesystem must support links. This requires NTFS.  Second, symbolic links are only supported in Vista and later. \n\nErrors: domain_error(link_type, Type) if the requested link-type is  unknown or not supported on the target OS.\n\n ",
    "prefix":"link_file"
  },
  "filesex:make_directory_path/1": {
    "body":"make_directory_path(${1:Dir})$2\n$0",
    "description":"[det]make_directory_path(+Dir).\nCreate Dir and all required components (like mkdir -p). Can  raise various file-specific exceptions.",
    "prefix":"make_directory_path"
  },
  "filesex:process_group_kill/2": {
    "body":"process_group_kill(${1:PID}, ${2:Signal})$3\n$0",
    "description":"[det]process_group_kill(+PID, +Signal).\nSend signal to the group containing process PID. Default is term. See process_wait/1 for  a description of signal handling. In Windows, the same restriction on PID  applies: it must have been created from process_create/3,  and the the group is terminated via the TerminateJobObject API.",
    "prefix":"process_group_kill"
  },
  "filesex:relative_file_name/3": {
    "body":"relative_file_name(${1:Path}, ${2:RelTo}, ${3:RelPath})$4\n$0",
    "description":"[det]relative_file_name(-Path:atom, +RelTo:atom, +RelPath:atom).\nTrue when RelPath is Path, relative to RelTo. Path  and RelTo are first handed to absolute_file_name/2,  which makes the absolute and canonical. Below are two examples:  \n\n?- relative_file_name('/home/janw/nice',\n                      '/home/janw/deep/dir/file', Path).\nPath = '../../nice'.\n\n?- relative_file_name(Path, '/home/janw/deep/dir/file', '../../nice').\nPath = '/home/janw/nice'.\n\n  All paths must be in canonical  POSIX notation, i.e., using / to separate segments in the path. See prolog_to_os_filename/2.   bug: This predicate is defined as a syntactical operation.\n\n ",
    "prefix":"relative_file_name"
  },
  "filesex:set_time_file/3": {
    "body":"set_time_file(${1:File}, ${2:OldTimes}, ${3:NewTimes})$4\n$0",
    "description":"[det]set_time_file(+File, -OldTimes, +NewTimes).\nQuery and set POSIX time attributes of a file. Both OldTimes  and NewTimes are lists of option-terms. Times are represented in  SWI-Prolog's standard floating point numbers. New times may be specified  as now to indicate the current time. Defined options are:  access(Time): Describes the time of last access of the file. This value can be read  and written.\n\nmodified(Time): Describes the time the contents of the file was last modified. This  value can be read and written.\n\nchanged(Time): Describes the time the file-structure itself was changed by adding (link())  or removing (unlink()) names.\n\n  Below are some example queries. The first retrieves the access-time,  while the second sets the last-modified time to the current time. \n\n\n\n?- set_time_file(foo, [access(Access)], []).\n?- set_time_file(foo, [], [modified(now)]).\n\n ",
    "prefix":"set_time_file"
  },
  "fill_buffer/1": {
    "body":"fill_buffer(${1:Stream})$2\n$0",
    "description":"[det]fill_buffer(+Stream).\nFill the Stream's input buffer. Subsequent calls try to read  more input until the buffer is completely filled. This predicate is used  together with read_pending_codes/3  to process input with minimal buffering.",
    "prefix":"fill_buffer"
  },
  "find_chr_constraint/1": {
    "body":"find_chr_constraint(${1:Constraint})$2\n$0",
    "description":"find_chr_constraint(-Constraint).\nReturns a constraint in the constraint store. Via backtracking, all  constraints in the store can be enumerated.",
    "prefix":"find_chr_constraint"
  },
  "findall/3": {
    "body":"findall(${1:Template}, ${2:Goal}, ${3:Bag})$4\n$0",
    "description":"[ISO]findall(+Template, :Goal, -Bag).\nCreate a list of the instantiations Template gets  successively on backtracking over Goal and unify the result  with Bag. Succeeds with an empty list if Goal has  no solutions. findall/3  is equivalent to bagof/3  with all free variables bound with the existential operator (^),  except that bagof/3  fails when Goal has no solutions.",
    "prefix":"findall"
  },
  "findall/4": {
    "body":"findall(${1:Template}, ${2:Goal}, ${3:Bag}, ${4:Tail})$5\n$0",
    "description":"findall(+Template, :Goal, -Bag, +Tail).\nAs findall/3,  but returns the result as the difference list Bag-Tail. The 3-argument version is defined as  \n\nfindall(Templ, Goal, Bag) :-\n        findall(Templ, Goal, Bag, [])\n\n ",
    "prefix":"findall"
  },
  "findnsols/4": {
    "body":"findnsols(${1:N}, ${2:Template}, ${3:Goal}, ${4:List})$5\n$0",
    "description":"[nondet]findnsols(+N, @Template, :Goal, -List).\n",
    "prefix":"findnsols"
  },
  "findnsols/5": {
    "body":"findnsols(${1:N}, ${2:Template}, ${3:Goal}, ${4:List}, ${5:Tail})$6\n$0",
    "description":"[nondet]findnsols(+N, @Template, :Goal, -List, ?Tail).\nAs findall/3  and findall/4,  but generates at most N solutions. If N solutions are returned, this predicate succeeds with a  choice point if Goal has a choice point. Backtracking returns  the next chunk of (at most) N solutions. In addition to  passing a plain integer for N, a term of the form count(N)  is accepted. Using count(N), the size of the next chunk can  be controlled using nb_setarg/3.  The non-deterministic behaviour used to implement the chunk option in library(pengines). Based on Ciao,  but the Ciao version is deterministic. Portability can be achieved by  wrapping the goal in once/1.  Below are three examples. The first illustrates standard chunking of  answers. The second illustrates that the chunk size can be adjusted  dynamically and the last illustrates that no choice point is left if Goal  leaves no choice-point after the last solution.  \n\n?- findnsols(5, I, between(1, 12, I), L).\nL = [1, 2, 3, 4, 5] ;\nL = [6, 7, 8, 9, 10] ;\nL = [11, 12].\n\n?- State = count(2),\n   findnsols(State, I, between(1, 12, I), L),\n   nb_setarg(1, State, 5).\nState = count(5), L = [1, 2] ;\nState = count(5), L = [3, 4, 5, 6, 7] ;\nState = count(5), L = [8, 9, 10, 11, 12].\n\n?- findnsols(4, I, between(1, 4, I), L).\nL = [1, 2, 3, 4].\n\n ",
    "prefix":"findnsols"
  },
  "flag/3": {
    "body":"flag(${1:Key}, ${2:Old}, ${3:New})$4\n$0",
    "description":"flag(+Key, -Old, +New).\nTrue when Old is the current value of the flag Key  and the flag has been set to New. New can be an  arithmetic expression. The update is atomic. This predicate can  be used to create a shared global counter as illustrated in the  example below.  \n\nnext_id(Id) :-\n    flag(my_id, Id, Id+1).\n\n  \n\n",
    "prefix":"flag"
  },
  "float/1": {
    "body":"float(${1:Term})$2\n$0",
    "description":"[ISO]float(@Term).\nTrue if Term is bound to a floating point number.",
    "prefix":"float"
  },
  "float_fractional_part/1": {
    "body":"float_fractional_part(${1:Expr})$2\n$0",
    "description":"[ISO]float_fractional_part(+Expr).\nFractional part of a floating point number. Negative if Expr  is negative, rational if Expr is rational and 0 if Expr  is integer. The following relation is always true: X is float_fractional_part(X) + float_integer_part(X).",
    "prefix":"float_fractional_part"
  },
  "float_integer_part/1": {
    "body":"float_integer_part(${1:Expr})$2\n$0",
    "description":"[ISO]float_integer_part(+Expr).\nInteger part of floating point number. Negative if Expr is  negative, Expr if Expr is integer.",
    "prefix":"float_integer_part"
  },
  "floor/1": {
    "body":"floor(${1:Expr})$2\n$0",
    "description":"[ISO]floor(+Expr).\nEvaluate Expr and return the largest integer smaller or equal  to the result of the evaluation.",
    "prefix":"floor"
  },
  "flush_output/1": {
    "body":"flush_output(${1:Stream})$2\n$0",
    "description":"[ISO]flush_output(+Stream).\nFlush output on the specified stream. The stream must be open for  writing.",
    "prefix":"flush_output"
  },
  "forall/2": {
    "body":"forall(${1:Cond}, ${2:Action})$3\n$0",
    "description":"[semidet]forall(:Cond, :Action).\nFor all alternative bindings of Cond, Action can  be proven. The example verifies that all arithmetic statements in the  given list are correct. It does not say which is wrong if one proves  wrong.  \n\n?- forall(member(Result = Formula, [2 = 1 + 1, 4 = 2 * 2]),\n                 Result =:= Formula).\n\n  The predicate forall/2  is implemented as \\+ ( Cond, \\+ Action), i.e., There is  no instantiation of Cond for which Action is  false.. The use of double negation implies that forall/2 does  not change any variable bindings. It proves a relation. The forall/2  control structure can be used for its side-effects. E.g., the following  asserts relations in a list into the dynamic database: \n\n\n\n?- forall(member(Child-Parent, ChildPairs),\n          assertz(child_of(Child, Parent))).\n\n  Using forall/2  as forall(Generator, SideEffect) is preferred over the  classical failure driven loop as shown below because it makes  it explicit which part of the construct is the generator and which part  creates the side effects. Also, unexpected failure of the side effect  causes the construct to fail. Failure makes it evident that there is an  issue with the code, while a failure driven loop would succeed with an  erroneous result. \n\n\n\n        ...,\n        (   Generator,\n            SideEffect,\n            fail\n        ;   true\n        )\n\n  If your intent is to create variable bindings, the forall/2  control structure is inadequate. Possibly you are looking for maplist/2, findall/3  or foreach/2.\n\n",
    "prefix":"forall"
  },
  "format/1": {
    "body":"format(${1:Format})$2\n$0",
    "description":"format(+Format).\nDefined as `format(Format) :- format(Format, []).'. See format/2  for details.",
    "prefix":"format"
  },
  "format/2": {
    "body":"format(${1:Format}, ${2:Arguments})$3\n$0",
    "description":"format(+Format, :Arguments).\nFormat is an atom, list of character codes, or a Prolog  string. Arguments provides the arguments required by the format  specification. If only one argument is required and this single argument  is not a list, the argument need not be put in a list. Otherwise the  arguments are put in a list.  Special sequences start with the tilde (~),  followed by an optional numeric argument, optionally followed by a colon  modifier (:), 121The colon modifiers is a  SWI-Prolog extension, proposed by Richard O'Keefe. followed  by a character describing the action to be undertaken. A numeric  argument is either a sequence of digits, representing a positive decimal  number, a sequence `<character>,  representing the character code value of the character (only useful for ~t) or a asterisk (*), in which  case the numeric argument is taken from the next argument of the  argument list, which should be a positive integer. E.g., the following  three examples all pass 46 (.) to ~t: \n\n\n\n?- format('~w ~46t ~w~72|~n', ['Title', 'Page']).\n?- format('~w ~`.t ~w~72|~n', ['Title', 'Page']).\n?- format('~w ~*t ~w~72|~n', ['Title', 46, 'Page']).\n\n  Numeric conversion (d, D, e, E, f, g  and G) accept an arithmetic expression as argument. This is  introduced to handle rational numbers transparently (see section 4.27.2.2). The floating  point conversions allow for unlimited precision for printing rational  numbers in decimal form. E.g., the following will write as many 3's as  you want by changing the `50'. \n\n\n\n?- format('~50f', [10 rdiv 3]).\n3.33333333333333333333333333333333333333333333333333\n\n  \n\n~ Output the tilde itself.  \na Output the next argument, which must be an atom. This option is  equivalent to w, except that it requires the argument to be an  atom.  \nc Interpret the next argument as a character code and add it to the  output. This argument must be a valid Unicode character code. Note that  the actually emitted bytes are defined by the character encoding of the  output stream and an exception may be raised if the output stream is not  capable of representing the requested Unicode character. See section 2.18.1 for details.  \nd Output next argument as a decimal number. It should be an integer. If a  numeric argument is specified, a dot is inserted argument  positions from the right (useful for doing fixed point arithmetic with  integers, such as handling amounts of money).  The colon modifier (e.g., ~:d) causes the number to be  printed according to the locale of the output stream. See section  4.23. \nD Same as d, but makes large values easier to read by inserting a  comma every three digits left or right of the dot. This is the same as ~:d,  but using the fixed English locale.  \ne Output next argument as a floating point number in exponential notation.  The numeric argument specifies the precision. Default is 6 digits. Exact  representation depends on the C library function printf(). This function  is invoked with the format %.<precision>e.  \nE Equivalent to e, but outputs a capital E to indicate the  exponent.  \nf Floating point in non-exponential notation. The numeric argument defines  the number of digits right of the decimal point. If the colon modifier  (:) is used, the float is formatted using conventions from the current  locale, which may define the decimal point as well as grouping of digits  left of the decimal point.  \ng Floating point in e or f notation, whichever is shorter.  \nG Floating point in E or f notation, whichever is shorter.  \ni Ignore next argument of the argument list. Produces no output.  \nI Emit a decimal number using Prolog digit grouping (the underscore, _). The argument describes the size of each digit group.  The default is 3. See also section  2.15.1.5. For example:  ?- A is 1<<100, format('~10I', [A]). 1_2676506002_2822940149_6703205376  \nk Give the next argument to write_canonical/1.\nn Output a newline character.\nN Only output a newline if the last character output on this stream was  not a newline. Not properly implemented yet.\np Give the next argument to print/1.\nq Give the next argument to writeq/1.  \nr Print integer in radix numeric argument notation. Thus ~16r prints its argument hexadecimal. The argument should  be in the range [2, ... , 36]. Lowercase letters are used for  digits above 9. The colon modifier may be used to form locale-specific  digit groups.  \nR Same as r, but uses uppercase letters for digits above 9.\ns Output text from a list of character codes or a string (see string/1  and section 5.2) from the next  argument.122The s modifier  also accepts an atom for compatibility. This is deprecated due to the  ambiguity of [].\n@ Interpret the next argument as a goal and execute it. Output written to  the current_output stream is inserted at this place. Goal  is called in the module calling format/3.  This option is not present in the original definition by Quintus, but  supported by some other Prolog systems.\nt All remaining space between 2 tab stops is distributed equally over ~t statements between the tab stops. This space is padded  with spaces by default. If an argument is supplied, it is taken to be  the character code of the character used for padding. This can be used  to do left or right alignment, centering, distributing, etc. See also ~|  and ~+ to set tab stops. A tab stop is assumed at the start  of each line.\n| Set a tab stop on the current position. If an argument is supplied set a  tab stop on the position of that argument. This will cause all ~t's to be distributed between the previous and this tab  stop.  \n+ Set a tab stop (as ~|) relative to the last tab stop or the  beginning of the line if no tab stops are set before the ~+.  This constructs can be used to fill fields. The partial format sequence  below prints an integer right-aligned and padded with zeros in 6  columns. The ... sequences in the example illustrate that the integer is  aligned in 6 columns regardless of the remainder of the format  specification.          format('...~|~`0t~d~6+...', [..., Integer, ...])  \nw Give the next argument to write/1.\nW Give the next two arguments to write_term/2.  For example, format('~W', [Term, [numbervars(true)]]). This option is  SWI-Prolog specific.\n\n  Example: \n\n\n\nsimple_statistics :-\n    <obtain statistics>         % left to the user\n    format('~tStatistics~t~72|~n~n'),\n    format('Runtime: ~`.t ~2f~34|  Inferences: ~`.t ~D~72|~n',\n                                            [RunT, Inf]),\n    ....\n\n  will output \n\n\n\n                             Statistics\n\nRuntime: .................. 3.45  Inferences: .......... 60,345\n\n ",
    "prefix":"format"
  },
  "format/3": {
    "body":"format(${1:Output}, ${2:Format}, ${3:Arguments})$4\n$0",
    "description":"format(+Output, +Format, :Arguments).\nAs format/2,  but write the output on the given Output. The de-facto  standard only allows Output to be a stream. The SWI-Prolog  implementation allows all valid arguments for with_output_to/2.123Earlier  versions defined sformat/3 . These predicates have been moved to the  library library(backcomp). For example:  \n\n?- format(atom(A), '~D', [1000000]).\nA = '1,000,000'\n\n  \n\n",
    "prefix":"format"
  },
  "format_predicate/2": {
    "body":"format_predicate(${1:Char}, ${2:Head})$3\n$0",
    "description":"format_predicate(+Char, +Head).\nIf a sequence ~c (tilde, followed by some character) is  found, the format/3  and friends first check whether the user has defined a predicate to  handle the format. If not, the built-in formatting rules described above  are used. Char is either a character code or a one-character  atom, specifying the letter to be (re)defined. Head is a  term, whose name and arity are used to determine the predicate to call  for the redefined formatting character. The first argument to the  predicate is the numeric argument of the format command, or the atom default  if no argument is specified. The remaining arguments are filled from the  argument list. The example below defines ~T to print a  timestamp in ISO8601 format (see format_time/3).  The subsequent block illustrates a possible call.  \n\n:- format_predicate('T', format_time(_Arg,_Time)).\n\nformat_time(_Arg, Stamp) :-\n        must_be(number, Stamp),\n        format_time(current_output, '%FT%T%z', Stamp).\n\n  \n\n?- get_time(Now),\n   format('Now, it is ~T~n', [Now]).\nNow, it is 2012-06-04T19:02:01+0200\nNow = 1338829321.6620328.\n\n ",
    "prefix":"format_predicate"
  },
  "format_time/3": {
    "body":"format_time(${1:Out}, ${2:Format}, ${3:StampOrDateTime})$4\n$0",
    "description":"format_time(+Out, +Format, +StampOrDateTime).\nModelled after POSIX strftime(), using GNU extensions. Out is  a destination as specified with with_output_to/2. Format  is an atom or string with the following conversions. Conversions start  with a percent (%) character.126Descriptions  taken from Linux Programmer's Manual StampOrDateTime is either a numeric time-stamp, a term date(Y,M,D,H,M,S,O,TZ,DST) or a term date(Y,M,D).  \n\na The abbreviated weekday name according to the current locale. Use format_time/4  for POSIX locale.\nA The full weekday name according to the current locale. Use format_time/4  for POSIX locale.\nb The abbreviated month name according to the current locale. Use format_time/4  for POSIX locale.\nB The full month name according to the current locale. Use format_time/4  for POSIX locale.\nc The preferred date and time representation for the current locale.\nC The century number (year/100) as a 2-digit integer.\nd The day of the month as a decimal number (range 01 to 31).\nD Equivalent to %m/%d/%y. (For Americans only. Americans should note that  in other countries %d/%m/%y is rather common. This means that in an  international context this format is ambiguous and should not be used.)\ne Like %d, the day of the month as a decimal number, but a leading zero is  replaced by a space.\nE Modifier. Not implemented.\nf Number of microseconds. The f can be prefixed by an integer  to print the desired number of digits. E.g., %3f prints  milliseconds. This format is not covered by any standard, but available  with different format specifiers in various incarnations of the  strftime() function.\nF Equivalent to %Y-%m-%d (the ISO 8601 date format).\ng Like %G, but without century, i.e., with a 2-digit year (00-99).\nG The ISO 8601 year with century as a decimal number. The 4-digit year  corresponding to the ISO week number (see %V). This has the same format  and value as %y, except that if the ISO week number belongs to the  previous or next year, that year is used instead.\nV The ISO 8601:1988 week number of the current year as a decimal number,  range 01 to 53, where week 1 is the first week that has at least 4 days  in the current year, and with Monday as the first day of the week. See  also %U and %W.\nh Equivalent to %b.\nH The hour as a decimal number using a 24-hour clock (range 00 to 23).\nI The hour as a decimal number using a 12-hour clock (range 01 to 12).\nj The day of the year as a decimal number (range 001 to 366).\nk The hour (24-hour clock) as a decimal number (range 0 to 23); single  digits are preceded by a blank. (See also %H.)\nl The hour (12-hour clock) as a decimal number (range 1 to 12); single  digits are preceded by a blank. (See also %I.)\nm The month as a decimal number (range 01 to 12).\nM The minute as a decimal number (range 00 to 59).\nn A newline character.\nO Modifier to select locale-specific output. Not implemented.\np Either `AM' or `PM' according to the given time value, or the  corresponding strings for the current locale. Noon is treated as `pm'  and midnight as `am'.\nP Like %p but in lowercase: `am' or `pm' or a corresponding string for the  current locale.\nr The time in a.m. or p.m. notation. In the POSIX locale this is  equivalent to `%I:%M:%S %p'.\nR The time in 24-hour notation (%H:%M). For a version including the  seconds, see %T below.\ns The number of seconds since the Epoch, i.e., since 1970-01-01 00:00:00  UTC.\nS The second as a decimal number (range 00 to 60). (The range is up to 60  to allow for occasional leap seconds.)\nt A tab character.\nT The time in 24-hour notation (%H:%M:%S).\nu The day of the week as a decimal, range 1 to 7, Monday being 1. See also %w.\nU The week number of the current year as a decimal number, range 00 to 53,  starting with the first Sunday as the first day of week 01. See also %V  and %W.\nw The day of the week as a decimal, range 0 to 6, Sunday being 0. See also %u.\nW The week number of the current year as a decimal number, range 00 to 53,  starting with the first Monday as the first day of week 01.\nx The preferred date representation for the current locale without the  time.\nX The preferred time representation for the current locale without the  date.\ny The year as a decimal number without a century (range 00 to 99).\nY The year as a decimal number including the century.\nz The timezone as hour offset from GMT using the format HHmm. Required to  emit RFC822-conforming dates (using '%a,%d%b%Y%T%z'). Our  implementation supports %:z, which modifies the output to HH:mm as required by  XML-Schema. Note that both notations are valid in ISO 8601. The sequence %:z  is compatible to the GNU date(1) command.\nZ The timezone or name or abbreviation.\n+ The date and time in date(1) format.\n% A literal `%' character.\n\n  The table below gives some format strings for popular time  representations. RFC1123 is used by HTTP. The full implementation of http_timestamp/2  as available from library(http/http_header) is here. \n\n\n\nhttp_timestamp(Time, Atom) :-\n        stamp_date_time(Time, Date, 'UTC'),\n        format_time(atom(Atom),\n                    '%a, %d %b %Y %T GMT',\n                    Date, posix).\n\n  \n\nStandard Format string xsd '%FT%T%:z' ISO8601 '%FT%T%z' RFC822 '%a, %d %b %Y %T %z' RFC1123 '%a, %d %b %Y %T GMT' ",
    "prefix":"format_time"
  },
  "format_time/4": {
    "body":"format_time(${1:Out}, ${2:Format}, ${3:StampOrDateTime}, ${4:Locale})$5\n$0",
    "description":"format_time(+Out, +Format, +StampOrDateTime, +Locale).\nFormat time given a specified Locale. This predicate is a  work-around for lacking proper portable and thread-safe time and locale  handling in current C libraries. In its current implementation the only  value allowed for Locale is posix, which  currently only modifies the behaviour of the a, A, b  and B format specifiers. The predicate is used to be able  to emit POSIX locale week and month names for emitting standardised  time-stamps such as RFC1123.",
    "prefix":"format_time"
  },
  "free_dtd/1": {
    "body":"free_dtd(${1:DTD})$2\n$0",
    "description":"free_dtd(+DTD).\nDeallocate all resources associated to the DTD. Further use of DTD  is invalid.",
    "prefix":"free_dtd"
  },
  "free_sgml_parser/1": {
    "body":"free_sgml_parser(${1:Parser})$2\n$0",
    "description":"free_sgml_parser(+Parser).\nDestroy all resources related to the parser. This does not destroy the  DTD if the parser was created using the dtd(DTD) option.",
    "prefix":"free_sgml_parser"
  },
  "free_table/1": {
    "body":"free_table(${1:Handle})$2\n$0",
    "description":"free_table(+Handle).\nClose and remove the handle. After this operation, Handle  becomes invalid and further references to it causes undefined behaviour.  \n\n",
    "prefix":"free_table"
  },
  "freeze/2": {
    "body":"freeze(${1:Var}, ${2:Goal})$3\n$0",
    "description":"freeze(+Var, :Goal).\nDelay the execution of Goal until Var is bound  (i.e. is not a variable or attributed variable). If Var is  bound on entry freeze/2  is equivalent to call/1.  The freeze/2  predicate is realised using an attributed variable associated with the  module freeze. Use frozen(Var, Goal) to find  out whether and which goals are delayed on Var.",
    "prefix":"freeze"
  },
  "frozen/2": {
    "body":"frozen(${1:Var}, ${2:Goal})$3\n$0",
    "description":"frozen(@Var, -Goal).\nUnify Goal with the goal or conjunction of goals delayed on Var. If no goals are frozen on Var, Goal  is unified to true.",
    "prefix":"frozen"
  },
  "functor/3": {
    "body":"functor(${1:Term}, ${2:Name}, ${3:Arity})$4\n$0",
    "description":"[ISO]functor(?Term, ?Name, ?Arity).\nTrue when Term is a term with functor Name/Arity.  If Term is a variable it is unified with a new term whose  arguments are all different variables (such a term is called a  skeleton). If Term is atomic, Arity will be  unified with the integer 0, and Name will be unified with Term.  Raises instantiation_error() if Term is unbound  and Name/Arity is insufficiently instantiated.  SWI-Prolog also supports terms with arity 0, as in a()  (see section 5. Such terms must be  processed using compound_name_arity/3.  The predicate functor/3  and =../2 raise a domain_error  when faced with these terms. Without this precaution, the inconsistency  demonstrated below could happen silently.90Raising  a domain error was suggested by Jeff Schultz. \n\n\n\n?- functor(a(), N, A).\nN = a, A = 0.\n?- functor(T, a, 0).\nT = a.\n\n ",
    "prefix":"functor"
  },
  "garbage_collect/0": {
    "body":"garbage_collect$1\n$0",
    "description":"garbage_collect.\nInvoke the global and trail stack garbage collector. Normally the  garbage collector is invoked automatically if necessary. Explicit  invocation might be useful to reduce the need for garbage collections in  time-critical segments of the code. After the garbage collection trim_stacks/0  is invoked to release the collected memory resources.",
    "prefix":"garbage_collect"
  },
  "garbage_collect_atoms/0": {
    "body":"garbage_collect_atoms$1\n$0",
    "description":"garbage_collect_atoms.\nReclaim unused atoms. Normally invoked after agc_margin  (a Prolog flag) atoms have been created. On multithreaded versions the  actual collection is delayed until there are no threads performing  normal garbage collection. In this case garbage_collect_atoms/0  returns immediately. Note that there is no guarantee it will ever  happen, as there may always be threads performing garbage collection.",
    "prefix":"garbage_collect_atoms"
  },
  "garbage_collect_clauses/0": {
    "body":"garbage_collect_clauses$1\n$0",
    "description":"garbage_collect_clauses.\nReclaim retracted clauses. During normal operation, retracting a clause  implies setting the erased generation to the current generation of the database and increment the generation.  Keeping the clause around is both needed to realise the logical  update view and deal with the fact that other threads may be  executing the clause. Both static and dynamic code is processed this  way.48Up to version 7.3.11,  dynamic code was handled using reference counts..  The clause garbage collector (CGC) scans the environment stacks of  all threads for referenced dirty predicates and at which generation this  reference accesses the predicate. It then removes the references for  clauses that have been retracted before the oldest access generation  from the clause list as well as the secondary clauses indexes of the  predicate. If the clause list is not being scanned, the clause  references and ultimately the clause itself is reclaimed. \n\nThe clause garbage collector is called under three conditions, (1)  after reloading a source file, (2) if the memory occupied by  retracted but not yet reclaimed clauses exceeds 12.5% of the program  store, or (3) if skipping dead clauses in the clause lists becomes too  costly. The cost of clause garbage collection is proportional with the  total size of the local stack of all threads (the scanning phase) and  the number of clauses in all `dirty' predicates (the reclaiming phase).\n\n",
    "prefix":"garbage_collect_clauses"
  },
  "gdebug/0": {
    "body":"gdebug$1\n$0",
    "description":"gdebug.\nUtility defined as guitracer,debug.",
    "prefix":"gdebug"
  },
  "gensym:gensym/2": {
    "body":"gensym(${1:Base}, ${2:Unique})$3\n$0",
    "description":"gensym(+Base, -Unique).\nGenerate a unique atom from base Base and unify it with Unique. Base should be an atom. The first call will return <base>1  , the next <base>2 , etc. Note that this is no  guarantee that the atom is unique in the system.",
    "prefix":"gensym"
  },
  "gensym:reset_gensym/0": {
    "body":"reset_gensym$1\n$0",
    "description":"reset_gensym.\nReset gensym for all registered keys. This predicate is available for  compatibility only. New code is strongly advised to avoid the use of  reset_gensym or at least to reset only the keys used by your program to  avoid unexpected side effects on other components.",
    "prefix":"reset_gensym"
  },
  "gensym:reset_gensym/1": {
    "body":"reset_gensym(${1:Base})$2\n$0",
    "description":"reset_gensym(+Base).\nRestart generation of identifiers from Base at <Base>1.  Used to make sure a program produces the same results on subsequent  runs. Use with care.",
    "prefix":"reset_gensym"
  },
  "get/1": {
    "body":"get(${1:Char})$2\n$0",
    "description":"[deprecated]get(-Char).\nRead the current input stream and unify the next non-blank character  with Char. Char is unified with -1 on end of file.  The predicate get/1  operates on character codes. See also get0/1.",
    "prefix":"get"
  },
  "get/2": {
    "body":"get(${1:Stream}, ${2:Char})$3\n$0",
    "description":"[deprecated]get(+Stream, -Char).\nRead the next non-blank character from Stream. See also get/1, get0/1  and get0/2.",
    "prefix":"get"
  },
  "get0/1": {
    "body":"get0(${1:Char})$2\n$0",
    "description":"[deprecated]get0(-Char).\nEdinburgh version of the ISO get_code/1  predicate. Note that Edinburgh Prolog didn't support wide characters and  therefore technically speaking get0/1  should have been mapped to get_byte/1.  The intention of get0/1,  however, is to read character codes.",
    "prefix":"get0"
  },
  "get0/2": {
    "body":"get0(${1:Stream}, ${2:Char})$3\n$0",
    "description":"[deprecated]get0(+Stream, -Char).\nEdinburgh version of the ISO get_code/2  predicate. See also get0/1.",
    "prefix":"get0"
  },
  "get_attr/3": {
    "body":"get_attr(${1:Var}, ${2:Module}, ${3:Value})$4\n$0",
    "description":"get_attr(+Var, +Module, -Value).\nRequest the current value for the attribute named Module.  If Var is not an attributed variable or the named attribute is  not associated to Var this predicate fails silently. If Module  is not an atom, a type error is raised.",
    "prefix":"get_attr"
  },
  "get_attrs/2": {
    "body":"get_attrs(${1:Var}, ${2:Attributes})$3\n$0",
    "description":"get_attrs(+Var, -Attributes).\nGet all attributes of Var. Attributes is a term of  the form att(Module, Value, MoreAttributes), where MoreAttributes  is [] for the last attribute.",
    "prefix":"get_attrs"
  },
  "get_byte/1": {
    "body":"get_byte(${1:Byte})$2\n$0",
    "description":"[ISO]get_byte(-Byte).\nRead the current input stream and unify the next byte with Byte  (an integer between 0 and 255). Byte is unified with -1 on  end of file.",
    "prefix":"get_byte"
  },
  "get_byte/2": {
    "body":"get_byte(${1:Stream}, ${2:Byte})$3\n$0",
    "description":"[ISO]get_byte(+Stream, -Byte).\nRead the next byte from Stream and unify Byte with  an integer between 0 and 255.",
    "prefix":"get_byte"
  },
  "get_char/1": {
    "body":"get_char(${1:Char})$2\n$0",
    "description":"[ISO]get_char(-Char).\nRead the current input stream and unify Char with the next  character as a one-character atom. See also atom_chars/2.  On end-of-file, Char is unified to the atom end_of_file.",
    "prefix":"get_char"
  },
  "get_char/2": {
    "body":"get_char(${1:Stream}, ${2:Char})$3\n$0",
    "description":"[ISO]get_char(+Stream, -Char).\nUnify Char with the next character from Stream as  a one-character atom. See also get_char/2, get_byte/2  and get_code/2.",
    "prefix":"get_char"
  },
  "get_code/1": {
    "body":"get_code(${1:Code})$2\n$0",
    "description":"[ISO]get_code(-Code).\nRead the current input stream and unify Code with the  character code of the next character. Code is unified with -1  on end of file. See also get_char/1.",
    "prefix":"get_code"
  },
  "get_code/2": {
    "body":"get_code(${1:Stream}, ${2:Code})$3\n$0",
    "description":"[ISO]get_code(+Stream, -Code).\nRead the next character code from Stream.",
    "prefix":"get_code"
  },
  "get_dict/3": {
    "body":"get_dict(${1:Key}, ${2:Dict}, ${3:Value})$4\n$0",
    "description":"get_dict(?Key, +Dict, -Value).\nUnify the value associated with Key in dict with Value.  If Key is unbound, all associations in Dict are  returned on backtracking. The order in which the associations are  returned is undefined. This predicate is normally accessed using the  functional notation Dict.Key. See section  5.4.1.",
    "prefix":"get_dict"
  },
  "get_dict/5": {
    "body":"get_dict(${1:Key}, ${2:Dict}, ${3:Value}, ${4:NewDict}, ${5:NewValue})$6\n$0",
    "description":"[semidet]get_dict(+Key, +Dict, -Value, -NewDict, +NewValue).\nCreate a new dict after updating the value for Key. Fails if Value does not unify with the current value associated with Key. Acts according to the following below. Dict  is either a dict or a list the can be converted into a dict.  \n\nget_dict(Key, Dict, Value, NewDict, NewDict) :-\n        get_dict(Key, Dict, Value),\n        put_dict(Key, Dict, NewDict, NewDict).\n\n ",
    "prefix":"get_dict"
  },
  "get_flag/2": {
    "body":"get_flag(${1:Key}, ${2:Value})$3\n$0",
    "description":"get_flag(+Key, -Value).\nTrue when Value is the value currently associated with Key.  If Key does not exist, a new flag with value `0' (zero) is  created.",
    "prefix":"get_flag"
  },
  "get_sgml_parser/2": {
    "body":"get_sgml_parser(${1:Parser}, ${2:Option})$3\n$0",
    "description":"get_sgml_parser(+Parser, -Option).\nRetrieve infomation on the current status of the parser. Notably useful  if the parser is used in the call-back mode. Currently defined options:  file(-File): Current file-name. Note that this may be different from the provided  file if an external entity is being loaded.\n\nline(-Line): Line-offset from where the parser started its processing in the  file-object.\n\ncharpos(-CharPos): Offset from where the parser started its processing in the file-object.  See section 6.\n\ncharpos(-Start, -End): Character offsets of the start and end of the source processed causing  the current call-back. Used in PceEmacs to for colouring text in  SGML and XML modes.\n\nsource(-Stream): Prolog stream being processed. May be used in the on_begin, etc.  callbacks from sgml_parse/2.\n\ndialect(-Dialect): Return the current dialect used by the parser (sgml, html, html5, xhtml, xhtml5, xml  or xmlns).\n\nevent_class(-Class): The event class can be requested in call-back events. It  denotes the cause of the event, providing useful information for syntax  highlighting. Defined values are:  explicitThe code generating this event is explicitely present in the document.omittedThe current event is caused by the insertion of an omitted tag. This may  be a normal event in SGML mode or an error in XML mode.shorttagThe current event (begin or end) is caused by  an element written down using the shorttag notation (<tag/value/>.shortrefThe current event is caused by the expansion of a shortref. This allows for highlighting shortref strings in the  source-text. \n\ndoctype(-Element): Return the defined document-type (= toplevel element). See also set_sgml_parser/2.\n\ndtd(-DTD): Return the currently used DTD. See dtd_property/2  for obtaining information on the DTD such as element and attribute  properties.\n\ncontext(-StackOfElements): Returns the stack of currently open elements as a list. The head of this  list is the current element. This can be used to determine the context  of, for example, CDATA events in call-back mode. The elements are passed  as atoms. Currently no access to the attributes is provided.\n\nallowed(-Elements): Determines which elements may be inserted at the current location. This  information is returned as a list of element-names. If character data is  allowed in the current location, #pcdata is part of Elements. If no element is open, the doctype is  returned.  This option is intended to support syntax-sensitive editors. Such an  editor should load the DTD, find an appropriate starting point and then  feed all data between the starting point and the caret into the parser.  Next it can use this option to determine the elements allowed at this  point. Below is a code fragment illustrating this use given a parser  with loaded DTD, an input stream and a start-location. \n\n        ...,\n        seek(In, Start, bof, _),\n        set_sgml_parser(Parser, charpos(Start)),\n        set_sgml_parser(Parser, doctype(_)),\n        Len is Caret - Start,\n        sgml_parse(Parser,\n                   [ source(In),\n                     content_length(Len),\n                     parse(input)       % do not complete document\n                   ]),\n        get_sgml_parser(Parser, allowed(Allowed)),\n        ...\n\n  \n\n ",
    "prefix":"get_sgml_parser"
  },
  "get_single_char/1": {
    "body":"get_single_char(${1:Code})$2\n$0",
    "description":"get_single_char(-Code).\nGet a single character from input stream `user' (regardless of the  current input stream). Unlike get_code/1,  this predicate does not wait for a return. The character is not echoed  to the user's terminal. This predicate is meant for keyboard menu  selection, etc. If SWI-Prolog was started with the -tty  option this predicate reads an entire line of input and returns the  first non-blank character on this line, or the character code of the  newline (10) if the entire line consisted of blank characters.",
    "prefix":"get_single_char"
  },
  "get_string_code/3": {
    "body":"get_string_code(${1:Index}, ${2:String}, ${3:Code})$4\n$0",
    "description":"get_string_code(+Index, +String, -Code).\nSemi-deterministic version of string_code/3.  In addition, this version provides strict range checking, throwing a  domain error if Index is less than 1 or greater than the  length of String. ECLiPSe provides this to support String[Index]  notation.",
    "prefix":"get_string_code"
  },
  "get_table_attribute/3": {
    "body":"get_table_attribute(${1:Handle}, ${2:Attribute}, ${3:Value})$4\n$0",
    "description":"get_table_attribute(+Handle, +Attribute, -Value).\nFetch attributes of the table. Defined attributes:  \n\nfileUnify value with the name  of the file with which the table is associated. field(N)Unify  value with declaration of n-th (1-based) field. field_separatorUnify value  with the field separator character. record_separatorUnify value  with the record separator character. key_fieldUnify value with the  1-based index of the field that is sorted or fails if the table contains  no sorted fields. field_countUnify value with  the total number of columns in the table. sizeUnify value with the  number of characters in the table-file, not the number of  records. windowUnify value with a term Start  - Size, indicating the properties of the current  window. ",
    "prefix":"get_table_attribute"
  },
  "get_time/1": {
    "body":"get_time(${1:TimeStamp})$2\n$0",
    "description":"get_time(-TimeStamp).\nReturn the current time as a TimeStamp. The granularity is  system-dependent. See section 4.35.2.1.",
    "prefix":"get_time"
  },
  "getbit/2": {
    "body":"getbit(${1:IntExprV}, ${2:IntExprI})$3\n$0",
    "description":"getbit(+IntExprV, +IntExprI).\nEvaluates to the bit value (0 or 1) of the IntExprI-th bit of IntExprV. Both arguments must evaluate to non-negative  integers. The result is equivalent to (IntExprV >> IntExprI)/\\1,  but more efficient because materialization of the shifted value is  avoided. Future versions will optimise (IntExprV >> IntExprI)/\\1  to a call to getbit/2,  providing both portability and performance.110This  issue was fiercely debated at the ISO standard mailinglist. The name getbit  was selected for compatibility with ECLiPSe, the only system providing  this support. Richard O'Keefe disliked the name and argued that  efficient handling of the above implementation is the best choice for  this functionality.",
    "prefix":"getbit"
  },
  "getenv/2": {
    "body":"getenv(${1:Name}, ${2:Value})$3\n$0",
    "description":"getenv(+Name, -Value).\nGet environment variable. Fails silently if the variable does not exist.  Please note that environment variable names are case-sensitive on Unix  systems and case-insensitive on Windows.",
    "prefix":"getenv"
  },
  "getpass:getpass/1": {
    "body": ["getpass(${1:Passwd})$2\n$0" ],
    "description":"  getpass(-Passwd)\n\n   Asks the user for a password.  Provides feedback as `*' characters\n   The password typed is returned as a Prolog list.  All intermediate\n   results use XPCE strings rather than atoms to avoid finding the\n   typed password by inspecting the Prolog or XPCE symbol-table.",
    "prefix":"getpass"
  },
  "git:git/2": {
    "body": ["git(${1:Argv}, ${2:Options})$3\n$0" ],
    "description":"  git(+Argv, +Options) is det.\n\n   Run a GIT command.  Defined options:\n\n     * directory(+Dir)\n     Execute in the given directory\n     * output(-Out)\n     Unify Out with a list of codes representing stdout of the\n     command.  Otherwise the output is handed to print_message/2\n     with level =informational=.\n     * error(-Error)\n     As output(Out), but messages are printed at level =error=.\n     * askpass(+Program)\n     Export GIT_ASKPASS=Program",
    "prefix":"git"
  },
  "git:git_branches/2": {
    "body": ["git_branches(${1:Branches}, ${2:Options})$3\n$0" ],
    "description":"  git_branches(-Branches, +Options) is det.\n\n   True when Branches is the list of branches in the repository.\n   In addition to the usual options, this processes:\n\n     - contains(Commit)\n     Return only branches that contain Commit.",
    "prefix":"git_branches"
  },
  "git:git_commit_data/3": {
    "body": [
      "git_commit_data(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"git_commit_data('Param1','Param2','Param3')",
    "prefix":"git_commit_data"
  },
  "git:git_default_branch/2": {
    "body": ["git_default_branch(${1:BranchName}, ${2:Options})$3\n$0" ],
    "description":"  git_default_branch(-BranchName, +Options) is det.\n\n   True when BranchName is the default branch of a repository.",
    "prefix":"git_default_branch"
  },
  "git:git_describe/2": {
    "body": ["git_describe(${1:Version}, ${2:Options})$3\n$0" ],
    "description":"  git_describe(-Version, +Options) is semidet.\n\n   Describe the running version  based  on   GIT  tags  and hashes.\n   Options:\n\n       * match(+Pattern)\n       Only use tags that match Pattern (a Unix glob-pattern; e.g.\n       =|V*|=)\n       * directory(Dir)\n       Provide the version-info for a directory that is part of\n       a GIT-repository.\n       * commit(+Commit)\n       Describe Commit rather than =HEAD=\n\n   @see git describe",
    "prefix":"git_describe"
  },
  "git:git_hash/2": {
    "body": ["git_hash(${1:Hash}, ${2:Options})$3\n$0" ],
    "description":"  git_hash(-Hash, +Options) is det.\n\n   Return the hash of the indicated object.",
    "prefix":"git_hash"
  },
  "git:git_log_data/3": {
    "body": ["git_log_data(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"git_log_data('Param1','Param2','Param3')",
    "prefix":"git_log_data"
  },
  "git:git_ls_remote/3": {
    "body": ["git_ls_remote(${1:GitURL}, ${2:Refs}, ${3:Options})$4\n$0" ],
    "description":"  git_ls_remote(+GitURL, -Refs, +Options) is det.\n\n   Execute =|git ls-remote|= against the remote repository to fetch\n   references from the remote.  Options processed:\n\n     * heads(Boolean)\n     * tags(Boolean)\n     * refs(List)\n\n   For example, to find the hash of the remote =HEAD=, one can use\n\n     ==\n     ?- git_ls_remote('git://www.swi-prolog.org/home/pl/git/pl-devel.git',\n                      Refs, [refs(['HEAD'])]).\n     Refs = ['5d596c52aa969d88e7959f86327f5c7ff23695f3'-'HEAD'].\n     ==\n\n   @param Refs is a list of pairs hash-name.",
    "prefix":"git_ls_remote"
  },
  "git:git_ls_tree/2": {
    "body": ["git_ls_tree(${1:Entries}, ${2:Options})$3\n$0" ],
    "description":"  git_ls_tree(-Entries, +Options) is det.\n\n   True  when  Entries  is  a  list  of  entries  in  the  the  GIT\n   repository, Each entry is a term:\n\n     ==\n     object(Mode, Type, Hash, Size, Name)\n     ==",
    "prefix":"git_ls_tree"
  },
  "git:git_open_file/4": {
    "body": [
      "git_open_file(${1:GitRepoDir}, ${2:File}, ${3:Branch}, ${4:Stream})$5\n$0"
    ],
    "description":"  git_open_file(+GitRepoDir, +File, +Branch, -Stream) is det.\n\n   Open the file File in the given bare GIT repository on the given\n   branch (treeisch).\n\n   @bug    We cannot tell whether opening failed for some reason.",
    "prefix":"git_open_file"
  },
  "git:git_process_output/3": {
    "body": ["git_process_output(${1:Argv}, ${2:OnOutput}, ${3:Options})$4\n$0" ],
    "description":"  git_process_output(+Argv, :OnOutput, +Options) is det.\n\n   Run a git-command and process the output with OnOutput, which is\n   called as call(OnOutput, Stream).",
    "prefix":"git_process_output"
  },
  "git:git_remote_branches/2": {
    "body": ["git_remote_branches(${1:GitURL}, ${2:Branches})$3\n$0" ],
    "description":"  git_remote_branches(+GitURL, -Branches) is det.\n\n   Exploit git_ls_remote/3 to fetch  the   branches  from  a remote\n   repository without downloading it.",
    "prefix":"git_remote_branches"
  },
  "git:git_remote_url/3": {
    "body": ["git_remote_url(${1:Remote}, ${2:URL}, ${3:Options})$4\n$0" ],
    "description":"  git_remote_url(+Remote, -URL, +Options) is det.\n\n   URL is the remote (fetch) URL for the given Remote.",
    "prefix":"git_remote_url"
  },
  "git:git_shortlog/3": {
    "body": ["git_shortlog(${1:Dir}, ${2:ShortLog}, ${3:Options})$4\n$0" ],
    "description":"  git_shortlog(+Dir, -ShortLog, +Options) is det.\n\n   Fetch information like the  GitWeb   change  overview. Processed\n   options:\n\n       * limit(+Count)\n       Maximum number of commits to show (default is 10)\n       * path(+Path)\n       Only show commits that affect Path.  Path is the path of\n       a checked out file.\n       * git_path(+Path)\n       Similar to =path=, but Path is relative to the repository.\n\n   @param ShortLog is a list of =git_log= records.",
    "prefix":"git_shortlog"
  },
  "git:git_show/4": {
    "body": ["git_show(${1:Dir}, ${2:Hash}, ${3:Commit}, ${4:Options})$5\n$0" ],
    "description":"  git_show(+Dir, +Hash, -Commit, +Options) is det.\n\n   Fetch info from a GIT commit.  Options processed:\n\n     * diff(Diff)\n     GIT option on how to format diffs.  E.g. =stat=\n     * max_lines(Count)\n     Truncate the body at Count lines.\n\n   @param  Commit is a term git_commit(...)-Body.  Body is currently\n           a list of lines, each line represented as a list of\n           codes.",
    "prefix":"git_show"
  },
  "git:git_tags_on_branch/3": {
    "body": ["git_tags_on_branch(${1:Dir}, ${2:Branch}, ${3:Tags})$4\n$0" ],
    "description":"  git_tags_on_branch(+Dir, +Branch, -Tags) is det.\n\n   Tags is a list of tags in Branch on the GIT repository Dir, most\n   recent tag first.\n\n   @see Git tricks at http://mislav.uniqpath.com/2010/07/git-tips/",
    "prefix":"git_tags_on_branch"
  },
  "git:is_git_directory/1": {
    "body": ["is_git_directory(${1:Directory})$2\n$0" ],
    "description":"  is_git_directory(+Directory) is semidet.\n\n   True if Directory is a  git   directory  (Either  checked out or\n   bare).",
    "prefix":"is_git_directory"
  },
  "goal_expansion/2": {
    "body":"goal_expansion(${1:Goal1}, ${2:Goal2})$3\n$0",
    "description":"goal_expansion(+Goal1, -Goal2).\nLike term_expansion/2, goal_expansion/2  provides for macro expansion of Prolog source code. Between expand_term/2  and the actual compilation, the body of clauses analysed and the goals  are handed to expand_goal/2,  which uses the goal_expansion/2  hook to do user-defined expansion.  The predicate goal_expansion/2  is first called in the module that is being compiled, and then follows  the module inheritance path as defined by default_module/2,  i.e., by default user and system. If Goal  is of the form Module:Goal where Module  is instantiated, goal_expansion/2  is called on Goal using rules from module Module  followed by default modules for Module. \n\nOnly goals appearing in the body of clauses when reading a source  file are expanded using this mechanism, and only if they appear  literally in the clause, or as an argument to a defined meta-predicate  that is annotated using `0' (see meta_predicate/1).  Other cases need a real predicate definition. \n\nThe expansion hook can use prolog_load_context/2  to obtain information about the context in which the goal is exanded  such as the module, variable names or the encapsulating term.\n\n",
    "prefix":"goal_expansion"
  },
  "goal_expansion/4": {
    "body":"goal_expansion(${1:Goal1}, ${2:Layout1}, ${3:Goal2}, ${4:Layout2})$5\n$0",
    "description":"goal_expansion(+Goal1, ?Layout1, -Goal2, -Layout2).\n",
    "prefix":"goal_expansion"
  },
  "ground/1": {
    "body":"ground(${1:Term})$2\n$0",
    "description":"[ISO]ground(@Term).\nTrue if Term holds no free variables.",
    "prefix":"ground"
  },
  "gspy/1": {
    "body":"gspy(${1:Predicate})$2\n$0",
    "description":"gspy(+Predicate).\nUtility defined as guitracer,spy(Predicate).",
    "prefix":"gspy"
  },
  "gtrace/0": {
    "body":"gtrace$1\n$0",
    "description":"gtrace.\nUtility defined as guitracer,trace.",
    "prefix":"gtrace"
  },
  "gui_tracer:gdebug/0": {
    "body": ["gdebug$1\n$0" ],
    "description":"  gdebug is det.\n\n   Same as debug/0, but uses the graphical tracer.",
    "prefix":"gdebug"
  },
  "gui_tracer:gspy/1": {
    "body": ["gspy(${1:Spec})$2\n$0" ],
    "description":"  gspy(:Spec) is det.\n\n   Same as spy/1, but uses the graphical debugger.",
    "prefix":"gspy"
  },
  "gui_tracer:gtrace/0": {
    "body": ["gtrace$1\n$0" ],
    "description":"  gtrace is det.\n\n   Like trace/0, but uses the graphical tracer.",
    "prefix":"gtrace"
  },
  "gui_tracer:gtrace/1": {
    "body": ["gtrace(${1:Goal})$2\n$0" ],
    "description":"  gtrace(:Goal) is det.\n\n   Trace Goal in a separate thread,  such that the toplevel remains\n   free for user interaction.",
    "prefix":"gtrace"
  },
  "gui_tracer:guitracer/0": {
    "body": ["guitracer$1\n$0" ],
    "description":"  guitracer is det.\n\n   Enable the graphical debugger.  A   subsequent  call  to trace/0\n   opens the de debugger window. The   tranditional debugger can be\n   re-enabled using noguitracer/0.",
    "prefix":"guitracer"
  },
  "gui_tracer:noguitracer/0": {
    "body": ["noguitracer$1\n$0" ],
    "description":"  noguitracer is det.\n\n   Disable the graphical debugger.\n\n   @see guitracer/0",
    "prefix":"noguitracer"
  },
  "guitracer/0": {
    "body":"guitracer$1\n$0",
    "description":"guitracer.\nThis predicate installs the above-mentioned hooks that redirect tracing  to the window-based environment. No window appears. The debugger window  appears as actual tracing is started through trace/0,  by hitting a spy point defined by spy/1  or a break point defined using the PceEmacs command Prolog/Break  at (Control-c b).",
    "prefix":"guitracer"
  },
  "gxref/0": {
    "body":"gxref$1\n$0",
    "description":"gxref.\nRun cross-referencer on all currently loaded files and present a  graphical overview of the result. As the predicate operates on the  currently loaded application it must be run after loading the  application.",
    "prefix":"gxref"
  },
  "gzopen/3": {
    "body":"gzopen(${1:File}, ${2:Mode}, ${3:Stream})$4\n$0",
    "description":"gzopen(+File, +Mode, -Stream).\nSame as gzopen(File, Mode, Stream,[]).",
    "prefix":"gzopen"
  },
  "gzopen/4": {
    "body":"gzopen(${1:File}, ${2:Mode}, ${3:Stream}, ${4:Options})$5\n$0",
    "description":"gzopen(+File, +Mode, -Stream, +Options).\nOpen gzip compatible File for reading or writing. If a  file is opened in =append= mode, a new gzip image will be added to the  end of the file. The gzip standard defines that a file can hold multiple  gzip images and inflating the file results in a concatenated stream of  all inflated images. Options are passed to open/4  and zopen/3.  Default format is gzip.",
    "prefix":"gzopen"
  },
  "halt/1": {
    "body":"halt(${1:Status})$2\n$0",
    "description":"[ISO]halt(+Status).\nTerminate Prolog execution with Status. This predicate calls PL_halt() which  preforms the following steps:  \n\nSet the Prolog flag exit_status  to Status.  \nCall all hooks registered using at_halt/1.  If Status equals 0 (zero), any of these hooks calls cancel_halt/1,  termination is cancelled.  \nCall all hooks registered using PL_at_halt(). In the future,  if any of these hooks returns non-zero, termination will be cancelled.  Currently, this only prints a warning.  \nPerform the following system cleanup actions:  Cancel all threads, calling thread_at_exit/1  registered termination hooks. Threads not responding within 1 second are  cancelled forcefully.Flush I/O and close all streams except for standard I/O.Reset the terminal if its properties were changed.Remove temporary files and incomplete compilation output.Reclaim memory.  \nCall exit(Status) to terminate the process\n\n",
    "prefix":"halt"
  },
  "hash_stream:alarm/3": {
    "body":"alarm(${1:Time}, ${2:Callable}, ${3:Id})$4\n$0",
    "description":"alarm(+Time, :Callable, -Id).\nSame as alarm(Time, Callable, Id,[]).",
    "prefix":"alarm"
  },
  "hash_stream:alarm/4": {
    "body":"alarm(${1:Time}, ${2:Callable}, ${3:Id}, ${4:Options})$5\n$0",
    "description":"alarm(+Time, :Callable, -Id, +Options).\nSchedule Callable to be called Time seconds from  now. Time is a number (integer or float). Callable is  called on the next pass through a call- or redo-port of the Prolog  engine, or a call to the PL_handle_signals() routine from  SWI-Prolog. Id is unified with a reference to the timer.  The resolution of the alarm depends on the underlying implementation,  which is based on pthread_cond_timedwait() (on Windows on the pthread  emulation thereof). Long-running foreign predicates that do not call PL_handle_signals() may further delay the alarm. The relation to  blocking system calls (sleep, reading from slow devices, etc.) is  undefined and varies between implementations. \n\nOptions is a list of Name(Value)  terms. Defined options are: \n\nremove(Bool): If true (default false), the timer is removed  automatically after fireing. Otherwise it must be destroyed explicitly  using remove_alarm/1.\n\ninstall(Bool): If false (default true), the timer is  allocated but not scheduled for execution. It must be started later  using install_alarm/1.\n\n ",
    "prefix":"alarm"
  },
  "hash_stream:alarm_at/4": {
    "body":"alarm_at(${1:Time}, ${2:Callable}, ${3:Id}, ${4:Options})$5\n$0",
    "description":"alarm_at(+Time, :Callable, -Id, +Options).\nas alarm/3,  but Time is the specification of an absolute point in time.  Absolute times are specified in seconds after the Jan 1, 1970 epoch. See  also date_time_stamp/2.",
    "prefix":"alarm_at"
  },
  "hash_stream:atom_to_memory_file/2": {
    "body":"atom_to_memory_file(${1:Atom}, ${2:Handle})$3\n$0",
    "description":"atom_to_memory_file(+Atom, -Handle).\nTurn an atom into a read-only memory-file containing the (shared)  characters of the atom. Opening this memory-file in mode write  yields a permission error.",
    "prefix":"atom_to_memory_file"
  },
  "hash_stream:call_with_time_limit/2": {
    "body":"call_with_time_limit(${1:Time}, ${2:Goal})$3\n$0",
    "description":"call_with_time_limit(+Time, :Goal).\nTrue if Goal completes within Time seconds. Goal  is executed as in once/1.  If Goal doesn't complete within Time seconds (wall  time), exit using the exception time_limit_exceeded. See catch/3.  Please note that this predicate uses alarm/4  and therefore its effect on long-running foreign code and system calls  is undefined. Blocking I/O can be handled using the timeout option of read_term/3.\n\n",
    "prefix":"call_with_time_limit"
  },
  "hash_stream:current_alarm/4": {
    "body":"current_alarm(${1:At}, ${2:Callable}, ${3:Id}, ${4:Status})$5\n$0",
    "description":"current_alarm(?At, ?:Callable, ?Id, ?Status).\nEnumerate the not-yet-removed alarms. Status is one of done if the alarm has been called, next if it  is the next to be fired and scheduled otherwise.",
    "prefix":"current_alarm"
  },
  "hash_stream:delete_memory_file/3": {
    "body":"delete_memory_file(${1:Handle}, ${2:Offset}, ${3:Length})$4\n$0",
    "description":"delete_memory_file(+Handle, +Offset, +Length).\nDelete a Length characters from the memory file, starting at Offset. This predicate raises a domain_error exception if Offset or Offset+Length is out of range and a  permission_error if the memory file is read-only or opened.",
    "prefix":"delete_memory_file"
  },
  "hash_stream:free_memory_file/1": {
    "body":"free_memory_file(${1:Handle})$2\n$0",
    "description":"free_memory_file(+Handle).\nDiscard the memory file and its contents. If the file is open it is  first closed.",
    "prefix":"free_memory_file"
  },
  "hash_stream:insert_memory_file/3": {
    "body":"insert_memory_file(${1:Handle}, ${2:Offset}, ${3:Data})$4\n$0",
    "description":"insert_memory_file(+Handle, +Offset, +Data).\nInsert Data into the memory file at location Offset.  The offset is specified in characters. Data can be an atom,  string, code or character list. Other terms are first serialized using writeq/1.  This predicate raises a domain_error exception if Offset is  out of range and a permission_error if the memory file is read-only or  opened.",
    "prefix":"insert_memory_file"
  },
  "hash_stream:install_alarm/1": {
    "body":"install_alarm(${1:Id})$2\n$0",
    "description":"install_alarm(+Id).\nActivate an alarm allocated using alarm/4  with the option install(false) or stopped using uninstall_alarm/1.",
    "prefix":"install_alarm"
  },
  "hash_stream:install_alarm/2": {
    "body":"install_alarm(${1:Id}, ${2:Time})$3\n$0",
    "description":"install_alarm(+Id, +Time).\nAs install_alarm/1,  but specifies a new (relative) timeout value.",
    "prefix":"install_alarm"
  },
  "hash_stream:md5_hash/3": {
    "body":"md5_hash(${1:Data}, ${2:Hash}, ${3:Options})$4\n$0",
    "description":"[det]md5_hash(+Data, -Hash, +Options).\nHash is the MD5 hash of Data, The conversion is  controlled by Options:  encoding(+Encoding): If Data is a sequence of character codes, this must be  translated into a sequence of bytes, because that is what the  hashing requires. The default encoding is utf8. The other  meaningful value is octet, claiming that Data  contains raw bytes.\n\n  Data is either an atom, string,  code-list or char-list. Hash is an atom holding 32  characters, representing the hash in hexadecimal notation ",
    "prefix":"md5_hash"
  },
  "hash_stream:memory_file_line_position/4": {
    "body":"memory_file_line_position(${1:MF}, ${2:Line}, ${3:LinePos}, ${4:Offset})$5\n$0",
    "description":"memory_file_line_position(+MF, ?Line, ?LinePos, ?Offset).\nTrue if the character offset Offset corresponds with the LinePos character on line Line. Lines are counted  from one (1). Note that LinePos is not the column  as each character counts for one, including backspace and tab.",
    "prefix":"memory_file_line_position"
  },
  "hash_stream:memory_file_substring/5": {
    "body":"memory_file_substring(${1:Handle}, ${2:Before}, ${3:Length}, ${4:After}, ${5:SubString})$6\n$0",
    "description":"memory_file_substring(+Handle, ?Before, ?Length, ?After, -SubString).\nSubString is a substring of the memory file. There are Before characters in the memory file before SubString, SubString contains Length character and is  followed by After characters in the memory file. The signature is the  same as sub_string/5  and sub_atom/5,  but currently at least two of the 3 position arguments must be  specified. Future versions might implement the full functionality of sub_string/5.",
    "prefix":"memory_file_substring"
  },
  "hash_stream:memory_file_to_atom/2": {
    "body":"memory_file_to_atom(${1:Handle}, ${2:Atom})$3\n$0",
    "description":"memory_file_to_atom(+Handle, -Atom).\nReturn the content of the memory-file in Atom.",
    "prefix":"memory_file_to_atom"
  },
  "hash_stream:memory_file_to_atom/3": {
    "body":"memory_file_to_atom(${1:Handle}, ${2:Atom}, ${3:Encoding})$4\n$0",
    "description":"memory_file_to_atom(+Handle, -Atom, +Encoding).\nReturn the content of the memory-file in Atom, pretending the  data is in the given Encoding. This can be used to convert  from one encoding into another, typically from/to bytes. For example, if  we must convert a set of bytes that contain text in UTF-8, open the  memory file as octet stream, fill it, and get the result using Encoding  is utf8.",
    "prefix":"memory_file_to_atom"
  },
  "hash_stream:memory_file_to_codes/2": {
    "body":"memory_file_to_codes(${1:Handle}, ${2:Codes})$3\n$0",
    "description":"memory_file_to_codes(+Handle, -Codes).\nReturn the content of the memory-file as a list of character-codes in Codes.",
    "prefix":"memory_file_to_codes"
  },
  "hash_stream:memory_file_to_codes/3": {
    "body":"memory_file_to_codes(${1:Handle}, ${2:Codes}, ${3:Encoding})$4\n$0",
    "description":"memory_file_to_codes(+Handle, -Codes, +Encoding).\nReturn the content of the memory-file as a list of character-codes in Codes,  pretending the data is in the given Encoding.",
    "prefix":"memory_file_to_codes"
  },
  "hash_stream:memory_file_to_string/2": {
    "body":"memory_file_to_string(${1:Handle}, ${2:String})$3\n$0",
    "description":"memory_file_to_string(+Handle, -String).\nReturn the content of the memory-file as a string in -String.",
    "prefix":"memory_file_to_string"
  },
  "hash_stream:memory_file_to_string/3": {
    "body":"memory_file_to_string(${1:Handle}, ${2:String}, ${3:Encoding})$4\n$0",
    "description":"memory_file_to_string(+Handle, -String, +Encoding).\nReturn the content of the memory-file as a string in String,  pretending the data is in the given Encoding.",
    "prefix":"memory_file_to_string"
  },
  "hash_stream:new_memory_file/1": {
    "body":"new_memory_file(${1:Handle})$2\n$0",
    "description":"new_memory_file(-Handle).\nCreate a new memory file and return a unique opaque handle to it.",
    "prefix":"new_memory_file"
  },
  "hash_stream:open_hash_stream/3": {
    "body":"open_hash_stream(${1:OrgStream}, ${2:HashStream}, ${3:Options})$4\n$0",
    "description":"[det]open_hash_stream(+OrgStream, -HashStream, +Options).\nOpen a filter stream on OrgStream that maintains a hash. The  hash can be retrieved at any time using stream_hash/2.  Provided options:  algorithm(+Algorithm): One of md5, sha1, sha224, sha256, sha384  or sha512. Default is sha1.\n\nclose_parent(+Bool): If true (default), closing the filter stream also closes  the original (parent) stream.\n\n ",
    "prefix":"open_hash_stream"
  },
  "hash_stream:open_memory_file/3": {
    "body":"open_memory_file(${1:Handle}, ${2:Mode}, ${3:Stream})$4\n$0",
    "description":"open_memory_file(+Handle, +Mode, -Stream).\nOpen the memory-file. Mode is one of read, write, append, update or insert. The  resulting Stream must be closed using close/1.  When opened for update or insert, the current location is  initialized at the start of the data and can be modified using seek/2  or set_stream_position/2.  In update mode, existing content is replaced, while the  size is enlarged after hitting the end of the data. In insert  mode, the new data is inserted at the current point.",
    "prefix":"open_memory_file"
  },
  "hash_stream:open_memory_file/4": {
    "body":"open_memory_file(${1:Handle}, ${2:Mode}, ${3:Stream}, ${4:Options})$5\n$0",
    "description":"open_memory_file(+Handle, +Mode, -Stream, +Options).\nOpen a memory-file as open_memory_file/3.  Options:  encoding(+Encoding): Set the encoding for a memory file and the created stream. Encoding  names are the same as used with open/4.  By default, memoryfiles represent UTF-8 streams, making them capable of  storing arbitrary Unicode text. In practice the only alternative is octet,  turning the memoryfile into binary mode. Please study SWI-Prolog Unicode  and encoding issues before using this option.\n\nfree_on_close(+Bool): If true (default false and the memory file is  opened for reading, discard the file (see free_memory_file/1)  if the input is closed. This is used to realise open_chars_stream/2  in library(charsio).\n\n ",
    "prefix":"open_memory_file"
  },
  "hash_stream:remove_alarm/1": {
    "body":"remove_alarm(${1:Id})$2\n$0",
    "description":"remove_alarm(+Id).\nRemove an alarm. If it is not yet fired, it will not be fired any more.",
    "prefix":"remove_alarm"
  },
  "hash_stream:size_memory_file/2": {
    "body":"size_memory_file(${1:Handle}, ${2:Size})$3\n$0",
    "description":"size_memory_file(+Handle, -Size).\nReturn the content-length of the memory-file in characters in the  current encoding of the memory file. The file should be closed and  contain data.",
    "prefix":"size_memory_file"
  },
  "hash_stream:size_memory_file/3": {
    "body":"size_memory_file(${1:Handle}, ${2:Size}, ${3:Encoding})$4\n$0",
    "description":"size_memory_file(+Handle, -Size, +Encoding).\nReturn the content-length of the memory-file it characters in the given Encoding. The file should be closed and contain data.",
    "prefix":"size_memory_file"
  },
  "hash_stream:stream_hash/2": {
    "body":"stream_hash(${1:HashStream}, ${2:Digest})$3\n$0",
    "description":"[det]stream_hash(+HashStream, -Digest:atom).\nUnify Digest with a hash for the bytes send to or read from HashStream. Note that the hash is computed on the stream  buffers. If the stream is an output stream, it is first flushed and the Digest  represents the hash at the current location. If the stream is an input  stream the Digest represents the hash of the processed input  including the already buffered data.",
    "prefix":"stream_hash"
  },
  "hash_stream:uninstall_alarm/1": {
    "body":"uninstall_alarm(${1:Id})$2\n$0",
    "description":"uninstall_alarm(+Id).\nDeactivate a running alarm, but do not invalidate the alarm identifier.  Later, the alarm can be reactivated using either install_alarm/1  or install_alarm/2.  Reinstalled using install_alarm/1,  it will fire at the originally scheduled time. Reinstalled using install_alarm/2  causes the alarm to fire at the specified time from now.",
    "prefix":"uninstall_alarm"
  },
  "heaps:add_to_heap/4": {
    "body": ["add_to_heap(${1:Heap0}, ${2:Priority}, ${3:Key}, ${4:Heap})$5\n$0" ],
    "description":"  add_to_heap(+Heap0, +Priority, ?Key, -Heap) is semidet.\n\n   Adds Key with priority Priority  to   Heap0,  constructing a new\n   heap in Heap.",
    "prefix":"add_to_heap"
  },
  "heaps:delete_from_heap/4": {
    "body": [
      "delete_from_heap(${1:Heap0}, ${2:Priority}, ${3:Key}, ${4:Heap})$5\n$0"
    ],
    "description":"  delete_from_heap(+Heap0, -Priority, +Key, -Heap) is semidet.\n\n   Deletes Key from Heap0, leaving its priority in Priority and the\n   resulting data structure in Heap.   Fails if Key is not found in\n   Heap0.\n\n   @bug This predicate is extremely inefficient and exists only for\n        SICStus compatibility.",
    "prefix":"delete_from_heap"
  },
  "heaps:empty_heap/1": {
    "body": ["empty_heap(${1:Heap})$2\n$0" ],
    "description":"  empty_heap(?Heap) is semidet.\n\n   True if Heap is an empty heap. Complexity: constant.",
    "prefix":"empty_heap"
  },
  "heaps:get_from_heap/4": {
    "body": [
      "get_from_heap(${1:Heap0}, ${2:Priority}, ${3:Key}, ${4:Heap})$5\n$0"
    ],
    "description":"  get_from_heap(?Heap0, ?Priority, ?Key, -Heap) is semidet.\n\n   Retrieves the minimum-priority  pair   Priority-Key  from Heap0.\n   Heap is Heap0 with that pair removed.   Complexity:  logarithmic\n   (amortized), linear in the worst case.",
    "prefix":"get_from_heap"
  },
  "heaps:heap_size/2": {
    "body": ["heap_size(${1:Heap}, ${2:Size})$3\n$0" ],
    "description":"  heap_size(+Heap, -Size:int) is det.\n\n   Determines the number of elements in Heap. Complexity: constant.",
    "prefix":"heap_size"
  },
  "heaps:heap_to_list/2": {
    "body": ["heap_to_list(${1:Heap}, ${2:List})$3\n$0" ],
    "description":"  heap_to_list(+Heap, -List:list) is det.\n\n   Constructs a list List  of   Priority-Element  terms, ordered by\n   (ascending) priority. Complexity: $O(n \\log n)$.",
    "prefix":"heap_to_list"
  },
  "heaps:is_heap/1": {
    "body": ["is_heap(${1:X})$2\n$0" ],
    "description":"  is_heap(+X) is semidet.\n\n   Returns true if X is a heap.  Validates the consistency of the\n   entire heap. Complexity: linear.",
    "prefix":"is_heap"
  },
  "heaps:list_to_heap/2": {
    "body": ["list_to_heap(${1:List}, ${2:Heap})$3\n$0" ],
    "description":"  list_to_heap(+List:list, -Heap) is det.\n\n   If List is a list of  Priority-Element  terms, constructs a heap\n   out of List. Complexity: linear.",
    "prefix":"list_to_heap"
  },
  "heaps:merge_heaps/3": {
    "body": ["merge_heaps(${1:Heap0}, ${2:Heap1}, ${3:Heap})$4\n$0" ],
    "description":"  merge_heaps(+Heap0, +Heap1, -Heap) is det.\n\n   Merge the two heaps Heap0 and Heap1 in Heap. Complexity: constant.",
    "prefix":"merge_heaps"
  },
  "heaps:min_of_heap/3": {
    "body": ["min_of_heap(${1:Heap}, ${2:Priority}, ${3:Key})$4\n$0" ],
    "description":"  min_of_heap(+Heap, ?Priority, ?Key) is semidet.\n\n   Unifies Key with  the  minimum-priority   element  of  Heap  and\n   Priority with its priority value. Complexity: constant.",
    "prefix":"min_of_heap"
  },
  "heaps:min_of_heap/5": {
    "body": [
      "min_of_heap(${1:Heap}, ${2:Priority1}, ${3:Key1}, ${4:Priority2}, ${5:Key2})$6\n$0"
    ],
    "description":"  min_of_heap(+Heap, ?Priority1, ?Key1, ?Priority2, ?Key2) is semidet.\n\n   Gets the two minimum-priority elements from Heap. Complexity: logarithmic\n   (amortized).\n\n   Do not use this predicate; it exists for compatibility with earlier\n   implementations of this library and the SICStus counterpart. It performs\n   a linear amount of work in the worst case that a following get_from_heap\n   has to re-do.",
    "prefix":"min_of_heap"
  },
  "heaps:singleton_heap/3": {
    "body": ["singleton_heap(${1:Heap}, ${2:Priority}, ${3:Key})$4\n$0" ],
    "description":"  singleton_heap(?Heap, ?Priority, ?Key) is semidet.\n\n   True if Heap is a heap with the single element Priority-Key.\n\n   Complexity: constant.",
    "prefix":"singleton_heap"
  },
  "help/0": {
    "body":"help$1\n$0",
    "description":"help.\nEquivalent to help(help/1).",
    "prefix":"help"
  },
  "help/1": {
    "body":"help(${1:What})$2\n$0",
    "description":"help(+What).\nShow specified part of the manual. What is one of: <Name>/<Arity> Give  help on specified predicate <Name> Give help on named  predicate with any arity or C interface function with that name <Section> Display  specified section. Section numbers are dash-separated numbers: 2-3  refers to section 2.3 of the manual. Section numbers are obtained using apropos/1.  Examples:\n\n?- help(assert). Give help on  predicate assert ?- help(3-4). Display section  3.4 of the manual ?- help('PL_retry').Give help  on interface function PL_retry()   See also apropos/1  and the SWI-Prolog home page at http://www.swi-prolog.org,  which provides a FAQ, an HTML version of the manual for online browsing,  and HTML and PDF versions for downloading.\n\n",
    "prefix":"help"
  },
  "help_index:function/3": {
    "body": ["function(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"function('Param1','Param2','Param3')",
    "prefix":"function"
  },
  "help_index:predicate/5": {
    "body": [
      "predicate(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"predicate('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"predicate"
  },
  "help_index:section/4": {
    "body": [
      "section(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"section('Param1','Param2','Param3','Param4')",
    "prefix":"section"
  },
  "http/authenticate:http_authenticate/3": {
    "body": ["http_authenticate(${1:Type}, ${2:Request}, ${3:Fields})$4\n$0" ],
    "description":"  http_authenticate(+Type, +Request, -Fields)\n\n   True if Request contains the   information to continue according\n   to Type. Type identifies the required authentication technique:\n\n           * basic(+PasswordFile)\n           Use HTTP =Basic= authetication and verify the password\n           from PasswordFile. PasswordFile is a file holding\n           usernames and passwords in a format compatible to\n           Unix and Apache. Each line is record with =|:|=\n           separated fields. The first field is the username and\n           the second the password _hash_.  Password hashes are\n           validated using crypt/2.\n\n   Successful authorization is  cached  for   60  seconds  to avoid\n   overhead of decoding and lookup of the user and password data.\n\n   http_authenticate/3 just validates the  header. If authorization\n   is not provided the browser must   be challenged, in response to\n   which it normally opens a   user-password dialogue. Example code\n   realising this is below. The exception   causes the HTTP wrapper\n   code to generate an HTTP 401 reply.\n\n   ==\n   (   http_authenticate(basic(passwd), Request, Fields)\n   ->  true\n   ;   throw(http_reply(authorise(basic, Realm)))\n   ).\n   ==\n\n   @param  Fields is a list of fields from the password-file entry.\n           The first element is the user.  The hash is skipped.\n   @tbd    Should we also cache failures to reduce the risc of\n           DoS attacks?",
    "prefix":"http_authenticate"
  },
  "http/authenticate:http_authorization_data/2": {
    "body": ["http_authorization_data(${1:AuthorizeText}, ${2:Data})$3\n$0" ],
    "description":"  http_authorization_data(+AuthorizeText, ?Data) is semidet.\n\n   Decode the HTTP =Authorization= header.  Data is a term\n\n       Method(User, Password)\n\n   where Method is the (downcased)  authorization method (typically\n   =basic=), User is an atom holding the  user name and Password is\n   a list of codes holding the password",
    "prefix":"http_authorization_data"
  },
  "http/authenticate:http_current_user/3": {
    "body": ["http_current_user(${1:File}, ${2:User}, ${3:Fields})$4\n$0" ],
    "description":"  http_current_user(+File, ?User, ?Fields) is nondet.\n\n   True when User is present in the htpasswd file File and Fields\n   provides the additional fields.\n\n   @arg    Fields are the fields from the password file File,\n           converted using name/2, which means that numeric values\n           are passed as numbers and other fields as atoms.  The\n           password hash is the first element of Fields and is\n           a string.",
    "prefix":"http_current_user"
  },
  "http/authenticate:http_read_passwd_file/2": {
    "body": ["http_read_passwd_file(${1:Path}, ${2:Data})$3\n$0" ],
    "description":"  http_read_passwd_file(+Path, -Data) is det.\n\n   Read a password file. Data is  a   list  of  terms of the format\n   below, where User is an atom  identifying   the  user, Hash is a\n   string containing the salted password   hash  and Fields contain\n   additional fields. The string value of   each field is converted\n   using name/2 to either a number or an atom.\n\n     ==\n     passwd(User, Hash, Fields)\n     ==",
    "prefix":"http_read_passwd_file"
  },
  "http/authenticate:http_write_passwd_file/2": {
    "body": ["http_write_passwd_file(${1:File}, ${2:Data})$3\n$0" ],
    "description":"  http_write_passwd_file(+File, +Data:list) is det.\n\n   Write password data Data to File. Data   is a list of entries as\n   below. See http_read_passwd_file/2 for details.\n\n     ==\n     passwd(User, Hash, Fields)\n     ==\n\n   @tbd    Write to a new file and atomically replace the old one.",
    "prefix":"http_write_passwd_file"
  },
  "http/html_head:html_current_resource/1": {
    "body":"html_current_resource(${1:About})$2\n$0",
    "description":"[nondet]html_current_resource(?About).\nTrue when About is a currently known resource.",
    "prefix":"html_current_resource"
  },
  "http/html_head:html_requires/1": {
    "body":"html_requires(${1:ResourceOrList})$2\n$0",
    "description":"[det]html_requires(+ResourceOrList)//.\nInclude ResourceOrList and all dependencies derived from it  and add them to the HTML head using html_post/2.  The actual dependencies are computed during the HTML output phase by html_insert_resource/3.",
    "prefix":"html_requires"
  },
  "http/html_head:html_requires/3": {
    "body": ["html_requires(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"html_requires('Param1','Param2','Param3')",
    "prefix":"html_requires"
  },
  "http/html_head:html_resource/2": {
    "body":"html_resource(${1:About}, ${2:Properties})$3\n$0",
    "description":"[det]html_resource(+About, +Properties).\nRegister an HTML head resource. About is either an atom that  specifies an HTTP location or a term Alias(Sub). This works similar to absolute_file_name/2.  See http:location_path/2 for details.  Recognised properties are:  requires(+Requirements): Other required script and css files. If this is a plain file name, it is  interpreted relative to the declared resource. Requirements  can be a list, which is equivalent to multiple requires properties.\n\nvirtual(+Bool): If true (default false), do not include About  itself, but only its dependencies. This allows for defining an alias for  one or more resources.\n\nordered(+Bool): Defines that the list of requirements is ordered, which means that each  requirement in the list depends on its predecessor.\n\naggregate(+List): States that About is an aggregate of the resources in List. This means that if both About and one of the  elements of List appears in the dependencies, About  is kept and the smaller one is dropped. If there are a number of  dependencies on the small members, these are replaced with dependency on  the big (aggregate) one, for example, to specify that a big javascript  is actually the composition of a number of smaller ones.\n\nmime_type(-Mime): May be specified for non-virtual resources to specify the mime-type of  the resource. By default, the mime type is derived from the file name  using file_mime_type/2.\n\n  Registering the same About multiple times extends the  properties defined for About. In particular, this allows for  adding additional dependencies to a (virtual) resource.\n\n",
    "prefix":"html_resource"
  },
  "http/html_head:js_arg/1": {
    "body":"js_arg(${1:Expression})$2\n$0",
    "description":"[semidet]js_arg(+Expression)//.\nSame as js_expression/3, but fails if Expression  is invalid, where js_expression/3 raises  an error.  deprecated: New code should use js_expression/3.\n\n ",
    "prefix":"js_arg"
  },
  "http/html_head:mime_include/2": {
    "body":"mime_include(${1:Mime}, ${2:Path})$3\n$0",
    "description":"[semidet,multifile]mime_include(+Mime, +Path)//.\nHook called to include a link to an HTML resource of type Mime  into the HTML head. The Mime type is computed from Path  using file_mime_type/2. If the hook fails, two  built-in rules for text/css and text/javascript are tried. For  example, to include a =.pl= files as a Prolog script, use:  \n\n:- multifile\n    html_head:mime_include//2.\n\nhtml_head:mime_include(text/'x-prolog', Path) --> !,\n    html(script([ type('text/x-prolog'),\n                  src(Path)\n                ],  [])).\n\n  \n\n",
    "prefix":"mime_include"
  },
  "http/html_quasi_quotations:html/4": {
    "body": ["html(${1:Content}, ${2:Vars}, ${3:VarDict}, ${4:DOM})$5\n$0" ],
    "description":"  html(+Content, +Vars, +VarDict, -DOM) is det.\n\n   The predicate html/4 implements  HTML   quasi  quotations. These\n   quotations produce a DOM term that   is suitable for html//1 and\n   other predicates that are declared to   consume this format. The\n   quasi quoter only  accepts  valid,   but  possibly  partial HTML\n   documents. The document *must* begin  with   a  tag.  The quoter\n   replaces attributes or content whose value  is a Prolog variable\n   that appears in the argument list   of  the =html= indicator. If\n   the variable defines content, it must  be the only content. Here\n   is  an  example,  replacing  both  a   content  element  and  an\n   attribute. Note that the document is valid HTML.\n\n     ==\n       html({|html(Name, URL)||\n              <p>Dear <span class=\"name\">Name<\/span>,\n\n              <p>You can <a href=\"URL\">download<\/a> the requested\n              article now.\n              |}\n     ==",
    "prefix":"html"
  },
  "http/html_write:html/1": {
    "body":"html(${1:Spec})$2\n$0",
    "description":"html(:Spec)//.\nThe DCG non-terminal html/3  is the main predicate of this library. It translates the specification  for an HTML page into a list of atoms that can be written to a stream  using print_html/[1,2].  The expansion rules of this predicate may be extended by defining the  multifile DCG html_write:expand//1. Spec is either a single  specification or a list of single specifications. Using nested lists is  not allowed to avoid ambiguity caused by the atom []  \n\nAtomic data Atomic data is quoted using html_quoted/3.  \nFmt - Args Fmt and Args are used as format-specification and  argument list to format/3.  The result is quoted and added to the output list.  \n\\List Escape sequence to add atoms directly to the output list. This can be  used to embed external HTML code or emit script output. List  is a list of the following terms:  Fmt - Args Fmt and Args are used as format-specification and  argument list to format/3.  The result is added to the output list.Atomic Atomic values are added directly to the output list.  \n\\Term Invoke the non-terminal Term in the calling module. This is  the common mechanism to realise abstraction and modularisation in  generating HTML.  \nModule:Term Invoke the non-terminal <Module>:<Term>.  This is similar to \\Term but allows for invoking grammar rules in  external packages.  \n&(Entity) Emit &<Entity>; or &#<Entity>;  if Entity is an integer. SWI-Prolog atoms and strings are  represented as Unicode. Explicit use of this construct is rarely needed  because code-points that are not supported by the output encoding are  automatically converted into character-entities.  \nTag(Content) Emit HTML element Tag using Content and no  attributes. Content is handed to html/3.  See section 3.19.4 for details on  the automatically generated layout.  \nTag(Attributes, Content) Emit HTML element Tag using Attributes and Content. Attributes is either a single attribute of a list of  attributes. Each attributes is of the format Name(Value) or Name=Value. Value is the atomic  attribute value but allows for a limited functional notation:  A + B Concatenation of A and BFormat-Arguments Use format/3  and emit the result as quoted value.encode(Atom) Use uri_encoded/3  to create a valid URL query component.location_by_id(ID) HTTP location of the HTTP handler with given ID. See http_location_by_id/2.A + List List is handled as a URL `search' component. The list members  are terms of the format Name = Value or Name(Value). Values are encoded as in the encode option  described above.List Emit SGML multi-valued attributes (e.g., NAMES). Each value  in list is separated by a space. This is particularly useful for setting  multiple class attributes on an element. For example:          ...         span(class([c1,c2]), ...),    The example below generates a URL that references the predicate set_lang/1  in the application with given parameters. The http_handler/3  declaration binds /setlang to the predicate set_lang/1  for which we provide a very simple implementation. The code between ...  is part of an HTML page showing the english flag which, when pressed,  calls set_lang(Request) where Request contains  the search parameter lang = en. Note that the  HTTP location (path) /setlang can be moved without  affecting this code. :- http_handler('/setlang', set_lang, []).  set_lang(Request) :-         http_parameters(Request,                         [ lang(Lang, [])                         ]),         http_session_retractall(lang(_)),         http_session_assert(lang(Lang)),         reply_html_page(title('Switched language'),                         p(['Switch language to ', Lang])).           ...         html(a(href(location_by_id(set_lang) + [lang(en)]),                img(src('/www/images/flags/en.png')))),         ...  \n\n",
    "prefix":"html"
  },
  "http/html_write:html/3": {
    "body": ["html(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"html('Param1','Param2','Param3')",
    "prefix":"html"
  },
  "http/html_write:html/4": {
    "body": [
      "html(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"html('Param1','Param2','Param3','Param4')",
    "prefix":"html"
  },
  "http/html_write:html_begin/1": {
    "body":"html_begin(${1:Begin})$2\n$0",
    "description":"html_begin(+Begin)//.\nJust open the given element. Begin is either an atom or a  compound term, In the latter case the arguments are used as arguments to  the begin-tag. Some examples:  \n\n        html_begin(table)\n        html_begin(table(border(2), align(center)))\n\n  This predicate provides an alternative to using the \\Command syntax in the html/3  specification. The following two fragments are the same. The preferred  solution depends on your preferences as well as whether the  specification is generated or entered by the programmer. \n\n\n\ntable(Rows) -->\n        html(table([border(1), align(center), width('80%')],\n                   [ \\table_header,\n                     \\table_rows(Rows)\n                   ])).\n\n% or\n\ntable(Rows) -->\n        html_begin(table(border(1), align(center), width('80%'))),\n        table_header,\n        table_rows,\n        html_end(table).\n\n ",
    "prefix":"html_begin"
  },
  "http/html_write:html_begin/3": {
    "body": ["html_begin(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"html_begin('Param1','Param2','Param3')",
    "prefix":"html_begin"
  },
  "http/html_write:html_current_option/1": {
    "body": ["html_current_option(${1:Option})$2\n$0" ],
    "description":"  html_current_option(?Option) is nondet.\n\n   True if Option is an active option for the HTML generator.",
    "prefix":"html_current_option"
  },
  "http/html_write:html_end/1": {
    "body":"html_end(${1:End})$2\n$0",
    "description":"html_end(+End)//.\nEnd an element. See html_begin/1  for details.",
    "prefix":"html_end"
  },
  "http/html_write:html_end/3": {
    "body": ["html_end(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"html_end('Param1','Param2','Param3')",
    "prefix":"html_end"
  },
  "http/html_write:html_meta/1": {
    "body": ["html_meta(${1:Heads})$2\n$0" ],
    "description":"  html_meta(+Heads) is det.\n\n   This directive can be used  to   declare  that an HTML rendering\n   rule takes HTML content as  argument.   It  has  two effects. It\n   emits  the  appropriate  meta_predicate/1    and  instructs  the\n   built-in editor (PceEmacs) to provide   proper colouring for the\n   arguments.  The  arguments  in  Head  are    the   same  as  for\n   meta_predicate or can be constant =html=.  For example:\n\n     ==\n     :- html_meta\n           page(html,html,?,?).\n     ==",
    "prefix":"html_meta"
  },
  "http/html_write:html_post/2": {
    "body":"html_post(${1:Id}, ${2:HTML})$3\n$0",
    "description":"[det]html_post(+Id, :HTML)//.\nReposition HTML to the receiving Id. The html_post/4  call processes HTML using html/3.  Embedded \\-commands are executed by mailman/1  from print_html/1 or html_print_length/2.  These commands are called in the calling context of the html_post/4  call.  A typical usage scenario is to get required CSS links in the document  head in a reusable fashion. First, we define css/3  as: \n\n\n\ncss(URL) -->\n        html_post(css,\n                  link([ type('text/css'),\n                         rel('stylesheet'),\n                         href(URL)\n                       ])).\n\n  Next we insert the unique CSS links, in the pagehead using the  following call to reply_html_page/2: \n\n\n\n        reply_html_page([ title(...),\n                          \\html_receive(css)\n                        ],\n                        ...)\n\n ",
    "prefix":"html_post"
  },
  "http/html_write:html_post/4": {
    "body": [
      "html_post(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"html_post('Param1','Param2','Param3','Param4')",
    "prefix":"html_post"
  },
  "http/html_write:html_print_length/2": {
    "body":"html_print_length(${1:List}, ${2:Length})$3\n$0",
    "description":"html_print_length(+List, -Length).\nWhen calling html_print/[1,2]  on List, Length characters will be produced.  Knowing the length is needed to provide the Content-length  field of an HTTP reply-header.",
    "prefix":"html_print_length"
  },
  "http/html_write:html_quoted/1": {
    "body":"html_quoted(${1:Atom})$2\n$0",
    "description":"html_quoted(+Atom)//.\nEmit the text in Atom, inserting entity-references for the  SGML special characters <&>.",
    "prefix":"html_quoted"
  },
  "http/html_write:html_quoted/3": {
    "body": ["html_quoted(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"html_quoted('Param1','Param2','Param3')",
    "prefix":"html_quoted"
  },
  "http/html_write:html_quoted_attribute/1": {
    "body":"html_quoted_attribute(${1:Atom})$2\n$0",
    "description":"html_quoted_attribute(+Atom)//.\nEmit the text in Atom suitable for use as an SGML attribute,  inserting entity-references for the SGML special characters <&>\".",
    "prefix":"html_quoted_attribute"
  },
  "http/html_write:html_quoted_attribute/3": {
    "body": [
      "html_quoted_attribute(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"html_quoted_attribute('Param1','Param2','Param3')",
    "prefix":"html_quoted_attribute"
  },
  "http/html_write:html_receive/1": {
    "body":"html_receive(${1:Id})$2\n$0",
    "description":"[det]html_receive(+Id)//.\nReceive posted HTML tokens. Unique sequences of tokens posted with html_post/4  are inserted at the location where html_receive/3 appears.  See also: - The local predicate sorted_html/3  handles the output of html_receive/3.  - html_receive/4 allows for  post-processing the posted material.\n\n ",
    "prefix":"html_receive"
  },
  "http/html_write:html_receive/2": {
    "body":"html_receive(${1:Id}, ${2:Handler})$3\n$0",
    "description":"[det]html_receive(+Id, :Handler)//.\nThis extended version of html_receive/3  causes Handler to be called to process all messages posted to  the channal at the time output is generated. Handler is a  grammar rule that is called with three extra arguments.  \n\nA list of Module:Term, of posted terms. Module is the contest module  of html_post and Term is the unmodified term. Members are in the order  posted and may contain duplicates.\nDCG input list. The final output must be produced by a call to html/3.\nDCG output list.\n\n  Typically, Handler collects the posted terms, creating a  term suitable for html/3 and finally calls html/3.\n\n",
    "prefix":"html_receive"
  },
  "http/html_write:html_receive/3": {
    "body": ["html_receive(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"html_receive('Param1','Param2','Param3')",
    "prefix":"html_receive"
  },
  "http/html_write:html_receive/4": {
    "body": [
      "html_receive(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"html_receive('Param1','Param2','Param3','Param4')",
    "prefix":"html_receive"
  },
  "http/html_write:html_root_attribute/4": {
    "body": [
      "html_root_attribute(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"html_root_attribute('Param1','Param2','Param3','Param4')",
    "prefix":"html_root_attribute"
  },
  "http/html_write:html_set_options/1": {
    "body": ["html_set_options(${1:Options})$2\n$0" ],
    "description":"  html_set_options(+Options) is det.\n\n   Set options for the HTML output.   Options  are stored in prolog\n   flags to ensure proper multi-threaded behaviour where setting an\n   option is local to the thread  and   new  threads start with the\n   options from the parent thread. Defined options are:\n\n     * dialect(Dialect)\n       One of =html4=, =xhtml= or =html5= (default). For\n       compatibility reasons, =html= is accepted as an\n       alias for =html4=.\n\n     * doctype(+DocType)\n       Set the =|<|DOCTYPE|= DocType =|>|= line for page//1 and\n       page//2.\n\n     * content_type(+ContentType)\n       Set the =|Content-type|= for reply_html_page/3\n\n   Note that the doctype and  content_type   flags  are  covered by\n   distinct  prolog  flags:  =html4_doctype=,  =xhtml_doctype=  and\n   =html5_doctype= and similar for the   content  type. The Dialect\n   must be switched before doctype and content type.",
    "prefix":"html_set_options"
  },
  "http/html_write:page/1": {
    "body":"page(${1:Contents})$2\n$0",
    "description":"page(:Contents)//.\nThis version of the page/[1,2]  only gives you the SGML DOCTYPE and the HTML  element. Contents is used to generate both the head and body  of the page.",
    "prefix":"page"
  },
  "http/html_write:page/2": {
    "body":"page(${1:HeadContent}, ${2:BodyContent})$3\n$0",
    "description":"page(:HeadContent, :BodyContent)//.\nThe DCG non-terminal page/4  generated a complete page, including the SGML DOCTYPE declaration. HeadContent are elements to  be placed in the head element and BodyContent  are elements to be placed in the body element.  To achieve common style (background, page header and footer), it is  possible to define DCG non-terminals head/3  and/or body/3.  Non-terminal page/3  checks for the definition of these non-terminals in the module it is  called from as well as in the user module. If no definition  is found, it creates a head with only the HeadContent (note  that the title is obligatory) and a body with bgcolor  set to white and the provided BodyContent. \n\nNote that further customisation is easily achieved using html/3  directly as page/4  is (besides handling the hooks) defined as: \n\n\n\npage(Head, Body) -->\n        html([ \\['<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 4.0//EN\">\\n'],\n               html([ head(Head),\n                      body(bgcolor(white), Body)\n                    ])\n             ]).\n\n ",
    "prefix":"page"
  },
  "http/html_write:page/3": {
    "body": ["page(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"page('Param1','Param2','Param3')",
    "prefix":"page"
  },
  "http/html_write:page/4": {
    "body": [
      "page(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"page('Param1','Param2','Param3','Param4')",
    "prefix":"page"
  },
  "http/html_write:page/5": {
    "body": [
      "page(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"page('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"page"
  },
  "http/html_write:print_html/1": {
    "body":"print_html(${1:List})$2\n$0",
    "description":"print_html(+List).\nPrint the token list to the Prolog current output stream.",
    "prefix":"print_html"
  },
  "http/html_write:print_html/2": {
    "body":"print_html(${1:Stream}, ${2:List})$3\n$0",
    "description":"print_html(+Stream, +List).\nPrint the token list to the specified output stream",
    "prefix":"print_html"
  },
  "http/html_write:reply_html_page/2": {
    "body":"reply_html_page(${1:Head}, ${2:Body})$3\n$0",
    "description":"reply_html_page(:Head, :Body).\nSame as reply_html_page(default, Head, Body).",
    "prefix":"reply_html_page"
  },
  "http/html_write:reply_html_page/3": {
    "body":"reply_html_page(${1:Style}, ${2:Head}, ${3:Body})$4\n$0",
    "description":"reply_html_page(+Style, :Head, :Body).\nWrites an HTML page preceded by an HTTP header as required by library(http_wrapper)  (CGI-style). Here is a simple typical example:  \n\nreply(Request) :-\n        reply_html_page(title('Welcome'),\n                        [ h1('Welcome'),\n                          p('Welcome to our ...')\n                        ]).\n\n  The header and footer of the page can be hooked using the  grammar-rules user:head//2 and user:body//2. The first argument passed  to these hooks is the Style argument of reply_html_page/3  and the second is the 2nd (for head/4)  or 3rd (for body/4)  argument of reply_html_page/3.  These hooks can be used to restyle the page, typically by embedding the  real body content in a div. E.g., the following code  provides a menu on top of each page of that is identified using the  style myapp. \n\n\n\n:- multifile\n        user:body//2.\n\nuser:body(myapp, Body) -->\n        html(body([ div(id(top), \\application_menu),\n                    div(id(content), Body)\n                  ])).\n\n  Redefining the head can be used to pull in scripts, but  typically html_requires/3  provides a more modular approach for pulling scripts and CSS-files.\n\n",
    "prefix":"reply_html_page"
  },
  "http/html_write:xhtml_ns/2": {
    "body":"xhtml_ns(${1:Id}, ${2:Value})$3\n$0",
    "description":"xhtml_ns(Id, Value)//.\nDemand an xmlns:id=Value in the outer html tag. This uses the html_post/2 mechanism to post to  the xmlns channel. Rdfa (http://www.w3.org/2006/07/SWD/RDFa/syntax/),  embedding RDF in (x)html provides a typical usage scenario where we want  to publish the required namespaces in the header. We can define:  \n\nrdf_ns(Id) -->\n        { rdf_global_id(Id:'', Value) },\n        xhtml_ns(Id, Value).\n\n  After which we can use rdf_ns/3 as a  normal rule in html/3 to publish  namespaces from library(semweb/rdf_db). Note that this  macro only has effect if the dialect is set to xhtml. In html mode it is silently ignored. \n\nThe required xmlns receiver is installed by html_begin/3  using the html tag and thus is present in any document that  opens the outer html environment through this library.\n\n",
    "prefix":"xhtml_ns"
  },
  "http/html_write:xhtml_ns/4": {
    "body": [
      "xhtml_ns(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"xhtml_ns('Param1','Param2','Param3','Param4')",
    "prefix":"xhtml_ns"
  },
  "http/http_authenticate:cors_enable/2": {
    "body":"cors_enable(${1:Request}, ${2:Options})$3\n$0",
    "description":"[det]cors_enable(+Request, +Options).\nCORS reply to a Preflight OPTIONS request. Request  is the HTTP request. Options provides:  methods(+List): List of supported HTTP methods. The default is GET,  only allowing for read requests.\n\nheaders(+List): List of headers the client asks for and we allow. The default  is to simply echo what has been requested for.\n\n  Both methods and headers may use Prolog friendly syntax, e.g., get for a method and content_type for a  header. \n\nSee also: http://www.html5rocks.com/en/tutorials/cors/\n\n ",
    "prefix":"cors_enable"
  },
  "http/http_authenticate:http_authenticate/3": {
    "body":"http_authenticate(${1:Type}, ${2:Request}, ${3:Fields})$4\n$0",
    "description":"http_authenticate(+Type, +Request, -Fields).\nTrue if Request contains the information to continue  according to Type. Type identifies the required  authentication technique:  basic(+PasswordFile): Use HTTP Basic authetication and verify the password from PasswordFile. PasswordFile  is a file holding usernames and passwords in a format compatible to Unix  and Apache. Each line is record with : separated fields.  The first field is the username and the second the password hash.  Password hashes are validated using crypt/2.\n\n  Successful authorization is cached for 60 seconds to avoid overhead  of decoding and lookup of the user and password data. \n\nhttp_authenticate/3  just validates the header. If authorization is not provided the browser  must be challenged, in response to which it normally opens a  user-password dialogue. Example code realising this is below. The  exception causes the HTTP wrapper code to generate an HTTP 401 reply. \n\n\n\n(   http_authenticate(basic(passwd), Request, Fields)\n->  true\n;   throw(http_reply(authorise(basic, Realm)))\n).\n\n  Fields is a list of fields from  the password-file entry. The first element is the user. The hash is  skipped.   To be done: Should we also cache failures to reduce the risc of DoS attacks?\n\n ",
    "prefix":"http_authenticate"
  },
  "http/http_authenticate:http_authorization_data/2": {
    "body":"http_authorization_data(${1:AuthorizeText}, ${2:Data})$3\n$0",
    "description":"[semidet]http_authorization_data(+AuthorizeText, ?Data).\nDecode the HTTP Authorization header. Data is a  term  \n\nMethod(User, Password)\n\n  where Method is the (downcased) authorization method (typically basic), User is an atom holding the user name and Password  is a list of codes holding the password\n\n",
    "prefix":"http_authorization_data"
  },
  "http/http_authenticate:http_current_user/3": {
    "body":"http_current_user(${1:File}, ${2:User}, ${3:Fields})$4\n$0",
    "description":"[nondet]http_current_user(+File, ?User, ?Fields).\nTrue when User is present in the htpasswd file File  and Fields provides the additional fields. Fields are the fields from the  password file File, converted using name/2,  which means that numeric values are passed as numbers and other fields  as atoms. The password hash is the first element of Fields  and is a string. ",
    "prefix":"http_current_user"
  },
  "http/http_authenticate:http_read_passwd_file/2": {
    "body":"http_read_passwd_file(${1:Path}, ${2:Data})$3\n$0",
    "description":"[det]http_read_passwd_file(+Path, -Data).\nRead a password file. Data is a list of terms of the format  below, where User is an atom identifying the user, Hash is a string  containing the salted password hash and Fields contain additional  fields. The string value of each field is converted using name/2  to either a number or an atom.  \n\npasswd(User, Hash, Fields)\n\n ",
    "prefix":"http_read_passwd_file"
  },
  "http/http_authenticate:http_write_passwd_file/2": {
    "body":"http_write_passwd_file(${1:File}, ${2:Data})$3\n$0",
    "description":"[det]http_write_passwd_file(+File, +Data:list).\nWrite password data Data to File. Data  is a list of entries as below. See http_read_passwd_file/2  for details.  \n\npasswd(User, Hash, Fields)\n\n  To be done: Write to a new file and atomically replace the old one.\n\n ",
    "prefix":"http_write_passwd_file"
  },
  "http/http_ax:ax_form_attributes/2": {
    "body": ["ax_form_attributes(${1:Form}, ${2:Values})$3\n$0" ],
    "description":"  ax_form_attributes(+Form, -Values) is det.\n\n   True if Values  is  a  list   Alias(Value)  for  each  exchanged\n   attribute.\n\n   Note that we assume we get the same   alias names as we used for\n   requesting the data. Not sure whether this is true.\n\n   @arg    Form is an HTTP form as returned using the form(Form)\n           option of http_parameters/3.",
    "prefix":"ax_form_attributes"
  },
  "http/http_ax:http_ax_attributes/2": {
    "body": ["http_ax_attributes(${1:Spec}, ${2:HTTPAttributes})$3\n$0" ],
    "description":"  http_ax_attributes(+Spec, -HTTPAttributes) is det.\n\n   True when HTTPAttributes is a list  of Name=Value pairs that can\n   be used with an HTTP request to   query for the attributes Spec.\n   Spec is a list of elements =|Alias(Value[, Options])|=.  Options\n   include:\n\n     - required\n     The attribute is required.  This is mutually exclusive\n     with =if_available=.\n     - if_available\n     Only provide the attribute if it is available. This is\n     mutually exclusive with =required=.  This is the default.\n     - url(+URL)\n     Can be used to ovcerrule or extend the ax_alias/2.\n     - count(+Count)\n     Maximum number of values to provide\n\n   For example:\n\n       ==\n       ?- http_ax_attributes([ nickname(Nick),\n                               email(Email, [required])\n                             ], Params).\n       Params = [ 'openid.ax.mode'          = fetch_request,\n                  'openid.ax.type.nickname' = 'http://axschema.org/namePerson/friendly',\n                  'openid.ax.type.email'    = 'http://axschema.org/contact/email',\n                  'openid.ax.required'      = email,\n                  'openid.ax.if_available'  = nickname\n                ].\n       ==",
    "prefix":"http_ax_attributes"
  },
  "http/http_chunked:http_chunked_open/3": {
    "body":"http_chunked_open(${1:RawStream}, ${2:DataStream}, ${3:Options})$4\n$0",
    "description":"http_chunked_open(+RawStream, -DataStream, +Options).\nCreate a stream to realise HTTP chunked encoding or decoding. The  technique is similar to library(zlib), using a Prolog stream as a filter  on another stream. See online documentation at http://www.swi-prolog.org/  for details.",
    "prefix":"http_chunked_open"
  },
  "http/http_chunked:reply_pwp_page/3": {
    "body":"reply_pwp_page(${1:File}, ${2:Options}, ${3:Request})$4\n$0",
    "description":"reply_pwp_page(:File, +Options, +Request).\nReply a PWP file. This interface is provided to server individual  locations from PWP files. Using a PWP file rather than generating the  page from Prolog may be desirable because the page contains a lot of  text (which is cumbersome to generate from Prolog) or because the  maintainer is not familiar with Prolog.  Options supported are: \n\nmime_type(+Type): Serve the file using the given mime-type. Default is text/html.\n\nunsafe(+Boolean): Passed to http_safe_file/2  to check for unsafe paths.\n\npwp_module(+Boolean): If true, (default false), process the PWP file  in a module constructed from its canonical absolute path. Otherwise, the  PWP file is processed in the calling module.\n\n  Initial context: \n\nSCRIPT_NAME: Virtual path of the script.\n\nSCRIPT_DIRECTORY: Physical directory where the script lives\n\nQUERY: Var=Value list representing the query-parameters\n\nREMOTE_USER: If access has been authenticated, this is the authenticated user.\n\nREQUEST_METHOD: One of get, post, put or head\n\nCONTENT_TYPE: Content-type provided with HTTP POST and PUT requests\n\nCONTENT_LENGTH: Content-length provided with HTTP POST and PUT requests\n\n  While processing the script, the file-search-path pwp includes the  current location of the script. I.e., the following will find myprolog  in the same directory as where the PWP file resides. \n\n\n\npwp:ask=\"ensure_loaded(pwp(myprolog))\"\n\n  See also: pwp_handler/2.\n\nTo be done: complete the initial context, as far as possible from CGI variables. See http://hoohoo.ncsa.illinois.edu/docs/cgi/env.html\n\n ",
    "prefix":"reply_pwp_page"
  },
  "http/http_client:http_convert_data/4": {
    "body":"http_convert_data(${1:In}, ${2:Fields}, ${3:Data}, ${4:Options})$5\n$0",
    "description":"[semidet,multifile]http_convert_data(+In, +Fields, -Data, +Options).\nMulti-file hook to convert a HTTP payload according to the Content-Type header. The default implementation deals with  application/x-prolog. The HTTP framework provides implementations for  JSON (library(http/http_json)), HTML/XML (library(http/http_sgml_plugin))",
    "prefix":"http_convert_data"
  },
  "http/http_client:http_delete/3": {
    "body":"http_delete(${1:URL}, ${2:Data}, ${3:Options})$4\n$0",
    "description":"[det]http_delete(+URL, -Data, +Options).\nExecute a DELETE method on the server. Arguments are the  same as for http_get/3. Typically  one should pass the option status_code(-Code) to assess and evaluate the returned  status code. Without, codes other than 200 are interpreted as an error.  See also: Implemented on top of http_get/3.\n\nTo be done: Properly map the 201, 202 and 204 replies.\n\n ",
    "prefix":"http_delete"
  },
  "http/http_client:http_disconnect/1": {
    "body":"http_disconnect(${1:Connections})$2\n$0",
    "description":"[det]http_disconnect(+Connections).\nClose down some connections. Currently Connections must have  the value all, closing all connections.  deprecated: New code should use http_close_keep_alive/1  from library(http/http_open).\n\n ",
    "prefix":"http_disconnect"
  },
  "http/http_client:http_get/3": {
    "body":"http_get(${1:URL}, ${2:Data}, ${3:Options})$4\n$0",
    "description":"[det]http_get(+URL, -Data, +Options).\nGet data from a URL server and convert it to a suitable  Prolog representation based on the Content-Type header and  plugins. This predicate is the common implementation of the HTTP client  operations. The predicates http_delete/3, http_post/4  and http_put/4 call this predicate  with an appropriate method(+Method) option and ---for http_post/4  and http_put/4--- a post(+Data)  option.  Options are passed to http_open/3  and http_read_data/3. Other  options: \n\nreply_header(-Fields): Synonym for headers(Fields) from http_open/3.  Provided for backward compatibility. Note that http_version(Major-Minor)  is missing in the new version.\n\n ",
    "prefix":"http_get"
  },
  "http/http_client:http_patch/4": {
    "body":"http_patch(${1:URL}, ${2:Data}, ${3:Reply}, ${4:Options})$5\n$0",
    "description":"http_patch(+URL, +Data, -Reply, +Options).\nIssue an HTTP PATCH request. Arguments are the same as for http_post/4.  See also: Implemented on top of http_post/4.\n\n ",
    "prefix":"http_patch"
  },
  "http/http_client:http_post/4": {
    "body":"http_post(${1:URL}, ${2:Data}, ${3:Reply}, ${4:Options})$5\n$0",
    "description":"[det]http_post(+URL, +Data, -Reply, +Options).\nIssue an HTTP POST request. Data is posted using http_post_data/3. The HTTP  server reply is returned in Reply, using the same rules as  for http_get/3.  See also: Implemented on top of http_get/3.\n\n ",
    "prefix":"http_post"
  },
  "http/http_client:http_put/4": {
    "body":"http_put(${1:URL}, ${2:Data}, ${3:Reply}, ${4:Options})$5\n$0",
    "description":"http_put(+URL, +Data, -Reply, +Options).\nIssue an HTTP PUT request. Arguments are the same as for http_post/4.  See also: Implemented on top of http_post/4.\n\n ",
    "prefix":"http_put"
  },
  "http/http_client:http_read_data/3": {
    "body":"http_read_data(${1:Request}, ${2:Data}, ${3:Options})$4\n$0",
    "description":"[det]http_read_data(+Request, -Data, +Options).\nRead data from an HTTP connection and convert it according to the  supplied to(Format) option or based on the Content-type  in the Request. The following options are supported:  to(Format): Convert data into Format. Values are:  stream(+WriteStream)) Append the content of the message  to Stream\natom Return the reply as an atom\nstring Return the reply as a string\ncodes Return the reply as a list of codes\n\n\n\nform_data(AsForm): input_encoding(+Encoding): on_filename(:CallBack): These options are implemented by the plugin library(http/http_multipart_plugin) and apply to processing multipart/form-data content.\n\ncontent_type(+Type): Overrule the content-type that is part of Request as a  work-around for wrongly configured servers.\n\n  Without plugins, this predicate handles \n\napplication/x-www-form-urlencoded: Converts form-data into a list of Name=Value terms.\n\napplication/x-prolog: Converts data into a Prolog term.\n\n  Request is a parsed HTTP  request as returned by http_read_request/2 or  available from the HTTP server's request dispatcher. Request  must contain a term input(In) that provides the input  stream from the HTTP server. ",
    "prefix":"http_read_data"
  },
  "http/http_cookie:cookie_current_cookie/4": {
    "body": [
      "cookie_current_cookie(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"cookie_current_cookie('Param1','Param2','Param3','Param4')",
    "prefix":"cookie_current_cookie"
  },
  "http/http_cookie:cookie_remove_all_clients/0": {
    "body": ["cookie_remove_all_clients$1\n$0" ],
    "description":"  cookie_remove_all_clients is det.\n\n   Simply logout all clients.  See http_remove_client/1.",
    "prefix":"cookie_remove_all_clients"
  },
  "http/http_cookie:cookie_remove_client/1": {
    "body": ["cookie_remove_client(${1:ClientId})$2\n$0" ],
    "description":"  cookie_remove_client(+ClientId) is det.\n\n   Fake user quitting a browser.   Removes all cookies that do\n   not have an expire date.",
    "prefix":"cookie_remove_client"
  },
  "http/http_cors:cors_enable/0": {
    "body": ["cors_enable$1\n$0" ],
    "description":"  cors_enable is det.\n\n   Emit  the  HTTP  header   =|Access-Control-Allow-Origin|=  using\n   domains from the setting http:cors.  This   this  setting  is []\n   (default), nothing is written. This  predicate is typically used\n   for replying to API  HTTP-request  (e.g.,   replies  to  an AJAX\n   request that typically serve JSON or XML).",
    "prefix":"cors_enable"
  },
  "http/http_cors:cors_enable/2": {
    "body":"cors_enable(${1:Request}, ${2:Options})$3\n$0",
    "description":"[det]cors_enable(+Request, +Options).\nCORS reply to a Preflight OPTIONS request. Request  is the HTTP request. Options provides:  methods(+List): List of supported HTTP methods. The default is GET,  only allowing for read requests.\n\nheaders(+List): List of headers the client asks for and we allow. The default  is to simply echo what has been requested for.\n\n  Both methods and headers may use Prolog friendly syntax, e.g., get for a method and content_type for a  header. \n\nSee also: http://www.html5rocks.com/en/tutorials/cors/\n\n ",
    "prefix":"cors_enable"
  },
  "http/http_cors:http_session_cookie/1": {
    "body":"http_session_cookie(${1:Cookie})$2\n$0",
    "description":"[det]http_session_cookie(-Cookie).\nGenerate a random cookie that can be used by a browser to identify the  current session. The cookie has the format XXXX-XXXX-XXXX-XXXX[.<route>],  where XXXX are random hexadecimal numbers and [.<route>]  is the optionally added routing information.",
    "prefix":"http_session_cookie"
  },
  "http/http_dcg_basics:alpha_to_lower/3": {
    "body": ["alpha_to_lower(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"alpha_to_lower('Param1','Param2','Param3')",
    "prefix":"alpha_to_lower"
  },
  "http/http_dcg_basics:atom/3": {
    "body": ["atom(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"atom('Param1','Param2','Param3')",
    "prefix":"atom"
  },
  "http/http_dcg_basics:blank/2": {
    "body": ["blank(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"blank('Param1','Param2')",
    "prefix":"blank"
  },
  "http/http_dcg_basics:blanks/2": {
    "body": ["blanks(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"blanks('Param1','Param2')",
    "prefix":"blanks"
  },
  "http/http_dcg_basics:blanks_to_nl/2": {
    "body": ["blanks_to_nl(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"blanks_to_nl('Param1','Param2')",
    "prefix":"blanks_to_nl"
  },
  "http/http_dcg_basics:digit/3": {
    "body": ["digit(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"digit('Param1','Param2','Param3')",
    "prefix":"digit"
  },
  "http/http_dcg_basics:digits/3": {
    "body": ["digits(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"digits('Param1','Param2','Param3')",
    "prefix":"digits"
  },
  "http/http_dcg_basics:eos/2": {
    "body": ["eos(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"eos('Param1','Param2')",
    "prefix":"eos"
  },
  "http/http_dcg_basics:float/3": {
    "body": ["float(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"float('Param1','Param2','Param3')",
    "prefix":"float"
  },
  "http/http_dcg_basics:integer/3": {
    "body": ["integer(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"integer('Param1','Param2','Param3')",
    "prefix":"integer"
  },
  "http/http_dcg_basics:nonblank/3": {
    "body": ["nonblank(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nonblank('Param1','Param2','Param3')",
    "prefix":"nonblank"
  },
  "http/http_dcg_basics:nonblanks/3": {
    "body": ["nonblanks(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"nonblanks('Param1','Param2','Param3')",
    "prefix":"nonblanks"
  },
  "http/http_dcg_basics:number/3": {
    "body": ["number(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"number('Param1','Param2','Param3')",
    "prefix":"number"
  },
  "http/http_dcg_basics:prolog_var_name/3": {
    "body": [
      "prolog_var_name(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"prolog_var_name('Param1','Param2','Param3')",
    "prefix":"prolog_var_name"
  },
  "http/http_dcg_basics:remainder/3": {
    "body": ["remainder(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"remainder('Param1','Param2','Param3')",
    "prefix":"remainder"
  },
  "http/http_dcg_basics:string/3": {
    "body": ["string(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"string('Param1','Param2','Param3')",
    "prefix":"string"
  },
  "http/http_dcg_basics:string_without/4": {
    "body": [
      "string_without(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"string_without('Param1','Param2','Param3','Param4')",
    "prefix":"string_without"
  },
  "http/http_dcg_basics:white/2": {
    "body": ["white(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"white('Param1','Param2')",
    "prefix":"white"
  },
  "http/http_dcg_basics:whites/2": {
    "body": ["whites(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"whites('Param1','Param2')",
    "prefix":"whites"
  },
  "http/http_dcg_basics:xdigit/3": {
    "body": ["xdigit(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"xdigit('Param1','Param2','Param3')",
    "prefix":"xdigit"
  },
  "http/http_dcg_basics:xdigits/3": {
    "body": ["xdigits(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"xdigits('Param1','Param2','Param3')",
    "prefix":"xdigits"
  },
  "http/http_dcg_basics:xinteger/3": {
    "body": ["xinteger(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"xinteger('Param1','Param2','Param3')",
    "prefix":"xinteger"
  },
  "http/http_digest:http_digest_challenge/2": {
    "body":"http_digest_challenge(${1:Realm}, ${2:Options})$3\n$0",
    "description":"http_digest_challenge(+Realm, +Options)//.\nGenerate the content for a 401 WWW-Authenticate: Digest  header field.",
    "prefix":"http_digest_challenge"
  },
  "http/http_digest:http_digest_password_hash/4": {
    "body":"http_digest_password_hash(${1:User}, ${2:Realm}, ${3:Password}, ${4:Hash})$5\n$0",
    "description":"[det]http_digest_password_hash(+User, +Realm, +Password, -Hash).\nCompute the password hash for the HTTP password file. Note that the HTTP  digest mechanism does allow us to use a seeded expensive arbitrary hash  function. Instead, the hash is defined as the MD5 of the following  components:  \n\n<user>:<realm>:<password>.\n\n  The inexpensive MD5 algorithm makes the hash sensitive to brute force  attacks while the lack of seeding make the hashes sensitive for rainbow  table attacks, although the value is somewhat limited because the realm  and user are part of the hash.\n\n",
    "prefix":"http_digest_password_hash"
  },
  "http/http_digest:http_digest_response/5": {
    "body":"http_digest_response(${1:Challenge}, ${2:User}, ${3:Password}, ${4:Reply}, ${5:Options})$6\n$0",
    "description":"http_digest_response(+Challenge, +User, +Password, -Reply, +Options).\nFormulate a reply to a digest authentication request. Options:  path(+Path): The request URI send along with the authentication. Defaults to /\n\nmethod(+Method): The HTTP method. Defaults to 'GET'\n\nnc(+Integer): The nonce-count as an integer. This is formatted as an 8 hex-digit  string.\n\n  Challenge is a list  Name(Value), normally from http_parse_digest_challenge/2.  Must contain realm and nonce. Optionally contains opaque. User is the user we want to  authenticated Password is the user's password Options provides additional  options ",
    "prefix":"http_digest_response"
  },
  "http/http_digest:http_parse_digest_challenge/2": {
    "body":"http_parse_digest_challenge(${1:Challenge}, ${2:Fields})$3\n$0",
    "description":"[det]http_parse_digest_challenge(+Challenge, -Fields).\nParse the value of an HTTP WWW-Authenticate header into a  list of Name(Value) terms.",
    "prefix":"http_parse_digest_challenge"
  },
  "http/http_dirindex:directory_index/2": {
    "body":"directory_index(${1:Dir}, ${2:Options})$3\n$0",
    "description":"[det]directory_index(+Dir, +Options)//.\nShow index for a directory. Options processed:  order_by(+Field): Sort the files in the directory listing by Field. Field  is one of name (default), size or time.\n\norder(+AscentDescent): Sorting order. Default is ascending. The altenative is descending\n\n ",
    "prefix":"directory_index"
  },
  "http/http_dirindex:http_reply_dirindex/3": {
    "body":"http_reply_dirindex(${1:DirSpec}, ${2:Options}, ${3:Request})$4\n$0",
    "description":"[det]http_reply_dirindex(+DirSpec, +Options, +Request).\nProvide a directory listing for Request, assuming it is an  index for the physical directrory Dir. If the request-path does not end  with /, first return a moved (301 Moved Permanently) reply.  The calling conventions allows for direct calling from http_handler/3.\n\n",
    "prefix":"http_reply_dirindex"
  },
  "http/http_dirindex:http_switch_protocol/2": {
    "body":"http_switch_protocol(${1:Goal}, ${2:Options})$3\n$0",
    "description":"http_switch_protocol(:Goal, +Options).\nSend an \"HTTP 101 Switching Protocols\" reply. After sending  the reply, the HTTP library calls call(Goal, InStream, OutStream),  where InStream and OutStream are the raw streams to the HTTP client.  This allows the communication to continue using an an alternative  protocol.  If Goal fails or throws an exception, the streams are  closed by the server. Otherwise Goal is responsible for  closing the streams. Note that Goal runs in the HTTP handler  thread. Typically, the handler should be registered using the spawn  option if http_handler/3 or Goal  must call thread_create/3 to allow the  HTTP worker to return to the worker pool. \n\nThe streams use binary (octet) encoding and have their I/O timeout  set to the server timeout (default 60 seconds). The predicate set_stream/2  can be used to change the encoding, change or cancel the timeout. \n\nThis predicate interacts with the server library by throwing an  exception. \n\nThe following options are supported: \n\nheader(+Headers): Backward compatible. Use headers(+Headers).\n\nheaders(+Headers): Additional headers send with the reply. Each header takes the form  Name(Value).\n\n ",
    "prefix":"http_switch_protocol"
  },
  "http/http_dispatch:http_404/2": {
    "body":"http_404(${1:Options}, ${2:Request})$3\n$0",
    "description":"[det]http_404(+Options, +Request).\nReply using an \"HTTP 404 not found\" page. This handler is intended as  fallback handler for prefix handlers. Options  processed are:  index(Location): If there is no path-info, redirect the request to Location using http_redirect/3.\n\n  Errors: http_reply(not_found(Path))\n\n ",
    "prefix":"http_404"
  },
  "http/http_dispatch:http_current_handler/2": {
    "body":"http_current_handler(${1:Location}, ${2:Closure})$3\n$0",
    "description":"[nondet]http_current_handler(-Location, :Closure).\nTrue if Location is handled by Closure.",
    "prefix":"http_current_handler"
  },
  "http/http_dispatch:http_current_handler/3": {
    "body":"http_current_handler(${1:Location}, ${2:Closure}, ${3:Options})$4\n$0",
    "description":"[nondet]http_current_handler(?Location, :Closure, ?Options).\nResolve the current handler and options to execute it.",
    "prefix":"http_current_handler"
  },
  "http/http_dispatch:http_delete_handler/1": {
    "body":"http_delete_handler(${1:Spec})$2\n$0",
    "description":"[det]http_delete_handler(+Spec).\nDelete handler for Spec. Typically, this should only be used  for handlers that are registered dynamically. Spec is one of:  id(Id): Delete a handler with the given id. The default id is the  handler-predicate-name.\n\npath(Path): Delete handler that serves the given path.\n\n ",
    "prefix":"http_delete_handler"
  },
  "http/http_dispatch:http_dispatch/1": {
    "body":"http_dispatch(${1:Request})$2\n$0",
    "description":"[det]http_dispatch(Request).\nDispatch a Request using http_handler/3  registrations.",
    "prefix":"http_dispatch"
  },
  "http/http_dispatch:http_handler/3": {
    "body":"http_handler(${1:Path}, ${2:Closure}, ${3:Options})$4\n$0",
    "description":"[det]http_handler(+Path, :Closure, +Options).\nRegister Closure as a handler for HTTP requests. Path  is a specification as provided by http_path.pl. If an HTTP  request arrives at the server that matches Path, Closure  is called with one extra argument: the parsed HTTP request. Options is a list containing the following options:  authentication(+Type): Demand authentication. Authentication methods are pluggable. The library http_authenticate.pl  provides a plugin for user/password based Basic HTTP  authentication.\n\nchunked: Use Transfer-encoding: chunked if the client allows for it.\n\ncontent_type(+Term): Specifies the content-type of the reply. This value is currently not  used by this library. It enhances the reflexive capabilities of this  library through http_current_handler/3.\n\nid(+Term): Identifier of the handler. The default identifier is the predicate name.  Used by http_location_by_id/2.\n\nhide_children(+Bool): If true on a prefix-handler (see prefix), possible children  are masked. This can be used to (temporary) overrule part of the tree.\n\nmethod(+Method): Declare that the handler processes Method. This is equivalent  to methods([Method]). Using method(*) allows  for all methods.\n\nmethods(+ListOfMethods): Declare that the handler processes all of the given methods. If this  option appears multiple times, the methods are combined.\n\nprefix: Call Pred on any location that is a specialisation of Path. If multiple handlers match, the one with the longest  path is used. Options defined with a prefix handler are the  default options for paths that start with this prefix. Note that the  handler acts as a fallback handler for the tree below it:  \n\n:- http_handler(/, http_404([index('index.html')]),\n                [spawn(my_pool),prefix]).\n\n \n\npriority(+Integer): If two handlers handle the same path, the one with the highest priority  is used. If equal, the last registered is used. Please be aware that the  order of clauses in multifile predicates can change due to reloading  files. The default priority is 0 (zero).\n\nspawn(+SpawnOptions): Run the handler in a seperate thread. If SpawnOptions is an  atom, it is interpreted as a thread pool name (see create_thread_pool/3).  Otherwise the options are passed to http_spawn/2  and from there to thread_create/3. These options are  typically used to set the stack limits.\n\ntime_limit(+Spec): One of infinite, default or a positive number  (seconds). If default, the value from the setting http:time_limit is taken. The default of this setting is  300 (5 minutes). See setting/2.\n\n  Note that http_handler/3  is normally invoked as a directive and processed using term-expansion.  Using term-expansion ensures proper update through make/0  when the specification is modified. We do not expand when the  cross-referencer is running to ensure proper handling of the meta-call. \n\nErrors: existence_error(http_location, Location)\n\nSee also: http_reply_file/3 and http_redirect/3  are generic handlers to serve files and achieve redirects.\n\n ",
    "prefix":"http_handler"
  },
  "http/http_dispatch:http_link_to_id/3": {
    "body":"http_link_to_id(${1:HandleID}, ${2:Parameters}, ${3:HREF})$4\n$0",
    "description":"http_link_to_id(+HandleID, +Parameters, -HREF).\nHREF is a link on the local server to a handler with given  ID, passing the given Parameters. This predicate is typically  used to formulate a HREF that resolves to a handler  implementing a particular predicate. The code below provides a typical  example. The predicate user_details/1  returns a page with details about a user from a given id. This predicate  is registered as a handler. The DCG user_link/3  renders a link to a user, displaying the name and calling user_details/1  when clicked. Note that the location (root(user_details))  is irrelevant in this equation and HTTP locations can thus be moved  freely without breaking this code fragment.  \n\n:- http_handler(root(user_details), user_details, []).\n\nuser_details(Request) :-\n    http_parameters(Request,\n                    [ user_id(ID)\n                    ]),\n    ...\n\nuser_link(ID) -->\n    { user_name(ID, Name),\n      http_link_to_id(user_details, [id(ID)], HREF)\n    },\n    html(a([class(user), href(HREF)], Name)).\n\n  Parameters is one of  \n\npath_postfix(File) to pass a single value as the last  segment of the HTTP location (path). This way of passing a parameter is  commonly used in REST APIs.\nA list of search parameters for a GET request.\n\n  \n\n  See also: http_location_by_id/2  and http_handler/3 for  defining and specifying handler IDs.\n\n ",
    "prefix":"http_link_to_id"
  },
  "http/http_dispatch:http_location_by_id/2": {
    "body":"http_location_by_id(${1:ID}, ${2:Location})$3\n$0",
    "description":"[det]http_location_by_id(+ID, -Location).\nFind the HTTP Location of handler with ID. If the  setting (see setting/2) http:prefix is active, Location  is the handler location prefixed with the prefix setting. Handler IDs  can be specified in two ways:  id(ID): If this appears in the option list of the handler, this it is used and  takes preference over using the predicate.\n\nM : PredName: The module-qualified name of the predicate.\n\nPredName: The unqualified name of the predicate.\n\n  Errors: existence_error(http_handler_id, Id).\n\ndeprecated: The predicate http_link_to_id/3  provides the same functionality with the option to add query parameters  or a path parameter.\n\n ",
    "prefix":"http_location_by_id"
  },
  "http/http_dispatch:http_redirect/3": {
    "body":"http_redirect(${1:How}, ${2:To}, ${3:Request})$4\n$0",
    "description":"[det]http_redirect(+How, +To, +Request).\nRedirect to a new location. The argument order, using the Request as last argument, allows for calling this directly  from the handler declaration:  \n\n:- http_handler(root(.),\n                http_redirect(moved, myapp('index.html')),\n                []).\n\n  How is one of moved, moved_temporary  or see_other To is an atom, a aliased path  as defined by http_absolute_location/3.  or a term location_by_id(Id). If To is not  absolute, it is resolved relative to the current location. ",
    "prefix":"http_redirect"
  },
  "http/http_dispatch:http_reload_with_parameters/3": {
    "body":"http_reload_with_parameters(${1:Request}, ${2:Parameters}, ${3:HREF})$4\n$0",
    "description":"[det]http_reload_with_parameters(+Request, +Parameters, -HREF).\nCreate a request on the current handler with replaced search parameters.",
    "prefix":"http_reload_with_parameters"
  },
  "http/http_dispatch:http_reply_file/3": {
    "body":"http_reply_file(${1:FileSpec}, ${2:Options}, ${3:Request})$4\n$0",
    "description":"[det]http_reply_file(+FileSpec, +Options, +Request).\nOptions is a list of  cache(+Boolean): If true (default), handle If-modified-since and send  modification time.\n\nmime_type(+Type): Overrule mime-type guessing from the filename as provided by file_mime_type/2.\n\nstatic_gzip(+Boolean): If true (default false) and, in addition to the plain file,  there is a .gz file that is not older than the plain file  and the client acceps gzip encoding, send the compressed  file with Transfer-encoding: gzip.\n\nunsafe(+Boolean): If false (default), validate that FileSpec does  not contain references to parent directories. E.g., specifications such  as www('../../etc/passwd') are not allowed.\n\nheaders(+List): Provides additional reply-header fields, encoded as a list of Field(Value).\n\n  If caching is not disabled, it processes the request headers If-modified-since and Range. \n\nthrows: - http_reply(not_modified)  - http_reply(file(MimeType, Path))\n\n ",
    "prefix":"http_reply_file"
  },
  "http/http_dispatch:http_safe_file/2": {
    "body":"http_safe_file(${1:FileSpec}, ${2:Options})$3\n$0",
    "description":"[det]http_safe_file(+FileSpec, +Options).\nTrue if FileSpec is considered safe. If it is an atom,  it cannot be absolute and cannot have references to parent directories.  If it is of the form alias(Sub), than Sub cannot have  references to parent directories.  Errors: - instantiation_error  - permission_error(read, file, FileSpec)\n\n ",
    "prefix":"http_safe_file"
  },
  "http/http_dispatch:http_switch_protocol/2": {
    "body":"http_switch_protocol(${1:Goal}, ${2:Options})$3\n$0",
    "description":"http_switch_protocol(:Goal, +Options).\nSend an \"HTTP 101 Switching Protocols\" reply. After sending  the reply, the HTTP library calls call(Goal, InStream, OutStream),  where InStream and OutStream are the raw streams to the HTTP client.  This allows the communication to continue using an an alternative  protocol.  If Goal fails or throws an exception, the streams are  closed by the server. Otherwise Goal is responsible for  closing the streams. Note that Goal runs in the HTTP handler  thread. Typically, the handler should be registered using the spawn  option if http_handler/3 or Goal  must call thread_create/3 to allow the  HTTP worker to return to the worker pool. \n\nThe streams use binary (octet) encoding and have their I/O timeout  set to the server timeout (default 60 seconds). The predicate set_stream/2  can be used to change the encoding, change or cancel the timeout. \n\nThis predicate interacts with the server library by throwing an  exception. \n\nThe following options are supported: \n\nheader(+Headers): Backward compatible. Use headers(+Headers).\n\nheaders(+Headers): Additional headers send with the reply. Each header takes the form  Name(Value).\n\n ",
    "prefix":"http_switch_protocol"
  },
  "http/http_exception:in_or_exclude_backtrace/2": {
    "body": ["in_or_exclude_backtrace(${1:ErrorIn}, ${2:ErrorOut})$3\n$0" ],
    "description":"  in_or_exclude_backtrace(+ErrorIn, -ErrorOut)\n\n   Remove  the  stacktrace  from  the   exception,  unless  setting\n   `http:client_backtrace` is `true`.",
    "prefix":"in_or_exclude_backtrace"
  },
  "http/http_exception:map_exception_to_http_status/4": {
    "body": [
      "map_exception_to_http_status(${1:Exception}, ${2:Reply}, ${3:HdrExtra}, ${4:Context})$5\n$0"
    ],
    "description":"  map_exception_to_http_status(+Exception, -Reply, -HdrExtra, -Context)\n\n   Map certain defined  exceptions  to   special  reply  codes. The\n   http(not_modified)   provides   backward     compatibility    to\n   http_reply(not_modified).",
    "prefix":"map_exception_to_http_status"
  },
  "http/http_files:http_reply_from_files/3": {
    "body":"http_reply_from_files(${1:Dir}, ${2:Options}, ${3:Request})$4\n$0",
    "description":"http_reply_from_files(+Dir, +Options, +Request).\nHTTP handler that serves files from the directory Dir. This  handler uses http_reply_file/3  to reply plain files. If the request resolves to a directory, it uses  the option indexes to locate an index file (see below) or  uses http_reply_dirindex/3  to create a listing of the directory.  Options: \n\nindexes(+List): List of files tried to find an index for a directory. The  default is ['index.html'].\n\n  Note that this handler must be tagged as a prefix  handler (see http_handler/3 and module  introduction). This also implies that it is possible to override more  specific locations in the hierarchy using http_handler/3  with a longer path-specifier.\n\nDir is either a directory or an  path-specification as used by absolute_file_name/3.  This option provides great flexibility in (re-)locating the physical  files and allows merging the files of multiple physical locations into  one web-hierarchy by using multiple user:file_search_path/2 clauses that  define the same alias.   See also: The hookable predicate file_mime_type/2 is  used to determine the Content-type from the file name.\n\n ",
    "prefix":"http_reply_from_files"
  },
  "http/http_header:http_join_headers/3": {
    "body":"http_join_headers(${1:Default}, ${2:Header}, ${3:Out})$4\n$0",
    "description":"http_join_headers(+Default, +Header, -Out).\nAppend headers from Default to Header if they are  not already part of it.",
    "prefix":"http_join_headers"
  },
  "http/http_header:http_parse_header/2": {
    "body":"http_parse_header(${1:Text}, ${2:Header})$3\n$0",
    "description":"[det]http_parse_header(+Text:codes, -Header:list).\nHeader is a list of Name(Value)-terms representing the  structure of the HTTP header in Text.  Errors: domain_error(http_request_line, Line)\n\n ",
    "prefix":"http_parse_header"
  },
  "http/http_header:http_parse_header_value/3": {
    "body":"http_parse_header_value(${1:Field}, ${2:Value}, ${3:Prolog})$4\n$0",
    "description":"[semidet]http_parse_header_value(+Field, +Value, -Prolog).\nTranslate Value in a meaningful Prolog term. Field  denotes the HTTP request field for which we do the translation.  Supported fields are:  content_length: Converted into an integer\n\ncookie: Converted into a list with Name=Value by cookies/3.\n\nset_cookie: Converted into a term set_cookie(Name, Value, Options).  Options is a list consisting of Name=Value or a single atom  (e.g., secure)\n\nhost: Converted to HostName:Port if applicable.\n\nrange: Converted into bytes(From, To), where From is an integer  and To is either an integer or the atom end.\n\naccept: Parsed to a list of media descriptions. Each media is a term media(Type, TypeParams, Quality, AcceptExts). The list is  sorted according to preference.\n\ncontent_disposition: Parsed into disposition(Name, Attributes), where Attributes  is a list of Name=Value pairs.\n\ncontent_type: Parsed into media(Type/SubType, Attributes), where  Attributes is a list of Name=Value pairs.\n\n ",
    "prefix":"http_parse_header_value"
  },
  "http/http_header:http_post_data/3": {
    "body":"http_post_data(${1:Data}, ${2:Out}, ${3:HdrExtra})$4\n$0",
    "description":"[det]http_post_data(+Data, +Out:stream, +HdrExtra).\nSend data on behalf on an HTTP POST request. This predicate is normally  called by http_post/4 from http_client.pl  to send the POST data to the server. Data is one of:  \n\nhtml(+Tokens) Result of html/3  from html_write.pl\nxml(+Term) Post the result of xml_write/3  using the Mime-type text/xml\nxml(+Type, +Term) Post the result of xml_write/3  using the given Mime-type and an empty option list to xml_write/3.\nxml(+Type, +Term, +Options) Post the result of xml_write/3  using the given Mime-type and option list for xml_write/3.\nfile(+File) Send contents of a file. Mime-type is  determined by file_mime_type/2.\nfile(+Type, +File) Send file with content of indicated  mime-type.\nmemory_file(+Type, +Handle) Similar to file(+Type, +File),  but using a memory file instead of a real file. See new_memory_file/1.\ncodes(+Codes) As codes(text/plain, Codes).\ncodes(+Type, +Codes) Send Codes using the indicated  MIME-type.\nbytes(+Type, +Bytes) Send Bytes using the indicated  MIME-type. Bytes is either a string of character codes 0..255 or list of  integers in the range 0..255. Out-of-bound codes result in a  representation error exception.\natom(+Atom) As atom(text/plain, Atom).\natom(+Type, +Atom) Send Atom using the indicated  MIME-type.\ncgi_stream(+Stream, +Len) Read the input from Stream  which, like CGI data starts with a partial HTTP header. The fields of  this header are merged with the provided HdrExtra fields. The  first Len characters of Stream are used.\nform(+ListOfParameter) Send data of the MIME type  application/x-www-form-urlencoded as produced by browsers issuing a POST  request from an HTML form. ListOfParameter is a list of Name=Value or  Name(Value).\nform_data(+ListOfData) Send data of the MIME type multipart/form-data  as produced by browsers issuing a POST request from an HTML form using  enctype multipart/form-data. ListOfData is the same as for  the List alternative described below. Below is an example. Repository,  etc. are atoms providing the value, while the last argument provides a  value from a file.  ..., http_post([ protocol(http),             host(Host),             port(Port),             path(ActionPath)           ],           form_data([ repository = Repository,                       dataFormat = DataFormat,                       baseURI    = BaseURI,                       verifyData = Verify,                       data       = file(File)                     ]),           _Reply,           []), ...,  \nList If the argument is a plain list, it is sent using the MIME type  multipart/mixed and packed using mime_pack/3.  See mime_pack/3 for details on  the argument format.\n\n",
    "prefix":"http_post_data"
  },
  "http/http_header:http_read_header/2": {
    "body":"http_read_header(${1:Fd}, ${2:Header})$3\n$0",
    "description":"[det]http_read_header(+Fd, -Header).\nRead Name: Value lines from FD until an empty line is encountered.  Field-name are converted to Prolog conventions (all lower, _ instead of  -): Content-Type: text/html --> content_type(text/html)",
    "prefix":"http_read_header"
  },
  "http/http_header:http_read_reply_header/2": {
    "body":"http_read_reply_header(${1:FdIn}, ${2:Reply})$3\n$0",
    "description":"http_read_reply_header(+FdIn, -Reply).\nRead the HTTP reply header. Throws an exception if the current input  does not contain a valid reply header.",
    "prefix":"http_read_reply_header"
  },
  "http/http_header:http_read_request/2": {
    "body":"http_read_request(${1:FdIn}, ${2:Request})$3\n$0",
    "description":"[det]http_read_request(+FdIn:stream, -Request).\nRead an HTTP request-header from FdIn and return the  broken-down request fields as +Name(+Value) pairs in a list. Request  is unified to end_of_file if FdIn is at the end  of input.",
    "prefix":"http_read_request"
  },
  "http/http_header:http_reply/2": {
    "body":"http_reply(${1:Data}, ${2:Out})$3\n$0",
    "description":"[det]http_reply(+Data, +Out:stream).\n",
    "prefix":"http_reply"
  },
  "http/http_header:http_reply/3": {
    "body":"http_reply(${1:Data}, ${2:Out}, ${3:HdrExtra})$4\n$0",
    "description":"[det]http_reply(+Data, +Out:stream, +HdrExtra).\n",
    "prefix":"http_reply"
  },
  "http/http_header:http_reply/4": {
    "body":"http_reply(${1:Data}, ${2:Out}, ${3:HdrExtra}, ${4:Code})$5\n$0",
    "description":"[det]http_reply(+Data, +Out:stream, +HdrExtra, -Code).\n",
    "prefix":"http_reply"
  },
  "http/http_header:http_reply/5": {
    "body":"http_reply(${1:Data}, ${2:Out}, ${3:HdrExtra}, ${4:Context}, ${5:Code})$6\n$0",
    "description":"[det]http_reply(+Data, +Out:stream, +HdrExtra, +Context, -Code).\n",
    "prefix":"http_reply"
  },
  "http/http_header:http_reply/6": {
    "body":"http_reply(${1:Data}, ${2:Out}, ${3:HdrExtra}, ${4:Context}, ${5:Request}, ${6:Code})$7\n$0",
    "description":"[det]http_reply(+Data, +Out:stream, +HdrExtra, +Context, +Request, -Code).\nCompose a complete HTTP reply from the term Data using  additional headers from HdrExtra to the output stream Out.  ExtraHeader is a list of Field(Value). Data is one of:  html(HTML): HTML tokens as produced by html/3  from html_write.pl\n\nfile(+MimeType, +FileName): Reply content of FileName using MimeType\n\nfile(+MimeType, +FileName, +Range): Reply partial content of FileName with given MimeType\n\ntmp_file(+MimeType, +FileName): Same as file, but do not include modification time\n\nbytes(+MimeType, +Bytes): Send a sequence of Bytes with the indicated MimeType. Bytes is either a string of character codes 0..255 or list of  integers in the range 0..255. Out-of-bound codes result in a  representation error exception.\n\nstream(+In, +Len): Reply content of stream.\n\ncgi_stream(+In, +Len): Reply content of stream, which should start with an HTTP header,  followed by a blank line. This is the typical output from a CGI script.\n\nStatus: HTTP status report as defined by http_status_reply/4.\n\n  HdrExtra provides additional  reply-header fields, encoded as Name(Value). It can also contain a field content_length(-Len) to retrieve the value of the  Content-length header that is replied. Code is the numeric HTTP status  code sent   To be done: Complete documentation\n\n ",
    "prefix":"http_reply"
  },
  "http/http_header:http_reply_header/3": {
    "body":"http_reply_header(${1:Out}, ${2:What}, ${3:HdrExtra})$4\n$0",
    "description":"[det]http_reply_header(+Out:stream, +What, +HdrExtra).\nCreate a reply header using reply_header/5  and send it to Stream.",
    "prefix":"http_reply_header"
  },
  "http/http_header:http_schedule_logrotate/2": {
    "body":"http_schedule_logrotate(${1:When}, ${2:Options})$3\n$0",
    "description":"http_schedule_logrotate(When, Options).\nSchedule log rotation based on maintenance broadcasts. When  is one of:  daily(Hour:Min): Run each day at Hour:Min. Min is  rounded to a multitude of 5.\n\nweekly(Day, Hour:Min): Run at the given Day and Time each week. Day is  either a number 1..7 (1 is Monday) or a weekday name or abbreviation.\n\nmonthly(DayOfTheMonth, Hour:Min): Run each month at the given Day (1..31). Note that not all months have  all days.\n\n  This must be used with a timer that broadcasts a maintenance(_,_) message (see broadcast/1).  Such a timer is part of library(http/http_unix_daemon).\n\n",
    "prefix":"http_schedule_logrotate"
  },
  "http/http_header:http_status_reply/4": {
    "body":"http_status_reply(${1:Status}, ${2:Out}, ${3:HdrExtra}, ${4:Code})$5\n$0",
    "description":"[det]http_status_reply(+Status, +Out, +HdrExtra, -Code).\n",
    "prefix":"http_status_reply"
  },
  "http/http_header:http_status_reply/5": {
    "body":"http_status_reply(${1:Status}, ${2:Out}, ${3:HdrExtra}, ${4:Context}, ${5:Code})$6\n$0",
    "description":"[det]http_status_reply(+Status, +Out, +HdrExtra, +Context, -Code).\n",
    "prefix":"http_status_reply"
  },
  "http/http_header:http_status_reply/6": {
    "body":"http_status_reply(${1:Status}, ${2:Out}, ${3:HdrExtra}, ${4:Context}, ${5:Request}, ${6:Code})$7\n$0",
    "description":"[det]http_status_reply(+Status, +Out, +HdrExtra, +Context, +Request, -Code).\nEmit HTML non-200 status reports. Such requests are always sent as UTF-8  documents.  Status can be one of the following: \n\nauthorise(Method): Challenge authorization. Method is one of  basic(Realm)\ndigest(Digest)\n\n\n\nauthorise(basic, Realm): Same as authorise(basic(Realm)). Deprecated.\n\nbad_request(ErrorTerm): busy: created(Location): forbidden(Url): moved(To): moved_temporary(To): no_content: not_acceptable(WhyHtml): not_found(Path): method_not_allowed(Method, Path): not_modified: resource_error(ErrorTerm): see_other(To): switching_protocols(Goal, Options): server_error(ErrorTerm): unavailable(WhyHtml): \n\n ",
    "prefix":"http_status_reply"
  },
  "http/http_header:http_timestamp/2": {
    "body":"http_timestamp(${1:Time}, ${2:Text})$3\n$0",
    "description":"[det]http_timestamp(+Time:timestamp, -Text:atom).\nGenerate a description of a Time in HTTP format (RFC1123)",
    "prefix":"http_timestamp"
  },
  "http/http_header:http_update_connection/4": {
    "body":"http_update_connection(${1:CGIHeader}, ${2:Request}, ${3:Connection}, ${4:Header})$5\n$0",
    "description":"http_update_connection(+CGIHeader, +Request, -Connection, -Header).\nMerge keep-alive information from Request and CGIHeader  into Header.",
    "prefix":"http_update_connection"
  },
  "http/http_header:http_update_encoding/3": {
    "body":"http_update_encoding(${1:HeaderIn}, ${2:Encoding}, ${3:HeaderOut})$4\n$0",
    "description":"http_update_encoding(+HeaderIn, -Encoding, -HeaderOut).\nAllow for rewrite of the header, adjusting the encoding. We distinguish  three options. If the user announces `text', we always use UTF-8  encoding. If the user announces charset=utf-8 we use UTF-8 and otherwise  we use octet (raw) encoding. Alternatively we could dynamically choose  for ASCII, ISO-Latin-1 or UTF-8.",
    "prefix":"http_update_encoding"
  },
  "http/http_header:http_update_transfer/4": {
    "body":"http_update_transfer(${1:Request}, ${2:CGIHeader}, ${3:Transfer}, ${4:Header})$5\n$0",
    "description":"http_update_transfer(+Request, +CGIHeader, -Transfer, -Header).\nDecide on the transfer encoding from the Request and the CGI  header. The behaviour depends on the setting http:chunked_transfer. If never,  even explitic requests are ignored. If on_request, chunked  encoding is used if requested through the CGI header and allowed by the  client. If if_possible, chunked encoding is used whenever the client  allows for it, which is interpreted as the client supporting HTTP 1.1 or  higher.  Chunked encoding is more space efficient and allows the client to  start processing partial results. The drawback is that errors lead to  incomplete pages instead of a nicely formatted complete page.\n\n",
    "prefix":"http_update_transfer"
  },
  "http/http_host:http_current_host/4": {
    "body":"http_current_host(${1:Request}, ${2:Hostname}, ${3:Port}, ${4:Options})$5\n$0",
    "description":"[det]http_current_host(?Request, -Hostname, -Port, +Options).\n deprecated: Use http_public_host/4  (same semantics)\n\n ",
    "prefix":"http_current_host"
  },
  "http/http_host:http_public_host/4": {
    "body":"http_public_host(${1:Request}, ${2:Hostname}, ${3:Port}, ${4:Options})$5\n$0",
    "description":"[det]http_public_host(?Request, -Hostname, -Port, +Options).\nCurrent global host and port of the HTTP server. This is the basis to  form absolute address, which we need for redirection based interaction  such as the OpenID protocol. Options are:  global(+Bool): If true (default false), try to replace a  local hostname by a world-wide accessible name.\n\n  This predicate performs the following steps to find the host and  port: \n\n\n\nUse the settings http:public_host and http:public_port\nUse X-Forwarded-Host header, which applies if this  server runs behind a proxy.\nUse the Host header, which applies for HTTP 1.1 if we  are contacted directly.\nUse gethostname/1 to find the host and http_current_server/2 to find the port.\n\n Request is the current request.  If it is left unbound, and the request is needed, it is obtained with http_current_request/1. ",
    "prefix":"http_public_host"
  },
  "http/http_host:http_public_host_url/2": {
    "body":"http_public_host_url(${1:Request}, ${2:URL})$3\n$0",
    "description":"[det]http_public_host_url(+Request, -URL).\nTrue when URL is the public URL at which this  server can be contacted. This value is not easy to obtain. See http_public_host/4 for  the hardest part: find the host and port.",
    "prefix":"http_public_host_url"
  },
  "http/http_host:http_public_url/2": {
    "body":"http_public_url(${1:Request}, ${2:URL})$3\n$0",
    "description":"[det]http_public_url(+Request, -URL).\nTrue when URL is an absolute URL for the current  request. Typically, the login page should redirect to this URL  to avoid losing the session.",
    "prefix":"http_public_url"
  },
  "http/http_host:http_relative_path/2": {
    "body":"http_relative_path(${1:AbsPath}, ${2:RelPath})$3\n$0",
    "description":"http_relative_path(+AbsPath, -RelPath).\nConvert an absolute path (without host, fragment or search) into a path  relative to the current page, defined as the path component from the  current request (see http_current_request/1).  This call is intended to create reusable components returning relative  paths for easier support of reverse proxies.  If ---for whatever reason--- the conversion is not possible it simply  unifies RelPath to AbsPath.\n\n",
    "prefix":"http_relative_path"
  },
  "http/http_inetd:http_server/2": {
    "body": ["http_server(${1:Goal}, ${2:Options})$3\n$0" ],
    "description":"  http_server(:Goal, +Options)\n\n   Start the server from inetd. This is really easy as user_input\n   is connected to the HTTP input and user_output is the place to\n   write our reply to.",
    "prefix":"http_server"
  },
  "http/http_json:http_read_json/2": {
    "body": ["http_read_json(${1:Request}, ${2:JSON})$3\n$0" ],
    "description":"  http_read_json(+Request, -JSON) is det.\n  http_read_json(+Request, -JSON, +Options) is det.\n\n   Extract JSON data posted  to  this   HTTP  request.  Options are\n   passed to json_read/3.  In addition, this option is processed:\n\n     * json_object(+As)\n     One of =term= (default) to generate a classical Prolog\n     term or =dict= to exploit the SWI-Prolog version 7 data type\n     extensions.  See json_read_dict/3.\n\n   @error  domain_error(mimetype, Found) if the mimetype is\n           not known (see json_type/1).\n   @error  domain_error(method, Method) if the request is not\n           a =POST= or =PUT= request.",
    "prefix":"http_read_json"
  },
  "http/http_json:http_read_json/3": {
    "body": ["http_read_json(${1:Request}, ${2:JSON}, ${3:Options})$4\n$0" ],
    "description":"  http_read_json(+Request, -JSON) is det.\n  http_read_json(+Request, -JSON, +Options) is det.\n\n   Extract JSON data posted  to  this   HTTP  request.  Options are\n   passed to json_read/3.  In addition, this option is processed:\n\n     * json_object(+As)\n     One of =term= (default) to generate a classical Prolog\n     term or =dict= to exploit the SWI-Prolog version 7 data type\n     extensions.  See json_read_dict/3.\n\n   @error  domain_error(mimetype, Found) if the mimetype is\n           not known (see json_type/1).\n   @error  domain_error(method, Method) if the request is not\n           a =POST= or =PUT= request.",
    "prefix":"http_read_json"
  },
  "http/http_json:http_read_json_dict/2": {
    "body": ["http_read_json_dict(${1:Request}, ${2:Dict})$3\n$0" ],
    "description":"  http_read_json_dict(+Request, -Dict) is det.\n  http_read_json_dict(+Request, -Dict, +Options) is det.\n\n   Similar to http_read_json/2,3, but by default uses the version 7\n   extended datatypes.",
    "prefix":"http_read_json_dict"
  },
  "http/http_json:http_read_json_dict/3": {
    "body": ["http_read_json_dict(${1:Request}, ${2:Dict}, ${3:Options})$4\n$0" ],
    "description":"  http_read_json_dict(+Request, -Dict) is det.\n  http_read_json_dict(+Request, -Dict, +Options) is det.\n\n   Similar to http_read_json/2,3, but by default uses the version 7\n   extended datatypes.",
    "prefix":"http_read_json_dict"
  },
  "http/http_json:reply_json/1": {
    "body": ["reply_json(${1:JSONTerm})$2\n$0" ],
    "description":"  reply_json(+JSONTerm) is det.\n  reply_json(+JSONTerm, +Options) is det.\n\n   Formulate a JSON  HTTP  reply.   See  json_write/2  for details.\n   The processed options are listed below.  Remaining options are\n   forwarded to json_write/3.\n\n       * content_type(+Type)\n       The default =|Content-type|= is =|application/json;\n       charset=UTF8|=. =|charset=UTF8|= should not be required\n       because JSON is defined to be UTF-8 encoded, but some\n       clients insist on it.\n\n       * status(+Code)\n       The default status is 200.  REST API functions may use\n       other values from the 2XX range, such as 201 (created).\n\n       * json_object(+As)\n       One of =term= (classical json representation) or =dict=\n       to use the new dict representation.  If omitted and Term\n       is a dict, =dict= is assumed.  SWI-Prolog Version 7.",
    "prefix":"reply_json"
  },
  "http/http_json:reply_json/2": {
    "body": ["reply_json(${1:JSONTerm}, ${2:Options})$3\n$0" ],
    "description":"  reply_json(+JSONTerm) is det.\n  reply_json(+JSONTerm, +Options) is det.\n\n   Formulate a JSON  HTTP  reply.   See  json_write/2  for details.\n   The processed options are listed below.  Remaining options are\n   forwarded to json_write/3.\n\n       * content_type(+Type)\n       The default =|Content-type|= is =|application/json;\n       charset=UTF8|=. =|charset=UTF8|= should not be required\n       because JSON is defined to be UTF-8 encoded, but some\n       clients insist on it.\n\n       * status(+Code)\n       The default status is 200.  REST API functions may use\n       other values from the 2XX range, such as 201 (created).\n\n       * json_object(+As)\n       One of =term= (classical json representation) or =dict=\n       to use the new dict representation.  If omitted and Term\n       is a dict, =dict= is assumed.  SWI-Prolog Version 7.",
    "prefix":"reply_json"
  },
  "http/http_json:reply_json_dict/1": {
    "body": ["reply_json_dict(${1:JSONTerm})$2\n$0" ],
    "description":"  reply_json_dict(+JSONTerm) is det.\n  reply_json_dict(+JSONTerm, +Options) is det.\n\n   As reply_json/1 and reply_json/2, but assumes the new dict based\n   data representation. Note that this is  the default if the outer\n   object is a dict. This predicate is   needed to serialize a list\n   of   objects   correctly   and     provides   consistency   with\n   http_read_json_dict/2 and friends.",
    "prefix":"reply_json_dict"
  },
  "http/http_json:reply_json_dict/2": {
    "body": ["reply_json_dict(${1:JSONTerm}, ${2:Options})$3\n$0" ],
    "description":"  reply_json_dict(+JSONTerm) is det.\n  reply_json_dict(+JSONTerm, +Options) is det.\n\n   As reply_json/1 and reply_json/2, but assumes the new dict based\n   data representation. Note that this is  the default if the outer\n   object is a dict. This predicate is   needed to serialize a list\n   of   objects   correctly   and     provides   consistency   with\n   http_read_json_dict/2 and friends.",
    "prefix":"reply_json_dict"
  },
  "http/http_log:http_current_host/4": {
    "body":"http_current_host(${1:Request}, ${2:Hostname}, ${3:Port}, ${4:Options})$5\n$0",
    "description":"[det]http_current_host(?Request, -Hostname, -Port, +Options).\n deprecated: Use http_public_host/4  (same semantics)\n\n ",
    "prefix":"http_current_host"
  },
  "http/http_log:http_log/2": {
    "body":"http_log(${1:Format}, ${2:Args})$3\n$0",
    "description":"[det]http_log(+Format, +Args).\nWrite message from Format and Args to log-stream.  See format/2 for details. Succeed without  side effects if logging is not enabled.",
    "prefix":"http_log"
  },
  "http/http_log:http_log_close/1": {
    "body":"http_log_close(${1:Reason})$2\n$0",
    "description":"[det]http_log_close(+Reason).\nIf there is a currently open HTTP logfile, close it after adding a term server(Reason, Time).  to the logfile. This call is intended for cooperation with the Unix  logrotate facility using the following schema:  \n\nMove logfile (the HTTP server keeps writing to the moved file)\nInform the server using an HTTP request that calls http_log_close/1\nCompress the moved logfile\n\n  author: Suggested by Jacco van Ossenbruggen\n\n ",
    "prefix":"http_log_close"
  },
  "http/http_log:http_log_stream/1": {
    "body":"http_log_stream(${1:Stream})$2\n$0",
    "description":"[semidet]http_log_stream(-Stream).\nTrue when Stream is a stream to the opened HTTP log file.  Opens the log file in append mode if the file is not yet  open. The log file is determined from the setting http:logfile.  If this setting is set to the empty atom (''), this predicate fails.  If a file error is encountered, this is reported using print_message/2, after which this  predicate silently fails.\n\n",
    "prefix":"http_log_stream"
  },
  "http/http_log:http_logrotate/1": {
    "body":"http_logrotate(${1:Options})$2\n$0",
    "description":"[det]http_logrotate(+Options).\nRotate the available log files. Note that there are two ways to deal  with the rotation of log files:  \n\nUse the OS log rotation facility. In that case the OS must (1) move  the logfile and (2) have something calling http_log_close/1 to close  the (moved) file and make this server create a new one on the next log  message. If library(http/http_unix_daemon) is used, closing is achieved  by sending SIGHUP or SIGUSR1 to the process.\nCall this predicate at scheduled intervals. This can be achieved by  calling http_schedule_logrotate/2  in the context of library(http/http_unix_daemon) which  schedules the maintenance actions.\n\n  Options: \n\nmin_size(+Bytes): Do not rotate if the log file is smaller than Bytes. The  default is 1Mbytes.\n\nkeep_logs(+Count): Number of rotated log files to keep (default 10)\n\ncompress_logs(+Format): Compress the log files to the given format.\n\nbackground(+Boolean): If true, rotate the log files in the background.\n\n ",
    "prefix":"http_logrotate"
  },
  "http/http_log:http_schedule_logrotate/2": {
    "body":"http_schedule_logrotate(${1:When}, ${2:Options})$3\n$0",
    "description":"http_schedule_logrotate(When, Options).\nSchedule log rotation based on maintenance broadcasts. When  is one of:  daily(Hour:Min): Run each day at Hour:Min. Min is  rounded to a multitude of 5.\n\nweekly(Day, Hour:Min): Run at the given Day and Time each week. Day is  either a number 1..7 (1 is Monday) or a weekday name or abbreviation.\n\nmonthly(DayOfTheMonth, Hour:Min): Run each month at the given Day (1..31). Note that not all months have  all days.\n\n  This must be used with a timer that broadcasts a maintenance(_,_) message (see broadcast/1).  Such a timer is part of library(http/http_unix_daemon).\n\n",
    "prefix":"http_schedule_logrotate"
  },
  "http/http_log:nolog/1": {
    "body":"nolog(${1:HTTPField})$2\n$0",
    "description":"[multifile]nolog(+HTTPField).\nMultifile predicate that can be defined to hide request parameters from  the request logfile.",
    "prefix":"nolog"
  },
  "http/http_log:nolog_post_content_type/1": {
    "body":"nolog_post_content_type(${1:Type})$2\n$0",
    "description":"[semidet,multifile]nolog_post_content_type(+Type).\nMultifile hook called with the Content-type header. If the  hook succeeds, the POST data is not logged. For example, to stop logging  anything but application/json messages:  \n\n:- multifile http_log:nolog_post_content_type/1.\n\nhttp_log:nolog_post_content_type(Type) :-\n   Type \\= (application/json).\n\n  Type is a term MainType/SubType ",
    "prefix":"nolog_post_content_type"
  },
  "http/http_log:password_field/1": {
    "body":"password_field(${1:Field})$2\n$0",
    "description":"[semidet,multifile]password_field(+Field).\nMultifile predicate that can be defined to hide passwords from the  logfile.",
    "prefix":"password_field"
  },
  "http/http_log:post_data_encoded/2": {
    "body":"post_data_encoded(${1:Bytes}, ${2:Encoded})$3\n$0",
    "description":"[det]post_data_encoded(?Bytes:string, ?Encoded:string).\nEncode the POST body for inclusion into the HTTP log file. The POST data  is (in/de)flated using zopen/3 and base64  encoded using base64/3. The encoding makes  long text messages shorter and keeps readable logfiles if binary data is  posted.",
    "prefix":"post_data_encoded"
  },
  "http/http_open:http_close_keep_alive/1": {
    "body":"http_close_keep_alive(${1:Address})$2\n$0",
    "description":"[det]http_close_keep_alive(+Address).\nClose all keep-alive connections matching Address. Address  is of the form Host:Port. In particular, http_close_keep_alive(_)  closes all currently known keep-alive connections.",
    "prefix":"http_close_keep_alive"
  },
  "http/http_open:http_open/3": {
    "body":"http_open(${1:URL}, ${2:Stream}, ${3:Options})$4\n$0",
    "description":"[det]http_open(+URL, -Stream, +Options).\nOpen the data at the HTTP server as a Prolog stream. URL is  either an atom specifying a URL or a list representing a  broken-down URL as specified below. After this predicate  succeeds the data can be read from Stream. After completion  this stream must be closed using the built-in Prolog predicate close/1. Options provides  additional options:  authenticate(+Boolean): If false (default true), do not try to  automatically authenticate the client if a 401 (Unauthorized) status  code is received.\n\nauthorization(+Term): Send authorization. See also http_set_authorization/2.  Supported schemes:  basic(+User, +Password)HTTP Basic authentication.bearer(+Token)HTTP Bearer authentication.digest(+User, +Password)HTTP Digest authentication. This option is only provided if the plugin library(http/http_digest)  is also loaded. \n\nconnection(+Connection): Specify the Connection header. Default is close.  The alternative is Keep-alive. This maintains a pool of  available connections as determined by keep_connection/1.  The library(http/websockets) uses Keep-alive, Upgrade.  Keep-alive connections can be closed explicitly using http_close_keep_alive/1.  Keep-alive connections may significantly improve repetitive requests on  the same server, especially if the IP route is long, HTTPS is used or  the connection uses a proxy.\n\nfinal_url(-FinalURL): Unify FinalURL with the final destination. This differs from  the original URL if the returned head of the original  indicates an HTTP redirect (codes 301, 302 or 303). Without a redirect, FinalURL  is the same as URL if URL is an atom, or a URL constructed from the parts.\n\nheader(Name, -AtomValue): If provided, AtomValue is unified with the value of the  indicated field in the reply header. Name is matched  case-insensitive and the underscore (_) matches the hyphen (-). Multiple  of these options may be provided to extract multiple header fields. If  the header is not available AtomValue is unified to the empty atom ('').\n\nheaders(-List): If provided, List is unified with a list of Name(Value) pairs  corresponding to fields in the reply header. Name and Value follow the  same conventions used by the header(Name,Value) option.\n\nmethod(+Method): One of get (default), head, delete, post, put  or patch. The head message can be used in  combination with the header(Name, Value) option to access  information on the resource without actually fetching the resource  itself. The returned stream must be closed immediately.  If post(Data) is provided, the default is post.\n\nsize(-Size): Size is unified with the integer value of Content-Length  in the reply header.\n\nversion(-Version): Version is a pair Major-Minor, where Major  and Minor are integers representing the HTTP version in the  reply header.\n\nrange(+Range): Ask for partial content. Range is a term Unit(From,To),  where From is an integer and To is either an  integer or the atom end. HTTP 1.1 only supports Unit = bytes.  E.g., to ask for bytes 1000-1999, use the option range(bytes(1000,1999))\n\nredirect(+Boolean): If false (default true), do not  automatically redirect if a 3XX code is received. Must be combined with status_code(Code) and one of the header options to read the  redirect reply. In particular, without status_code(Code) a  redirect is mapped to an exception.\n\nstatus_code(-Code): If this option is present and Code unifies with the HTTP  status code, do not translate errors (4xx, 5xx) into an  exception. Instead, http_open/3  behaves as if 200 (success) is returned, providing the application to  read the error document from the returned stream.\n\noutput(-Out): Unify the output stream with Out and do not close it. This  can be used to upgrade a connection.\n\ntimeout(+Timeout): If provided, set a timeout on the stream using set_stream/2.  With this option if no new data arrives within Timeout  seconds the stream raises an exception. Default is to wait forever (infinite).\n\npost(+Data): Issue a POST request on the HTTP server. Data is  handed to http_post_data/3.\n\nproxy(+Host:Port): Use an HTTP proxy to connect to the outside world. See also socket:proxy_for_url/3. This option  overrules the proxy specification defined by socket:proxy_for_url/3.\n\nproxy(+Host, +Port): Synonym for proxy(+Host:Port). Deprecated.\n\nproxy_authorization(+Authorization): Send authorization to the proxy. Otherwise the same as the authorization option.\n\nbypass_proxy(+Boolean): If true, bypass proxy hooks. Default is false.\n\nrequest_header(Name=Value): Additional name-value parts are added in the order of appearance to the  HTTP request header. No interpretation is done.\n\nmax_redirect(+Max): Sets the maximum length of a redirection chain. This is needed for some  IRIs that redirect indefinitely to other IRIs without looping (e.g.,  redirecting to IRIs with a random element in them). Max must be either a non-negative integer or the atom infinite.  The default value is 10.\n\nuser_agent(+Agent): Defines the value of the User-Agent field of the HTTP  header. Default is SWI-Prolog.\n\n  The hook http:open_options/2  can be used to provide default options based on the broken-down URL.  The option status_code(-Code) is particularly useful to query REST  interfaces that commonly return status codes other than 200  that need to be be processed by the client code.\n\nURL is either an atom or string  (url) or a list of parts. ",
    "prefix":"http_open"
  },
  "http/http_open:http_set_authorization/2": {
    "body":"http_set_authorization(${1:URL}, ${2:Authorization})$3\n$0",
    "description":"[det]http_set_authorization(+URL, +Authorization).\nSet user/password to supply with URLs that have URL as  prefix. If Authorization is the atom -, possibly  defined authorization is cleared. For example:  \n\n?- http_set_authorization('http://www.example.com/private/',\n                          basic('John', 'Secret'))\n\n  To be done: Move to a separate module, so http_get/3,  etc. can use this too.\n\n ",
    "prefix":"http_set_authorization"
  },
  "http/http_openid:http_add_worker/2": {
    "body":"http_add_worker(${1:Port}, ${2:Options})$3\n$0",
    "description":"http_add_worker(+Port, +Options).\nAdd a new worker to the HTTP server for port Port. Options  overrule the default queue options. The following additional options are  processed:  max_idle_time(+Seconds): The created worker will automatically terminate if there is no new work  within Seconds.\n\n ",
    "prefix":"http_add_worker"
  },
  "http/http_openid:http_certificate_hook/3": {
    "body":"http_certificate_hook(${1:CertFile}, ${2:KeyFile}, ${3:Password})$4\n$0",
    "description":"[semidet,multifile]http_certificate_hook(+CertFile, +KeyFile, -Password).\nHook called before starting the server if the --https option is used.  This hook may be used to create or refresh the certificate. If the hook  binds Password to a string, this string will be used to  decrypt the server private key as if the --password=Password  option was given.",
    "prefix":"http_certificate_hook"
  },
  "http/http_openid:http_current_request/1": {
    "body":"http_current_request(${1:Request})$2\n$0",
    "description":"http_current_request(-Request).\nGet access to the currently executing request. Request is the  same as handed to Goal of http_wrapper/5 after  applying rewrite rules as defined by http:request_expansion/2. Raises an  existence error if there is no request in progress.",
    "prefix":"http_current_request"
  },
  "http/http_openid:http_current_worker/2": {
    "body":"http_current_worker(${1:Port}, ${2:ThreadID})$3\n$0",
    "description":"http_current_worker(?Port, ?ThreadID).\nTrue if ThreadID is the identifier of a Prolog thread serving Port. This predicate is motivated to allow for the use of  arbitrary interaction with the worker thread for development and  statistics.",
    "prefix":"http_current_worker"
  },
  "http/http_openid:http_daemon/0": {
    "body":"http_daemon$1\n$0",
    "description":"http_daemon.\nStart the HTTP server as a daemon process. This predicate processes the  commandline arguments below. Commandline arguments that specify servers  are processed in the order they appear using the following schema:  \n\nArguments that act as default for all servers.\n--http=Spec or --https=Spec is followed by  arguments for that server until the next --http=Spec or --https=Spec  or the end of the options.\nIf no --http=Spec or --https=Spec appears,  one HTTP server is created from the specified parameters.  Examples: --workers=10 --http --https --http=8080 --https=8443 --http=localhost:8080 --workers=1 --https=8443 --workers=25  \n\n  --port=Port: Start HTTP server at Port. It requires root permission and the option --user=User  to open ports below 1000. The default port is 80. If --https  is used, the default port is 443.\n\n--ip=IP: Only listen to the given IP address. Typically used as --ip=localhost to restrict access to connections from localhost if the server itself is behind an (Apache) proxy server  running on the same host.\n\n--debug=Topic: Enable debugging Topic. See debug/3.\n\n--syslog=Ident: Write debug messages to the syslog daemon using Ident\n\n--user=User: When started as root to open a port below 1000, this option must be  provided to switch to the target user for operating the server. The  following actions are performed as root, i.e., before switching to User:  open the socket(s)\nwrite the pidfile\nsetup syslog interaction\nRead the certificate, key and password file (--pwfile=File)\n\n\n\n--group=Group: May be used in addition to --user. If omitted, the login  group of the target user is used.\n\n--pidfile=File: Write the PID of the daemon process to File.\n\n--output=File: Send output of the process to File. By default, all Prolog console  output is discarded.\n\n--fork[=Bool]: If given as --no-fork or --fork=false, the  process runs in the foreground.\n\n--http[=(Bool|Port|BindTo:Port)]: Create a plain HTTP server. If the argument is missing or true, create at the specified or default address. Else use  the given port and interface. Thus, --http creates a server  at port 80, --http=8080 creates one at port 8080 and --http=localhost:8080  creates one at port 8080 that is only accessible from localhost.\n\n--https[=(Bool|Port|BindTo:Port)]: As --http, but creates an HTTPS server. Use --certfile, --keyfile, -pwfile, --password and --cipherlist to configure SSL  for this server.\n\n--certfile=File: The server certificate for HTTPS.\n\n--keyfile=File: The server private key for HTTPS.\n\n--pwfile=File: File holding the password for accessing the private key. This is  preferred over using --password=PW as it allows using file  protection to avoid leaking the password. The file is read before  the server drops privileges when started with the --user  option.\n\n--password=PW: The password for accessing the private key. See also `--pwfile`.\n\n--cipherlist=Ciphers: One or more cipher strings separated by colons. See the OpenSSL  documentation for more information. Default is DEFAULT.\n\n--interactive[=Bool]: If true (default false) implies --no-fork  and presents the Prolog toplevel after starting the server.\n\n--gtrace=[Bool]: Use the debugger to trace http_daemon/1.\n\n--sighup=Action: Action to perform on kill -HUP <pid>. Default is reload  (running make/0). Alternative is quit,  stopping the server.\n\n  Other options are converted by argv_options/3  and passed to http_server/1. For example, this allows  for: \n\n--workers=Count: Set the number of workers for the multi-threaded server.\n\n  http_daemon/0 is defined as  below. The start code for a specific server can use this as a starting  point, for example for specifying defaults. \n\n\n\nhttp_daemon :-\n    current_prolog_flag(argv, Argv),\n    argv_options(Argv, _RestArgv, Options),\n    http_daemon(Options).\n\n  See also: http_daemon/1\n\n ",
    "prefix":"http_daemon"
  },
  "http/http_openid:http_daemon/1": {
    "body":"http_daemon(${1:Options})$2\n$0",
    "description":"http_daemon(+Options).\nStart the HTTP server as a daemon process. This predicate processes a  Prolog option list. It is normally called from http_daemon/0,  which derives the option list from the command line arguments.  Error handling depends on whether or not interactive(true)  is in effect. If so, the error is printed before entering the toplevel.  In non-interactive mode this predicate calls halt(1).\n\n",
    "prefix":"http_daemon"
  },
  "http/http_openid:http_parameters/2": {
    "body":"http_parameters(${1:Request}, ${2:Parameters})$3\n$0",
    "description":"http_parameters(+Request, ?Parameters).\nThe predicate is passes the Request as provided to the  handler goal by http_wrapper/5  as well as a partially instantiated lists describing the requested  parameters and their types. Each parameter specification in Parameters  is a term of the format Name(-Value, +Options) . Options  is a list of option terms describing the type, default, etc. If no  options are specified the parameter must be present and its value is  returned in Value as an atom.  If a parameter is missing the exception error(existence_error(http_parameter, Name), _)  is thrown which. If the argument cannot be converted to the requested  type, a error(existence_error(Type, Value), _) is  raised, where the error context indicates the HTTP parameter. If not  caught, the server translates both errors into a 400 Bad request  HTTP message. \n\nOptions fall into three categories: those that handle presence of the  parameter, those that guide conversion and restrict types and those that  support automatic generation of documention. First, the  presence-options: \n\ndefault(Default): If the named parameter is missing, Value is unified to Default.\n\noptional(true): If the named parameter is missing, Value is left unbound and  no error is generated.\n\nlist(Type): The same parameter may not appear or appear multiple times. If this  option is present, default and optional are  ignored and the value is returned as a list. Type checking options are  processed on each value.\n\nzero_or_more: Deprecated. Use list(Type).\n\n  The type and conversion options are given below. The type-language  can be extended by providing clauses for the multifile hook  http:convert_parameter/3. \n\n;(Type1, Type2): Succeed if either Type1 or Type2 applies. It  allows for checks such as (nonneg;oneof([infinite])) to  specify an integer or a symbolic value.\n\noneof(List): Succeeds if the value is member of the given list.\n\nlength > N: Succeeds if value is an atom of more than N characters.\n\nlength >= N: Succeeds if value is an atom of more or than equal to N  characters.\n\nlength < N: Succeeds if value is an atom of less than N characters.\n\nlength =< N: Succeeds if value is an atom of length than or equal to N  characters.\n\natom: No-op. Allowed for consistency.\n\nstring: Convert value to a string.\n\nbetween(+Low, +High): Convert value to a number and if either Low or High  is a float, force value to be a float. Then check that the value is in  the given range, which includes the boundaries.\n\nboolean: Translate =true=, =yes=, =on= and '1' into =true=; =false=, =no=, =off=  and '0' into =false= and raises an error otherwise.\n\nfloat: Convert value to a float. Integers are transformed into float. Throws a  type-error otherwise.\n\ninteger: Convert value to an integer. Throws a type-error otherwise.\n\nnonneg: Convert value to a non-negative integer. Throws a type-error of the  value cannot be converted to an integer and a domain-error otherwise.\n\nnumber: Convert value to a number. Throws a type-error otherwise.\n\n  The last set of options is to support automatic generation of HTTP  API documentation from the sources.2This  facility is under development in ClioPatria; see http_help.pl. \n\ndescription(+Atom): Description of the parameter in plain text.\n\ngroup(+Parameters, +Options): Define a logical group of parameters. Parameters are  processed as normal. Options may include a description of the  group. Groups can be nested.\n\n  Below is an example \n\n\n\nreply(Request) :-\n        http_parameters(Request,\n                        [ title(Title, [ optional(true) ]),\n                          name(Name,   [ length >= 2 ]),\n                          age(Age,     [ between(0, 150) ])\n                        ]),\n        ...\n\n  Same as http_parameters(Request, Parameters,[])\n\n",
    "prefix":"http_parameters"
  },
  "http/http_openid:http_parameters/3": {
    "body":"http_parameters(${1:Request}, ${2:Parameters}, ${3:Options})$4\n$0",
    "description":"http_parameters(+Request, ?Parameters, +Options).\nIn addition to http_parameters/2,  the following options are defined.  form_data(-Data): Return the entire set of provided Name=Value pairs  from the GET or POST request. All values are returned as atoms.\n\nattribute_declarations(:Goal): If a parameter specification lacks the parameter options, call call(Goal, +ParamName, -Options) to find the options.  Intended to share declarations over many calls to http_parameters/3.  Using this construct the above can be written as below.  \n\nreply(Request) :-\n        http_parameters(Request,\n                        [ title(Title),\n                          name(Name),\n                          age(Age)\n                        ],\n                        [ attribute_declarations(param)\n                        ]),\n        ...\n\nparam(title, [optional(true)]).\nparam(name,  [length >= 2 ]).\nparam(age,   [integer]).\n\n  \n\n ",
    "prefix":"http_parameters"
  },
  "http/http_openid:http_read_request/2": {
    "body":"http_read_request(${1:Stream}, ${2:Request})$3\n$0",
    "description":"http_read_request(+Stream, -Request).\nReads an HTTP request from Stream and unify Request  with the parsed request. Request is a list of Name(Value)  elements. It provides a number of predefined elements for the result of  parsing the first line of the request, followed by the additional  request parameters. The predefined fields are:  host(Host): If the request contains Host: Host, Host is  unified with the host-name. If Host is of the format <host>:<port> Host only describes <host> and a field port(Port)  where Port is an integer is added.\n\ninput(Stream): The Stream is passed along, allowing to read more data or  requests from the same stream. This field is always present.\n\nmethod(Method): Method is the HTTP method represented as a  lower-case atom, e.g., get, put, post.  This field is present if the header has been parsed successfully.\n\npath(Path): Path associated to the request. This field is always present.\n\npeer(Peer): Peer is a term ip(A,B,C,D) containing the IP  address of the contacting host.\n\nport(Port): Port requested. See host for details.\n\nrequest_uri(RequestURI): This is the untranslated string that follows the method in the request  header. It is used to construct the path and search fields of the Request.  It is provided because reconstructing this string from the path and  search fields may yield a different value due to different usage of  percent encoding.\n\nsearch(ListOfNameValue): Search-specification of URI. This is the part after the ?,  normally used to transfer data from HTML forms that use the `GET'  protocol. In the URL it consists of a www-form-encoded list of Name=Value  pairs. This is mapped to a list of Prolog Name=Value  terms with decoded names and values. This field is only present if the  location contains a search-specification.  The URL specification does not demand the query part to be  of the form name=value. If the field is syntactically incorrect,  ListOfNameValue is bound the the empty list ([]).\n\nhttp_version(Major-Minor): If the first line contains the HTTP/Major.Minor  version indicator this element indicate the HTTP version of the peer.  Otherwise this field is not present.\n\ncookie(ListOfNameValue): If the header contains a Cookie line, the value of the  cookie is broken down in Name=Value pairs, where  the Name is the lowercase version of the cookie name as used for  the HTTP fields.\n\nset_cookie(set_cookie(Name, Value, Options)): If the header contains a SetCookie line, the cookie field  is broken down into the Name of the cookie, the Value  and a list of Name=Value pairs for additional  options such as expire, path, domain  or secure.\n\n  If the first line of the request is tagged with HTTP/Major.Minor, http_read_request/2  reads all input upto the first blank line. This header consists of Name:Value fields. Each such field appears as a  term Name(Value) in the Request, where Name  is canonicalised for use with Prolog. Canonisation implies that the Name is converted to lower case and all occurrences of the - are replaced by _. The value  for the Content-length fields is translated into an integer.\n\n",
    "prefix":"http_read_request"
  },
  "http/http_openid:http_relative_path/2": {
    "body":"http_relative_path(${1:AbsPath}, ${2:RelPath})$3\n$0",
    "description":"http_relative_path(+AbsPath, -RelPath).\nConvert an absolute path (without host, fragment or search) into a path  relative to the current page, defined as the path component from the  current request (see http_current_request/1).  This call is intended to create reusable components returning relative  paths for easier support of reverse proxies.  If ---for whatever reason--- the conversion is not possible it simply  unifies RelPath to AbsPath.\n\n",
    "prefix":"http_relative_path"
  },
  "http/http_openid:http_server/2": {
    "body":"http_server(${1:Goal}, ${2:Options})$3\n$0",
    "description":"http_server(:Goal, +Options).\nInitialises and runs http_wrapper/5  in a loop until failure or end-of-file. This server does not support the Port  option as the port is specified with the inetd configuration. The  only supported option is After.",
    "prefix":"http_server"
  },
  "http/http_openid:http_server_hook/1": {
    "body":"http_server_hook(${1:Options})$2\n$0",
    "description":"[semidet,multifile]http_server_hook(+Options).\nHook that is called to start the HTTP server. This hook must be  compatible to http_server(Handler, Options). The default is  provided by start_server/1.",
    "prefix":"http_server_hook"
  },
  "http/http_openid:http_server_property/2": {
    "body":"http_server_property(${1:Port}, ${2:Property})$3\n$0",
    "description":"http_server_property(?Port, ?Property).\nTrue if Property is a property of the HTTP server running at Port. Defined properties are:  goal(:Goal): Goal used to start the server. This is often http_dispatch/1.\n\nscheme(-Scheme): Scheme is one of http or https.\n\nstart_time(-Time): Time-stamp when the server was created. See format_time/3  for creating a human-readable representation.\n\n ",
    "prefix":"http_server_property"
  },
  "http/http_openid:http_spawn/2": {
    "body":"http_spawn(${1:Goal}, ${2:Spec})$3\n$0",
    "description":"http_spawn(:Goal, +Spec).\nContinue handling this request in a new thread running Goal.  After http_spawn/2,  the worker returns to the pool to process new requests. In its simplest  form, Spec is the name of a thread pool as defined by thread_pool_create/3.  Alternatively it is an option list, whose options are passed to thread_create_in_pool/4  if Spec contains pool(Pool) or to thread_create/3  of the pool option is not present. If the dispatch module is used (see section  3.2), spawning is normally specified as an option to the http_handler/3  registration.  We recomment the use of thread pools. They allow registration of a  set of threads using common characteristics, specify how many can be  active and what to do if all threads are active. A typical application  may define a small pool of threads with large stacks for computation  intensive tasks, and a large pool of threads with small stacks to serve  media. The declaration could be the one below, allowing for max 3  concurrent solvers and a maximum backlog of 5 and 30 tasks creating  image thumbnails. \n\n\n\n:- use_module(library(thread_pool)).\n\n:- thread_pool_create(compute, 3,\n                      [ local(20000), global(100000), trail(50000),\n                        backlog(5)\n                      ]).\n:- thread_pool_create(media, 30,\n                      [ local(100), global(100), trail(100),\n                        backlog(100)\n                      ]).\n\n:- http_handler('/solve',     solve,     [spawn(compute)]).\n:- http_handler('/thumbnail', thumbnail, [spawn(media)]).\n\n  \n\n",
    "prefix":"http_spawn"
  },
  "http/http_openid:http_stop_server/2": {
    "body":"http_stop_server(${1:Port}, ${2:Options})$3\n$0",
    "description":"http_stop_server(+Port, +Options).\nStop the HTTP server at Port. Halting a server is done gracefully, which means that requests being processed are not  abandoned. The Options list is for future refinements of this  predicate such as a forced immediate abort of the server, but is  currently ignored.",
    "prefix":"http_stop_server"
  },
  "http/http_openid:http_workers/2": {
    "body":"http_workers(${1:Port}, ${2:Workers})$3\n$0",
    "description":"http_workers(+Port, ?Workers).\nQuery or manipulate the number of workers of the server identified by Port. If Workers is unbound it is unified with the  number of running servers. If it is an integer greater than the current  size of the worker pool new workers are created with the same  specification as the running workers. If the number is less than the  current size of the worker pool, this predicate inserts a number of  `quit' requests in the queue, discarding the excess workers as they  finish their jobs (i.e. no worker is abandoned while serving a client).  This can be used to tune the number of workers for performance.  Another possible application is to reduce the pool to one worker to  facilitate easier debugging.\n\n",
    "prefix":"http_workers"
  },
  "http/http_openid:http_wrapper/5": {
    "body":"http_wrapper(${1:Goal}, ${2:In}, ${3:Out}, ${4:Connection}, ${5:Options})$6\n$0",
    "description":"http_wrapper(:Goal, +In, +Out, -Connection, +Options).\nHandle an HTTP request where In is an input stream from the  client, Out is an output stream to the client and Goal  defines the goal realising the body. Connection is unified to 'Keep-alive' if both ends of the connection want to  continue the connection or close if either side wishes to  close the connection.  This predicate reads an HTTP request-header from In,  redirects current output to a memory file and then runs call(Goal,  Request), watching for exceptions and failure. If Goal  executes successfully it generates a complete reply from the created  output. Otherwise it generates an HTTP server error with additional  context information derived from the exception. \n\nhttp_wrapper/5  supports the following options: \n\nrequest(-Request): Return the executed request to the caller.\n\npeer(+Peer): Add peer(Peer) to the request header handed to Goal. The  format of Peer is defined by tcp_accept/3  from the clib package.\n\n ",
    "prefix":"http_wrapper"
  },
  "http/http_openid:openid_associate/3": {
    "body": ["openid_associate(${1:URL}, ${2:Handle}, ${3:Assoc})$4\n$0" ],
    "description":"  openid_associate(?URL, ?Handle, ?Assoc) is det.\n\n   Calls openid_associate/4 as\n\n       ==\n       openid_associate(URL, Handle, Assoc, []).\n       ==",
    "prefix":"openid_associate"
  },
  "http/http_openid:openid_associate/4": {
    "body": [
      "openid_associate(${1:URL}, ${2:Handle}, ${3:Assoc}, ${4:Options})$5\n$0"
    ],
    "description":"  openid_associate(+URL, -Handle, -Assoc, +Options) is det.\n  openid_associate(?URL, +Handle, -Assoc, +Options) is semidet.\n\n   Associate with an open-id server.  We   first  check for a still\n   valid old association. If there is  none   or  it is expired, we\n   esstablish one and remember it.  Options:\n\n     * ns(URL)\n     One of =http://specs.openid.net/auth/2.0= (default) or\n     =http://openid.net/signon/1.1=.\n\n   @tbd    Should we store known associations permanently?  Where?",
    "prefix":"openid_associate"
  },
  "http/http_openid:openid_authenticate/4": {
    "body": [
      "openid_authenticate(${1:Request}, ${2:Server}, ${3:OpenID}, ${4:\n%})$5\n$0"
    ],
    "description":"  openid_authenticate(+Request, -Server:url, -OpenID:url,\n                      -ReturnTo:url) is semidet.\n\n   Succeeds if Request comes from the   OpenID  server and confirms\n   that User is a verified OpenID   user. ReturnTo provides the URL\n   to return to.\n\n   After openid_verify/2 has redirected the   browser to the OpenID\n   server, and the OpenID server did   its  magic, it redirects the\n   browser back to this address.  The   work  is fairly trivial. If\n   =mode= is =cancel=, the OpenId server   denied. If =id_res=, the\n   OpenId server replied positive, but  we   must  verify  what the\n   server told us by checking the HMAC-SHA signature.\n\n   This call fails silently if their is no =|openid.mode|= field in\n   the request.\n\n   @throws openid(cancel)\n           if request was cancelled by the OpenId server\n   @throws openid(signature_mismatch)\n           if the HMAC signature check failed",
    "prefix":"openid_authenticate"
  },
  "http/http_openid:openid_current_host/3": {
    "body": ["openid_current_host(${1:Request}, ${2:Host}, ${3:Port})$4\n$0" ],
    "description":"  openid_current_host(Request, Host, Port)\n\n   Find current location of the server.\n\n   @deprecated     New code should use http_current_host/4 with the\n                   option global(true).",
    "prefix":"openid_current_host"
  },
  "http/http_openid:openid_current_url/2": {
    "body": ["openid_current_url(${1:Request}, ${2:URL})$3\n$0" ],
    "description":"  openid_current_url(+Request, -URL) is det.\n\n   @deprecated     New code should use http_public_url/2 with the\n                   same semantics.",
    "prefix":"openid_current_url"
  },
  "http/http_openid:openid_grant/1": {
    "body": ["openid_grant(${1:Request})$2\n$0" ],
    "description":"  openid_grant(+Request)\n\n   Handle the reply from checkid_setup_server/3.   If  the reply is\n   =yes=, check the authority (typically the   password) and if all\n   looks good redirect the browser to   ReturnTo, adding the OpenID\n   properties needed by the Relying Party to verify the login.",
    "prefix":"openid_grant"
  },
  "http/http_openid:openid_logged_in/1": {
    "body": ["openid_logged_in(${1:OpenID})$2\n$0" ],
    "description":"  openid_logged_in(-OpenID) is semidet.\n\n   True if session is associated with OpenID.",
    "prefix":"openid_logged_in"
  },
  "http/http_openid:openid_login/1": {
    "body": ["openid_login(${1:OpenID})$2\n$0" ],
    "description":"  openid_login(+OpenID) is det.\n\n   Associate the current  HTTP  session   with  OpenID.  If another\n   OpenID is already associated, this association is first removed.",
    "prefix":"openid_login"
  },
  "http/http_openid:openid_logout/1": {
    "body": ["openid_logout(${1:OpenID})$2\n$0" ],
    "description":"  openid_logout(+OpenID) is det.\n\n   Remove the association of the current session with any OpenID",
    "prefix":"openid_logout"
  },
  "http/http_openid:openid_server/2": {
    "body": ["openid_server(${1:Options}, ${2:Request})$3\n$0" ],
    "description":"  openid_server(+Options, +Request)\n\n   Realise the OpenID server. The protocol   demands a POST request\n   here.",
    "prefix":"openid_server"
  },
  "http/http_openid:openid_server/3": {
    "body": ["openid_server(${1:OpenIDLogin}, ${2:OpenID}, ${3:Server})$4\n$0" ],
    "description":"  openid_server(?OpenIDLogin, ?OpenID, ?Server) is nondet.\n\n   True if OpenIDLogin is the typed id for OpenID verified by\n   Server.\n\n   @param OpenIDLogin ID as typed by user (canonized)\n   @param OpenID ID as verified by server\n   @param Server URL of the OpenID server",
    "prefix":"openid_server"
  },
  "http/http_openid:openid_user/3": {
    "body": ["openid_user(${1:Request}, ${2:OpenID}, ${3:Options})$4\n$0" ],
    "description":"  openid_user(+Request:http_request, -OpenID:url, +Options) is det.\n\n   True if OpenID is a validated OpenID associated with the current\n   session. The scenario for which this predicate is designed is to\n   allow  an  HTTP  handler  that  requires    a   valid  login  to\n   use the transparent code below.\n\n     ==\n     handler(Request) :-\n           openid_user(Request, OpenID, []),\n           ...\n     ==\n\n   If the user is not yet logged on a sequence of redirects will\n   follow:\n\n     1. Show a page for login (default: page /openid/login),\n        predicate reply_openid_login/1)\n     2. By default, the OpenID login page is a form that is\n        submitted to the =verify=, which calls openid_verify/2.\n     3. openid_verify/2 does the following:\n        - Find the OpenID claimed identity and server\n        - Associate to the OpenID server\n        - redirects to the OpenID server for validation\n     4. The OpenID server will redirect here with the authetication\n        information.  This is handled by openid_authenticate/4.\n\n   Options:\n\n     * login_url(Login)\n       (Local) URL of page to enter OpenID information. Default\n       is the handler for openid_login_page/1\n\n   @see openid_authenticate/4 produces errors if login is invalid\n   or cancelled.",
    "prefix":"openid_user"
  },
  "http/http_openid:openid_verify/2": {
    "body": ["openid_verify(${1:Options}, ${2:Request})$3\n$0" ],
    "description":"  openid_verify(+Options, +Request)\n\n   Handle the initial login  form  presented   to  the  user by the\n   relying party (consumer). This predicate   discovers  the OpenID\n   server, associates itself with  this   server  and redirects the\n   user's  browser  to  the  OpenID  server,  providing  the  extra\n   openid.X name-value pairs. Options is,  against the conventions,\n   placed in front of the Request   to allow for smooth cooperation\n   with http_dispatch.pl.  Options processes:\n\n     * return_to(+URL)\n     Specifies where the OpenID provider should return to.\n     Normally, that is the current location.\n     * trust_root(+URL)\n     Specifies the =openid.trust_root= attribute.  Defaults to\n     the root of the current server (i.e., =|http://host[.port]/|=).\n     * realm(+URL)\n     Specifies the =openid.realm= attribute.  Default is the\n     =trust_root=.\n     * ax(+Spec)\n     Request the exchange of additional attributes from the\n     identity provider.  See http_ax_attributes/2 for details.\n\n   The OpenId server will redirect to the =openid.return_to= URL.\n\n   @throws http_reply(moved_temporary(Redirect))",
    "prefix":"openid_verify"
  },
  "http/http_parameters:http_convert_parameter/4": {
    "body": [
      "http_convert_parameter(${1:Options}, ${2:FieldName}, ${3:ValueIn}, ${4:ValueOut})$5\n$0"
    ],
    "description":"  http_convert_parameter(+Options, +FieldName, +ValueIn, -ValueOut) is det.\n\n   Conversion of an HTTP form value. First tries the multifile hook\n   http:convert_parameter/3 and next the built-in checks.\n\n   @param Option           List as provided with the parameter\n   @param FieldName        Name of the HTTP field (for better message)\n   @param ValueIn          Atom value as received from HTTP layer\n   @param ValueOut         Possibly converted final value\n   @error type_error(Type, Value)",
    "prefix":"http_convert_parameter"
  },
  "http/http_parameters:http_convert_parameters/2": {
    "body": ["http_convert_parameters(${1:Data}, ${2:Params})$3\n$0" ],
    "description":"  http_convert_parameters(+Data, ?Params) is det.\n  http_convert_parameters(+Data, ?Params, :AttrDecl) is det.\n\n   Implements the parameter  translation   of  http_parameters/2 or\n   http_parameters/3. I.e., http_parameters/2 for   a  POST request\n   can be implemented as:\n\n     ==\n     http_parameters(Request, Params) :-\n         http_read_data(Request, Data, []),\n         http_convert_parameters(Data, Params).\n     ==",
    "prefix":"http_convert_parameters"
  },
  "http/http_parameters:http_convert_parameters/3": {
    "body": [
      "http_convert_parameters(${1:Data}, ${2:Params}, ${3:AttrDecl})$4\n$0"
    ],
    "description":"  http_convert_parameters(+Data, ?Params) is det.\n  http_convert_parameters(+Data, ?Params, :AttrDecl) is det.\n\n   Implements the parameter  translation   of  http_parameters/2 or\n   http_parameters/3. I.e., http_parameters/2 for   a  POST request\n   can be implemented as:\n\n     ==\n     http_parameters(Request, Params) :-\n         http_read_data(Request, Data, []),\n         http_convert_parameters(Data, Params).\n     ==",
    "prefix":"http_convert_parameters"
  },
  "http/http_parameters:http_parameters/2": {
    "body": ["http_parameters(${1:Request}, ${2:Parms})$3\n$0" ],
    "description":"  http_parameters(+Request, ?Parms) is det.\n  http_parameters(+Request, ?Parms, :Options) is det.\n\n   Get HTTP GET  or  POST   form-data,  applying  type  validation,\n   default values, etc.  Provided options are:\n\n           * attribute_declarations(:Goal)\n           Causes the declarations for an attributed named A to be\n           fetched using call(Goal, A, Declarations).\n\n           * form_data(-Data)\n           Return the data read from the GET por POST request as a\n           list Name = Value.  All data, including name/value pairs\n           used for Parms, is unified with Data.\n\n   The attribute_declarations hook allows   sharing the declaration\n   of attribute-properties between many http_parameters/3 calls. In\n   this form, the requested attribute takes   only one argument and\n   the options are acquired by calling the hook. For example:\n\n       ==\n           ...,\n           http_parameters(Request,\n                           [ sex(Sex)\n                           ],\n                           [ attribute_declarations(http_param)\n                           ]),\n           ...\n\n       http_param(sex, [ oneof(male, female),\n                         description('Sex of the person')\n                       ]).\n       ==",
    "prefix":"http_parameters"
  },
  "http/http_parameters:http_parameters/3": {
    "body": ["http_parameters(${1:Request}, ${2:Parms}, ${3:Options})$4\n$0" ],
    "description":"  http_parameters(+Request, ?Parms) is det.\n  http_parameters(+Request, ?Parms, :Options) is det.\n\n   Get HTTP GET  or  POST   form-data,  applying  type  validation,\n   default values, etc.  Provided options are:\n\n           * attribute_declarations(:Goal)\n           Causes the declarations for an attributed named A to be\n           fetched using call(Goal, A, Declarations).\n\n           * form_data(-Data)\n           Return the data read from the GET por POST request as a\n           list Name = Value.  All data, including name/value pairs\n           used for Parms, is unified with Data.\n\n   The attribute_declarations hook allows   sharing the declaration\n   of attribute-properties between many http_parameters/3 calls. In\n   this form, the requested attribute takes   only one argument and\n   the options are acquired by calling the hook. For example:\n\n       ==\n           ...,\n           http_parameters(Request,\n                           [ sex(Sex)\n                           ],\n                           [ attribute_declarations(http_param)\n                           ]),\n           ...\n\n       http_param(sex, [ oneof(male, female),\n                         description('Sex of the person')\n                       ]).\n       ==",
    "prefix":"http_parameters"
  },
  "http/http_path:http_absolute_location/3": {
    "body": ["http_absolute_location(${1:Spec}, ${2:Path}, ${3:Options})$4\n$0" ],
    "description":"  http_absolute_location(+Spec, -Path, +Options) is det.\n\n   Path is the HTTP location for the abstract specification Spec.\n   Options:\n\n       * relative_to(Base)\n       Path is made relative to Base.  Default is to generate\n       absolute URLs.\n\n   @see     http_absolute_uri/2 to create a reference that can be\n            used on another server.",
    "prefix":"http_absolute_location"
  },
  "http/http_path:http_absolute_uri/2": {
    "body": ["http_absolute_uri(${1:Spec}, ${2:URI})$3\n$0" ],
    "description":"  http_absolute_uri(+Spec, -URI) is det.\n\n   URI is the absolute (i.e., starting   with  =|http://|=) URI for\n   the abstract specification Spec. Use http_absolute_location/3 to\n   create references to locations on the same server.\n\n   @tbd    Distinguish =http= from =https=",
    "prefix":"http_absolute_uri"
  },
  "http/http_path:http_clean_location_cache/0": {
    "body": ["http_clean_location_cache$1\n$0" ],
    "description":"  http_clean_location_cache\n\n   HTTP locations resolved  through   http_absolute_location/3  are\n   cached.  This  predicate  wipes   the    cache.   The  cache  is\n   automatically wiped by make/0 and if  the setting http:prefix is\n   changed.",
    "prefix":"http_clean_location_cache"
  },
  "http/http_pwp:mime_include/2": {
    "body":"mime_include(${1:Mime}, ${2:Path})$3\n$0",
    "description":"[semidet,multifile]mime_include(+Mime, +Path)//.\nHook called to include a link to an HTML resource of type Mime  into the HTML head. The Mime type is computed from Path  using file_mime_type/2. If the hook fails, two  built-in rules for text/css and text/javascript are tried. For  example, to include a =.pl= files as a Prolog script, use:  \n\n:- multifile\n    html_head:mime_include//2.\n\nhtml_head:mime_include(text/'x-prolog', Path) --> !,\n    html(script([ type('text/x-prolog'),\n                  src(Path)\n                ],  [])).\n\n  \n\n",
    "prefix":"mime_include"
  },
  "http/http_pwp:pwp_handler/2": {
    "body":"pwp_handler(${1:Options}, ${2:Request})$3\n$0",
    "description":"pwp_handler(+Options, +Request).\nHandle PWP files. This predicate is defined to create a simple HTTP  server from a hierarchy of PWP, HTML and other files. The interface is  kept compatible with the library(http/http_dispatch). In the typical usage scenario,  one needs to define an http location and a file-search path that is used  as the root of the server. E.g., the following declarations create a  self-contained web-server for files in /web/pwp/.  \n\nuser:file_search_path(pwp, '/web/pwp').\n\n:- http_handler(root(.), pwp_handler([path_alias(pwp)]), [prefix]).\n\n  Options include: \n\npath_alias(+Alias): Search for PWP files as Alias(Path). See absolute_file_name/3.\n\nindex(+Index): Name of the directory index (pwp) file. This option may appear multiple  times. If no such option is provided, pwp_handler/2 looks for index.pwp.\n\nview(+Boolean): If true (default is false), allow for  ?view=source to serve PWP file as source.\n\nindex_hook(:Hook): If a directory has no index-file, pwp_handler/2  calls Hook(PhysicalDir, Options, Request). If  this semidet predicate succeeds, the request is considered handled.\n\nhide_extensions(+List): Hide files of the given extensions. The default is to hide .pl files.\n\ndtd(?DTD): DTD to parse the input file with. If unbound, the generated DTD is returned\n\n  Errors: permission_error(index, http_location, Location) is raised  if the handler resolves to a directory that has no index.\n\nSee also: reply_pwp_page/3\n\n ",
    "prefix":"pwp_handler"
  },
  "http/http_pwp:reply_pwp_page/3": {
    "body":"reply_pwp_page(${1:File}, ${2:Options}, ${3:Request})$4\n$0",
    "description":"reply_pwp_page(:File, +Options, +Request).\nReply a PWP file. This interface is provided to server individual  locations from PWP files. Using a PWP file rather than generating the  page from Prolog may be desirable because the page contains a lot of  text (which is cumbersome to generate from Prolog) or because the  maintainer is not familiar with Prolog.  Options supported are: \n\nmime_type(+Type): Serve the file using the given mime-type. Default is text/html.\n\nunsafe(+Boolean): Passed to http_safe_file/2  to check for unsafe paths.\n\npwp_module(+Boolean): If true, (default false), process the PWP file  in a module constructed from its canonical absolute path. Otherwise, the  PWP file is processed in the calling module.\n\n  Initial context: \n\nSCRIPT_NAME: Virtual path of the script.\n\nSCRIPT_DIRECTORY: Physical directory where the script lives\n\nQUERY: Var=Value list representing the query-parameters\n\nREMOTE_USER: If access has been authenticated, this is the authenticated user.\n\nREQUEST_METHOD: One of get, post, put or head\n\nCONTENT_TYPE: Content-type provided with HTTP POST and PUT requests\n\nCONTENT_LENGTH: Content-length provided with HTTP POST and PUT requests\n\n  While processing the script, the file-search-path pwp includes the  current location of the script. I.e., the following will find myprolog  in the same directory as where the PWP file resides. \n\n\n\npwp:ask=\"ensure_loaded(pwp(myprolog))\"\n\n  See also: pwp_handler/2.\n\nTo be done: complete the initial context, as far as possible from CGI variables. See http://hoohoo.ncsa.illinois.edu/docs/cgi/env.html\n\n ",
    "prefix":"reply_pwp_page"
  },
  "http/http_server_files:serve_files_in_directory/2": {
    "body": ["serve_files_in_directory(${1:Alias}, ${2:Request})$3\n$0" ],
    "description":"  serve_files_in_directory(+Alias, +Request)\n\n   Serve files from the directory  Alias   from  the path-info from\n   Request.    This    predicate    is     used    together    with\n   file_search_path/2. Note that multiple  clauses   for  the  same\n   file_search_path alias can be used to merge files from different\n   physical locations onto the same HTTP   directory. Note that the\n   handler must be declared  as  =prefix=.   Below  is  an  example\n   serving images from  http://<host>/img/...   from  the directory\n   =http/web/icons=.\n\n       ==\n       http:location(img, root(img), []).\n       user:file_search_path(icons, library('http/web/icons')).\n\n       :- http_handler(img(.), serve_files_in_directory(icons), [prefix]).\n       ==\n\n   This predicate calls http_404/2 if the   physical file cannot be\n   located. If the requested  path-name   is  unsafe  (i.e., points\n   outside  the  hierarchy  defines    by   the  file_search_path/2\n   declaration), this handlers returns a _403 Forbidden_ page.\n\n   @see http_reply_file/3",
    "prefix":"serve_files_in_directory"
  },
  "http/http_session:http_close_session/1": {
    "body":"http_close_session(${1:SessionID})$2\n$0",
    "description":"[det]http_close_session(+SessionID).\nCloses an HTTP session. This predicate can be called from any thread to  terminate a session. It uses the broadcast/1  service with the message below.  \n\nhttp_session(end(SessionId, Peer))\n\n  The broadcast is done before the session data is destroyed and  the listen-handlers are executed in context of the session that is being  closed. Here is an example that destroys a Prolog thread that is  associated to a thread: \n\n\n\n:- listen(http_session(end(SessionId, _Peer)),\n          kill_session_thread(SessionID)).\n\nkill_session_thread(SessionID) :-\n        http_session_data(thread(ThreadID)),\n        thread_signal(ThreadID, throw(session_closed)).\n\n  Succeed without any effect if SessionID does not refer to  an active session. \n\nIf http_close_session/1  is called from a handler operating in the current session and the CGI  stream is still in state header, this predicate emits a Set-Cookie to  expire the cookie. \n\nErrors: type_error(atom, SessionID)\n\nSee also: listen/2 for acting upon closed sessions\n\n ",
    "prefix":"http_close_session"
  },
  "http/http_session:http_current_session/2": {
    "body":"http_current_session(${1:SessionID}, ${2:Data})$3\n$0",
    "description":"[nondet]http_current_session(?SessionID, ?Data).\nEnumerate the current sessions and associated data. There are two Pseudo  data elements:  idle(Seconds): Session has been idle for Seconds.\n\npeer(Peer): Peer of the connection.\n\n ",
    "prefix":"http_current_session"
  },
  "http/http_session:http_in_session/1": {
    "body":"http_in_session(${1:SessionId})$2\n$0",
    "description":"[semidet]http_in_session(-SessionId).\nTrue if SessionId is an identifier for the current session.  The current session is extracted from session(ID) from the  current HTTP request (see http_current_request/1).  The value is cached in a backtrackable global variable http_session_id.  Using a backtrackable global variable is safe because continuous worker  threads use a failure driven loop and spawned threads start without any  global variables. This variable can be set from the commandline to fake  running a goal from the commandline in the context of a session.  See also: http_session_id/1\n\n ",
    "prefix":"http_in_session"
  },
  "http/http_session:http_open_session/2": {
    "body":"http_open_session(${1:SessionID}, ${2:Options})$3\n$0",
    "description":"[det]http_open_session(-SessionID, +Options).\nEstablish a new session. This is normally used if the create option is  set to noauto. Options:  renew(+Boolean): If true (default false) and the current  request is part of a session, generate a new session-id. By default,  this predicate returns the current session as obtained with http_in_session/1.\n\n  Errors: permission_error(open, http_session, CGI) if this call is  used after closing the CGI header.\n\nSee also: - http_set_session_options/1  to control the create option.  - http_close_session/1  for closing the session.\n\n ",
    "prefix":"http_open_session"
  },
  "http/http_session:http_reply_from_files/3": {
    "body":"http_reply_from_files(${1:Dir}, ${2:Options}, ${3:Request})$4\n$0",
    "description":"http_reply_from_files(+Dir, +Options, +Request).\nHTTP handler that serves files from the directory Dir. This  handler uses http_reply_file/3  to reply plain files. If the request resolves to a directory, it uses  the option indexes to locate an index file (see below) or  uses http_reply_dirindex/3  to create a listing of the directory.  Options: \n\nindexes(+List): List of files tried to find an index for a directory. The  default is ['index.html'].\n\n  Note that this handler must be tagged as a prefix  handler (see http_handler/3 and module  introduction). This also implies that it is possible to override more  specific locations in the hierarchy using http_handler/3  with a longer path-specifier.\n\nDir is either a directory or an  path-specification as used by absolute_file_name/3.  This option provides great flexibility in (re-)locating the physical  files and allows merging the files of multiple physical locations into  one web-hierarchy by using multiple user:file_search_path/2 clauses that  define the same alias.   See also: The hookable predicate file_mime_type/2 is  used to determine the Content-type from the file name.\n\n ",
    "prefix":"http_reply_from_files"
  },
  "http/http_session:http_session_assert/1": {
    "body":"http_session_assert(${1:Data})$2\n$0",
    "description":"[det]http_session_assert(+Data).\n",
    "prefix":"http_session_assert"
  },
  "http/http_session:http_session_asserta/1": {
    "body":"http_session_asserta(${1:Data})$2\n$0",
    "description":"[det]http_session_asserta(+Data).\n",
    "prefix":"http_session_asserta"
  },
  "http/http_session:http_session_cookie/1": {
    "body":"http_session_cookie(${1:Cookie})$2\n$0",
    "description":"[det]http_session_cookie(-Cookie).\nGenerate a random cookie that can be used by a browser to identify the  current session. The cookie has the format XXXX-XXXX-XXXX-XXXX[.<route>],  where XXXX are random hexadecimal numbers and [.<route>]  is the optionally added routing information.",
    "prefix":"http_session_cookie"
  },
  "http/http_session:http_session_data/1": {
    "body":"http_session_data(${1:Data})$2\n$0",
    "description":"[nondet]http_session_data(?Data).\nTrue if Data is associated using http_session_assert/1  to the current HTTP session.  Errors: existence_error(http_session,_)\n\n ",
    "prefix":"http_session_data"
  },
  "http/http_session:http_session_id/1": {
    "body":"http_session_id(${1:SessionId})$2\n$0",
    "description":"[det]http_session_id(-SessionId).\nTrue if SessionId is an identifier for the current session. SessionId is an atom.   Errors: existence_error(http_session, _)\n\nSee also: http_in_session/1 for a  version that fails if there is no session.\n\n ",
    "prefix":"http_session_id"
  },
  "http/http_session:http_session_option/1": {
    "body":"http_session_option(${1:Option})$2\n$0",
    "description":"[nondet]http_session_option(?Option).\nTrue if Option is a current option of the session system.",
    "prefix":"http_session_option"
  },
  "http/http_session:http_session_retract/1": {
    "body":"http_session_retract(${1:Data})$2\n$0",
    "description":"[nondet]http_session_retract(?Data).\n",
    "prefix":"http_session_retract"
  },
  "http/http_session:http_session_retractall/1": {
    "body":"http_session_retractall(${1:Data})$2\n$0",
    "description":"[det]http_session_retractall(?Data).\nVersions of assert/1, retract/1  and retractall/1 that associate data with  the current HTTP session.",
    "prefix":"http_session_retractall"
  },
  "http/http_session:http_set_session/1": {
    "body":"http_set_session(${1:Setting})$2\n$0",
    "description":"[det]http_set_session(Setting).\n",
    "prefix":"http_set_session"
  },
  "http/http_session:http_set_session/2": {
    "body":"http_set_session(${1:SessionId}, ${2:Setting})$3\n$0",
    "description":"[det]http_set_session(SessionId, Setting).\nOverrule a setting for the current or specified session. Currently, the  only setting that can be overruled is timeout.  Errors: permission_error(set, http_session, Setting) if setting a  setting that is not supported on per-session basis.\n\n ",
    "prefix":"http_set_session"
  },
  "http/http_session:http_set_session_options/1": {
    "body":"http_set_session_options(${1:Options})$2\n$0",
    "description":"[det]http_set_session_options(+Options).\nSet options for the session library. Provided options are:  timeout(+Seconds): Session timeout in seconds. Default is 600 (10 min). A timeout of 0  (zero) disables timeout.\n\ncookie(+Cookiekname): Name to use for the cookie to identify the session. Default swipl_session.\n\npath(+Path): Path to which the cookie is associated. Default is /. Cookies are only sent if the HTTP request path is a  refinement of Path.\n\nroute(+Route): Set the route name. Default is the unqualified hostname. To cancel  adding a route, use the empty atom. See route/1.\n\nenabled(+Boolean): Enable/disable session management. Sesion management is enabled by  default after loading this file.\n\ncreate(+Atom): Defines when a session is created. This is one of auto  (default), which creates a session if there is a request whose path  matches the defined session path or noauto, in which cases  sessions are only created by calling http_open_session/2  explicitely.\n\nproxy_enabled(+Boolean): Enable/disable proxy session management. Proxy session management  associates the originating IP address of the client to the  session rather than the proxy IP address. Default is false.\n\n ",
    "prefix":"http_set_session_options"
  },
  "http/http_stream:cgi_discard/1": {
    "body": ["cgi_discard(${1:CGIStream})$2\n$0" ],
    "description":"  cgi_discard(+CGIStream) is det.\n\n   Discard content produced sofar. It sets   the  state property to\n   =discarded=, causing close to omit the   writing  the data. This\n   must be used for an alternate output (e.g. an error page) if the\n   page generator fails.",
    "prefix":"cgi_discard"
  },
  "http/http_stream:cgi_open/4": {
    "body": [
      "cgi_open(${1:OutStream}, ${2:CGIStream}, ${3:Hook}, ${4:Options})$5\n$0"
    ],
    "description":"  cgi_open(+OutStream, -CGIStream, :Hook, +Options) is det.\n\n   Process CGI output. OutStream is   normally the socket returning\n   data to the HTTP client. CGIStream   is  the stream the (Prolog)\n   code writes to. The CGIStream provides the following functions:\n\n       * At the end of the header, it calls Hook using\n       call(Hook, header, Stream), where Stream is a stream holding\n       the buffered header.\n\n       * If the stream is closed, it calls Hook using\n       call(Hook, data, Stream), where Stream holds the buffered\n       data.\n\n   The stream calls Hook, adding  the   event  and CGIStream to the\n   closure. Defined events are:\n\n       * header\n       Called  if  the  header  is   complete.  Typically  it  uses\n       cgi_property/2 to extract the collected  header and combines\n       these with the request and policies   to decide on encoding,\n       transfer-encoding, connection parameters and   the  complete\n       header (as a Prolog term). Typically   it  uses cgi_set/2 to\n       associate these with the stream.\n\n       * send_header\n       Called if the HTTP header must  be sent. This is immediately\n       after setting the transfer encoding to =chunked= or when the\n       CGI stream is closed.  Typically   it  requests  the current\n       header, optionally the content-length and   sends the header\n       to the original (client) stream.\n\n       * close\n       Called from close/1 on the CGI   stream  after everything is\n       complete.\n\n   The predicates cgi_property/2  and  cgi_set/2   can  be  used to\n   control the stream and store status   info.  Terms are stored as\n   Prolog records and can thus be transferred between threads.",
    "prefix":"cgi_open"
  },
  "http/http_stream:cgi_property/2": {
    "body": ["cgi_property(${1:CGIStream}, ${2:Property})$3\n$0" ],
    "description":"  cgi_property(+CGIStream, ?Property) is det.\n\n   Inquire the status of the CGI stream.  Defined properties are:\n\n       * request(-Term)\n       The original request\n       * header(-Term)\n       Term is the header term as registered using cgi_set/2\n       * client(-Stream)\n       Stream is the original output stream used to create\n       this stream.\n       * thread(-ThreadID)\n       ThreadID is the identifier of the `owning thread'\n       * transfer_encoding(-Tranfer)\n       One of =chunked= or =none=.\n       * connection(-Connection)\n       One of =Keep-Alive= or =close=\n       * content_length(-ContentLength)\n       Total byte-size of the content.  Available in the close\n       handler if the transfer_encoding is =none=.\n       * header_codes(-Codes)\n       Codes represents the header collected.  Available in the\n       header handler.\n       * state(-State)\n       One of =header=, =data= or =discarded=\n       * id(-ID)\n       Request sequence number.  This number is guaranteed to be\n       unique.",
    "prefix":"cgi_property"
  },
  "http/http_stream:cgi_set/2": {
    "body": ["cgi_set(${1:CGIStream}, ${2:Property})$3\n$0" ],
    "description":"  cgi_set(+CGIStream, ?Property) is det.\n\n   Change one of the properies.  Supported properties are:\n\n       * request(+Term)\n       Associate a request to the stream.\n       * header(+Term)\n       Register a reply header.  This header is normally retrieved\n       from the =send_header= hook to send the reply header to the\n       client.\n       * connection(-Connection)\n       One of =Keep-Alive= or =close=.\n       * transfer_encoding(-Tranfer)\n       One of =chunked= or =none=.  Initially set to =none=.  When\n       switching to =chunked= from the =header= hook, it calls the\n       =send_header= hook and if there is data queed this is send\n       as first chunk.  Each subsequent write to the CGI stream\n       emits a chunk.",
    "prefix":"cgi_set"
  },
  "http/http_stream:cgi_statistics/1": {
    "body": ["cgi_statistics(${1:Term})$2\n$0" ],
    "description":"  cgi_statistics(?Term)\n\n   Return statistics on the CGI stream subsystem. Currently defined\n   statistics are:\n\n       * requests(-Integer)\n       Total number of requests processed\n       * bytes_sent(-Integer)\n       Total number of bytes sent.",
    "prefix":"cgi_statistics"
  },
  "http/http_stream:http_chunked_open/3": {
    "body": [
      "http_chunked_open(${1:RawStream}, ${2:DataStream}, ${3:Options})$4\n$0"
    ],
    "description":"  http_chunked_open(+RawStream, -DataStream, +Options) is det.\n\n   Create a stream to realise HTTP   chunked  encoding or decoding.\n   The technique is similar to library(zlib), using a Prolog stream\n   as a filter on another stream.  Options:\n\n           * close_parent(+Bool)\n           If =true= (default =false=), the parent stream is closed\n           if DataStream is closed.\n\n           * max_chunk_size(+PosInt)\n           Define the maximum size of a chunk.  Default is the\n           default buffer size of fully buffered streams (4096).\n           Larger values may improve throughput.  It is also\n           allowed to use =|set_stream(DataStream, buffer(line))|=\n           on the data stream to get line-buffered output. See\n           set_stream/2 for details. Switching buffering to =false=\n           is supported.\n\n   Here is example code to write a chunked data to a stream\n\n   ==\n           http_chunked_open(Out, S, []),\n           format(S, 'Hello world~n', []),\n           close(S).\n   ==\n\n   If a stream is known to contain chunked data, we can extract\n   this data using\n\n   ==\n           http_chunked_open(In, S, []),\n           read_stream_to_codes(S, Codes),\n           close(S).\n   ==\n\n   The current implementation does not  generate chunked extensions\n   or an HTTP trailer. If such extensions  appear on the input they\n   are silently ignored. This  is  compatible   with  the  HTTP 1.1\n   specifications. Although a filtering  stream   is  an  excellent\n   mechanism for encoding and decoding   the core chunked protocol,\n   it does not well support out-of-band data.\n\n   After http_chunked_open/3, the encoding  of   DataStream  is the\n   same as the  encoding  of  RawStream,   while  the  encoding  of\n   RawStream is =octet=, the only value   allowed  for HTTP chunked\n   streams. Closing the DataStream  restores   the  old encoding on\n   RawStream.\n\n   @error  io_error(read, Stream) where the message context provides\n           an indication of the problem.  This error is raised if\n           the input is not valid HTTP chunked data.",
    "prefix":"http_chunked_open"
  },
  "http/http_stream:is_cgi_stream/1": {
    "body": ["is_cgi_stream(${1:Stream})$2\n$0" ],
    "description":"  is_cgi_stream(+Stream) is semidet.\n\n   True if Stream is a CGI stream created using cgi_open/4.",
    "prefix":"is_cgi_stream"
  },
  "http/http_stream:multipart_open/3": {
    "body": ["multipart_open(${1:Stream}, ${2:DataSttream}, ${3:Options})$4\n$0" ],
    "description":"  multipart_open(+Stream, -DataSttream, +Options) is det.\n\n   DataStream  is  a  stream  that  signals  `end_of_file`  if  the\n   multipart _boundary_ is encountered. The stream  can be reset to\n   read the next part using multipart_open_next/1. Options:\n\n     - close_parent(+Boolean)\n     Close Stream if DataStream is closed.\n     - boundary(+Text)\n     Define the boundary string.  Text is an atom, string, code or\n     character list.\n\n   All parts of a multipart input can   be read using the following\n   skeleton:\n\n     ==\n     process_multipart(Stream) :-\n           multipart_open(Stream, DataStream, [boundary(...)]),\n           process_parts(DataStream).\n\n     process_parts(DataStream) :-\n           process_part(DataStream),\n           (   multipart_open_next(DataStream)\n           ->  process_parts(DataStream)\n           ;   close(DataStream)\n           ).\n     ==\n\n   @license The multipart parser contains   code licensed under the\n   MIT license, based on _node-formidable_   by Felix Geisendoerfer\n   and Igor Afonov.",
    "prefix":"multipart_open"
  },
  "http/http_stream:multipart_open_next/1": {
    "body": ["multipart_open_next(${1:DataStream})$2\n$0" ],
    "description":"  multipart_open_next(+DataStream) is semidet.\n\n   Prepare DataStream to read the  next   part  from  the multipart\n   input data. Succeeds if a next part exists and fails if the last\n   part was processed. Note that it is  mandatory to read each part\n   up to the end_of_file.",
    "prefix":"multipart_open_next"
  },
  "http/http_stream:stream_range_open/3": {
    "body": [
      "stream_range_open(${1:RawStream}, ${2:DataStream}, ${3:Options})$4\n$0"
    ],
    "description":"  stream_range_open(+RawStream, -DataStream, +Options) is det.\n\n   DataStream is a stream  whose  size   is  defined  by the option\n   size(ContentLength).   Closing   DataStream   does   not   close\n   RawStream.  Options processed:\n\n     - size(+Bytes)\n     Number of bytes represented by the main stream.\n     - onclose(:Closure)\n     Calls call(Closure, RawStream, BytesLeft) when DataStream is\n     closed. BytesLeft is the number of bytes of the range stream\n     that have *not* been read, i.e., 0 (zero) if all data has been\n     read from the stream when the range is closed. This was\n     introduced for supporting Keep-alive in http_open/3 to\n     reschedule the original stream for a new request if the data\n     of the previous request was processed.",
    "prefix":"stream_range_open"
  },
  "http/http_unix_daemon:http_daemon/0": {
    "body": ["http_daemon$1\n$0" ],
    "description":"  http_daemon\n\n   Start the HTTP server  as  a   daemon  process.  This  predicate\n   processes the commandline arguments below. Commandline arguments\n   that specify servers are processed  in   the  order  they appear\n   using the following schema:\n\n     1. Arguments that act as default for all servers.\n     2. =|--http=Spec|= or =|--https=Spec|= is followed by\n        arguments for that server until the next =|--http=Spec|=\n        or =|--https=Spec|= or the end of the options.\n     3. If no =|--http=Spec|= or =|--https=Spec|= appears, one\n        HTTP server is created from the specified parameters.\n\n     Examples:\n\n       ==\n       --workers=10 --http --https\n       --http=8080 --https=8443\n       --http=localhost:8080 --workers=1 --https=8443 --workers=25\n       ==\n\n     $ --port=Port :\n     Start HTTP server at Port. It requires root permission and the\n     option =|--user=User|= to open ports below 1000.  The default\n     port is 80. If =|--https|= is used, the default port is 443.\n\n     $ --ip=IP :\n     Only listen to the given IP address.  Typically used as\n     =|--ip=localhost|= to restrict access to connections from\n     _localhost_ if the server itself is behind an (Apache)\n     proxy server running on the same host.\n\n     $ --debug=Topic :\n     Enable debugging Topic.  See debug/3.\n\n     $ --syslog=Ident :\n     Write debug messages to the syslog daemon using Ident\n\n     $ --user=User :\n     When started as root to open a port below 1000, this option\n     must be provided to switch to the target user for operating\n     the server. The following actions are performed as root, i.e.,\n     _before_ switching to User:\n\n       - open the socket(s)\n       - write the pidfile\n       - setup syslog interaction\n       - Read the certificate, key and password file (=|--pwfile=File|=)\n\n     $ --group=Group :\n     May be used in addition to =|--user|=.  If omitted, the login\n     group of the target user is used.\n\n     $ --pidfile=File :\n     Write the PID of the daemon process to File.\n\n     $ --output=File :\n     Send output of the process to File.  By default, all\n     Prolog console output is discarded.\n\n     $ --fork[=Bool] :\n     If given as =|--no-fork|= or =|--fork=false|=, the process\n     runs in the foreground.\n\n     $ --http[=(Bool|Port|BindTo:Port)] :\n     Create a plain HTTP server.  If the argument is missing or\n     =true=, create at the specified or default address.  Else\n     use the given port and interface.  Thus, =|--http|= creates\n     a server at port 80, =|--http=8080|= creates one at port\n     8080 and =|--http=localhost:8080|= creates one at port\n     8080 that is only accessible from `localhost`.\n\n     $ --https[=(Bool|Port|BindTo:Port)] :\n     As =|--http|=, but creates an HTTPS server.\n     Use =|--certfile|=, =|--keyfile|=, =|-pwfile|=,\n     =|--password|= and =|--cipherlist|= to configure SSL for\n     this server.\n\n     $ --certfile=File :\n     The server certificate for HTTPS.\n\n     $ --keyfile=File :\n     The server private key for HTTPS.\n\n     $ --pwfile=File :\n     File holding the password for accessing  the private key. This\n     is preferred over using =|--password=PW|=   as it allows using\n     file protection to avoid leaking the password.  The file is\n     read _before_ the server drops privileges when started with\n     the =|--user|= option.\n\n     $ --password=PW :\n     The password for accessing the private key. See also `--pwfile`.\n\n     $ --cipherlist=Ciphers :\n     One or more cipher strings separated by colons. See the OpenSSL\n     documentation for more information. Default is `DEFAULT`.\n\n     $ --interactive[=Bool] :\n     If =true= (default =false=) implies =|--no-fork|= and presents\n     the Prolog toplevel after starting the server.\n\n     $ --gtrace=[Bool] :\n     Use the debugger to trace http_daemon/1.\n\n     $ --sighup=Action :\n     Action to perform on =|kill -HUP <pid>|=.  Default is `reload`\n     (running make/0).  Alternative is `quit`, stopping the server.\n\n   Other options are converted  by   argv_options/3  and  passed to\n   http_server/1.  For example, this allows for:\n\n     $ --workers=Count :\n     Set the number of workers for the multi-threaded server.\n\n   http_daemon/0 is defined as below.  The   start  code for a specific\n   server can use this as a starting  point, for example for specifying\n   defaults.\n\n   ```\n   http_daemon :-\n       current_prolog_flag(argv, Argv),\n       argv_options(Argv, _RestArgv, Options),\n       http_daemon(Options).\n   ```\n\n   @see http_daemon/1",
    "prefix":"http_daemon"
  },
  "http/http_unix_daemon:http_daemon/1": {
    "body": ["http_daemon(${1:Options})$2\n$0" ],
    "description":"  http_daemon(+Options)\n\n   Start the HTTP server as a  daemon process. This predicate processes\n   a Prolog option list. It  is   normally  called  from http_daemon/0,\n   which derives the option list from the command line arguments.\n\n   Error handling depends on whether  or   not  interactive(true) is in\n   effect. If so, the error is printed before entering the toplevel. In\n   non-interactive mode this predicate calls halt(1).",
    "prefix":"http_daemon"
  },
  "http/httpd_wrapper:http_current_request/1": {
    "body": ["http_current_request(${1:Request})$2\n$0" ],
    "description":"  http_current_request(-Request) is semidet.\n\n   Returns  the  HTTP  request  currently  being  processed.  Fails\n   silently if there is no current  request. This typically happens\n   if a goal is run outside the HTTP server context.",
    "prefix":"http_current_request"
  },
  "http/httpd_wrapper:http_peer/2": {
    "body": ["http_peer(${1:Request}, ${2:PeerIP})$3\n$0" ],
    "description":"  http_peer(+Request, -PeerIP:atom) is semidet.\n\n   True when PeerIP is the IP address   of  the connection peer. If the\n   connection is established via a proxy  or   CDN  we  try to find the\n   initiating peer.  Currently supports:\n\n     - =Fastly-client-ip=\n     - =X-forwarded-for=\n     - =X-real-ip=\n     - Direct connections",
    "prefix":"http_peer"
  },
  "http/httpd_wrapper:http_relative_path/2": {
    "body": ["http_relative_path(${1:AbsPath}, ${2:RelPath})$3\n$0" ],
    "description":"  http_relative_path(+AbsPath, -RelPath) is det.\n\n   Convert an absolute path (without host, fragment or search) into\n   a path relative to the current page.   This  call is intended to\n   create reusable components returning relative   paths for easier\n   support of reverse proxies.",
    "prefix":"http_relative_path"
  },
  "http/httpd_wrapper:http_send_header/1": {
    "body": ["http_send_header(${1:Header})$2\n$0" ],
    "description":"  http_send_header(+Header)\n\n   This API provides an alternative for writing the header field as\n   a CGI header. Header has the  format Name(Value), as produced by\n   http_read_header/2.\n\n   @deprecated     Use CGI lines instead",
    "prefix":"http_send_header"
  },
  "http/httpd_wrapper:http_spawned/1": {
    "body": ["http_spawned(${1:ThreadId})$2\n$0" ],
    "description":"  http_spawned(+ThreadId)\n\n   Internal use only. Indicate that the request is handed to thread\n   ThreadId.",
    "prefix":"http_spawned"
  },
  "http/httpd_wrapper:http_wrap_spawned/3": {
    "body": ["http_wrap_spawned(${1:Goal}, ${2:Request}, ${3:Close})$4\n$0" ],
    "description":"  http_wrap_spawned(:Goal, -Request, -Close) is det.\n\n   Internal  use  only.  Helper  for    wrapping  the  handler  for\n   http_spawn/2.\n\n   @see http_spawned/1, http_spawn/2.",
    "prefix":"http_wrap_spawned"
  },
  "http/httpd_wrapper:http_wrapper/5": {
    "body": [
      "http_wrapper(${1:Goal}, ${2:In}, ${3:Out}, ${4:Close}, ${5:Options})$6\n$0"
    ],
    "description":"  http_wrapper(:Goal, +In, +Out, -Close, +Options) is det.\n\n   Simple wrapper to read and decode an HTTP header from `In', call\n   :Goal while watching for exceptions and send the result to the\n   stream `Out'.\n\n   The goal is assumed  to  write   the  reply  to =current_output=\n   preceeded by an HTTP header, closed by  a blank line. The header\n   *must* contain a Content-type: <type>   line.  It may optionally\n   contain a line =|Transfer-encoding: chunked|= to request chunked\n   encoding.\n\n   Options:\n\n           * request(-Request)\n           Return the full request to the caller\n           * peer(+Peer)\n           IP address of client\n\n   @param Close    Unified to one of =close=, =|Keep-Alive|= or\n                   spawned(ThreadId).",
    "prefix":"http_wrapper"
  },
  "http/hub:current_hub/2": {
    "body":"current_hub(${1:Name}, ${2:Hub})$3\n$0",
    "description":"[nondet]current_hub(?Name, ?Hub).\nTrue when there exists a hub Hub with Name.",
    "prefix":"current_hub"
  },
  "http/hub:hub_add/3": {
    "body":"hub_add(${1:Hub}, ${2:WebSocket}, ${3:Id})$4\n$0",
    "description":"[det]hub_add(+Hub, +WebSocket, ?Id).\nAdd a WebSocket to the hub. Id is used to identify  this user. It may be provided (as a ground term) or is generated as a  UUID.",
    "prefix":"hub_add"
  },
  "http/hub:hub_broadcast/2": {
    "body":"hub_broadcast(${1:Hub}, ${2:Message})$3\n$0",
    "description":"[det]hub_broadcast(+Hub, +Message).\n",
    "prefix":"hub_broadcast"
  },
  "http/hub:hub_broadcast/3": {
    "body":"hub_broadcast(${1:Hub}, ${2:Message}, ${3:Condition})$4\n$0",
    "description":"[det]hub_broadcast(+Hub, +Message, :Condition).\nSend Message to all websockets associated with Hub  for which call(Condition, Id) succeeds. Note that this process is asynchronous: this predicate returns immediately after putting  all requests in a broadcast queue. If a message cannot be delivered due  to a network error, the hub is informed through io_error/3.",
    "prefix":"hub_broadcast"
  },
  "http/hub:hub_create/3": {
    "body":"hub_create(${1:Name}, ${2:Hub}, ${3:Options})$4\n$0",
    "description":"[det]hub_create(+Name, -Hub, +Options).\nCreate a new hub. Hub is a dict containing the following  public information:  Hub . name(): The name of the hub (the Name argument)\n\nqueues() . event(): Message queue to which the hub thread(s) can listen.\n\n  After creating a hub, the application normally creates a thread that  listens to Hub.queues.event and exposes some mechanisms to  establish websockets and add them to the hub using hub_add/3. \n\nSee also: http_upgrade_to_websocket/3  establishes a websocket from the SWI-Prolog webserver.\n\n ",
    "prefix":"hub_create"
  },
  "http/hub:hub_send/2": {
    "body":"hub_send(${1:ClientId}, ${2:Message})$3\n$0",
    "description":"[semidet]hub_send(+ClientId, +Message).\nSend message to the indicated ClientId. Fails silently if ClientId  does not exist. Message is either a single  message (as accepted by ws_send/2) or a list of such  messages. ",
    "prefix":"hub_send"
  },
  "http/hub:ws_property/2": {
    "body":"ws_property(${1:WebSocket}, ${2:Property})$3\n$0",
    "description":"[nondet]ws_property(+WebSocket, ?Property).\nTrue if Property is a property WebSocket. Defined  properties are:  subprotocol(Protocol): Protocol is the negotiated subprotocol. This is typically set  as a property of the websocket by ws_open/3.\n\n ",
    "prefix":"ws_property"
  },
  "http/javascript:javascript/4": {
    "body": ["javascript(${1:Content}, ${2:Vars}, ${3:VarDict}, ${4:DOM})$5\n$0" ],
    "description":"  javascript(+Content, +Vars, +VarDict, -DOM) is det.\n\n   Quasi quotation parser for JavaScript  that allows for embedding\n   Prolog variables to substitude _identifiers_   in the JavaScript\n   snippet. Parameterizing a JavaScript string   is  achieved using\n   the JavaScript `+` operator, which   results in concatenation at\n   the client side.\n\n     ==\n         ...,\n         js_script({|javascript(Id, Config)||\n                     $(document).ready(function() {\n                        $(\"#\"+Id).tagit(Config);\n                      });\n                    |}),\n         ...\n     ==\n\n   The current implementation tokenizes the   JavaScript  input and\n   yields syntax errors on unterminated  comments, strings, etc. No\n   further parsing is  implemented,  which   makes  it  possible to\n   produce syntactically incorrect and   partial JavaScript. Future\n   versions are likely to include a  full parser, generating syntax\n   errors.\n\n   The parser produces a  term  `\\List`,   which  is  suitable  for\n   js_script//1 and html//1.  Embedded  variables   are  mapped  to\n   `\\js_expression(Var)`, while the remaining  text   is  mapped to\n   atoms.\n\n   @tbd    Implement a full JavaScript parser. Users should _not_\n           rely on the ability to generate partial JavaScript\n           snippets.",
    "prefix":"javascript"
  },
  "http/javascript:js_args/3": {
    "body": ["js_args(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"js_args('Param1','Param2','Param3')",
    "prefix":"js_args"
  },
  "http/js_write:javascript/4": {
    "body":"javascript(${1:Content}, ${2:Vars}, ${3:VarDict}, ${4:DOM})$5\n$0",
    "description":"[det]javascript(+Content, +Vars, +VarDict, -DOM).\nQuasi quotation parser for JavaScript that allows for embedding Prolog  variables to substitude identifiers in the JavaScript snippet.  Parameterizing a JavaScript string is achieved using the JavaScript +  operator, which results in concatenation at the client side.  \n\n    ...,\n    js_script({|javascript(Id, Config)||\n                $(document).ready(function() {\n                   $(\"#\"+Id).tagit(Config);\n                 });\n               |}),\n    ...\n\n  The current implementation tokenizes the JavaScript input and yields  syntax errors on unterminated comments, strings, etc. No further parsing  is implemented, which makes it possible to produce syntactically  incorrect and partial JavaScript. Future versions are likely to include  a full parser, generating syntax errors. \n\nThe parser produces a term \\List, which is suitable for js_script/3 and html/3.  Embedded variables are mapped to \\js_expression(Var), while the remaining text is mapped to  atoms. \n\nTo be done: Implement a full JavaScript parser. Users should not rely on the  ability to generate partial JavaScript snippets.\n\n ",
    "prefix":"javascript"
  },
  "http/js_write:js_arg/1": {
    "body":"js_arg(${1:Expression})$2\n$0",
    "description":"[semidet]js_arg(+Expression)//.\nSame as js_expression/3, but fails if Expression  is invalid, where js_expression/3 raises  an error.  deprecated: New code should use js_expression/3.\n\n ",
    "prefix":"js_arg"
  },
  "http/js_write:js_arg_list/1": {
    "body":"js_arg_list(${1:Expressions})$2\n$0",
    "description":"[det]js_arg_list(+Expressions:list)//.\nWrite javascript (function) arguments. This writes \"(\", Arg, ..., \")\".  See js_expression/3 for valid argument  values.",
    "prefix":"js_arg_list"
  },
  "http/js_write:js_call/1": {
    "body":"js_call(${1:Term})$2\n$0",
    "description":"[det]js_call(+Term)//.\nEmit a call to a Javascript function. The Prolog functor is the name of  the function. The arguments are converted from Prolog to JavaScript  using js_arg_list/3. Please not that  Prolog functors can be quoted atom and thus the following is legal:  \n\n    ...\n    html(script(type('text/javascript'),\n         [ \\js_call('x.y.z'(hello, 42)\n         ]),\n\n ",
    "prefix":"js_call"
  },
  "http/js_write:js_expression/1": {
    "body":"js_expression(${1:Expression})$2\n$0",
    "description":"[det]js_expression(+Expression)//.\nEmit a single JSON argument. Expression is one of:  Variable: Emitted as Javascript null\n\nList: Produces a Javascript list, where each element is processed by this  library.\n\nobject(Attributes): Where Attributes is a Key-Value list where each pair can be written as  Key-Value, Key=Value or Key(Value), accomodating all common constructs  for this used in Prolog. $ { K:V, ... } Same as object(Attributes), providing a more  JavaScript-like syntax. This may be useful if the object appears  literally in the source-code, but is generally less friendlyto produce  as a result from a computation.\n\nDict: Emit a dict as a JSON object using json_write_dict/3.\n\njson(Term): Emits a term using json_write/3.\n\n@(Atom): Emits these constants without quotes. Normally used for the symbols true, false  and null, but can also be use for emitting JavaScript  symbols (i.e. function- or variable names).\n\nNumber: Emited literally\n\nsymbol(Atom): Synonym for @(Atom). Deprecated.\n\nAtom or String: Emitted as quoted JavaScript string.\n\n ",
    "prefix":"js_expression"
  },
  "http/js_write:js_new/2": {
    "body":"js_new(${1:Id}, ${2:Term})$3\n$0",
    "description":"[det]js_new(+Id, +Term)//.\nEmit a call to a Javascript object declaration. This is the same as:  \n\n['var ', Id, ' = new ', \\js_call(Term)]\n\n ",
    "prefix":"js_new"
  },
  "http/js_write:js_script/1": {
    "body":"js_script(${1:Content})$2\n$0",
    "description":"[det]js_script(+Content)//.\nGenerate a JavaScript script element with the given  content.",
    "prefix":"js_script"
  },
  "http/json:atom_json_dict/3": {
    "body": ["atom_json_dict(${1:Atom}, ${2:JSONDict}, ${3:Options})$4\n$0" ],
    "description":"  atom_json_dict(+Atom, -JSONDict, +Options) is det.\n  atom_json_dict(-Text, +JSONDict, +Options) is det.\n\n   Convert  between  textual  representation  and    a   JSON  term\n   represented as a dict. Options are as for json_read/3.\n   In _write_ mode, the addtional option\n\n       * as(Type)\n       defines the output type, which is one of =atom=,\n       =string= or =codes=.",
    "prefix":"atom_json_dict"
  },
  "http/json:atom_json_term/3": {
    "body": ["atom_json_term(${1:Atom}, ${2:JSONTerm}, ${3:Options})$4\n$0" ],
    "description":"  atom_json_term(?Atom, ?JSONTerm, +Options) is det.\n\n   Convert between textual  representation  and   a  JSON  term. In\n   _write_ mode (JSONTerm to Atom), the option\n\n       * as(Type)\n       defines the output type, which is one of =atom= (default),\n       =string=, =codes= or =chars=.",
    "prefix":"atom_json_term"
  },
  "http/json:is_json_term/1": {
    "body": ["is_json_term(${1:Term})$2\n$0" ],
    "description":"  is_json_term(@Term) is semidet.\n  is_json_term(@Term, +Options) is semidet.\n\n   True if Term is  a  json  term.   Options  are  the  same as for\n   json_read/2, defining the Prolog  representation   for  the JSON\n   =true=, =false= and =null= constants.",
    "prefix":"is_json_term"
  },
  "http/json:is_json_term/2": {
    "body": ["is_json_term(${1:Term}, ${2:Options})$3\n$0" ],
    "description":"  is_json_term(@Term) is semidet.\n  is_json_term(@Term, +Options) is semidet.\n\n   True if Term is  a  json  term.   Options  are  the  same as for\n   json_read/2, defining the Prolog  representation   for  the JSON\n   =true=, =false= and =null= constants.",
    "prefix":"is_json_term"
  },
  "http/json:json_read/2": {
    "body": ["json_read(${1:Stream}, ${2:Term})$3\n$0" ],
    "description":"  json_read(+Stream, -Term) is det.\n  json_read(+Stream, -Term, +Options) is det.\n\n   Read next JSON value from Stream into a Prolog term. The\n   canonical representation for Term is:\n\n     * A JSON object is mapped to a term json(NameValueList), where\n       NameValueList is a list of Name=Value. Name is an atom\n       created from the JSON string.\n\n     * A JSON array is mapped to a Prolog list of JSON values.\n\n     * A JSON string is mapped to a Prolog atom\n\n     * A JSON number is mapped to a Prolog number\n\n     * The JSON constants =true= and =false= are mapped -like JPL-\n       to @(true) and @(false).\n\n     * The JSON constant =null= is mapped to the Prolog term\n       @(null)\n\n   Here is a complete example in  JSON and its corresponding Prolog\n   term.\n\n     ==\n     { \"name\":\"Demo term\",\n       \"created\": {\n         \"day\":null,\n         \"month\":\"December\",\n         \"year\":2007\n       },\n       \"confirmed\":true,\n       \"members\":[1,2,3]\n     }\n     ==\n\n     ==\n     json([ name='Demo term',\n            created=json([day= @null, month='December', year=2007]),\n            confirmed= @true,\n            members=[1, 2, 3]\n          ])\n     ==\n\n   The following options are processed:\n\n           * null(+NullTerm)\n           Term used to represent JSON =null=.  Default @(null)\n           * true(+TrueTerm)\n           Term used to represent JSON =true=.  Default @(true)\n           * false(+FalseTerm)\n           Term used to represent JSON =false=.  Default @(false)\n           * value_string_as(+Type)\n           Prolog type used for strings used as value.  Default\n           is =atom=.  The alternative is =string=, producing a\n           packed string object.  Please note that =codes= or\n           =chars= would produce ambiguous output and is therefore\n           not supported.\n\n   If json_read/3 encounters end-of-file before any real data it\n   binds Term to the term @(end_of_file).\n\n   @see    json_read_dict/3 to read a JSON term using the version 7\n           extended data types.",
    "prefix":"json_read"
  },
  "http/json:json_read/3": {
    "body": ["json_read(${1:Stream}, ${2:Term}, ${3:Options})$4\n$0" ],
    "description":"  json_read(+Stream, -Term) is det.\n  json_read(+Stream, -Term, +Options) is det.\n\n   Read next JSON value from Stream into a Prolog term. The\n   canonical representation for Term is:\n\n     * A JSON object is mapped to a term json(NameValueList), where\n       NameValueList is a list of Name=Value. Name is an atom\n       created from the JSON string.\n\n     * A JSON array is mapped to a Prolog list of JSON values.\n\n     * A JSON string is mapped to a Prolog atom\n\n     * A JSON number is mapped to a Prolog number\n\n     * The JSON constants =true= and =false= are mapped -like JPL-\n       to @(true) and @(false).\n\n     * The JSON constant =null= is mapped to the Prolog term\n       @(null)\n\n   Here is a complete example in  JSON and its corresponding Prolog\n   term.\n\n     ==\n     { \"name\":\"Demo term\",\n       \"created\": {\n         \"day\":null,\n         \"month\":\"December\",\n         \"year\":2007\n       },\n       \"confirmed\":true,\n       \"members\":[1,2,3]\n     }\n     ==\n\n     ==\n     json([ name='Demo term',\n            created=json([day= @null, month='December', year=2007]),\n            confirmed= @true,\n            members=[1, 2, 3]\n          ])\n     ==\n\n   The following options are processed:\n\n           * null(+NullTerm)\n           Term used to represent JSON =null=.  Default @(null)\n           * true(+TrueTerm)\n           Term used to represent JSON =true=.  Default @(true)\n           * false(+FalseTerm)\n           Term used to represent JSON =false=.  Default @(false)\n           * value_string_as(+Type)\n           Prolog type used for strings used as value.  Default\n           is =atom=.  The alternative is =string=, producing a\n           packed string object.  Please note that =codes= or\n           =chars= would produce ambiguous output and is therefore\n           not supported.\n\n   If json_read/3 encounters end-of-file before any real data it\n   binds Term to the term @(end_of_file).\n\n   @see    json_read_dict/3 to read a JSON term using the version 7\n           extended data types.",
    "prefix":"json_read"
  },
  "http/json:json_read_dict/2": {
    "body": ["json_read_dict(${1:Stream}, ${2:Dict})$3\n$0" ],
    "description":"  json_read_dict(+Stream, -Dict) is det.\n  json_read_dict(+Stream, -Dict, +Options) is det.\n\n   Read  a  JSON  object,  returning  objects    as  a  dicts.  The\n   representation depends on the options, where the default is:\n\n     * String values are mapped to Prolog strings\n     * JSON =true=, =false= and =null= are represented using these\n       Prolog atoms.\n     * JSON objects are mapped to dicts.\n     * By default, a =type= field in an object assigns a tag for\n       the dict.\n\n   The predicate json_read_dict/3 processes  the   same  options as\n   json_read/3,  but  with  different  defaults.  In  addition,  it\n   processes the `tag` option. See   json_read/3  for details about\n   the shared options.\n\n     * tag(+Name)\n       When converting to/from a dict, map the indicated JSON\n       attribute to the dict _tag_. No mapping is performed if Name\n       is the empty atom ('', default). See json_read_dict/2 and\n       json_write_dict/2.\n     * null(+NullTerm)\n     Default the atom `null`.\n     * true(+TrueTerm)\n     Default the atom `true`.\n     * false(+FalseTerm)\n     Default the atom `false`\n     * value_string_as(+Type)\n     Type defaults to `string`, producing a packed string object.",
    "prefix":"json_read_dict"
  },
  "http/json:json_read_dict/3": {
    "body": ["json_read_dict(${1:Stream}, ${2:Dict}, ${3:Options})$4\n$0" ],
    "description":"  json_read_dict(+Stream, -Dict) is det.\n  json_read_dict(+Stream, -Dict, +Options) is det.\n\n   Read  a  JSON  object,  returning  objects    as  a  dicts.  The\n   representation depends on the options, where the default is:\n\n     * String values are mapped to Prolog strings\n     * JSON =true=, =false= and =null= are represented using these\n       Prolog atoms.\n     * JSON objects are mapped to dicts.\n     * By default, a =type= field in an object assigns a tag for\n       the dict.\n\n   The predicate json_read_dict/3 processes  the   same  options as\n   json_read/3,  but  with  different  defaults.  In  addition,  it\n   processes the `tag` option. See   json_read/3  for details about\n   the shared options.\n\n     * tag(+Name)\n       When converting to/from a dict, map the indicated JSON\n       attribute to the dict _tag_. No mapping is performed if Name\n       is the empty atom ('', default). See json_read_dict/2 and\n       json_write_dict/2.\n     * null(+NullTerm)\n     Default the atom `null`.\n     * true(+TrueTerm)\n     Default the atom `true`.\n     * false(+FalseTerm)\n     Default the atom `false`\n     * value_string_as(+Type)\n     Type defaults to `string`, producing a packed string object.",
    "prefix":"json_read_dict"
  },
  "http/json:json_write/2": {
    "body": ["json_write(${1:Stream}, ${2:Term})$3\n$0" ],
    "description":"  json_write(+Stream, +Term) is det.\n  json_write(+Stream, +Term, +Options) is det.\n\n   Write a JSON term to Stream.  The   JSON  object  is of the same\n   format as produced by json_read/2, though we allow for some more\n   flexibility with regard to pairs in  objects. All of Name=Value,\n   Name-Value and Name(Value) produce the  same output.\n\n   Values can be of the form  #(Term),   which  causes `Term` to be\n   _stringified_ if it is not an atom or string. Stringification is\n   based on term_string/2.\n\n   The version 7 _dict_ type is supported as well. If the dicts has\n   a _tag_, a property \"type\":\"tag\" is   added  to the object. This\n   behaviour can be changed using the =tag= option (see below). For\n   example:\n\n     ==\n     ?- json_write(current_output, point{x:1,y:2}).\n     {\n       \"type\":\"point\",\n       \"x\":1,\n       \"y\":2\n     }\n     ==\n\n   In addition to the options recognised by json_read/3, we process\n   the following options are recognised:\n\n       * width(+Width)\n       Width in which we try to format the result.  Too long lines\n       switch from _horizontal_ to _vertical_ layout for better\n       readability. If performance is critical and human\n       readability is not an issue use Width = 0, which causes a\n       single-line output.\n\n       * step(+Step)\n       Indentation increnment for next level.  Default is 2.\n\n       * tab(+TabDistance)\n       Distance between tab-stops.  If equal to Step, layout\n       is generated with one tab per level.\n\n       * serialize_unknown(+Boolean)\n       If =true= (default =false=), serialize unknown terms and\n       print them as a JSON string.  The default raises a type\n       error.  Note that this option only makes sense if you can\n       guarantee that the passed value is not an otherwise valid\n       Prolog reporesentation of a Prolog term.\n\n   If a string is  emitted,  the   sequence  =|<\/|=  is  emitted as\n   =|<\\/|=. This is valid  JSON  syntax   which  ensures  that JSON\n   objects  can  be  safely  embedded  into  an  HTML  =|<script>|=\n   element.",
    "prefix":"json_write"
  },
  "http/json:json_write/3": {
    "body": ["json_write(${1:Stream}, ${2:Term}, ${3:Options})$4\n$0" ],
    "description":"  json_write(+Stream, +Term) is det.\n  json_write(+Stream, +Term, +Options) is det.\n\n   Write a JSON term to Stream.  The   JSON  object  is of the same\n   format as produced by json_read/2, though we allow for some more\n   flexibility with regard to pairs in  objects. All of Name=Value,\n   Name-Value and Name(Value) produce the  same output.\n\n   Values can be of the form  #(Term),   which  causes `Term` to be\n   _stringified_ if it is not an atom or string. Stringification is\n   based on term_string/2.\n\n   The version 7 _dict_ type is supported as well. If the dicts has\n   a _tag_, a property \"type\":\"tag\" is   added  to the object. This\n   behaviour can be changed using the =tag= option (see below). For\n   example:\n\n     ==\n     ?- json_write(current_output, point{x:1,y:2}).\n     {\n       \"type\":\"point\",\n       \"x\":1,\n       \"y\":2\n     }\n     ==\n\n   In addition to the options recognised by json_read/3, we process\n   the following options are recognised:\n\n       * width(+Width)\n       Width in which we try to format the result.  Too long lines\n       switch from _horizontal_ to _vertical_ layout for better\n       readability. If performance is critical and human\n       readability is not an issue use Width = 0, which causes a\n       single-line output.\n\n       * step(+Step)\n       Indentation increnment for next level.  Default is 2.\n\n       * tab(+TabDistance)\n       Distance between tab-stops.  If equal to Step, layout\n       is generated with one tab per level.\n\n       * serialize_unknown(+Boolean)\n       If =true= (default =false=), serialize unknown terms and\n       print them as a JSON string.  The default raises a type\n       error.  Note that this option only makes sense if you can\n       guarantee that the passed value is not an otherwise valid\n       Prolog reporesentation of a Prolog term.\n\n   If a string is  emitted,  the   sequence  =|<\/|=  is  emitted as\n   =|<\\/|=. This is valid  JSON  syntax   which  ensures  that JSON\n   objects  can  be  safely  embedded  into  an  HTML  =|<script>|=\n   element.",
    "prefix":"json_write"
  },
  "http/json:json_write_dict/2": {
    "body": ["json_write_dict(${1:Stream}, ${2:Dict})$3\n$0" ],
    "description":"  json_write_dict(+Stream, +Dict) is det.\n  json_write_dict(+Stream, +Dict, +Options) is det.\n\n   Write a JSON term, represented using dicts.  This is the same as\n   json_write/3, but assuming the default   representation  of JSON\n   objects as dicts.",
    "prefix":"json_write_dict"
  },
  "http/json:json_write_dict/3": {
    "body": ["json_write_dict(${1:Stream}, ${2:Dict}, ${3:Options})$4\n$0" ],
    "description":"  json_write_dict(+Stream, +Dict) is det.\n  json_write_dict(+Stream, +Dict, +Options) is det.\n\n   Write a JSON term, represented using dicts.  This is the same as\n   json_write/3, but assuming the default   representation  of JSON\n   objects as dicts.",
    "prefix":"json_write_dict"
  },
  "http/json_convert:json_object/1": {
    "body": ["json_object(${1:Declaration})$2\n$0" ],
    "description":"  json_object(+Declaration)\n\n   Declare a JSON object.  The declaration takes the same format as\n   using in record/1 from library(record).  E.g.\n\n     ==\n     ?- json_object\n           point(x:int, y:int, z:int=0).\n     ==\n\n   The type arguments are either types as know to library(error) or\n   functor  names  of  other  JSON   objects.  The  constant  =any=\n   indicates an untyped argument.  If  this   is  a  JSON  term, it\n   becomes  subject  to  json_to_prolog/2.  I.e.,  using  the  type\n   list(any) causes the conversion to be   executed on each element\n   of the list.\n\n   If a field has a default, the default   is  used if the field is\n   not specified in the JSON  object.   Extending  the  record type\n   definition, types can be of  the   form  (Type1|Type2). The type\n   =null= means that the field may _not_ be present.\n\n   Conversion of JSON  to  Prolog   applies  if  all  non-defaulted\n   arguments can be found in  the   JSON  object. If multiple rules\n   match, the term with the highest arity gets preference.",
    "prefix":"json_object"
  },
  "http/json_convert:json_to_prolog/2": {
    "body": ["json_to_prolog(${1:JSON}, ${2:Term})$3\n$0" ],
    "description":"  json_to_prolog(+JSON, -Term) is det.\n\n   Translate  a  JSON  term   into    an   application  term.  This\n   transformation is based on  :-   json_object/1  declarations. An\n   efficient transformation is non-trivial,  but   we  rely  on the\n   assumption that, although the order of   fields in JSON terms is\n   irrelevant and can therefore vary  a lot, practical applications\n   will normally generate the JSON objects in a consistent order.\n\n   If a field in a json_object is declared of type =boolean=, @true\n   and @false are  translated  to  =true=   or  =false=,  the  most\n   commonly used Prolog representation for truth-values.",
    "prefix":"json_to_prolog"
  },
  "http/json_convert:prolog_to_json/2": {
    "body": ["prolog_to_json(${1:Term}, ${2:JSONObject})$3\n$0" ],
    "description":"  prolog_to_json(:Term, -JSONObject) is det.\n\n   Translate a Prolog application Term  into   a  JSON object term.\n   This transformation is based on   :- json_object/1 declarations.\n   If  a  json_object/1  declaration  declares   a  field  of  type\n   =boolean=, commonly used thruth-values in   Prolog are converted\n   to JSON booleans. Boolean  translation   accepts  one of =true=,\n   =on=, =1=, @true, =false=, =fail=, =off= or =0=, @false.\n\n   @error  type_error(json_term, X)\n   @error  instantiation_error",
    "prefix":"prolog_to_json"
  },
  "http/mime_pack:mime_pack/3": {
    "body": ["mime_pack(${1:Inputs}, ${2:Out}, ${3:Boundary})$4\n$0" ],
    "description":"  mime_pack(+Inputs, +Out:stream, ?Boundary) is det.\n\n   Pack a number of inputs into a MIME package using a specified or\n   generated boundary. The  generated  boundary   consists  of  the\n   current time in milliseconds  since  the   epoch  and  10 random\n   hexadecimal numbers. Inputs is a  list   of  _documents_ that is\n   added to the mime message.  Each element is one of:\n\n     * Name = Value\n     Name the document. This emits a header of the form below. The\n     =filename= is present if Value is of the form file(File).\n     Value may be any of remaining value specifications.\n\n       ==\n       Content-Disposition: form-data; name=\"Name\"[; filename=\"<File>\"\n       ==\n\n     * html(Tokens)\n     Tokens is a list of HTML tokens as produced by html//1. The\n     token list is emitted using print_html/1.\n\n     * file(File)\n     Emit the contents of File. The =|Content-type|= is derived\n     from the File using file_mime_type/2.  If the content-type\n     is =|text/_|=, the file data is copied in text mode, which\n     implies that it is read in the default encoding of the system\n     and written using the encoding of the Out stream.  Otherwise\n     the file data is copied binary.\n\n     * stream(In, Len)\n     Content is the next Len units from In.  Data is copied using\n     copy_stream_data/3. Units is bytes for binary streams and\n     characters codes for text streams.\n\n     * stream(In)\n     Content of the stream In, copied using copy_stream_data/2.\n     This is often used with memory files (see new_memory_file/1).\n\n     * mime(Attributes, Value, [])\n     Create a MIME header from Attributes and add Value, which can\n     be any of remaining values of this list. Attributes may\n     contain type(ContentType) and/or character_set(CharSet).  This\n     can be used to give a content-type to values that otherwise\n     do not have a content-type.  For example:\n\n       ==\n       mime([type(text/html)], '<b>Hello World<\/b>', [])\n       ==\n\n     * mime([], '', Parts)\n     Creates a nested multipart MIME message.  Parts is passed\n     as Inputs to a recursive call to mime_pack/2.\n\n     * Atomic\n     Atomic values are passed to write/1. This embeds simple atoms\n     and numbers.\n\n   @param  Out is a stream opened for writing. Typically, it should\n           be opened in text mode using UTF-8 encoding.\n\n   @bug    Does not validate that the boundary does not appear in\n           any of the input documents.",
    "prefix":"mime_pack"
  },
  "http/mimepack:hub_broadcast/3": {
    "body":"hub_broadcast(${1:Hub}, ${2:Message}, ${3:Condition})$4\n$0",
    "description":"[det]hub_broadcast(+Hub, +Message, :Condition).\nSend Message to all websockets associated with Hub  for which call(Condition, Id) succeeds. Note that this process is asynchronous: this predicate returns immediately after putting  all requests in a broadcast queue. If a message cannot be delivered due  to a network error, the hub is informed through io_error/3.",
    "prefix":"hub_broadcast"
  },
  "http/mimepack:mime_pack/3": {
    "body":"mime_pack(${1:Inputs}, ${2:Out}, ${3:Boundary})$4\n$0",
    "description":"[det]mime_pack(+Inputs, +Out:stream, ?Boundary).\nPack a number of inputs into a MIME package using a specified or  generated boundary. The generated boundary consists of the current time  in milliseconds since the epoch and 10 random hexadecimal numbers. Inputs  is a list of documents that is added to the mime message. Each  element is one of:  Name = Value: Name the document. This emits a header of the form below. The filename is present if Value is of the form file(File). Value may be any of remaining value specifications.  \n\nContent-Disposition: form-data; name=\"Name\"[; filename=\"<File>\"\n\n \n\nhtml(Tokens): Tokens is a list of HTML tokens as produced by html/3.  The token list is emitted using print_html/1.\n\nfile(File): Emit the contents of File. The Content-type is  derived from the File using file_mime_type/2.  If the content-type is text/_, the file data is copied in  text mode, which implies that it is read in the default encoding of the  system and written using the encoding of the Out stream.  Otherwise the file data is copied binary.\n\nstream(In, Len): Content is the next Len units from In. Data is  copied using copy_stream_data/3. Units is bytes for  binary streams and characters codes for text streams.\n\nstream(In): Content of the stream In, copied using copy_stream_data/2.  This is often used with memory files (see new_memory_file/1).\n\nmime(Attributes, Value,[]): Create a MIME header from Attributes and add Value,  which can be any of remaining values of this list. Attributes  may contain type(ContentType) and/or character_set(CharSet).  This can be used to give a content-type to values that otherwise do not  have a content-type. For example:  \n\nmime([type(text/html)], '<b>Hello World<\/b>', [])\n\n \n\nmime([], , Parts): Creates a nested multipart MIME message. Parts is passed as Inputs  to a recursive call to mime_pack/2.\n\nAtomic: Atomic values are passed to write/1.  This embeds simple atoms and numbers.\n\n  Out is a stream opened for  writing. Typically, it should be opened in text mode using UTF-8  encoding.   bug: Does not validate that the boundary does not appear in any of the input  documents.\n\n ",
    "prefix":"mime_pack"
  },
  "http/mimetype:file_mime_type/2": {
    "body": ["file_mime_type(${1:FileName}, ${2:MimeType})$3\n$0" ],
    "description":"  file_mime_type(+FileName, -MimeType) is semidet.\n\n   True when MimeType is  the  mime-type   to  be  used for sending\n   FileName. The default rules can be overridden and extended using\n   the hook mime:mime_extension/2.\n\n   @param MimeType is a compound term of the form Type/SubType.",
    "prefix":"file_mime_type"
  },
  "http/term_html:term/4": {
    "body": [
      "term(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"term('Param1','Param2','Param3','Param4')",
    "prefix":"term"
  },
  "http/thread_httpd:http_add_worker/2": {
    "body": ["http_add_worker(${1:Port}, ${2:Options})$3\n$0" ],
    "description":"  http_add_worker(+Port, +Options) is det.\n\n   Add a new worker to  the  HTTP   server  for  port Port. Options\n   overrule the default queue  options.   The  following additional\n   options are processed:\n\n     - max_idle_time(+Seconds)\n     The created worker will automatically terminate if there is\n     no new work within Seconds.",
    "prefix":"http_add_worker"
  },
  "http/thread_httpd:http_close_connection/1": {
    "body": ["http_close_connection(${1:Request})$2\n$0" ],
    "description":"  http_close_connection(+Request)\n\n   Close connection associated to Request.  See also http_requeue/1.",
    "prefix":"http_close_connection"
  },
  "http/thread_httpd:http_current_server/2": {
    "body": ["http_current_server(${1:Goal}, ${2:Port})$3\n$0" ],
    "description":"  http_current_server(:Goal, ?Port) is nondet.\n\n   True if Goal is the goal of a server at Port.\n\n   @deprecated Use http_server_property(Port, goal(Goal))",
    "prefix":"http_current_server"
  },
  "http/thread_httpd:http_current_worker/2": {
    "body": ["http_current_worker(${1:Port}, ${2:ThreadID})$3\n$0" ],
    "description":"  http_current_worker(?Port, ?ThreadID) is nondet.\n\n   True if ThreadID is the identifier   of  a Prolog thread serving\n   Port. This predicate is  motivated  to   allow  for  the  use of\n   arbitrary interaction with the worker thread for development and\n   statistics.",
    "prefix":"http_current_worker"
  },
  "http/thread_httpd:http_enough_workers/3": {
    "body": ["http_enough_workers(${1:Queue}, ${2:Why}, ${3:Peer})$4\n$0" ],
    "description":"  http_enough_workers(+Queue, +Why, +Peer) is det.\n\n   Check that we have enough workers in our queue. If not, call the\n   hook http:schedule_workers/1 to extend  the   worker  pool. This\n   predicate can be used by accept_hook/2.",
    "prefix":"http_enough_workers"
  },
  "http/thread_httpd:http_requeue/1": {
    "body": ["http_requeue(${1:Header})$2\n$0" ],
    "description":"  http_requeue(+Header)\n\n   Re-queue a connection to  the  worker   pool.  This  deals  with\n   processing additional requests on keep-alive connections.",
    "prefix":"http_requeue"
  },
  "http/thread_httpd:http_server/2": {
    "body": ["http_server(${1:Goal}, ${2:Options})$3\n$0" ],
    "description":"  http_server(:Goal, :Options) is det.\n\n   Create a server at Port that calls Goal for each parsed request.\n   Options provide a list of options. Defined options are\n\n     * port(?Address)\n     Port to bind to.  Address is either a port or a term\n     Host:Port. The port may be a variable, causing the system\n     to select a free port.  See tcp_bind/2.\n\n     * tcp_socket(+Socket)\n     If provided, use this socket instead of the creating one and\n     binding it to an address.  The socket must be bound to an\n     address.\n\n     * workers(+Count)\n     Determine the number of worker threads.  Default is 5.  This\n     is fine for small scale usage.  Public servers typically need\n     a higher number.\n\n     * timeout(+Seconds)\n     Max time of inactivity trying to read the request after a\n     connection has been opened.  Default is 60 seconds.  See\n     set_stream/1 using the _timeout_ option.\n\n     * keep_alive_timeout(+Seconds)\n     Time to keep `Keep alive' connections alive.  Default is\n     2 seconds.\n\n     * local(+Kbytes)\n     * global(+Kbytes)\n     * trail(+Kbytes)\n     Stack sizes to use for the workers.  The default is inherited\n     from the `main` thread. As of version 5.9 stacks are no longer\n     _pre-allocated_ and the given sizes only act as a limit.\n     If you need to control resource usage look at the `spawn`\n     option of http_handler/3 and library(thread_pool).\n\n   A  typical  initialization  for  an    HTTP   server  that  uses\n   http_dispatch/1 to relay requests to predicates is:\n\n     ==\n     :- use_module(library(http/thread_httpd)).\n     :- use_module(library(http/http_dispatch)).\n\n     start_server(Port) :-\n         http_server(http_dispatch, [port(Port)]).\n     ==\n\n   Note that multiple servers  can  coexist   in  the  same  Prolog\n   process. A notable application of this is   to have both an HTTP\n   and HTTPS server, where the HTTP   server redirects to the HTTPS\n   server for handling sensitive requests.",
    "prefix":"http_server"
  },
  "http/thread_httpd:http_server_property/2": {
    "body": ["http_server_property(${1:Port}, ${2:Property})$3\n$0" ],
    "description":"  http_server_property(?Port, ?Property) is nondet.\n\n   True if Property is a property of the HTTP server running at\n   Port.  Defined properties are:\n\n       * goal(:Goal)\n       Goal used to start the server. This is often\n       http_dispatch/1.\n       * scheme(-Scheme)\n       Scheme is one of `http` or `https`.\n       * start_time(?Time)\n       Time-stamp when the server was created.",
    "prefix":"http_server_property"
  },
  "http/thread_httpd:http_spawn/2": {
    "body": ["http_spawn(${1:Goal}, ${2:Options})$3\n$0" ],
    "description":"  http_spawn(:Goal, +Options) is det.\n\n   Continue this connection on a  new   thread.  A handler may call\n   http_spawn/2 to start a new thread that continues processing the\n   current request using Goal. The original   thread returns to the\n   worker pool for processing new requests.   Options are passed to\n   thread_create/3, except for:\n\n       * pool(+Pool)\n       Interfaces to library(thread_pool), starting the thread\n       on the given pool.\n\n   If a pool does not exist, this predicate calls the multifile\n   hook http:create_pool/1 to create it. If this predicate succeeds\n   the operation is retried.",
    "prefix":"http_spawn"
  },
  "http/thread_httpd:http_stop_server/2": {
    "body": ["http_stop_server(${1:Port}, ${2:Options})$3\n$0" ],
    "description":"  http_stop_server(+Port, +Options)\n\n   Stop the indicated  HTTP  server   gracefully.  First  stops all\n   workers, then stops the server.\n\n   @tbd    Realise non-graceful stop",
    "prefix":"http_stop_server"
  },
  "http/thread_httpd:http_workers/2": {
    "body": ["http_workers(${1:Port}, ${2:Workers})$3\n$0" ],
    "description":"  http_workers(+Port, -Workers) is det.\n  http_workers(+Port, +Workers:int) is det.\n\n   Query or set the number of workers  for the server at this port.\n   The number of workers is dynamically   modified. Setting it to 1\n   (one) can be used to profile the worker using tprofile/1.",
    "prefix":"http_workers"
  },
  "http/websocket:http_chunked_open/3": {
    "body":"http_chunked_open(${1:RawStream}, ${2:DataStream}, ${3:Options})$4\n$0",
    "description":"http_chunked_open(+RawStream, -DataStream, +Options).\nCreate a stream to realise HTTP chunked encoding or decoding. The  technique is similar to library(zlib), using a Prolog stream as a filter  on another stream. See online documentation at http://www.swi-prolog.org/  for details.",
    "prefix":"http_chunked_open"
  },
  "http/websocket:http_open_websocket/3": {
    "body":"http_open_websocket(${1:URL}, ${2:WebSocket}, ${3:Options})$4\n$0",
    "description":"[det]http_open_websocket(+URL, -WebSocket, +Options).\nEstablish a client websocket connection. This predicate calls http_open/3 with additional  headers to negotiate a websocket connection. In addition to the options  processed by http_open, the following options are recognised:  subprotocols(+List): List of subprotocols that are acceptable. The selected  protocol is available as ws_property(WebSocket, subprotocol(Protocol).\n\n  The following example exchanges a message with the  html5rocks.websocket.org echo service: \n\n\n\n?- URL = 'ws://html5rocks.websocket.org/echo',\n   http_open_websocket(URL, WS, []),\n   ws_send(WS, text('Hello World!')),\n   ws_receive(WS, Reply),\n   ws_close(WS, 1000, \"Goodbye\").\nURL = 'ws://html5rocks.websocket.org/echo',\nWS = <stream>(0xe4a440,0xe4a610),\nReply = websocket{data:\"Hello World!\", opcode:text}.\n\n  WebSocket is a stream pair (see stream_pair/3) ",
    "prefix":"http_open_websocket"
  },
  "http/websocket:http_upgrade_to_websocket/3": {
    "body":"http_upgrade_to_websocket(${1:Goal}, ${2:Options}, ${3:Request})$4\n$0",
    "description":"http_upgrade_to_websocket(:Goal, +Options, +Request).\nCreate a websocket connection running call(Goal, WebSocket),  where WebSocket is a socket-pair. Options:  guarded(+Boolean): If true (default), guard the execution of Goal  and close the websocket on both normal and abnormal termination of Goal.  If false, Goal itself is responsible for the  created websocket. This can be used to create a single thread that  manages multiple websockets using I/O multiplexing.\n\nsubprotocols(+List): List of acceptable subprotocols.\n\ntimeout(+TimeOut): Timeout to apply to the input stream. Default is infinite.\n\n  Note that the Request argument is the last for cooperation  with http_handler/3. A simple echo  server that can be accessed at =/ws/= can be implemented as: \n\n\n\n:- use_module(library(http/websocket)).\n:- use_module(library(http/thread_httpd)).\n:- use_module(library(http/http_dispatch)).\n\n:- http_handler(root(ws),\n                http_upgrade_to_websocket(echo, []),\n                [spawn([])]).\n\necho(WebSocket) :-\n    ws_receive(WebSocket, Message),\n    (   Message.opcode == close\n    ->  true\n    ;   ws_send(WebSocket, Message),\n        echo(WebSocket)\n    ).\n\n  throws: switching_protocols(Goal, Options). The recovery from this  exception causes the HTTP infrastructure to call call(Goal, WebSocket).\n\nSee also: http_switch_protocol/2.\n\n ",
    "prefix":"http_upgrade_to_websocket"
  },
  "http/websocket:ws_close/3": {
    "body":"ws_close(${1:WebSocket}, ${2:Code}, ${3:Data})$4\n$0",
    "description":"[det]ws_close(+WebSocket:stream_pair, +Code, +Data).\nClose a WebSocket connection by sending a close  message if this was not already sent and wait for the close reply. Code is the numerical code  indicating the close status. This is 16-bit integer. The codes are  defined in section 7.4.1. Defined Status Codes of RFC6455.  Notably, 1000 indicates a normal closure. Data is currently interpreted  as text.   Errors: websocket_error(unexpected_message, Reply) if the other  side did not send a close message in reply.\n\n ",
    "prefix":"ws_close"
  },
  "http/websocket:ws_open/3": {
    "body":"ws_open(${1:Stream}, ${2:WSStream}, ${3:Options})$4\n$0",
    "description":"[det]ws_open(+Stream, -WSStream, +Options).\nTurn a raw TCP/IP (or any other binary stream) into a websocket stream. Stream  can be an input stream, output stream or a stream pair. Options  includes  mode(+Mode): One of server or client. If client,  messages are sent as masked.\n\nbuffer_size(+Count): Send partial messages for each Count bytes or when flushing  the output. The default is to buffer the entire message before it is  sent.\n\nclose_parent(+Boolean): If true (default), closing WSStream also closes Stream.\n\nsubprotocol(+Protocol): Set the subprotocol property of WsStream. This value can be retrieved  using ws_property/2. Protocol  is an atom. See also the subprotocols option of http_open_websocket/3  and http_upgrade_to_websocket/3.\n\n  A typical sequence to turn a pair of streams into a WebSocket is  here: \n\n\n\n    ...,\n    Options = [mode(server), subprotocol(chat)],\n    ws_open(Input, WsInput, Options),\n    ws_open(Output, WsOutput, Options),\n    stream_pair(WebSocket, WsInput, WsOutput).\n\n ",
    "prefix":"ws_open"
  },
  "http/websocket:ws_property/2": {
    "body":"ws_property(${1:WebSocket}, ${2:Property})$3\n$0",
    "description":"[nondet]ws_property(+WebSocket, ?Property).\nTrue if Property is a property WebSocket. Defined  properties are:  subprotocol(Protocol): Protocol is the negotiated subprotocol. This is typically set  as a property of the websocket by ws_open/3.\n\n ",
    "prefix":"ws_property"
  },
  "http/websocket:ws_receive/2": {
    "body":"ws_receive(${1:WebSocket}, ${2:Message})$3\n$0",
    "description":"[det]ws_receive(+WebSocket, -Message:dict).\n",
    "prefix":"ws_receive"
  },
  "http/websocket:ws_receive/3": {
    "body":"ws_receive(${1:WebSocket}, ${2:Message}, ${3:Options})$4\n$0",
    "description":"[det]ws_receive(+WebSocket, -Message:dict, +Options).\nReceive the next message from WebSocket. Message  is a dict containing the following keys:  opcode() : OpCode: OpCode of the message. This is an atom for known opcodes and  an integer for unknown ones. If the peer closed the stream, OpCode  is bound to close and data to the atom end_of_file.\n\ndata() : String: The data, represented as a string. This field is always present. String  is the empty string if there is no data in the message.\n\nrsv() : RSV: Present if the WebSocket RSV header is not 0. RSV  is an integer in the range [1..7].\n\n  If ping message is received and WebSocket is  a stream pair, ws_receive/1 replies with a pong  and waits for the next message. \n\nThe predicate ws_receive/3  processes the following options: \n\nformat(+Format): Defines how text messages are parsed. Format is one of  stringData is returned as a Prolog string (default)jsonData is parsed using json_read_dict/3,  which also receives Options.prologData is parsed using read_term/3, which  also receives Options. \n\n  To be done: Add a hook to allow for more data formats?\n\n ",
    "prefix":"ws_receive"
  },
  "http/websocket:ws_send/2": {
    "body":"ws_send(${1:WebSocket}, ${2:Message})$3\n$0",
    "description":"[det]ws_send(+WebSocket, +Message).\nSend a message over a websocket. The following terms are allowed for Message:  text(+Text): Send a text message. Text is serialized using write/1.\n\nbinary(+Content): As text(+Text), but all character codes produced by Content  must be in the range [0..255]. Typically, Content will be an  atom or string holding binary data.\n\nprolog(+Term): Send a Prolog term as a text message. Text is serialized using write_canonical/1.\n\njson(+JSON): Send the Prolog representation of a JSON term using json_write_dict/2.\n\nstring(+Text): Same as text(+Text), provided for consistency.\n\nclose(+Code, +Text): Send a close message. Code is 1000 for normal close. See  websocket documentation for other values.\n\nDict: A dict that minimally contains an opcode key. Other keys  used are:  format() : FormatSerialization format used for Message.data. Format  is one of string, prolog or json.  See ws_receive/3.data() : TermIf this key is present, it is serialized according to Message.format.  Otherwise it is serialized using write/1, which implies that string and  atoms are just sent verbatim. \n\n  Note that ws_start_message/3 does not  unlock the stream. This is done by ws_send/1.  This implies that multiple threads can use ws_send/2 and the messages are  properly serialized. \n\nTo be done: Provide serialization details using options.\n\n ",
    "prefix":"ws_send"
  },
  "http/xpce_httpd:http_current_server/2": {
    "body": ["http_current_server(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"http_current_server('Param1','Param2')",
    "prefix":"http_current_server"
  },
  "http/xpce_httpd:http_server/2": {
    "body": ["http_server(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"http_server('Param1','Param2')",
    "prefix":"http_server"
  },
  "http/yadis:xrds_dom/2": {
    "body": ["xrds_dom(${1:Id}, ${2:XRDS_DOM})$3\n$0" ],
    "description":"  xrds_dom(+Id, -XRDS_DOM) is det.\n\n   True when XRDS_DOM is  a  parsed   XML  document  for  the given\n   resource.",
    "prefix":"xrds_dom"
  },
  "http/yadis:xrds_location/2": {
    "body": ["xrds_location(${1:Id}, ${2:XRDSLocation})$3\n$0" ],
    "description":"  xrds_location(+Id, -XRDSLocation) is semidet.\n\n   Discover the location of the XRDS document from the given Id.",
    "prefix":"xrds_location"
  },
  "ignore/1": {
    "body":"ignore(${1:Goal})$2\n$0",
    "description":"ignore(:Goal).\nCalls Goal as once/1,  but succeeds, regardless of whether Goal succeeded or not. Defined as:  \n\nignore(Goal) :-\n        Goal, !.\nignore(_).\n\n ",
    "prefix":"ignore"
  },
  "import/2": {
    "body":"import(${1:PredicateIndicator}, ${2:...})$3\n$0",
    "description":"import(+PredicateIndicator, ...).\nImport predicates PredicateIndicator into the current context  module. PredicateIndicator must specify the source module  using the <module>:<pi> construct.  Note that predicates are normally imported using one of the directives use_module/[1,2].  The import/1  alternative is meant for handling imports into dynamically created  modules. See also export/1  and export_list/2.",
    "prefix":"import"
  },
  "import_module/2": {
    "body":"import_module(${1:Module}, ${2:Import})$3\n$0",
    "description":"[nondet]import_module(+Module, -Import).\nTrue if Module inherits directly from Import. All  normal modules only import from user, which imports from system. The predicates add_import_module/3  and delete_import_module/2  can be used to manipulate the import list. See also default_module/2.",
    "prefix":"import_module"
  },
  "in_pce_thread/1": {
    "body":"in_pce_thread(${1:Goal})$2\n$0",
    "description":"[det]in_pce_thread(:Goal).\nAssuming XPCE is running in the foreground thread, this call gives  background threads the opportunity to make calls to the XPCE thread. A  call to in_pce_thread/1  succeeds immediately, copying Goal to the XPCE thread. Goal  is added to the XPCE event queue and executed synchronous to normal user  events like typing and clicking.",
    "prefix":"in_pce_thread"
  },
  "in_pce_thread_sync/1": {
    "body":"in_pce_thread_sync(${1:Goal})$2\n$0",
    "description":"[semidet]in_pce_thread_sync(:Goal).\nSame as in_pce_thread/1,  but wait for Goal to be completed. Success depends on the  success of executing Goal. Variable bindings inside Goal  are visible to the caller, but it should be noted that the values are  being copied. If Goal throws an exception, this  exception is re-thrown by in_pce_thread/1.  If the calling thread is the `pce thread', in_pce_thread_sync/1  executes a direct meta-call. See also pce_thread/1.  Note that in_pce_thread_sync/1  is expensive because it requires copying and thread communication. For  example, in_pce_thread_synctrue runs at approximately  50,000 calls per second (AMD Phenom 9600B, Ubuntu 11.04).\n\n",
    "prefix":"in_pce_thread_sync"
  },
  "in_table/3": {
    "body":"in_table(${1:Handle}, ${2:Fields}, ${3:RecordPos})$4\n$0",
    "description":"in_table(+Handle, ?Fields, -RecordPos).\nSearches the table for records matching Fields. If a match is  found, the variable (see below) fields in Fields are unified  with the corresponding field value, and RecordPos is unified  with the position of the record. The latter handle may be used in a  subsequent call to read_table_record/4  or read_table_fields/4.  Fields is a list of field specifiers. Each specifier is of  the format:\n\nFieldName(Value [, Options])  Options is a list of options to specify the search. By  default, the package will search for an exact match, possibly using the  ordering table associated with the field (see order option  in new_table/4).  Options are: \n\n\n\nprefixUses prefix search with  the default table. prefix(Table)Uses  prefix search with the specified ordering table. substringSearches for a  substring in the field. This requires linear search of the table. substring(Table)Searches  for a substring, using the table information for determining the  equivalence of characters. =Default equivalence. =(Table)Equivalence  using the given table.   If Value is unbound (i.e. a variable), the record is  considered not specified. The possible option list is ignored. If a  match is found on the remaining fields, the variable is unified with the  value found in the field. \n\nFirst, the system checks whether there is an ordered field that is  specified. In this case, binary search is employed to find the matching  record(s). Otherwise, linear search is used. \n\nIf the match contains a specified field that has the property unique set (see new_table/4), in_table/3  succeeds deterministically. Otherwise it will create a backtrack-point  and backtracking will yield further solutions to the query. \n\nin_table/3  may be comfortable used to bind the table transparently to a predicate.  For example, we have a file with lines of the format.1This  is the disproot.dat table from the AAT  database used in GRASP \n\n\n\n    C1C2,Full Name\n    \n\n  C1C2 is a two-character identifier used in the other  tables, and FullName is the description of the identifier. We  want to have a predicate identifier_name(?Id, ?FullName) to reflect this  table. The code below does the trick: \n\n\n\n    :- dynamic stored_idtable_handle/1.\n\n\n    idtable(Handle) :-\n            stored_idtable_handle(Handle).\n    idtable(Handle) :-\n            new_table('disproot.dat',\n                      [ id(atom, [downcase, sorted, unique]),\n                        name(atom)\n                      ],\n                      [ field_separator(0',)\n                      ], Handle),\n            assert(stored_idtable_handle(Handle)).\n\n    identifier_name(Id, Name) :-\n            idtable(Handle),\n            in_table(Handle, [id(Id), name(Name)], _).\n    \n\n  \n\n",
    "prefix":"in_table"
  },
  "include/1": {
    "body":"include(${1:File})$2\n$0",
    "description":"[ISO]include(+File).\nTextually include the content of File at the position where  the directive :- include(File). appears. The include  construct is only honoured if it appears as a directive in a source  file. Textual include (similar to C/C++ #include) is obviously  useful for sharing declarations such as dynamic/1  or multifile/1  by including a file with directives from multiple files that use these  predicates.  Textually including files that contain clauses is less  obvious. Normally, in SWI-Prolog, clauses are owned by the file  in which they are defined. This information is used to replace  the old definition after the file has been modified and is reloaded by,  e.g., make/0.  As we understand it, include/1  is intended to include the same file multiple times. Including a file  holding clauses multiple times into the same module is rather  meaningless as it just duplicates the same clauses. Including a file  holding clauses in multiple modules does not suffer from this problem,  but leads to multiple equivalent copies of predicates. Using use_module/1  can achieve the same result while sharing the predicates. \n\nIf include/1  is used to load files holding clauses, and if these files are loaded  only once, then these include/1  directives can be replaced by other predicates (such as consult/1).  However, there are several cases where either include/1  has no alternative, or using any alternative also requires other  changes. An example of the former is using include/1  to share directives. An example of the latter are cases where clauses of  different predicates are distributed over multiple files: If these files  are loaded with include/1,  the directive discontiguous/1  is appropriate, whereas if they are consulted, one must use the  directive multifile/1. \n\nTo accommodate included files holding clauses, SWI-Prolog  distinguishes between the source location of a clause (in this case the  included file) and the owner of a clause (the file that  includes the file holding the clause). The source location is used by,  e.g., edit/1,  the graphical tracer, etc., while the owner is used to determine which  clauses are removed if the file is modified. Relevant information is  found with the following predicates: \n\n\n\nsource_file/2  describes the owner relation.\npredicate_property/2  describes the source location (of the first clause).\nclause_property/2  provides access to both source and ownership.\nsource_file_property/2  can be used to query include relationships between files.\n\n",
    "prefix":"include"
  },
  "inf/0": {
    "body":"inf$1\n$0",
    "description":"inf.\nEvaluate to positive infinity. See section  2.15.1.6. This value can be negated using -/1.",
    "prefix":"inf"
  },
  "instance/2": {
    "body":"instance(${1:Reference}, ${2:Term})$3\n$0",
    "description":"instance(+Reference, -Term).\nUnify Term with the referenced clause or database record.  Unit clauses are represented as Head :- true.",
    "prefix":"instance"
  },
  "integer/1": {
    "body":"integer(${1:Term})$2\n$0",
    "description":"[ISO]integer(@Term).\nTrue if Term is bound to an integer.",
    "prefix":"integer"
  },
  "iostream:close_any/1": {
    "body":"close_any(${1:Goal})$2\n$0",
    "description":"close_any(+Goal).\nExecute the Close closure returned by open_any/5.  The closure can also be called directly. Using close_any/1  can be considered better style and enhances tractability of the source  code.",
    "prefix":"close_any"
  },
  "iostream:open_any/5": {
    "body":"open_any(${1:Specification}, ${2:Mode}, ${3:Stream}, ${4:Close}, ${5:Options})$6\n$0",
    "description":"open_any(+Specification, +Mode, -Stream, -Close, +Options).\nEstablish a stream from Specification that should be closed  using Close, which can either be called or passed to close_any/1. Options  processed:  encoding(Enc): Set stream to encoding Enc.\n\n  Without loaded plugins, the open_any/5  processes the following values for Specification. If no rule  matches, open_any/5  processes Specification as file(Specification). \n\nStream: A plain stream handle. Possisible post-processing options such as  encoding are applied. Close does not close the stream,  but resets other side-effects such as the encoding.\n\nstream(Stream): Same as a plain Stream.\n\nFileURL: If Specification is of the form =file://...=, the pointed to  file is opened using open/4.  Requires library(uri) to be installed.\n\nfile(Path): Explicitly open the file Path. Path can be an Path(File)  term as accepted by absolute_file_name/3.\n\nstring(String): Open a Prolog string, atom, list of characters or codes as an input  stream.\n\n  The typical usage scenario is given in the code below, where <process> processes the input. \n\n\n\nsetup_call_cleanup(\n    open_any(Spec, read, In, Close, Options),\n    <process>(In),\n    Close).\n\n  Currently, the following libraries extend this predicate: \n\nlibrary(http/http_open): Adds support for URLs using the http and https  schemes.\n\n ",
    "prefix":"open_any"
  },
  "iostream:open_hook/6": {
    "body":"open_hook(${1:Spec}, ${2:Mode}, ${3:Stream}, ${4:Close}, ${5:Options0}, ${6:Options})$7\n$0",
    "description":"[semidet,multifile]open_hook(+Spec, +Mode, -Stream, -Close, +Options0, -Options).\nOpen Spec in Mode, producing Stream. Close is unified to a goal that  must be called to undo the side-effects of the action, e.g., typically  the term close(Stream) Options0 are the options passed  to open_any/5 Options are passed to the post  processing filters that may be installed by open_any/5. ",
    "prefix":"open_hook"
  },
  "iri_xml_namespace/2": {
    "body":"iri_xml_namespace(${1:IRI}, ${2:Namespace})$3\n$0",
    "description":"[det]iri_xml_namespace(+IRI, -Namespace).\nSame as iri_xml_namespace/3,  but avoids creating an atom for the Localname.",
    "prefix":"iri_xml_namespace"
  },
  "iri_xml_namespace/3": {
    "body":"iri_xml_namespace(${1:IRI}, ${2:Namespace}, ${3:Localname})$4\n$0",
    "description":"[det]iri_xml_namespace(+IRI, -Namespace, -Localname).\nSplit an IRI (Unicode URI) into its Namespace (an IRI) and Localname (a Unicode XML name, see xml_name/2).  The Localname is defined as the longest last part of the IRI that  satisfies the syntax of an XML name. With IRI schemas that are designed  to work with XML namespaces, this will typically break the IRI on the  last # or /. Note however that  this can produce unexpected results. E.g., in the example below, one  might expect the namespace to be http://example.com/images\\#,  but an XML name cannot start with a digit.  \n\n?- iri_xml_namespace('http://example.com/images#12345', NS, L).\nNS = 'http://example.com/images#12345',\nL = ''.\n\n  As we see from the example above, the Localname can be the  empty atom. Similarly, Namespace can be the empty atom if IRI  is an XML name. Applications will often have to check for either or both  these conditions. We decided against failing in these conditions because  the application typically wants to know which of the two conditions  (empty namespace or empty localname) holds. This predicate is often used  for generating RDF/XML from an RDF graph.\n\n",
    "prefix":"iri_xml_namespace"
  },
  "is_absolute_file_name/1": {
    "body":"is_absolute_file_name(${1:File})$2\n$0",
    "description":"is_absolute_file_name(+File).\nTrue if File specifies an absolute path name. On Unix  systems, this implies the path starts with a `/'. For Microsoft-based  systems this implies the path starts with <letter>:.  This predicate is intended to provide platform-independent checking for  absolute paths. See also absolute_file_name/2  and prolog_to_os_filename/2.",
    "prefix":"is_absolute_file_name"
  },
  "is_dict/1": {
    "body":"is_dict(${1:Term})$2\n$0",
    "description":"is_dict(@Term).\nTrue if Term is a dict. This is the same as is_dict(Term,_).",
    "prefix":"is_dict"
  },
  "is_dict/2": {
    "body":"is_dict(${1:Term}, ${2:Tag})$3\n$0",
    "description":"is_dict(@Term, -Tag).\nTrue if Term is a dict of Tag.",
    "prefix":"is_dict"
  },
  "is_engine/1": {
    "body":"is_engine(${1:Term})$2\n$0",
    "description":"[semidet]is_engine(@Term).\nTrue if Term is a reference to or the alias name of an  existing engine.",
    "prefix":"is_engine"
  },
  "is_list/1": {
    "body":"is_list(${1:Term})$2\n$0",
    "description":"is_list(+Term).\nTrue if Term is bound to the empty list ([]) or  a term with functor `'[|]''112The  traditional list functor is the dot ('.'). This is still  the case of the command line option --traditional is  given. See also section 5.1.  and arity2 and the second argument is a list.113In  versions before 5.0.1, is_list/1  just checked for [] or [_|_] and proper_list/1  had the role of the current is_list/1.  The current definition conforms to the de facto standard. Assuming  proper coding standards, there should only be very few cases where a  quick-and-dirty is_list/1  is a good choice. Richard O'Keefe pointed at this issue.  This predicate acts as if defined by the definition below on acyclic terms. The implementation fails safely if Term represents a cyclic list.  \n\nis_list(X) :-\n        var(X), !,\n        fail.\nis_list([]).\nis_list([_|T]) :-\n        is_list(T).\n\n ",
    "prefix":"is_list"
  },
  "is_stream/1": {
    "body":"is_stream(${1:Term})$2\n$0",
    "description":"is_stream(+Term).\nTrue if Term is a stream name or valid stream handle. This  predicate realises a safe test for the existence of a stream alias or  handle.",
    "prefix":"is_stream"
  },
  "is_thread/1": {
    "body":"is_thread(${1:Term})$2\n$0",
    "description":"is_thread(@Term).\nTrue if Term is a handle to an existing thread.",
    "prefix":"is_thread"
  },
  "iso_639:iso_639/2": {
    "body": ["iso_639(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"iso_639('Param1','Param2')",
    "prefix":"iso_639"
  },
  "iso_639:iso_639_2/2": {
    "body": ["iso_639_2(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"iso_639_2('Param1','Param2')",
    "prefix":"iso_639_2"
  },
  "iso_639:iso_639_3/2": {
    "body": ["iso_639_3(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"iso_639_3('Param1','Param2')",
    "prefix":"iso_639_3"
  },
  "isocomp:iso_check_application/1": {
    "body": ["iso_check_application(${1:'Param1'})$2\n$0" ],
    "description":"iso_check_application('Param1')",
    "prefix":"iso_check_application"
  },
  "isocomp:iso_check_directory/1": {
    "body": ["iso_check_directory(${1:'Param1'})$2\n$0" ],
    "description":"iso_check_directory('Param1')",
    "prefix":"iso_check_directory"
  },
  "isocomp:iso_check_file/1": {
    "body": ["iso_check_file(${1:'Param1'})$2\n$0" ],
    "description":"iso_check_file('Param1')",
    "prefix":"iso_check_file"
  },
  "isub:isub/4": {
    "body":"isub(${1:Text1}, ${2:Text2}, ${3:Normalize}, ${4:Similarity})$5\n$0",
    "description":"[det]isub(+Text1:atomic, +Text2:atomic, +Normalize:bool, -Similarity:float).\nSimilarity is a measure for the distance between Text1  and Text2. E.g.  \n\n?- isub('E56.Language', 'languange', true, D).\nD = 0.711348.\n\n  If Normalize is true, isub/4  applies string normalization as implemented by the original authors: Text1  and Text2 are mapped to lowercase and the characters \"._ \"  are removed. Lowercase mapping is done with the C-library function towlower().  In general, the required normalization is domain dependent and is better  left to the caller. See e.g., unaccent_atom/2.\n\nSimilarity is a float in the  range [0.0..1.0], where 1.0 means most similar ",
    "prefix":"isub"
  },
  "isub:snowball_current_algorithm/1": {
    "body":"snowball_current_algorithm(${1:Algorithm})$2\n$0",
    "description":"[nondet]snowball_current_algorithm(?Algorithm).\nTrue if Algorithm is the official name of an algorithm  suported by snowball/3. The  predicate is semidet if Algorithm is given.",
    "prefix":"snowball_current_algorithm"
  },
  "jpl:jpl_array_to_length/2": {
    "body":"jpl_array_to_length(${1:Array}, ${2:Length})$3\n$0",
    "description":"jpl_array_to_length(+Array:jref, -Length:integer).\nArray should be a JPL reference to a Java array of any type.  Length is the length of that array. \n\nThis is a utility predicate, defined thus: \n\n\n\njpl_array_to_length(A, N) :-\n    (   jpl_ref_to_type(A, array(_))\n    ->  jGetArrayLength(A, N)\n    ).\n\n ",
    "prefix":"jpl_array_to_length"
  },
  "jpl:jpl_array_to_list/2": {
    "body":"jpl_array_to_list(${1:Array}, ${2:Elements})$3\n$0",
    "description":"jpl_array_to_list(+Array:jref, -Elements:list(datum)).\nArray should be a JPL reference to a Java array of any type.  Elements is a Prolog list of JPL representations of the  array's elements (values or references, as appropriate). \n\nThis is a utility predicate, defined thus: \n\n\n\njpl_array_to_list(A, Es) :-\n    jpl_array_to_length(A, Len),\n    (   Len > 0\n    ->  LoBound is 0,\n        HiBound is Len-1,\n        jpl_get(A, LoBound-HiBound, Es)\n    ;   Es = []\n    ).\n\n ",
    "prefix":"jpl_array_to_list"
  },
  "jpl:jpl_array_to_terms/2": {
    "body":"jpl_array_to_terms(${1:JRef}, ${2:Terms})$3\n$0",
    "description":"jpl_array_to_terms(+JRef:jref, -Terms:list(term)).\nJRef should be a JPL reference to a Java array of  org.jpl7.Term instances (or ots subtypes); Terms will be a list of the terms which the respective array  elements represent.",
    "prefix":"jpl_array_to_terms"
  },
  "jpl:jpl_c_lib_version/1": {
    "body":"jpl_c_lib_version(${1:Version})$2\n$0",
    "description":"jpl_c_lib_version(-Version).\nVersion is the fully qualified version identifier of the  in-use C component (jpl.c) of JPL.  It should exactly match the version identifiers of JPL's Prolog (jpl.pl)  and Java (jpl.jar) components. \n\nExample \n\n\n\n?- jpl_c_lib_version(V).\nV = '7.4.0-alpha'.\n\n ",
    "prefix":"jpl_c_lib_version"
  },
  "jpl:jpl_call/4": {
    "body":"jpl_call(${1:X}, ${2:MethodName}, ${3:Params}, ${4:Result})$5\n$0",
    "description":"[det]jpl_call(+X, +MethodName:atom, +Params:list(datum), -Result:datum).\nX should be either  \n\nan object reference, e.g. <jref>(1552320) (for  static or instance methods)\nor a classname, e.g. 'java.util.Date' (for static  methods only)\nor a descriptor, e.g. 'Ljava.util.Date;' (for static  methods only)\nor type, e.g. class([java,util],['Date']) (for static  methods only)\n\n  MethodName should be a method name (as an atom) (may  involve dynamic overload resolution based on inferred types of params) \n\nParams should be a proper list (perhaps empty) of suitable  actual parameters for the named method. \n\nThe class or object may have several methods with the given name; JPL  will resolve (per call) to the most appropriate method based on the  quantity and inferred types of Params. This resolution mimics  the corresponding static resolution performed by Java compilers. \n\nFinally, an attempt will be made to unify Result with the  method's returned value, or with @(void) if it has none.\n\n",
    "prefix":"jpl_call"
  },
  "jpl:jpl_class_to_classname/2": {
    "body":"jpl_class_to_classname(${1:Class}, ${2:ClassName})$3\n$0",
    "description":"jpl_class_to_classname(+Class:jref, -ClassName:dottedName).\nClass is a reference to a class object.  ClassName is its canonical (?) source-syntax (dotted)  name, e.g. 'java.util.Date' \n\nNB not used outside jni_junk and jpl_test (is this (still) true?) \n\nNB oughta use the available caches (but their indexing doesn't suit)\n\n",
    "prefix":"jpl_class_to_classname"
  },
  "jpl:jpl_class_to_type/2": {
    "body":"jpl_class_to_type(${1:ClassObject}, ${2:Type})$3\n$0",
    "description":"jpl_class_to_type(+ClassObject:jref, -Type:type).\nClassObject is a reference to a class object of Type.  NB should ensure that, if not found in cache, then cache is updated. \n\nIntriguingly, getParameterTypes returns class objects (undocumented  AFAIK) with names 'boolean', 'byte' etc. and even 'void' (?!)\n\n",
    "prefix":"jpl_class_to_type"
  },
  "jpl:jpl_classname_to_class/2": {
    "body":"jpl_classname_to_class(${1:ClassName}, ${2:Class})$3\n$0",
    "description":"jpl_classname_to_class(+ClassName:className, -Class:jref).\nClassName unambiguously represents a class, e.g. 'java.lang.String'  Class is a (canonical) reference to the corresponding  class object. \n\nNB uses caches where the class is already encountered.\n\n",
    "prefix":"jpl_classname_to_class"
  },
  "jpl:jpl_classname_to_type/2": {
    "body":"jpl_classname_to_type(${1:Classname}, ${2:Type})$3\n$0",
    "description":"jpl_classname_to_type(+Classname:className, -Type:type).\nClassname is any of: a source-syntax (dotted) class name,  e.g. 'java.util.Date', '[java.util.Date' or '[L'  Type is its corresponding JPL type structure, e.g. class([java,util],['Date']), array(class([java,util],['Date'])), array(long) \n\nNB by \"classname\" do I mean \"typename\"? \n\nNB should this throw an exception for unbound CN? is this public API?\n\n",
    "prefix":"jpl_classname_to_type"
  },
  "jpl:jpl_datum_to_type/2": {
    "body":"jpl_datum_to_type(${1:Datum}, ${2:Type})$3\n$0",
    "description":"jpl_datum_to_type(+Datum:datum, -Type:type).\nDatum must be a JPL representation of an instance of one (or  more) Java types;  Type is the unique most specialised type of which Datum  denotes an instance; \n\nNB 3 is an instance of byte, char, short, int and long, of which byte  and char are the joint, overlapping most specialised types, so this  relates 3 to the pseudo subtype 'char_byte'; \n\nSee also: jpl_type_to_preferred_concrete_type/2 for  converting inferred types to instantiable types\n\n ",
    "prefix":"jpl_datum_to_type"
  },
  "jpl:jpl_datums_to_array/2": {
    "body":"jpl_datums_to_array(${1:Datums}, ${2:A})$3\n$0",
    "description":"jpl_datums_to_array(+Datums:list(datum), -A:jref).\nA will be a JPL reference to a new Java array, whose base  type is the most specific Java type of which each member of Datums  is (directly or indirectly) an instance.  NB this fails silently if \n\n\n\nDatums is an empty list (no base type can be inferred)\nDatums contains both a primitive value and an object  (including array) reference (no common supertype)\n\n",
    "prefix":"jpl_datums_to_array"
  },
  "jpl:jpl_enumeration_element/2": {
    "body":"jpl_enumeration_element(${1:Enumeration}, ${2:Element})$3\n$0",
    "description":"jpl_enumeration_element(+Enumeration:jref, -Element:datum).\ngenerates each Element from the Enumeration  \n\nif the element is a java.lang.String then Element will be  an atom\nif the element is null then Element will (oughta) be null\notherwise I reckon it has to be an object ref\n\n",
    "prefix":"jpl_enumeration_element"
  },
  "jpl:jpl_enumeration_to_list/2": {
    "body":"jpl_enumeration_to_list(${1:Enumeration}, ${2:Elements})$3\n$0",
    "description":"jpl_enumeration_to_list(+Enumeration:jref, -Elements:list(datum)).\nEnumeration should be a JPL reference to an object which  implements the Enumeration interface.  Elements is a Prolog list of JPL references to the  enumerated objects. \n\nThis is a utility predicate, defined thus: \n\n\n\njpl_enumeration_to_list(Enumeration, Es) :-\n    (   jpl_call(Enumeration, hasMoreElements, [], @(true))\n    ->  jpl_call(Enumeration, nextElement, [], E),\n        Es = [E|Es1],\n        jpl_enumeration_to_list(Enumeration, Es1)\n    ;   Es = []\n    ).\n\n ",
    "prefix":"jpl_enumeration_to_list"
  },
  "jpl:jpl_false/1": {
    "body":"jpl_false(${1:X})$2\n$0",
    "description":"[semidet]jpl_false(-X:datum).\nX is @(false), the JPL representation of the  Java boolean value 'false'.  See also: jpl_is_false/1\n\n ",
    "prefix":"jpl_false"
  },
  "jpl:jpl_get/3": {
    "body":"jpl_get(${1:X}, ${2:Fspec}, ${3:V})$4\n$0",
    "description":"[det]jpl_get(+X, +Fspec, -V:datum).\nX can be  \n\na classname\nor a descriptor\nor an (object or array) type (for static fields)\nor a non-array object (for static and non-static fields)\nor an array (for 'length' pseudo field, or indexed element  retrieval)\n\n  Fspec can be \n\n\n\nan atomic field name\nor an integral array index (to get an element from an array)\nor a pair I-J of integers (to get a subrange of an array).\n\n  Finally, an attempt will be made to unify V with the  retrieved value or object reference. \n\nExamples \n\n\n\njpl_get('java.awt.Cursor', 'NE_RESIZE_CURSOR', Q).\nQ = 7.\n\njpl_new(array(class([java,lang],['String'])), [for,while,do,if,then,else,try,catch,finally], A),\njpl_get(A, 3-5, B).\nB = [if, then, else].\n\n ",
    "prefix":"jpl_get"
  },
  "jpl:jpl_get_actual_jvm_opts/1": {
    "body":"jpl_get_actual_jvm_opts(${1:Opts})$2\n$0",
    "description":"[semidet]jpl_get_actual_jvm_opts(-Opts:list(atom)).\nReturns (as a list of atoms) the options with which the JVM was  initialised.  Fails silently if a JVM has not yet been started, and can thus be  used to test for this.\n\n",
    "prefix":"jpl_get_actual_jvm_opts"
  },
  "jpl:jpl_get_default_jvm_opts/1": {
    "body":"jpl_get_default_jvm_opts(${1:Opts})$2\n$0",
    "description":"[det]jpl_get_default_jvm_opts(-Opts:list(atom)).\nReturns (as a list of atoms) the options which will be passed to the JVM  when it is initialised, e.g. ['-Xrs']",
    "prefix":"jpl_get_default_jvm_opts"
  },
  "jpl:jpl_hashtable_pair/2": {
    "body": ["jpl_hashtable_pair(${1:datum}, ${2:datum})$3\n$0" ],
    "description":" jpl_hashtable_pair(+HashTable:jref, -KeyValuePair:pair(datum,datum)) is nondet\n\n Generates Key-Value pairs from the given HashTable.\n\n NB String is converted to atom but Integer is presumably returned as an object ref\n (i.e. as elsewhere, no auto unboxing);\n\n NB this is anachronistic: the Map interface is preferred.",
    "prefix":"jpl_hashtable_pair"
  },
  "jpl:jpl_hashtable_pair/3": {
    "body":"jpl_hashtable_pair(${1:HashTable}, ${2:KeyValuePair}, ${3:datum)})$4\n$0",
    "description":"[nondet]jpl_hashtable_pair(+HashTable:jref, -KeyValuePair:pair(datum,datum)).\nGenerates Key-Value pairs from the given HashTable.  NB String is converted to atom but Integer is presumably returned as  an object ref (i.e. as elsewhere, no auto unboxing); \n\nNB this is anachronistic: the Map interface is preferred.\n\n",
    "prefix":"jpl_hashtable_pair"
  },
  "jpl:jpl_is_class/1": {
    "body":"jpl_is_class(${1:Term})$2\n$0",
    "description":"jpl_is_class(@Term).\nTrue if Term is a JPL reference to an instance of java.lang.Class.",
    "prefix":"jpl_is_class"
  },
  "jpl:jpl_is_false/1": {
    "body":"jpl_is_false(${1:Term})$2\n$0",
    "description":"jpl_is_false(@Term).\nTrue if Term is @(false), the JPL representation  of the Java boolean value 'false'.",
    "prefix":"jpl_is_false"
  },
  "jpl:jpl_is_null/1": {
    "body":"jpl_is_null(${1:Term})$2\n$0",
    "description":"jpl_is_null(@Term).\nTrue if Term is @(null), the JPL representation  of Java's 'null' reference.",
    "prefix":"jpl_is_null"
  },
  "jpl:jpl_is_object/1": {
    "body":"jpl_is_object(${1:Term})$2\n$0",
    "description":"jpl_is_object(@Term).\nTrue if Term is a well-formed JPL object reference.  NB this checks only syntax, not whether the object exists.\n\n",
    "prefix":"jpl_is_object"
  },
  "jpl:jpl_is_object_type/1": {
    "body":"jpl_is_object_type(${1:Term})$2\n$0",
    "description":"jpl_is_object_type(@Term).\nTrue if Term is an object (class or array) type, not e.g. a  primitive, null or void.",
    "prefix":"jpl_is_object_type"
  },
  "jpl:jpl_is_ref/1": {
    "body":"jpl_is_ref(${1:Term})$2\n$0",
    "description":"jpl_is_ref(@Term).\nTrue if Term is a well-formed JPL reference, either to a Java  object or to Java's notional but important 'null' non-object.",
    "prefix":"jpl_is_ref"
  },
  "jpl:jpl_is_true/1": {
    "body":"jpl_is_true(${1:Term})$2\n$0",
    "description":"jpl_is_true(@Term).\nTrue if Term is @(true), the JPL representation  of the Java boolean value 'true'.",
    "prefix":"jpl_is_true"
  },
  "jpl:jpl_is_type/1": {
    "body":"jpl_is_type(${1:Term})$2\n$0",
    "description":"jpl_is_type(@Term).\nTrue if Term is a well-formed JPL type structure.",
    "prefix":"jpl_is_type"
  },
  "jpl:jpl_is_void/1": {
    "body":"jpl_is_void(${1:Term})$2\n$0",
    "description":"jpl_is_void(@Term).\nTrue if Term is @(void), the JPL representation  of the pseudo Java value 'void' (which is returned by jpl_call/4  when invoked on void methods).  NB you can try passing 'void' back to Java, but it won't ever be  interested.\n\n",
    "prefix":"jpl_is_void"
  },
  "jpl:jpl_iterator_element/2": {
    "body":"jpl_iterator_element(${1:Iterator}, ${2:Element})$3\n$0",
    "description":"jpl_iterator_element(+Iterator:jref, -Element:datum).\nIterator should be a JPL reference to an object which  implements the java.util.Iterator interface.  Element is the JPL representation of the next element in  the iteration. \n\nThis is a utility predicate, defined thus: \n\n\n\njpl_iterator_element(I, E) :-\n    (   jpl_call(I, hasNext, [], @(true))\n    ->  (   jpl_call(I, next, [], E)\n        ;   jpl_iterator_element(I, E)\n        )\n    ).\n\n ",
    "prefix":"jpl_iterator_element"
  },
  "jpl:jpl_list_to_array/2": {
    "body":"jpl_list_to_array(${1:Datums}, ${2:Array})$3\n$0",
    "description":"jpl_list_to_array(+Datums:list(datum), -Array:jref).\nDatums should be a proper Prolog list of JPL datums (values  or references).  If Datums have a most specific common supertype, then Array  is a JPL reference to a new Java array, whose base type is that common  supertype, and whose respective elements are the Java values or objects  represented by Datums.\n\n",
    "prefix":"jpl_list_to_array"
  },
  "jpl:jpl_map_element/2": {
    "body": ["jpl_map_element(${1:datum}, ${2:datum})$3\n$0" ],
    "description":" jpl_map_element(+Map:jref, -KeyValue:pair(datum,datum)) is nondet\n\n Map must be a JPL Reference to an object which implements the =|java.util.Map|= interface\n\n This generates each Key-Value pair from the Map, e.g.\n\n  ==\n  ?- jpl_call('java.lang.System', getProperties, [], Map), jpl_map_element(Map, E).\n  Map = @<jref>(0x20b5c38),\n  E = 'java.runtime.name'-'Java(TM) SE Runtime Environment' ;\n  Map = @<jref>(0x20b5c38),\n  E = 'sun.boot.library.path'-'C:\\\\Program Files\\\\Java\\\\jre7\\\\bin'\n  etc.\n  ==\n\n This is a utility predicate, defined thus:\n\n  ==\n  jpl_map_element(Map, K-V) :-\n      jpl_call(Map, entrySet, [], ES),\n      jpl_set_element(ES, E),\n      jpl_call(E, getKey, [], K),\n      jpl_call(E, getValue, [], V).\n  ==",
    "prefix":"jpl_map_element"
  },
  "jpl:jpl_map_element/3": {
    "body":"jpl_map_element(${1:Map}, ${2:KeyValue}, ${3:datum)})$4\n$0",
    "description":"[nondet]jpl_map_element(+Map:jref, -KeyValue:pair(datum,datum)).\nMap must be a JPL Reference to an object which implements the java.util.Map  interface  This generates each Key-Value pair from the Map, e.g. \n\n\n\n?- jpl_call('java.lang.System', getProperties, [], Map), jpl_map_element(Map, E).\nMap = @<jref>(0x20b5c38),\nE = 'java.runtime.name'-'Java(TM) SE Runtime Environment' ;\nMap = @<jref>(0x20b5c38),\nE = 'sun.boot.library.path'-'C:\\\\Program Files\\\\Java\\\\jre7\\\\bin'\netc.\n\n  This is a utility predicate, defined thus: \n\n\n\njpl_map_element(Map, K-V) :-\n    jpl_call(Map, entrySet, [], ES),\n    jpl_set_element(ES, E),\n    jpl_call(E, getKey, [], K),\n    jpl_call(E, getValue, [], V).\n\n ",
    "prefix":"jpl_map_element"
  },
  "jpl:jpl_new/3": {
    "body":"jpl_new(${1:X}, ${2:Params}, ${3:V})$4\n$0",
    "description":"[det]jpl_new(+X, +Params, -V).\nX can be:  \n\nan atomic classname, e.g. 'java.lang.String'\nor an atomic descriptor, e.g. '[I' or 'Ljava.lang.String;'\nor a suitable type, i.e. any class(_,_) or array(_),  e.g. class([java,util],['Date'])\n\n  If X is an object (non-array) type or descriptor and Params  is a list of values or references, then V is the result of an  invocation of that type's most specifically-typed constructor to whose  respective formal parameters the actual Params are assignable  (and assigned). \n\nIf X is an array type or descriptor and Params  is a list of values or references, each of which is (independently)  assignable to the array element type, then V is a new array  of as many elements as Params has members, initialised with the respective members  of Params. \n\nIf X is an array type or descriptor and Params  is a non-negative integer N, then V is a new array of that  type, with N elements, each initialised to Java's appropriate default  value for the type. \n\nIf V is {Term} then we attempt to convert a new  org.jpl7.Term instance to a corresponding term; this is of little  obvious use here, but is consistent with jpl_call/4  and jpl_get/3.\n\n",
    "prefix":"jpl_new"
  },
  "jpl:jpl_null/1": {
    "body":"jpl_null(${1:X})$2\n$0",
    "description":"[semidet]jpl_null(-X:datum).\nX is @(null), the JPL representation of Java's  'null' reference  See also: jpl_is_null/1\n\n ",
    "prefix":"jpl_null"
  },
  "jpl:jpl_object_to_class/2": {
    "body":"jpl_object_to_class(${1:Object}, ${2:Class})$3\n$0",
    "description":"jpl_object_to_class(+Object:jref, -Class:jref).\nfails silently if Object is not a valid reference to a Java  object  Class is a (canonical) reference to the (canonical) class  object which represents the class of Object \n\nNB what's the point of caching the type if we don't look there first?\n\n",
    "prefix":"jpl_object_to_class"
  },
  "jpl:jpl_object_to_type/2": {
    "body":"jpl_object_to_type(${1:Object}, ${2:Type})$3\n$0",
    "description":"jpl_object_to_type(+Object:jref, -Type:type).\nObject must be a proper JPL reference to a Java object (i.e.  a class or array instance, but not null, void or String).  Type is the JPL type of that object.\n\n",
    "prefix":"jpl_object_to_type"
  },
  "jpl:jpl_pl_lib_version/1": {
    "body":"jpl_pl_lib_version(${1:Version})$2\n$0",
    "description":"jpl_pl_lib_version(-Version).\nVersion is the fully qualified version identifier of the  in-use Prolog component (jpl.pl) of JPL.  It should exactly match the version identifiers of JPL's C (jpl.c)  and Java (jpl.jar) components. \n\nExample \n\n\n\n?- jpl_pl_lib_version(V).\nV = '7.4.0-alpha'.\n\n ",
    "prefix":"jpl_pl_lib_version"
  },
  "jpl:jpl_pl_syntax/1": {
    "body":"jpl_pl_syntax(${1:Syntax})$2\n$0",
    "description":"jpl_pl_syntax(-Syntax:atom).\nunifies Syntax with 'traditional' or 'modern' according to  the mode in which SWI Prolog 7.x was started",
    "prefix":"jpl_pl_syntax"
  },
  "jpl:jpl_primitive_type/1": {
    "body":"jpl_primitive_type(${1:Type})$2\n$0",
    "description":"[nondet]jpl_primitive_type(-Type:atom).\nType is an atomic JPL representation of one of Java's  primitive types.  \n\n?- setof(Type, jpl_primitive_type(Type), Types).\nTypes = [boolean, byte, char, double, float, int, long, short].\n\n ",
    "prefix":"jpl_primitive_type"
  },
  "jpl:jpl_ref_to_type/2": {
    "body":"jpl_ref_to_type(${1:Ref}, ${2:Type})$3\n$0",
    "description":"jpl_ref_to_type(+Ref:jref, -Type:type).\nRef must be a proper JPL reference (to an object, null or  void).  Type is its type.\n\n",
    "prefix":"jpl_ref_to_type"
  },
  "jpl:jpl_servlet_byref/3": {
    "body":"jpl_servlet_byref(${1:Config}, ${2:Request}, ${3:Response})$4\n$0",
    "description":"jpl_servlet_byref(+Config, +Request, +Response).\nThis serves the \"byref\" servlet demo, exemplifying one tactic for  implementing a servlet in Prolog by accepting the Request and Response  objects as JPL references and accessing their members via JPL as  required;  See also: jpl_servlet_byval/3\n\n ",
    "prefix":"jpl_servlet_byref"
  },
  "jpl:jpl_servlet_byval/3": {
    "body":"jpl_servlet_byval(${1:MultiMap}, ${2:ContentType}, ${3:Body})$4\n$0",
    "description":"jpl_servlet_byval(+MultiMap, -ContentType:atom, -Body:atom).\nThis exemplifies an alternative (to jpl_servlet_byref) tactic for  implementing a servlet in Prolog; most Request fields are extracted in  Java before this is called, and passed in as a multimap (a map, some of  whose values are maps).",
    "prefix":"jpl_servlet_byval"
  },
  "jpl:jpl_set/3": {
    "body":"jpl_set(${1:X}, ${2:Fspec}, ${3:V})$4\n$0",
    "description":"[det]jpl_set(+X, +Fspec, +V).\nsets the Fspec-th field of (class or object) X to  value V iff it is assignable  X can be \n\n\n\na class instance (for static or non-static fields)\nor an array (for indexed element or subrange assignment)\nor a classname, or a class(_,_) or array(_)  type (for static fields)\nbut not a String (no fields to retrieve)\n\n  Fspec can be \n\n\n\nan atomic field name (overloading through shadowing has yet to be  handled properly)\nor an array index I (X must be an array object: V  is assigned to X[I])\nor a pair I-J of integers (X must be an array object, V  must be a list of values: successive members of V are  assigned to X[I..J])\n\n  V must be a suitable value or object.\n\n",
    "prefix":"jpl_set"
  },
  "jpl:jpl_set_default_jvm_opts/1": {
    "body":"jpl_set_default_jvm_opts(${1:Opts})$2\n$0",
    "description":"[det]jpl_set_default_jvm_opts(+Opts:list(atom)).\nReplaces the default JVM initialisation options with those supplied.",
    "prefix":"jpl_set_default_jvm_opts"
  },
  "jpl:jpl_set_element/2": {
    "body":"jpl_set_element(${1:Set}, ${2:Element})$3\n$0",
    "description":"[nondet]jpl_set_element(+Set:jref, -Element:datum).\nSet must be a JPL reference to an object which implements the java.util.Set  interface.  On backtracking, Element is bound to a JPL representation  of each element of Set. \n\nThis is a utility predicate, defined thus: \n\n\n\njpl_set_element(S, E) :-\n    jpl_call(S, iterator, [], I),\n    jpl_iterator_element(I, E).\n\n ",
    "prefix":"jpl_set_element"
  },
  "jpl:jpl_terms_to_array/2": {
    "body":"jpl_terms_to_array(${1:Terms}, ${2:Array})$3\n$0",
    "description":"[semidet]jpl_terms_to_array(+Terms:list(term), -Array:jref).\nTerms should be a proper Prolog list of arbitrary terms.  Array is a JPL reference to a new Java array of  org.jpl7.Term, whose elements represent the respective members of the  list.\n\n",
    "prefix":"jpl_terms_to_array"
  },
  "jpl:jpl_true/1": {
    "body":"jpl_true(${1:X})$2\n$0",
    "description":"[semidet]jpl_true(-X:datum).\nX is @(true), the JPL representation of the Java  boolean value 'true'.  See also: jpl_is_true/1\n\n ",
    "prefix":"jpl_true"
  },
  "jpl:jpl_type_to_class/2": {
    "body":"jpl_type_to_class(${1:Type}, ${2:Class})$3\n$0",
    "description":"jpl_type_to_class(+Type:type, -Class:jref).\nIncomplete types are now never cached (or otherwise passed around).  jFindClass throws an exception if FCN can't be found.\n\n",
    "prefix":"jpl_type_to_class"
  },
  "jpl:jpl_type_to_classname/2": {
    "body":"jpl_type_to_classname(${1:Type}, ${2:ClassName})$3\n$0",
    "description":"jpl_type_to_classname(+Type:type, -ClassName:dottedName).\nType, which is a class or array type (not sure about the  others...), is denoted by ClassName in dotted syntax.  e.g. jpl_type_to_classname(class([java,util],['Date']), 'java.util.Date') \n\nSee also: jpl_type_to_nicename/2\n\n ",
    "prefix":"jpl_type_to_classname"
  },
  "jpl:jpl_void/1": {
    "body":"jpl_void(${1:X})$2\n$0",
    "description":"[semidet]jpl_void(-X:datum).\nX is @(void), the JPL representation of the  pseudo Java value 'void'  See also: jpl_is_void/1\n\n ",
    "prefix":"jpl_void"
  },
  "key_binding:show_key_bindings/1": {
    "body": ["show_key_bindings(${1:'Param1'})$2\n$0" ],
    "description":"show_key_bindings('Param1')",
    "prefix":"show_key_bindings"
  },
  "keysort/2": {
    "body":"keysort(${1:List}, ${2:Sorted})$3\n$0",
    "description":"[ISO]keysort(+List, -Sorted).\nSort a list of pairs. List must be a list of Key-Value pairs, terms whose  principal functor is (-)/2. List is sorted on Key  according to the standard order of terms (see section  4.7.1). Duplicates are not removed. Sorting is stable  with regard to the order of the Values, i.e., the order of multiple elements that have the  same Key is not changed.  The keysort/2  predicate is often used together with library library(pairs). It can be used to sort lists on different  or multiple criteria. For example, the following predicates sorts a list  of atoms according to their length, maintaining the initial order for  atoms that have the same length. \n\n\n\n:- use_module(library(pairs)).\n\nsort_atoms_by_length(Atoms, ByLength) :-\n        map_list_to_pairs(atom_length, Atoms, Pairs),\n        keysort(Pairs, Sorted),\n        pairs_values(Sorted, ByLength).\n\n ",
    "prefix":"keysort"
  },
  "known_licenses/0": {
    "body":"known_licenses$1\n$0",
    "description":"known_licenses.\nList all licenses known to the system. This does not imply the  system contains code covered by the listed licenses. See license/2.",
    "prefix":"known_licenses"
  },
  "lazy_lists:lazy_engine_next/4": {
    "body": ["lazy_engine_next(${1:Engine}, ${2:N}, ${3:List}, ${4:Tail})$5\n$0" ],
    "description":"  lazy_engine_next(+Engine, +N, -List, -Tail)\n\n   Lazy list iterator for  engines.  This   is  used  to  implement\n   lazy_findall/3,4.",
    "prefix":"lazy_engine_next"
  },
  "lazy_lists:lazy_findall/3": {
    "body": ["lazy_findall(${1:Templ}, ${2:Goal}, ${3:List})$4\n$0" ],
    "description":"  lazy_findall(?Templ, :Goal, -List) is det.\n  lazy_findall(+ChunkSize, ?Templ, :Goal, -List) is det.\n\n   True when List is a lazy  list containing the instantiations for\n   Template for each  answer  of  Goal.   Goal  is  executed  in an\n   _engine_ (see engine_create/3).\n\n   @bug    Engines are reclaimed by atom garbage collection.  As\n           they can be quite expensive, a large amount of resources\n           may be waiting for collection.  If the list is fully\n           materialized only the dead engine remains, which is\n           fairly cheap.",
    "prefix":"lazy_findall"
  },
  "lazy_lists:lazy_findall/4": {
    "body": [
      "lazy_findall(${1:ChunkSize}, ${2:Templ}, ${3:Goal}, ${4:List})$5\n$0"
    ],
    "description":"  lazy_findall(?Templ, :Goal, -List) is det.\n  lazy_findall(+ChunkSize, ?Templ, :Goal, -List) is det.\n\n   True when List is a lazy  list containing the instantiations for\n   Template for each  answer  of  Goal.   Goal  is  executed  in an\n   _engine_ (see engine_create/3).\n\n   @bug    Engines are reclaimed by atom garbage collection.  As\n           they can be quite expensive, a large amount of resources\n           may be waiting for collection.  If the list is fully\n           materialized only the dead engine remains, which is\n           fairly cheap.",
    "prefix":"lazy_findall"
  },
  "lazy_lists:lazy_get_codes/4": {
    "body": ["lazy_get_codes(${1:Stream}, ${2:N}, ${3:List}, ${4:Tail})$5\n$0" ],
    "description":"  lazy_get_codes(+Stream, +N, -List, -Tail)\n\n   Lazy list iterator to get character   codes  from a stream.\n\n   @see library(pure_input) The predicate lazy_get_codes/4 provides\n   similar functionality to what   stream_to_lazy_list/2 does while\n   in addition library(pure_input) is faster due to the use of more\n   low-level primitives and supports fetching   the location in the\n   stream.",
    "prefix":"lazy_get_codes"
  },
  "lazy_lists:lazy_list/2": {
    "body": ["lazy_list(${1:Next}, ${2:List})$3\n$0" ],
    "description":"  lazy_list(:Next, -List)\n\n   Create a lazy list from a callback. Next is called repeatedly to\n   extend the list. It is called   as call(Next, List, Tail), where\n   the _difference list_ List\\Tail produces the   next slice of the\n   list. If the end of  the  input   is  reached,  `List` must be a\n   proper list and `Tail` must be `[]`.\n\n   @bug The content returned  by  the   iterator  is  duplicated in\n   nb_setarg/3. This is  needed  by  avoid   the  risk  of  trailed\n   assignments in the structure. Avoiding   this  duplication would\n   significantly reduce the overhead.",
    "prefix":"lazy_list"
  },
  "lazy_lists:lazy_list/3": {
    "body": ["lazy_list(${1:Next}, ${2:State0}, ${3:List})$4\n$0" ],
    "description":"  lazy_list(:Next, +State0, -List)\n\n   Create a lazy list where the next element is defined by\n\n       call(Next, State0, State1, Head)\n\n   The example below uses this  predicate   to  define  a lazy list\n   holding the Fibonacci numbers. Our state  keeps the two previous\n   Fibonacci numbers.\n\n     ```\n     fibonacci_numbers(L) :-\n         lazy_list(fib, state(-,-), L).\n\n     fib(state(-,-), state(0,-), 0) :- !.\n     fib(state(0,-), state(1,0), 1) :- !.\n     fib(state(P,Q), state(F,P), F) :-\n         F is P+Q.\n     ```\n\n   The above can be used to retrieve   the Nth Fibonacci number. As\n   fib/2 provides no access  to  the   complete  list  of Fibonacci\n   numbers, this can be used to generate large Fibonacci numbers.\n\n     ```\n     fib(N, F) :-\n         fibonacci_numbers(L),\n         nth1(N, L, F).\n     ```",
    "prefix":"lazy_list"
  },
  "lazy_lists:lazy_list_iterator/4": {
    "body": [
      "lazy_list_iterator(${1:Iterator}, ${2:Next}, ${3:GetNext}, ${4:TestEnd})$5\n$0"
    ],
    "description":"  lazy_list_iterator(+Iterator, -Next, :GetNext, :TestEnd)\n\n   Directive to create a lazy list  iterator from a predicate that\n   gets a single next value.",
    "prefix":"lazy_list_iterator"
  },
  "lazy_lists:lazy_list_length/2": {
    "body": ["lazy_list_length(${1:List}, ${2:Len})$3\n$0" ],
    "description":"  lazy_list_length(+List, -Len) is det.\n\n   True if Len is the length of   the  materialized lazy list. Note\n   that length/2 reports the length   of the currently materialized\n   part and on backtracking longer lists.",
    "prefix":"lazy_list_length"
  },
  "lazy_lists:lazy_list_materialize/1": {
    "body": ["lazy_list_materialize(${1:List})$2\n$0" ],
    "description":"  lazy_list_materialize(?List) is det.\n\n   Materialize the lazy list.",
    "prefix":"lazy_list_materialize"
  },
  "lazy_lists:lazy_message_queue/4": {
    "body": [
      "lazy_message_queue(${1:Queue}, ${2:Options}, ${3:List}, ${4:Tail})$5\n$0"
    ],
    "description":"  lazy_message_queue(+Queue, +Options, -List, -Tail) is det.\n\n   Lazy list iterator for message  queues.   Options  are passed to\n   thread_get_message/3. In addition,  the   following  options are\n   processed:\n\n     - chunk(ChunkSize)\n     Determines the read chunk size.  Default is 1.\n\n   A thread can listen to its own message queue using\n\n   ```\n           thread_self(Me),\n           lazy_list(lazy_message_queue(Me, []), List),\n           phrase(action(List)).\n   ```",
    "prefix":"lazy_message_queue"
  },
  "lazy_lists:lazy_read_lines/4": {
    "body": [
      "lazy_read_lines(${1:Stream}, ${2:Options}, ${3:List}, ${4:Tail})$5\n$0"
    ],
    "description":"  lazy_read_lines(+Stream, +Options, -List, -Tail) is det.\n\n   Lazy list iterator to read lines from Stream.  Options include:\n\n     - chunk(ChunkSize)\n     Determines the read chunk size.  Default is 10.\n     - as(+Type)\n     Determine the output type for each line.  Valid values are\n     `atom`, `string`, `codes` or `chars`.  Default is `string`.",
    "prefix":"lazy_read_lines"
  },
  "lazy_lists:lazy_read_terms/4": {
    "body": [
      "lazy_read_terms(${1:Stream}, ${2:Options}, ${3:List}, ${4:Tail})$5\n$0"
    ],
    "description":"  lazy_read_terms(+Stream, +Options, -List, -Tail)\n\n   Turn a stream into a lazy list of Prolog terms.  Options are\n   passed to read_term/3, except for:\n\n     - chunk(ChunkSize)\n     Determines the read chunk size.  Default is 10.",
    "prefix":"lazy_read_terms"
  },
  "leash/1": {
    "body":"leash(${1:Ports})$2\n$0",
    "description":"leash(?Ports).\nSet/query leashing (ports which allow for user interaction). Ports  is one of +Name, -Name, ?Name or a list  of these. +Name enables leashing on that port, -Name  disables it and ?Name succeeds or fails according to the current setting.  Recognised ports are call, redo, exit, fail  and unify. The special shorthand all refers to all  ports, full refers to all ports except for the unify port  (default). half refers to the call, redo and fail  port.",
    "prefix":"leash"
  },
  "length/2": {
    "body":"length(${1:List}, ${2:Int})$3\n$0",
    "description":"[ISO]length(?List, ?Int).\nTrue if Int represents the number of elements in List.  This predicate is a true relation and can be used to find the length of  a list or produce a list (holding variables) of length Int.  The predicate is non-deterministic, producing lists of increasing length  if List is a partial list and Int is  unbound. It raises errors if  \n\nInt is bound to a non-integer.\nInt is a negative integer.\nList is neither a list nor a partial list. This error  condition includes cyclic lists.115ISO  demands failure here. We think an error is more appropriate.\n\n  This predicate fails if the tail of List is equivalent to Int (e.g., length(L,L)).116This  is logically correct. An exception would be more appropriate, but to our  best knowledge, current practice in Prolog does not describe a suitable  candidate exception term.\n\n",
    "prefix":"length"
  },
  "lgamma/1": {
    "body":"lgamma(${1:Expr})$2\n$0",
    "description":"lgamma(+Expr).\nReturn the natural logarithm of the absolute value of the Gamma  function.108Some interfaces also  provide the sign of the Gamma function. We canot do that in an  arithmetic function. Future versions may provide a predicate  lgamma/3 that returns both the value and the sign.",
    "prefix":"lgamma"
  },
  "library_directory/1": {
    "body":"library_directory(${1:Atom})$2\n$0",
    "description":"library_directory(?Atom).\nDynamic predicate used to specify library directories. Default ./lib,  /lib/prolog and the system's library  (in this order) are defined. The user may add library directories using assertz/1, asserta/1  or remove system defaults using retract/1.  Deprecated. New code should use file_search_path/2.",
    "prefix":"library_directory"
  },
  "license/0": {
    "body":"license$1\n$0",
    "description":"license.\nEvaluate the license conditions of all loaded components. If the system  contains one or more components that are licenced under GPL-like  restrictions the system indicates this program may only be distributed  under the GPL license as well as which components prohibit  the use of other license conditions. Likewise for for LGPL components.",
    "prefix":"license"
  },
  "license/1": {
    "body":"license(${1:LicenseId})$2\n$0",
    "description":"license(+LicenseId).\nIntended as a directive in Prolog source files. It takes the current  filename and calls license/2.",
    "prefix":"license"
  },
  "license/2": {
    "body":"license(${1:LicenseId}, ${2:Component})$3\n$0",
    "description":"license(+LicenseId, +Component).\nRegister the fact that Component is distributed under a  license identified by LicenseId. Known license identifiers  can be listed using known_licenses/0.  A new license can be registered as a known language using a declaration  like below. The second argument defines the category if the license, which is one of gpl, lgpl, permissive or proprietary.  \n\n:- multifile license:license/3.\n\nlicense:license(mylicense, permissive,\n                [ comment('My personal license'),\n                  url('http://www.mine.org/license.html')\n                ]).\n\n:- license(mylicense).\n\n ",
    "prefix":"license"
  },
  "line_count/2": {
    "body":"line_count(${1:Stream}, ${2:Count})$3\n$0",
    "description":"line_count(+Stream, -Count).\nUnify Count with the number of lines read or written.  Counting starts at 1.",
    "prefix":"line_count"
  },
  "line_position/2": {
    "body":"line_position(${1:Stream}, ${2:Count})$3\n$0",
    "description":"line_position(+Stream, -Count).\nUnify Count with the position on the current line. Note that  this assumes the position is 0 after the open. Tabs are assumed to be  defined on each 8-th character, and backspaces are assumed to reduce the  count by one, provided it is positive.",
    "prefix":"line_position"
  },
  "list_strings/0": {
    "body":"list_strings$1\n$0",
    "description":"list_strings.\nThis predicate may be used to assess compatibility issues due to the  representation of double quoted text as string objects. See section 5.2 and section  5.2.4. To use it, load your program into Prolog and run list_strings/0.  The predicate lists source locations of string objects encountered in  the program that are not considered safe. Such string need to be  examined manually, after which one of the actions below may be  appropriate:  \n\nRewrite the code. For example, change [X] = \"a\" into X = 0'a.\nIf a particular module relies heavily on representing strings as  lists of character code, consider adding the following directive to the  module. Note that this flag only applies to the module in which it  appears.            :- set_prolog_flag(double_quotes, codes).             \nUse a back quoted string (e.g., `text`). Note that this  will not make your code run regardless of the --traditional  command line option and code exploiting this mapping is also not  portable to ISO compliant systems.\nIf the strings appear in facts and usage is safe, add a clause to  the multifile predicate check:string_predicate/1 to silence list_strings/0  on all clauses of that predicate.\nIf the strings appear as an argument to a predicate that can handle  string objects, add a clause to the multifile predicate  check:valid_string_goal/1 to silence list_strings/0.\n\n",
    "prefix":"list_strings"
  },
  "listing/0": {
    "body":"listing$1\n$0",
    "description":"listing.\nList all predicates from the calling module using listing/1.  For example, ?- listing. lists clauses in the default user  module and ?- lists:listing. lists the clauses in the  module lists.",
    "prefix":"listing"
  },
  "listing/1": {
    "body":"listing(${1:Pred})$2\n$0",
    "description":"listing(:Pred).\nList predicates specified by Pred. Pred may be a  predicate name (atom), which lists all predicates with this name,  regardless of their arity. It can also be a predicate indicator (<name>/<arity>  or <name>//<arity>), possibly qualified  with a module. For example: ?- listing(lists:member/2)..  A listing is produced by enumerating the clauses of the predicate  using clause/2  and printing each clause using portray_clause/1.  This implies that the variable names are generated (A, B,  ... ) and the layout is defined by rules in portray_clause/1.\n\n",
    "prefix":"listing"
  },
  "lists:append/2": {
    "body":"append(${1:ListOfLists}, ${2:List})$3\n$0",
    "description":"append(+ListOfLists, ?List).\nConcatenate a list of lists. Is true if ListOfLists is a list  of lists, and List is the concatenation of these lists. ListOfLists must be a list of possibly  partial lists ",
    "prefix":"append"
  },
  "lists:append/3": {
    "body":"append(${1:List1}, ${2:List2}, ${3:List1AndList2})$4\n$0",
    "description":"append(?List1, ?List2, ?List1AndList2).\nList1AndList2 is the concatenation of List1 and List2",
    "prefix":"append"
  },
  "lists:delete/3": {
    "body":"delete(${1:List1}, ${2:Elem}, ${3:List2})$4\n$0",
    "description":"[det]delete(+List1, @Elem, -List2).\nDelete matching elements from a list. True when List2 is a  list with all elements from List1 except for those that unify  with Elem. Matching Elem with elements of List1  is uses \\+ Elem \\= H, which implies that Elem is  not changed.  See also: select/3, subtract/3.\n\ndeprecated: There are too many ways in which one might want to delete elements from  a list to justify the name. Think of matching (= vs. ==),  delete first/all, be deterministic or not.\n\n ",
    "prefix":"delete"
  },
  "lists:flatten/2": {
    "body":"flatten(${1:NestedList}, ${2:FlatList})$3\n$0",
    "description":"[det]flatten(+NestedList, -FlatList).\nIs true if FlatList is a non-nested version of NestedList.  Note that empty lists are removed. In standard Prolog, this implies that  the atom '[]' is removed too. In SWI7, [] is  distinct from '[]'.  Ending up needing flatten/2  often indicates, like append/3  for appending two lists, a bad design. Efficient code that generates  lists from generated small lists must use difference lists, often  possible through grammar rules for optimal readability. \n\nSee also: append/2\n\n ",
    "prefix":"flatten"
  },
  "lists:intersection/3": {
    "body":"intersection(${1:Set1}, ${2:Set2}, ${3:Set3})$4\n$0",
    "description":"[det]intersection(+Set1, +Set2, -Set3).\nTrue if Set3 unifies with the intersection of Set1  and Set2. The complexity of this predicate is |Set1|*|Set2|  See also: ord_intersection/3.\n\n ",
    "prefix":"intersection"
  },
  "lists:is_set/1": {
    "body":"is_set(${1:Set})$2\n$0",
    "description":"[semidet]is_set(@Set).\nTrue if Set is a proper list without duplicates. Equivalence  is based on ==/2. The  implementation uses sort/2,  which implies that the complexity is N*log(N) and the  predicate may cause a resource-error. There are no other error  conditions.",
    "prefix":"is_set"
  },
  "lists:last/2": {
    "body":"last(${1:List}, ${2:Last})$3\n$0",
    "description":"last(?List, ?Last).\nSucceeds when Last is the last element of List.  This predicate is semidet if List is a list and multi  if List is a partial list.  Compatibility: There is no de-facto standard for the argument order of last/2. Be careful when  porting code or use append(_, [Last], List) as a portable alternative.\n\n ",
    "prefix":"last"
  },
  "lists:list_to_set/2": {
    "body":"list_to_set(${1:List}, ${2:Set})$3\n$0",
    "description":"[det]list_to_set(+List, ?Set).\nTrue when Set has the same elements as List in the  same order. The left-most copy of duplicate elements is retained. List  may contain variables. Elements E1 and E2 are considered  duplicates iff E1 == E2 holds. The complexity  of the implementation is N*log(N).  Errors: List is type-checked.\n\nSee also: sort/2 can be used to  create an ordered set. Many set operations on ordered sets are order N  rather than order N**2. The list_to_set/2  predicate is more expensive than sort/2  because it involves, two sorts and a linear scan.\n\nCompatibility: Up to version 6.3.11, list_to_set/2  had complexity N**2 and equality was tested using =/2.\n\n ",
    "prefix":"list_to_set"
  },
  "lists:max_list/2": {
    "body":"max_list(${1:List}, ${2:Max})$3\n$0",
    "description":"[semidet]max_list(+List:list(number), -Max:number).\nTrue if Max is the largest number in List. Fails  if List is empty.  See also: max_member/2.\n\n ",
    "prefix":"max_list"
  },
  "lists:max_member/2": {
    "body":"max_member(${1:Max}, ${2:List})$3\n$0",
    "description":"[semidet]max_member(-Max, +List).\nTrue when Max is the largest member in the standard order of  terms. Fails if List is empty.  See also: - compare/3  - max_list/2 for the  maximum of a list of numbers.\n\n ",
    "prefix":"max_member"
  },
  "lists:member/2": {
    "body":"member(${1:Elem}, ${2:List})$3\n$0",
    "description":"member(?Elem, ?List).\nTrue if Elem is a member of List. The SWI-Prolog  definition differs from the classical one. Our definition avoids  unpacking each list element twice and provides determinism on the last  element. E.g. this is deterministic:  \n\n    member(X, [One]).\n\n  author: Gertjan van Noord\n\n ",
    "prefix":"member"
  },
  "lists:min_list/2": {
    "body":"min_list(${1:List}, ${2:Min})$3\n$0",
    "description":"[semidet]min_list(+List:list(number), -Min:number).\nTrue if Min is the smallest number in List. Fails  if List is empty.  See also: min_member/2.\n\n ",
    "prefix":"min_list"
  },
  "lists:min_member/2": {
    "body":"min_member(${1:Min}, ${2:List})$3\n$0",
    "description":"[semidet]min_member(-Min, +List).\nTrue when Min is the smallest member in the standard order of  terms. Fails if List is empty.  See also: - compare/3  - min_list/2 for the  minimum of a list of numbers.\n\n ",
    "prefix":"min_member"
  },
  "lists:nextto/3": {
    "body":"nextto(${1:X}, ${2:Y}, ${3:List})$4\n$0",
    "description":"nextto(?X, ?Y, ?List).\nTrue if Y directly follows X in List.",
    "prefix":"nextto"
  },
  "lists:nth0/3": {
    "body":"nth0(${1:Index}, ${2:List}, ${3:Elem})$4\n$0",
    "description":"nth0(?Index, ?List, ?Elem).\nTrue when Elem is the Index'th element of List.  Counting starts at 0.  Errors: type_error(integer, Index) if Index is not an  integer or unbound.\n\nSee also: nth1/3.\n\n ",
    "prefix":"nth0"
  },
  "lists:nth0/4": {
    "body":"nth0(${1:N}, ${2:List}, ${3:Elem}, ${4:Rest})$5\n$0",
    "description":"[det]nth0(?N, ?List, ?Elem, ?Rest).\nSelect/insert element at index. True when Elem is the N'th  (0-based) element of List and Rest is the  remainder (as in by select/3) of List.  For example:  \n\n?- nth0(I, [a,b,c], E, R).\nI = 0, E = a, R = [b, c] ;\nI = 1, E = b, R = [a, c] ;\nI = 2, E = c, R = [a, b] ;\nfalse.\n\n  \n\n?- nth0(1, L, a1, [a,b]).\nL = [a, a1, b].\n\n ",
    "prefix":"nth0"
  },
  "lists:nth1/3": {
    "body":"nth1(${1:Index}, ${2:List}, ${3:Elem})$4\n$0",
    "description":"nth1(?Index, ?List, ?Elem).\nIs true when Elem is the Index'th element of List.  Counting starts at 1.  See also: nth0/3.\n\n ",
    "prefix":"nth1"
  },
  "lists:nth1/4": {
    "body":"nth1(${1:N}, ${2:List}, ${3:Elem}, ${4:Rest})$5\n$0",
    "description":"[det]nth1(?N, ?List, ?Elem, ?Rest).\nAs nth0/4, but counting  starts at 1.",
    "prefix":"nth1"
  },
  "lists:numlist/3": {
    "body":"numlist(${1:Low}, ${2:High}, ${3:List})$4\n$0",
    "description":"[semidet]numlist(+Low, +High, -List).\nList is a list [Low, Low+1, ... High].  Fails if High < Low.  Errors: - type_error(integer, Low)  - type_error(integer, High)\n\n ",
    "prefix":"numlist"
  },
  "lists:permutation/2": {
    "body":"permutation(${1:Xs}, ${2:Ys})$3\n$0",
    "description":"[nondet]permutation(?Xs, ?Ys).\nTrue when Xs is a permutation of Ys. This can  solve for Ys given Xs or Xs given Ys, or even enumerate Xs  and Ys together. The predicate permutation/2  is primarily intended to generate permutations. Note that a list of  length N has N! permutations, and unbounded permutation generation  becomes prohibitively expensive, even for rather short lists (10! =  3,628,800).  If both Xs and Ys are provided and both lists  have equal length the order is |Xs|^2.  Simply testing whether Xs is a permutation of Ys  can be achieved in order log(|Xs|)  using msort/2 as  illustrated below with the semidet predicate is_permutation/2: \n\n\n\nis_permutation(Xs, Ys) :-\n  msort(Xs, Sorted),\n  msort(Ys, Sorted).\n\n  The example below illustrates that Xs and Ys  being proper lists is not a sufficient condition to use the above  replacement. \n\n\n\n?- permutation([1,2], [X,Y]).\nX = 1, Y = 2 ;\nX = 2, Y = 1 ;\nfalse.\n\n  Errors: type_error(list, Arg) if either argument is not a proper or  partial list.\n\n ",
    "prefix":"permutation"
  },
  "lists:prefix/2": {
    "body":"prefix(${1:Part}, ${2:Whole})$3\n$0",
    "description":"prefix(?Part, ?Whole).\nTrue iff Part is a leading substring of Whole.  This is the same as append(Part, _, Whole).",
    "prefix":"prefix"
  },
  "lists:proper_length/2": {
    "body":"proper_length(${1:List}, ${2:Length})$3\n$0",
    "description":"[semidet]proper_length(@List, -Length).\nTrue when Length is the number of elements in the proper list List. This is equivalent to  \n\nproper_length(List, Length) :-\n      is_list(List),\n      length(List, Length).\n\n ",
    "prefix":"proper_length"
  },
  "lists:reverse/2": {
    "body":"reverse(${1:List1}, ${2:List2})$3\n$0",
    "description":"reverse(?List1, ?List2).\nIs true when the elements of List2 are in reverse order  compared to List1.",
    "prefix":"reverse"
  },
  "lists:same_length/2": {
    "body":"same_length(${1:List1}, ${2:List2})$3\n$0",
    "description":"same_length(?List1, ?List2).\nIs true when List1 and List2 are lists with the  same number of elements. The predicate is deterministic if at least one  of the arguments is a proper list. It is non-deterministic if both  arguments are partial lists.  See also: length/2\n\n ",
    "prefix":"same_length"
  },
  "lists:select/3": {
    "body":"select(${1:Elem}, ${2:List1}, ${3:List2})$4\n$0",
    "description":"select(?Elem, ?List1, ?List2).\nIs true when List1, with Elem removed, results in List2.",
    "prefix":"select"
  },
  "lists:select/4": {
    "body":"select(${1:X}, ${2:XList}, ${3:Y}, ${4:YList})$5\n$0",
    "description":"[nondet]select(?X, ?XList, ?Y, ?YList).\nSelect from two lists at the same positon. True if XList is  unifiable with YList apart a single element at the same  position that is unified with X in XList and with Y  in YList. A typical use for this predicate is to replace  an element, as shown in the example below. All possible substitutions  are performed on backtracking.  \n\n?- select(b, [a,b,c,b], 2, X).\nX = [a, 2, c, b] ;\nX = [a, b, c, 2] ;\nfalse.\n\n  See also: selectchk/4 provides a  semidet version.\n\n ",
    "prefix":"select"
  },
  "lists:selectchk/3": {
    "body":"selectchk(${1:Elem}, ${2:List}, ${3:Rest})$4\n$0",
    "description":"[semidet]selectchk(+Elem, +List, -Rest).\nSemi-deterministic removal of first element in List that  unifies with Elem.",
    "prefix":"selectchk"
  },
  "lists:selectchk/4": {
    "body":"selectchk(${1:X}, ${2:XList}, ${3:Y}, ${4:YList})$5\n$0",
    "description":"[semidet]selectchk(?X, ?XList, ?Y, ?YList).\nSemi-deterministic version of select/4.",
    "prefix":"selectchk"
  },
  "lists:subset/2": {
    "body":"subset(${1:SubSet}, ${2:Set})$3\n$0",
    "description":"[semidet]subset(+SubSet, +Set).\nTrue if all elements of SubSet belong to Set as  well. Membership test is based on memberchk/2.  The complexity is |SubSet|*|Set|.  See also: ord_subset/2.\n\n ",
    "prefix":"subset"
  },
  "lists:subtract/3": {
    "body":"subtract(${1:Set}, ${2:Delete}, ${3:Result})$4\n$0",
    "description":"[det]subtract(+Set, +Delete, -Result).\nDelete all elements in Delete from Set.  Deletion is based on unification using memberchk/2.  The complexity is |Delete|*|Set|.  See also: ord_subtract/3.\n\n ",
    "prefix":"subtract"
  },
  "lists:sum_list/2": {
    "body":"sum_list(${1:List}, ${2:Sum})$3\n$0",
    "description":"[det]sum_list(+List, -Sum).\nSum is the result of adding all numbers in List.",
    "prefix":"sum_list"
  },
  "lists:union/3": {
    "body":"union(${1:Set1}, ${2:Set2}, ${3:Set3})$4\n$0",
    "description":"[det]union(+Set1, +Set2, -Set3).\nTrue if Set3 unifies with the union of Set1 and Set2.  The complexity of this predicate is |Set1|*|Set2|  See also: ord_union/3.\n\n ",
    "prefix":"union"
  },
  "load_dtd/2": {
    "body":"load_dtd(${1:DTD}, ${2:File})$3\n$0",
    "description":"load_dtd(+DTD, +File).\nDefine the DTD by loading the SGML-DTD file File. Same as load_dtd/3  with empty option list.",
    "prefix":"load_dtd"
  },
  "load_dtd/3": {
    "body":"load_dtd(${1:DTD}, ${2:File}, ${3:Options})$4\n$0",
    "description":"load_dtd(+DTD, +File, +Options).\nDefine the DTD by loading File. Defined options are the dialect option from open_dtd/3  and the encoding option from open/4.  Notably the dialect option must match the dialect used for  subsequent parsing using this DTD.",
    "prefix":"load_dtd"
  },
  "load_files/1": {
    "body":"load_files(${1:Files})$2\n$0",
    "description":"load_files(:Files).\nEquivalent to load_files(Files,[]). Same as consult/1,  See load_files/2  for supported options.",
    "prefix":"load_files"
  },
  "load_files/2": {
    "body":"load_files(${1:Files}, ${2:Options})$3\n$0",
    "description":"load_files(:Files, +Options).\nThe predicate load_files/2  is the parent of all the other loading predicates except for include/1.  It currently supports a subset of the options of Quintus load_files/2. Files  is either a single source file or a list of source files. The  specification for a source file is handed to absolute_file_name/2.  See this predicate for the supported expansions. Options is a  list of options using the format OptionName(OptionValue).  The following options are currently supported: \n\nautoload(Bool): If true (default false), indicate that this  load is a demand load. This implies that, depending on the setting of the  Prolog flag verbose_autoload,  the load action is printed at level informational or silent.  See also print_message/2  and current_prolog_flag/2.\n\nderived_from(File): Indicate that the loaded file is derived from File. Used by make/0  to time-check and load the original file rather than the derived file.\n\ndialect(+Dialect): Load Files with enhanced compatibility with the target Prolog  system identified by Dialect. See expects_dialect/1  and section C for details.\n\nencoding(Encoding): Specify the way characters are encoded in the file. Default is taken  from the Prolog flag encoding.  See section 2.18.1 for details.\n\nexpand(Bool): If true, run the filenames through expand_file_name/2  and load the returned files. Default is false, except for consult/1  which is intended for interactive use. Flexible location of files is  defined by file_search_path/2.\n\nformat(+Format): Used to specify the file format if data is loaded from a stream using  the stream(Stream) option. Default is source,  loading Prolog source text. If qlf, load QLF data (see qcompile/1).\n\nif(Condition): Load the file only if the specified condition is satisfied. The value true loads the file unconditionally, changed  loads the file if it was not loaded before or has been modified since it  was loaded the last time, and not_loaded loads the file if  it was not loaded before.\n\nimports(Import): Specify what to import from the loaded module. The default for use_module/1  is all. Import is passed from the second  argument of use_module/2.  Traditionally it is a list of predicate indicators to import. As part of  the SWI-Prolog/YAP integration, we also support Pred as Name  to import a predicate under another name. Finally, Import can  be the term except(Exceptions), where Exceptions  is a list of predicate indicators that specify predicates that are not  imported or Pred as Name terms to denote renamed  predicates. See also reexport/2  and use_module/2.bugName/Arity  as NewName is currently implemented using a link clause.  This harms efficiency and does not allow for querying the relation  through predicate_property/2.  If Import equals all, all operators are  imported as well. Otherwise, operators are not imported.  Operators can be imported selectively by adding terms op(Pri,Assoc,Name)  to the Import list. If such a term is encountered, all exported  operators that unify with this term are imported. Typically, this  construct will be used with all arguments unbound to import all  operators or with only Name bound to import a particular  operator.\n\nmodified(TimeStamp): Claim that the source was loaded at TimeStamp without  checking the source. This option is intended to be used together with  the stream(Input) option, for example after extracting the  time from an HTTP server or database.\n\nmodule(+Module): Load the indicated file into the given module, overruling the module  name specified in the :- module(Name, ...) directive. This  currently serves two purposes: (1) allow loading two module files that  specify the same module into the same process and force and (2): force  loading source code in a specific module, even if the code provides its  own module name. Experimental.\n\nmust_be_module(Bool): If true, raise an error if the file is not a module file.  Used by use_module/[1,2].\n\nqcompile(Atom): How to deal with quick-load-file compilation by qcompile/1.  Values are:  neverDefault. Do not use qcompile unless called explicitly.autoUse qcompile for all writeable files. See comment below.largeUse qcompile if the file is `large'. Currently, files larger than 100Kbytes  are considered large.partIf load_files/2  appears in a directive of a file that is compiled into Quick Load Format  using qcompile/1,  the contents of the argument files are included in the .qlf  file instead of the loading directive.  If this option is not present, it uses the value of the Prolog flag qcompile  as default.\n\nredefine_module(+Action): Defines what to do if a file is loaded that provides a module that is  already loaded from another file. Action is one of false  (default), which prints an error and refuses to load the file, or true, which uses unload_file/1  on the old file and then proceeds loading the new file. Finally, there  is ask, which starts interaction with the user. ask  is only provided if the stream user_input is associated  with a terminal.\n\nreexport(Bool): If true re-export the imported predicate. Used by reexport/1  and reexport/2.\n\nregister(Bool): If false, do not register the load location and options.  This option is used by make/0  and load_hotfixes1 to avoid polluting the load-context database. See source_file_property/2.\n\nsandboxed(Bool): Load the file in sandboxed mode. This option controls the flag sandboxed_load.  The only meaningful value for Bool is true. Using false while the  Prolog flag is set to true raises a permission error.\n\nscope_settings(Bool): Scope style_check/1  and expects_dialect/1  to the file and files loaded from the file after the directive. Default  is true. The system and user initialization files (see -f  and -F) are loading with scope_settings(false).\n\nsilent(Bool): If true, load the file without printing a message. The  specified value is the default for all files loaded as a result of  loading the specified files. This option writes the Prolog flag verbose_load  with the negation of Bool.\n\nstream(Input): This SWI-Prolog extension compiles the data from the stream Input. If this option is used, Files must be a  single atom which is used to identify the source location of the loaded  clauses as well as to remove all clauses if the data is reconsulted.  This option is added to allow compiling from non-file locations such  as databases, the web, the user (see consult/1)  or other servers. It can be combined with format(qlf) to  load QLF data from a stream.\n\n  The load_files/2  predicate can be hooked to load other data or data from objects other  than files. See prolog_load_file/2  for a description and library(http/http_load) for an example. All hooks for load_files/2  are documented in section B.8.\n\n",
    "prefix":"load_files"
  },
  "load_html/3": {
    "body":"load_html(${1:Source}, ${2:ListOfContent}, ${3:Options})$4\n$0",
    "description":"load_html(+Source, -ListOfContent, :Options).\nCalls load_structure/3  with the given Options, using the default options dialect(HTMLDialect),  where HTMLDialect is html4 or html5  (default), depending on the Prolog flag html_dialect. Both  imply the option shorttag(false). The option dtd(DTD)  is passed, where DTD is the HTML DTD as obtained using dtd(html,  DTD). See dtd/2.",
    "prefix":"load_html"
  },
  "load_rdf/2": {
    "body":"load_rdf(${1:File}, ${2:Triples})$3\n$0",
    "description":"load_rdf(+File, -Triples).\nSame as load_rdf(File, Triples,[]).",
    "prefix":"load_rdf"
  },
  "load_rdf/3": {
    "body":"load_rdf(${1:File}, ${2:Triples}, ${3:Options})$4\n$0",
    "description":"load_rdf(+File, -Triples, +Options).\nRead the RDF-XML file File and return a list of Triples. Options defines additional processing options. Currently  defined options are:  base_uri(BaseURI): If provided local identifiers and identifier-references are globalised  using this URI. If omited or the atom [], local identifiers  are not tagged.\n\nblank_nodes(Mode): If Mode is share (default), blank-node  properties (i.e. complex properties without identifier) are reused if  they result in exactly the same triple-set. Two descriptions are shared  if their intermediate description is the same. This means they should  produce the same set of triples in the same order. The value noshare  creates a new resource for each blank node.\n\nexpand_foreach(Boolean): If Boolean is true, expand rdf:aboutEach  into a set of triples. By default the parser generates rdf(each(Container), Predicate, Subject).\n\nlang(Lang): Define the initial language (i.e. pretend there is an xml:lang  declaration in an enclosing element).\n\nignore_lang(Bool): If true, xml:lang declarations in the document  are ignored. This is mostly for compatibility with older versions of  this library that did not support language identifiers.\n\nconvert_typed_literal(:ConvertPred): If the parser finds a literal with the rdf:datatype=Type  attribute, call ConvertPred(+Type, +Content, -Literal). Content is the XML element contentas returned by the XML  parser (a list). The predicate must unify Literal with a  Prolog representation of Content according to Type or throw an exception if the conversion cannot be made.  This option servers two purposes. First of all it can be used to  ignore type declarations for backward compatibility of this library.  Second it can be used to convert typed literals to a meaningful Prolog  representation. E.g. convert '42' to the Prolog integer 42 if the type  is xsd:int or a related type.\n\nnamespaces(-List): Unify List with a list of NS=URL for  each encountered xmlns:NS=URL  declaration found in the source.\n\nentity(+Name, +Value): Overrule entity declaration in file. As it is common practice to declare  namespaces using entities in RDF/XML, this option allows for changing  the namespace without changing the file. Multiple of these options are  allowed.\n\n  The Triples list is a list of rdf(Subject,  Predicate, Object) triples. Subject is either a plain  resource (an atom), or one of the terms each(URI) or prefix(URI)  with the obvious meaning. Predicate is either a plain atom  for explicitely non-qualified names or a term NameSpace:Name. If NameSpace is  the defined RDF name space it is returned as the atom rdf.  Finally, Object is a URI, a Predicate or a term of  the format literal(Value) for literal values. Value  is either a plain atom or a parsed XML term (list of atoms and  elements).\n\n",
    "prefix":"load_rdf"
  },
  "load_sgml/3": {
    "body":"load_sgml(${1:Source}, ${2:ListOfContent}, ${3:Options})$4\n$0",
    "description":"load_sgml(+Source, -ListOfContent, :Options).\nCalls load_structure/3  with the given Options, using the default option dialect(sgml)",
    "prefix":"load_sgml"
  },
  "load_structure/3": {
    "body":"load_structure(${1:Source}, ${2:ListOfContent}, ${3:Options})$4\n$0",
    "description":"load_structure(+Source, -ListOfContent, +Options).\nParse Source and return the resulting structure in ListOfContent. Source is either a term of the  format stream(StreamHandle) or a file-name. Options is  a list of options controlling the conversion process.  A proper XML document contains only a single toplevel element whose  name matches the document type. Nevertheless, a list is returned for  consistency with the representation of element content. The ListOfContent consists of the following types: \n\nAtom: Atoms are used to represent CDATA. Note this is possible in  SWI-Prolog, as there is no length-limit on atoms and atom garbage  collection is provided.\n\nelement(Name, ListAttributes, ListOfContent): Name is the name of the element. Using SGML, which is  case-insensitive, all element names are returned as lowercase atoms.  ListOfAttributes is a list of Name=Value  pairs for attributes. Attributes of type CDATA are returned  literal. Multi-valued attributes (NAMES, etc.) are  returned as a list of atoms. Handling attributes of the types NUMBER  and NUMBERS depends on the setting of the number(+NumberMode)  attribute through set_sgml_parser/2  or load_structure/3.  By default they are returned as atoms, but automatic conversion to  Prolog integers is supported. ListOfContent defines the  content for the element.\n\nsdata(Text): If an entity with declared content-type SDATA is  encountered, this term is returned holding the data in Text.\n\nndata(Text): If an entity with declared content-type NDATA is  encountered, this term is returned holding the data in Text.\n\npi(Text): If a processing instruction is encountered (<?...?>), Text  holds the text of the processing instruction. Please note that the <?xml ...?> instruction is handled internally.\n\n  The Options list controls the conversion process.  Currently defined options are below. Other options are passed to sgml_parse/2. \n\ndtd(?DTD): Reference to a DTD object. If specified, the <!DOCTYPE ...>  declaration is ignored and the document is parsed and validated against  the provided DTD. If provided as a variable, the created DTD is  returned. See section 3.5.\n\ndialect(+Dialect): Specify the parsing dialect. Supported are sgml (default), html4, html5, html (same as html4, xhtml, xhtml5, xml and xmlns.  See the option dialect of set_sgml_parser/2  for details.\n\nshorttag(+Bool): Define whether SHORTTAG abbreviation is accepted. The default is true  for SGML mode and false for the XML modes. Without SHORTTAG, a / is accepted with warning as part of an  unquoted attribute-value, though /> still closes the  element-tag in XML mode. It may be set to false for parsing HTML  documents to allow for unquoted URLs containing /.\n\nspace(+SpaceMode): Sets the `space-handling-mode' for the initial environment. This mode is  inherited by the other environments, which can override the inherited  value using the XML reserved attribute xml:space. See section 3.2.\n\nnumber(+NumberMode): Determines how attributes of type NUMBER and NUMBERS  are handled. If token (default) they are passed as an atom.  If integer the parser attempts to convert the value to an  integer. If successful, the attribute is passed as a Prolog integer.  Otherwise it is still passed as an atom. Note that SGML defines a  numeric attribute to be a sequence of digits. The -  sign is not allowed and 1 is different from 01. For this reason the  default is to handle numeric attributes as tokens. If conversion to  integer is enabled, negative values are silently accepted.\n\ncase_sensitive_attributes(+Boolean): Treat attribute values as case sensitive. The default is true  for XML and false for SGML and HTML dialects.\n\ncase_preserving_attributes(+Boolean): Treat attribute values as case insensitive but do not alter their case.  The default is false. Setting this option sets the case_sensitive_attributes to the same value. This option  was added to support HTML quasi quotations and most likely has little  value in other contexts.\n\nsystem_entities(+Boolean): Define whether SYSTEM entities are expanded. The default is false.\n\ndefaults(+Bool): Determines how default and fixed values from the DTD are used. By  default, defaults are included in the output if they do not appear in  the source. If false, only the attributes occurring in the  source are emitted.\n\nentity(+Name, +Value): Defines (overwrites) an entity definition. At the moment, only CDATA entities can be specified with this construct.  Multiple entity options are allowed.\n\nfile(+Name): Sets the name of the file on which errors are reported. Sets the  linenumber to 1.\n\nline(+Line): Sets the starting line-number for reporting errors.\n\nmax_memory(+Max): Sets the maximum buffer size in bytes available for input data and CDATA  output. If this limit is reached a resource error is raised. Using max_memory(0)  (the default) means no resource limit will be enforced.\n\ncdata(+Representation): Specify the representation of cdata elements. Supported are atom (default), and string. The choice is not  obvious. Strings are allocated on the Prolog stacks and subject to  normal stack garbage collection. They are quicker to create and avoid  memory fragmentation. But, multiple copies of the same string are stored  multiple times, while the text is shared if atoms are used. Strings are  also useful for security sensitive information as they are invisible to  other threads and cannot be enumerated using, e.g., current_atom/1.  Finally, using strings allows for resource usage limits using the global  stack limit (see set_prolog_stack/2).\n\nattribute_value(+Representation): Specify the representation of attribute values. Supported are atom (default), and string. See above for the  advantages and disadvantages of using strings.\n\nkeep_prefix(+Boolean): If true, xmlns namespaces with prefixes are returned as ns(Prefix, URI) terms. If false (default), the  prefix is ignored and the xmlns namespace is returned as just the URI.\n\n ",
    "prefix":"load_structure"
  },
  "load_test_files/1": {
    "body":"load_test_files(${1:Options})$2\n$0",
    "description":"load_test_files(+Options).\nLoad .plt test-files that belong to the currently loaded  sources.",
    "prefix":"load_test_files"
  },
  "load_xml/3": {
    "body":"load_xml(${1:Source}, ${2:ListOfContent}, ${3:Options})$4\n$0",
    "description":"load_xml(+Source, -ListOfContent, :Options).\nCalls load_structure/3  with the given Options, using the default option dialect(xml)",
    "prefix":"load_xml"
  },
  "locale_create/3": {
    "body":"locale_create(${1:Locale}, ${2:Default}, ${3:Options})$4\n$0",
    "description":"locale_create(-Locale, +Default, +Options).\nCreate a new locale object. Default is either an existing  locale or a string that denotes the name of a locale provided by the  system, such as \"en_EN.UTF-8\". The values read from the  default locale can be modified using Options. Options  provided are:  alias(+Atom): Give the locale a name.\n\ndecimal_point(+Atom): Specify the decimal point to use.\n\nthousands_sep(+Atom): Specify the string that delimits digit groups. Only effective is grouping  is also specified.\n\ngrouping(+List): Specify the grouping of digits. Groups are created from the right (least  significant) digits, left of the decimal point. List is a  list of integers, specifying the number of digits in each group,  counting from the right. If the last element is repeat(Count),  the remaining digits are grouped in groups of size Count. If  the last element is a normal integer, digits further to the left are not  grouped.\n\n  For example, the English locale uses \n\n\n\n[ decimal_point('.'), thousands_sep(','), grouping([repeat(3)]) ]\n\n  Named locales exists until they are destroyed using locale_destroy/1  and they are no longer referenced. Unnamed locales are subject to (atom)  garbage collection.\n\n",
    "prefix":"locale_create"
  },
  "locale_destroy/1": {
    "body":"locale_destroy(${1:Locale})$2\n$0",
    "description":"locale_destroy(+Locale).\nDestroy a locale. If the locale is named, this removes the name  association from the locale, after which the locale is left to be  reclaimed by garbage collection.",
    "prefix":"locale_destroy"
  },
  "locale_property/2": {
    "body":"locale_property(${1:Locale}, ${2:Property})$3\n$0",
    "description":"locale_property(?Locale, ?Property).\nTrue when Locale has Property. Properties are the  same as the Options described with locale_create/3.",
    "prefix":"locale_property"
  },
  "locale_sort/2": {
    "body":"locale_sort(${1:List}, ${2:Sorted})$3\n$0",
    "description":"locale_sort(+List, -Sorted).\nSort a list of atoms using the current locale. List is a list  of atoms or string objects (see section  5.2). Sorted is unified with a list containing all atoms  of List, sorted to the rules of the current locale. See also collation_key/2  and setlocale/3.",
    "prefix":"locale_sort"
  },
  "log/1": {
    "body":"log(${1:Expr})$2\n$0",
    "description":"[ISO]log(+Expr).\nNatural logarithm. Result = ln(Expr)",
    "prefix":"log"
  },
  "log10/1": {
    "body":"log10(${1:Expr})$2\n$0",
    "description":"log10(+Expr).\nBase-10 logarithm. Result = log10(Expr)",
    "prefix":"log10"
  },
  "lsb/1": {
    "body":"lsb(${1:IntExpr})$2\n$0",
    "description":"lsb(+IntExpr).\nReturn the smallest integer N such that (IntExpr >> N) /\\ 1 =:= 1.  This is the (zero-origin) index of the least significant 1 bit in the  value of IntExpr, which must evaluate to a positive integer.  Errors for 0, negative integers, and non-integers.",
    "prefix":"lsb"
  },
  "make/0": {
    "body":"make$1\n$0",
    "description":"make.\nConsult all source files that have been changed since they were  consulted. It checks all loaded source files: files loaded  into a compiled state using pl -c ... and files loaded  using consult/1  or one of its derivatives. The predicate make/0  is called after edit/1,  automatically reloading all modified files. If the user uses an external  editor (in a separate window), make/0  is normally used to update the program after editing. In addition, make/0  updates the autoload indices (see section  2.13) and runs list_undefined/0  from the library(check) library to report on undefined  predicates.",
    "prefix":"make"
  },
  "make:make/0": {
    "body": ["make$1\n$0" ],
    "description":"  make\n\n   Reload all source files that have   been changed since they were\n   loaded. This predicate peforms the following steps:\n\n     1. Compute the set of files that need to be reloaded.\n     2. Call the hook prolog:make_hook(before, Files)\n     3. Reload the files\n     4. Call the hook prolog:make_hook(after, Files)\n     5. If (4) fails, call list_undefined/0.\n\n   The hooks are called  with  an  empty   list  if  no  files need\n   reloading.",
    "prefix":"make"
  },
  "make_directory/1": {
    "body":"make_directory(${1:Directory})$2\n$0",
    "description":"make_directory(+Directory).\nCreate a new directory (folder) on the filesystem. Raises an exception  on failure. On Unix systems, the directory is created with default  permissions (defined by the process umask setting).",
    "prefix":"make_directory"
  },
  "make_library_index/1": {
    "body":"make_library_index(${1:Directory})$2\n$0",
    "description":"make_library_index(+Directory).\nCreate an index for this directory. The index is written to the file  'INDEX.pl' in the specified directory. Fails with a warning if the  directory does not exist or is write protected.",
    "prefix":"make_library_index"
  },
  "make_library_index/2": {
    "body":"make_library_index(${1:Directory}, ${2:ListOfPatterns})$3\n$0",
    "description":"make_library_index(+Directory, +ListOfPatterns).\nNormally used in MKINDEX.pl, this predicate creates INDEX.pl  for Directory, indexing all files that match one of the file  patterns in ListOfPatterns.  Sometimes library packages consist of one public load file and a  number of files used by this load file, exporting predicates that should  not be used directly by the end user. Such a library can be placed in a  sub-directory of the library and the files containing public  functionality can be added to the index of the library. As an example we  give the XPCE library's MKINDEX.pl, including the public  functionality of trace/browse.pl to the autoloadable  predicates for the XPCE package. \n\n\n\n:- make_library_index('.',\n                      [ '*.pl',\n                        'trace/browse.pl'\n                      ]).\n\n ",
    "prefix":"make_library_index"
  },
  "malloc_info:mallinfo/1": {
    "body": ["mallinfo(${1:Info})$2\n$0" ],
    "description":"  mallinfo(-Info:dict) is det.\n\n   Return the content  of  the   =|struct  mallinfo|=  returned  by\n   =|mallinfo()|= as a dict. See =|man mallinfo|= for an\n   explanation of the fields.\n\n   @bug    The =|struct mallinfo|= contains =int= fields and is thus\n           incapable of expressing the memory sizes of 64-bit\n           machines.  The fields are interpreted as _unsigned_ and\n           thus represent the true value modulo 2**32 (4Gb).",
    "prefix":"mallinfo"
  },
  "malloc_info:malloc_info/1": {
    "body": ["malloc_info(${1:Info})$2\n$0" ],
    "description":"  malloc_info(-Info:dict) is det.\n\n   Interface to =|malloc_info()|=, which provides   an XML document\n   describing the status of the   GNU  glibc malloc implementation.\n   The XML document is parsed and  translated   into  a dict with a\n   similar structure. The  malloc_info()  XML   is  supposed  to be\n   self-explanatory.",
    "prefix":"malloc_info"
  },
  "max/2": {
    "body":"max(${1:Expr1}, ${2:Expr2})$3\n$0",
    "description":"[ISO]max(+Expr1, +Expr2).\nEvaluate to the larger of Expr1 and Expr2. Both  arguments are compared after converting to the same type, but the return  value is in the original type. For example, max(2.5, 3) compares the two  values after converting to float, but returns the integer 3.",
    "prefix":"max"
  },
  "md5:hash_atom/2": {
    "body":"hash_atom(${1:Hash}, ${2:HexAtom})$3\n$0",
    "description":"hash_atom(+Hash, -HexAtom).\nTrue when HexAtom is the commonly used hexadecimal encoding  of the hash code. E.g.,  \n\n?- sha_hash('SWI-Prolog', Hash, []),\n   hash_atom(Hash, Hex).\nHash = [61, 128, 252, 38, 121, 69, 229, 85, 199|...],\nHex = '3d80fc267945e555c730403bd0ab0716e2a68c68'.\n\n  \n\n",
    "prefix":"hash_atom"
  },
  "md5:md5_hash/3": {
    "body":"md5_hash(${1:Data}, ${2:Hash}, ${3:Options})$4\n$0",
    "description":"[det]md5_hash(+Data, -Hash, +Options).\nHash is the MD5 hash of Data, The conversion is  controlled by Options:  encoding(+Encoding): If Data is a sequence of character codes, this must be  translated into a sequence of bytes, because that is what the  hashing requires. The default encoding is utf8. The other  meaningful value is octet, claiming that Data  contains raw bytes.\n\n  Data is either an atom, string,  code-list or char-list. Hash is an atom holding 32  characters, representing the hash in hexadecimal notation ",
    "prefix":"md5_hash"
  },
  "memberchk/2": {
    "body":"memberchk(${1:Elem}, ${2:List})$3\n$0",
    "description":"[semidet]memberchk(?Elem, +List).\nTrue when Elem is an element of List. This `chk'  variant of member/2  is semi deterministic and typically used to test membership of a list.  Raises a type error if scanning List encounters  a non-list. Note that memberchk/2  does not perform a full list typecheck. For example, memberchk(a,  [a|b]) succeeds without error. If List is cyclic and Elem  is not a member of List, memberchk/2  eventually raises a type error.114Eventually  here means it will scan as many elements as the longest list that may  exist given the current stack usage before raising the exception.",
    "prefix":"memberchk"
  },
  "memory_file:atom_to_memory_file/2": {
    "body": ["atom_to_memory_file(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"atom_to_memory_file('Param1','Param2')",
    "prefix":"atom_to_memory_file"
  },
  "memory_file:delete_memory_file/3": {
    "body": [
      "delete_memory_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"delete_memory_file('Param1','Param2','Param3')",
    "prefix":"delete_memory_file"
  },
  "memory_file:free_memory_file/1": {
    "body": ["free_memory_file(${1:'Param1'})$2\n$0" ],
    "description":"free_memory_file('Param1')",
    "prefix":"free_memory_file"
  },
  "memory_file:insert_memory_file/3": {
    "body": [
      "insert_memory_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"insert_memory_file('Param1','Param2','Param3')",
    "prefix":"insert_memory_file"
  },
  "memory_file:memory_file_line_position/4": {
    "body": [
      "memory_file_line_position(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"memory_file_line_position('Param1','Param2','Param3','Param4')",
    "prefix":"memory_file_line_position"
  },
  "memory_file:memory_file_substring/5": {
    "body": [
      "memory_file_substring(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"memory_file_substring('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"memory_file_substring"
  },
  "memory_file:memory_file_to_atom/2": {
    "body": ["memory_file_to_atom(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"memory_file_to_atom('Param1','Param2')",
    "prefix":"memory_file_to_atom"
  },
  "memory_file:memory_file_to_atom/3": {
    "body": [
      "memory_file_to_atom(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"memory_file_to_atom('Param1','Param2','Param3')",
    "prefix":"memory_file_to_atom"
  },
  "memory_file:memory_file_to_codes/2": {
    "body": ["memory_file_to_codes(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"memory_file_to_codes('Param1','Param2')",
    "prefix":"memory_file_to_codes"
  },
  "memory_file:memory_file_to_codes/3": {
    "body": [
      "memory_file_to_codes(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"memory_file_to_codes('Param1','Param2','Param3')",
    "prefix":"memory_file_to_codes"
  },
  "memory_file:memory_file_to_string/2": {
    "body": ["memory_file_to_string(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"memory_file_to_string('Param1','Param2')",
    "prefix":"memory_file_to_string"
  },
  "memory_file:memory_file_to_string/3": {
    "body": [
      "memory_file_to_string(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"memory_file_to_string('Param1','Param2','Param3')",
    "prefix":"memory_file_to_string"
  },
  "memory_file:new_memory_file/1": {
    "body": ["new_memory_file(${1:'Param1'})$2\n$0" ],
    "description":"new_memory_file('Param1')",
    "prefix":"new_memory_file"
  },
  "memory_file:open_memory_file/3": {
    "body": [
      "open_memory_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"open_memory_file('Param1','Param2','Param3')",
    "prefix":"open_memory_file"
  },
  "memory_file:open_memory_file/4": {
    "body": [
      "open_memory_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"open_memory_file('Param1','Param2','Param3','Param4')",
    "prefix":"open_memory_file"
  },
  "memory_file:size_memory_file/2": {
    "body": ["size_memory_file(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"size_memory_file('Param1','Param2')",
    "prefix":"size_memory_file"
  },
  "memory_file:size_memory_file/3": {
    "body": [
      "size_memory_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"size_memory_file('Param1','Param2','Param3')",
    "prefix":"size_memory_file"
  },
  "memory_file:utf8_position_memory_file/3": {
    "body": [
      "utf8_position_memory_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"utf8_position_memory_file('Param1','Param2','Param3')",
    "prefix":"utf8_position_memory_file"
  },
  "message_hook/3": {
    "body":"message_hook(${1:Term}, ${2:Kind}, ${3:Lines})$4\n$0",
    "description":"message_hook(+Term, +Kind, +Lines).\nHook predicate that may be defined in the module user to  intercept messages from print_message/2. Term  and Kind are the same as passed to print_message/2. Lines  is a list of format statements as described with print_message_lines/3.  See also message_to_string/2.  This predicate must be defined dynamic and multifile to allow other  modules defining clauses for it too.\n\n",
    "prefix":"message_hook"
  },
  "message_property/2": {
    "body":"message_property(${1:Kind}, ${2:Property})$3\n$0",
    "description":"message_property(+Kind, ?Property).\nThis hook can be used to define additional message kinds and the way  they are displayed. The following properties are defined:  color(-Attributes): Print message using ANSI terminal attributes. See ansi_format/3  for details. Here is an example, printing help messages in blue:  \n\n:- multifile user:message_property/2.\n\nuser:message_property(help, color([fg(blue)])).\n\n \n\nprefix(-Prefix): Prefix printed before each line. This argument is handed to format/3.  The default is '~N'. For example, messages of kind warning use '~NWarning: '.\n\nlocation_prefix(+Location, -FirstPrefix,  -ContinuePrefix): Used for printing messages that are related to a source location.  Currently, Location is a term File:Line. FirstPrefix is the prefix for the first line and -ContinuePrefix is the prefix for continuation lines. For  example, the default for errors is  \n\nlocation_prefix(File:Line,\n                '~NERROR: ~w:~d:'-[File,Line], '~N\\t')).\n\n \n\nstream(-Stream): Stream to which to print the message. Default is user_error.\n\nwait(-Seconds): Amount of time to wait after printing the message. Default is not to  wait.\n\n ",
    "prefix":"message_property"
  },
  "message_queue_create/1": {
    "body":"message_queue_create(${1:Queue})$2\n$0",
    "description":"message_queue_create(?Queue).\nEquivalent to message_queue_create(Queue,[]). For  compatibility, calling message_queue_create(+Atom) is  equivalent to message_queue_create(Queue, [alias(Atom)]). New code should  use message_queue_create/2  to create a named queue.",
    "prefix":"message_queue_create"
  },
  "message_queue_create/2": {
    "body":"message_queue_create(${1:Queue}, ${2:Options})$3\n$0",
    "description":"message_queue_create(-Queue, +Options).\nCreate a message queue from Options. Defined options are:  alias(+Alias): Create a message queue that is identified by the atom Alias.  Message queues created this way must be explicitly destroyed by the  user. If the alias option is omitted, an Anonymous queue is  created that is indentified by a blob (see section  11.4.7) and subject to garbage collection.155Garbage  collecting anonymous message queues is not part of the ISO proposal and  most likely not a widely implemented feature.\n\nmax_size(+Size): Maximum number of terms in the queue. If this number is reached, thread_send_message/2  will suspend until the queue is drained. The option can be used if the  source, sending messages to the queue, is faster than the drain,  consuming the messages.\n\n ",
    "prefix":"message_queue_create"
  },
  "message_queue_destroy/1": {
    "body":"message_queue_destroy(${1:Queue})$2\n$0",
    "description":"[det]message_queue_destroy(+Queue).\nDestroy a message queue created with message_queue_create/1.  A permission error is raised if Queue refers to (the default  queue of) a thread. Other threads that are waiting for Queue  using thread_get_message/2  receive an existence error.",
    "prefix":"message_queue_destroy"
  },
  "message_queue_property/2": {
    "body":"message_queue_property(${1:Queue}, ${2:Property})$3\n$0",
    "description":"message_queue_property(?Queue, ?Property).\nTrue if Property is a property of Queue. Defined  properties are:  alias(Alias): Queue has the given alias name.\n\nmax_size(Size): Maximum number of terms that can be in the queue. See message_queue_create/2.  This property is not present if there is no limit (default).\n\nsize(Size): Queue currently contains Size terms. Note that due to  concurrent access the returned value may be outdated before it is  returned. It can be used for debugging purposes as well as work  distribution purposes.\n\n  The size(Size) property is always present and may be  used to enumerate the created message queues. Note that this predicate  does not enumerate threads, but can be used to query the properties  of the default queue of a thread.\n\n",
    "prefix":"message_queue_property"
  },
  "message_to_string/2": {
    "body":"message_to_string(${1:Term}, ${2:String})$3\n$0",
    "description":"message_to_string(+Term, -String).\nTranslates a message term into a string object (see section  5.2).",
    "prefix":"message_to_string"
  },
  "min/2": {
    "body":"min(${1:Expr1}, ${2:Expr2})$3\n$0",
    "description":"[ISO]min(+Expr1, +Expr2).\nEvaluate to the smaller of Expr1 and Expr2. See max/2 for a  description of type handling.",
    "prefix":"min"
  },
  "module/1": {
    "body":"module(${1:Module})$2\n$0",
    "description":"module(+Module).\nThe call module(Module) may be used to switch  the default working module for the interactive top level (see prolog/0).  This may be used when debugging a module. The example below lists the  clauses of file_of_label/2  in the module tex.  \n\n1 ?- module(tex).\ntrue.\ntex: 2 ?- listing(file_of_label/2).\n...\n\n  \n\n",
    "prefix":"module"
  },
  "module_property/2": {
    "body":"module_property(${1:Module}, ${2:Property})$3\n$0",
    "description":"module_property(?Module, ?Property).\nTrue if Property is a property of Module. Defined  properties are:  class(-Class): True when Class is the class of the module. Defined classes  are  userDefault for user-defined modules.systemModule system and modules from <home>/boot.libraryOther modules from the system directories.temporaryModule is temporary.testModules that create tests.developmentModules that only support the development environment. \n\nfile(?File): True if Module was loaded from File.\n\nline_count(-Line): True if Module was loaded from the N-th line of file.\n\nexports(-ListOfPredicateIndicators): True if Module exports the given predicates. Predicate  indicators are in canonical form (i.e., always using name/arity and  never the DCG form name//arity). Future versions may also use the DCG  form and include public operators. See also predicate_property/2.\n\nexported_operators(-ListOfOperators): True if Module exports the given operators. Each exported  operator is represented as a term op(Pri,Assoc,Name).\n\nprogram_size(-Bytes): Memory (in bytes) used for storing the predicates of this module. This  figure includes the predicate header and clauses. Future versions might  give a more precise number, including e.g., the clause index tables.\n\nprogram_space(-Bytes): If present, this number limits the program_size. See set_module/1.\n\n ",
    "prefix":"module_property"
  },
  "modules:in_temporary_module/3": {
    "body": ["in_temporary_module(${1:Module}, ${2:Setup}, ${3:Goal})$4\n$0" ],
    "description":"  in_temporary_module(?Module, :Setup, :Goal)\n\n   Run Goal on temporary loaded sources  and discard the module and\n   loaded predicates after completion.  This predicate performs the\n   following steps:\n\n     1. If Module is unbound, create a unique identifier for it.\n     2. Turn Module into a _temporary_ module using set_module/1.\n        Note that this requires the module to be non-existent or\n        empty.  If Module is specified, it should typically be set\n        to a unique value as obtained from e.g. uuid/1.\n     3. Run Setup in the context of Module.\n     4. If setup succeeded possible choice points are discarded\n        and Goal is started.\n\n   The  logical  result  of  this   predicate    is   the  same  as\n   `(Setup@Module -> Goal@Module)`, i.e., both   Setup and Goal are\n   resolved relative to the current  module,   but  executed in the\n   context of Module.  If  Goal  must   be  called  in  Module, use\n   `call(Goal)`.\n\n   The module and all  its  predicates   are  destroyed  after Goal\n   terminates, as defined by setup_call_cleanup/3.\n\n   *Discussion* This predicate is intended to   load programs in an\n   isolated   environment   and   reclaim   all   resources.   This\n   unfortunately is incomplete:\n\n     - Running the code may leave side effects such as creating\n       records, flags, changing Prolog flags, etc.  The system\n       has no provisions to track this.\n     - So called _functors_ (name/arity pairs) are not yet subject\n       to garbage collection.  Functors are both used to define\n       predicates and to create compound terms.\n\n   @see    library(sandbox) determines whether unknown goals are safe\n           to call.\n   @see    load_files/2 offers the option sandboxed(true) to load code\n           from unknown sources safely.",
    "prefix":"in_temporary_module"
  },
  "msb/1": {
    "body":"msb(${1:IntExpr})$2\n$0",
    "description":"msb(+IntExpr).\nReturn the largest integer N such that (IntExpr >> N) /\\ 1 =:= 1.  This is the (zero-origin) index of the most significant 1 bit in the  value of IntExpr, which must evaluate to a positive integer.  Errors for 0, negative integers, and non-integers.",
    "prefix":"msb"
  },
  "msort/2": {
    "body":"msort(${1:List}, ${2:Sorted})$3\n$0",
    "description":"msort(+List, -Sorted).\nEquivalent to sort/2,  but does not remove duplicates. Raises a type_error if List is a cyclic list or not a  list.",
    "prefix":"msort"
  },
  "mutex_create/1": {
    "body":"mutex_create(${1:MutexId})$2\n$0",
    "description":"mutex_create(?MutexId).\nCreate a mutex. If MutexId is an atom, a named mutex  is created. If it is a variable, an anonymous mutex reference is  returned. Anonymous mutexes are subject to (atom) garbage collection.",
    "prefix":"mutex_create"
  },
  "mutex_create/2": {
    "body":"mutex_create(${1:MutexId}, ${2:Options})$3\n$0",
    "description":"mutex_create(-MutexId, +Options).\nCreate a mutex using options. Defined options are:  alias(Alias): Set the alias name. Using mutex_create(X, [alias(name)]) is  preferred over the equivalent mutex_create(name).\n\n ",
    "prefix":"mutex_create"
  },
  "mutex_destroy/1": {
    "body":"mutex_destroy(${1:MutexId})$2\n$0",
    "description":"mutex_destroy(+MutexId).\nDestroy a mutex. If the mutex is not locked, it is destroyed and further  access yields an existence_error exception. As of version  7.1.19, this behaviour is reliable. If the mutex is locked, the mutex is  sheduled for delayed destruction: it will be destroyed when it  becomes unlocked.",
    "prefix":"mutex_destroy"
  },
  "mutex_lock/1": {
    "body":"mutex_lock(${1:MutexId})$2\n$0",
    "description":"mutex_lock(+MutexId).\nLock the mutex. Prolog mutexes are recursive mutexes: they can  be locked multiple times by the same thread. Only after unlocking it as  many times as it is locked does the mutex become available for locking  by other threads. If another thread has locked the mutex the calling  thread is suspended until the mutex is unlocked.  If MutexId is an atom, and there is no current mutex with  that name, the mutex is created automatically using mutex_create/1.  This implies named mutexes need not be declared explicitly. \n\nPlease note that locking and unlocking mutexes should be paired  carefully. Especially make sure to unlock mutexes even if the protected  code fails or raises an exception. For most common cases, use with_mutex/2,  which provides a safer way for handling Prolog-level mutexes. The  predicate setup_call_cleanup/3  is another way to guarantee that the mutex is unlocked while retaining  non-determinism.\n\n",
    "prefix":"mutex_lock"
  },
  "mutex_property/2": {
    "body":"mutex_property(${1:MutexId}, ${2:Property})$3\n$0",
    "description":"mutex_property(?MutexId, ?Property).\nTrue if Property is a property of MutexId. Defined  properties are:  alias(Alias): Mutex has the defined alias name. See mutex_create/2  using the `alias' option.\n\nstatus(Status): Current status of the mutex. One of unlocked if the mutex  is currently not locked, or locked(Owner, Count) if mutex  is locked Count times by thread Owner. Note that unless Owner  is the calling thread, the locked status can change at any time. There  is no useful application of this property, except for diagnostic  purposes.bugAs Owner  and Count are fetched separately from the mutex, the values  may be inconsistent.\n\n ",
    "prefix":"mutex_property"
  },
  "mutex_statistics/0": {
    "body":"mutex_statistics$1\n$0",
    "description":"mutex_statistics.\nPrint usage statistics on internal mutexes and mutexes associated with  dynamic predicates. For each mutex two numbers are printed: the number  of times the mutex was acquired and the number of collisions:  the number of times the calling thread has to wait for the mutex.  Generally collision count is close to zero on single-CPU hardware.",
    "prefix":"mutex_statistics"
  },
  "mutex_trylock/1": {
    "body":"mutex_trylock(${1:MutexId})$2\n$0",
    "description":"mutex_trylock(+MutexId).\nAs mutex_lock/1,  but if the mutex is held by another thread, this predicates fails  immediately.",
    "prefix":"mutex_trylock"
  },
  "mutex_unlock/1": {
    "body":"mutex_unlock(${1:MutexId})$2\n$0",
    "description":"mutex_unlock(+MutexId).\nUnlock the mutex. This can only be called if the mutex is held by the  calling thread. If this is not the case, a permission_error  exception is raised.",
    "prefix":"mutex_unlock"
  },
  "name/2": {
    "body":"name(${1:Atomic}, ${2:CodeList})$3\n$0",
    "description":"name(?Atomic, ?CodeList).\nCodeList is a list of character codes representing the same  text as Atomic. Each of the arguments may be a variable, but  not both. When CodeList describes an integer or floating  point number and Atomic is a variable, Atomic will be unified with  the numeric value described by CodeList (e.g., name(N,  \"300\"), 400 is N + 100 succeeds). If CodeList is not a  representation of a number, Atomic will be unified with the atom with the name given by  the character code list. When Atomic is an atom or number,  the unquoted print representation of it as a character code list will be  unified with CodeList.  Note that it is not possible to produce the atom '300' using name/2,  and that name(300, CodeList), name('300', CodeList)  succeeds. For these reasons, new code should consider using the ISO  predicates atom_codes/2  or number_codes/2.98Unfortunately,  the ISO predicates provide no neat way to check that a string can be  interpreted as a number. The most sensible way is to use catch/3  to catch the exception from number_codes/2;  however, this is both slow and cumbersome. We consider making, e.g., number_codes(N,  \"abc\") fail silently in future versions. See also atom_number/2.\n\n",
    "prefix":"name"
  },
  "nan/0": {
    "body":"nan$1\n$0",
    "description":"nan.\nEvaluate to Not a Number. See section  2.15.1.6.",
    "prefix":"nan"
  },
  "nb_current/2": {
    "body":"nb_current(${1:Name}, ${2:Value})$3\n$0",
    "description":"nb_current(?Name, ?Value).\nEnumerate all defined variables with their value. The order of  enumeration is undefined. Note that nb_current/2  can be used as an alternative for nb_getval/2  to request the value of a variable and fail silently if the variable  does not exists.",
    "prefix":"nb_current"
  },
  "nb_delete/1": {
    "body":"nb_delete(${1:Name})$2\n$0",
    "description":"nb_delete(+Name).\nDelete the named global variable. Succeeds also if the named variable  does not exist.",
    "prefix":"nb_delete"
  },
  "nb_getval/2": {
    "body":"nb_getval(${1:Name}, ${2:Value})$3\n$0",
    "description":"nb_getval(+Name, -Value).\nThe nb_getval/2  predicate is a synonym for b_getval/2,  introduced for compatibility and symmetry. As most scenarios will use a  particular global variable using either non-backtrackable or  backtrackable assignment, using nb_getval/2  can be used to document that the variable is non-backtrackable. Raises existence_error(variable,  Name) if the variable does not exist. Alternatively, nb_current/2  can used to query a global variable. This version fails if the  variable does not exist rather than raising an exception.",
    "prefix":"nb_getval"
  },
  "nb_link_dict/3": {
    "body":"nb_link_dict(${1:Key}, ${2:Dict}, ${3:Value})$4\n$0",
    "description":"[det]nb_link_dict(+Key, !Dict, +Value).\nDestructively update the value associated with Key in Dict  to Value. The update is not undone on backtracking.  This predicate raises an existence error if Key does not  appear in Dict. The update semantics are equivalent to nb_linkarg/3  and nb_linkval/2.  Use with extreme care and consult the documentation of nb_linkval/2  before use.",
    "prefix":"nb_link_dict"
  },
  "nb_linkarg/3": {
    "body":"nb_linkarg(${1:Arg}, ${2:Term}, ${3:Value})$4\n$0",
    "description":"nb_linkarg(+Arg, +Term, +Value).\nAs nb_setarg/3,  but like nb_linkval/2  it does not duplicate Value. Use with extreme care and consult the documentation of nb_linkval/2  before use.",
    "prefix":"nb_linkarg"
  },
  "nb_linkval/2": {
    "body":"nb_linkval(${1:Name}, ${2:Value})$3\n$0",
    "description":"nb_linkval(+Name, +Value).\nAssociates the term Value with the atom Name  without copying it. This is a fast special-purpose variation of nb_setval/2  intended for expert users only because the semantics on backtracking to  a point before creating the link are poorly defined for compound terms.  The principal term is always left untouched, but backtracking behaviour  on arguments is undone if the original assignment was trailed  and left alone otherwise, which implies that the history that created  the term affects the behaviour on backtracking. Consider the following  example:  \n\ndemo_nb_linkval :-\n        T = nice(N),\n        (   N = world,\n            nb_linkval(myvar, T),\n            fail\n        ;   nb_getval(myvar, V),\n            writeln(V)\n        ).\n\n ",
    "prefix":"nb_linkval"
  },
  "nb_rbtrees:nb_rb_get_node/3": {
    "body": ["nb_rb_get_node(${1:RBTree}, ${2:Key}, ${3:Node})$4\n$0" ],
    "description":"  nb_rb_get_node(+RBTree, +Key, -Node) is semidet.\n\n   True if Node is the node in   RBTree associated to Key. Fails if\n   Key is not in RBTree. This  predicate   is  intended  to be used\n   together with nb_rb_set_node_value/2 to   update  the associated\n   key destructively.",
    "prefix":"nb_rb_get_node"
  },
  "nb_rbtrees:nb_rb_insert/3": {
    "body": ["nb_rb_insert(${1:RBTree}, ${2:Key}, ${3:Value})$4\n$0" ],
    "description":"  nb_rb_insert(!RBTree, +Key, +Value)\n\n   Add  Key-Value  to  the  tree   RBTree  using  non-backtrackable\n   destructive assignment.",
    "prefix":"nb_rb_insert"
  },
  "nb_rbtrees:nb_rb_node_value/2": {
    "body": ["nb_rb_node_value(${1:Node}, ${2:Value})$3\n$0" ],
    "description":"  nb_rb_node_value(+Node, -Value) is det.\n\n   Value is the value associated to Node.",
    "prefix":"nb_rb_node_value"
  },
  "nb_rbtrees:nb_rb_set_node_value/2": {
    "body": ["nb_rb_set_node_value(${1:Node}, ${2:Value})$3\n$0" ],
    "description":"  nb_rb_set_node_value(!Node, +Value) is det.\n\n   Associate Value with Node.",
    "prefix":"nb_rb_set_node_value"
  },
  "nb_set:add_nb_set/2": {
    "body":"add_nb_set(${1:Key}, ${2:Set})$3\n$0",
    "description":"add_nb_set(+Key, !Set).\nAdd Key to Set. If Key is already a  member of Set, add_nb_set/3  succeeds without modifying Set.",
    "prefix":"add_nb_set"
  },
  "nb_set:add_nb_set/3": {
    "body":"add_nb_set(${1:Key}, ${2:Set}, ${3:New})$4\n$0",
    "description":"add_nb_set(+Key, !Set, ?New).\nIf Key is not in Set and New is unified  to true, Key is added to Set. If Key  is in Set, New is unified to false.  It can be used for many purposes:  \n\nadd_nb_set(+, +, false)Test  membership add_nb_set(+, +, true)Succeed  only if new member add_nb_set(+, +, Var)Succeed,  binding Var ",
    "prefix":"add_nb_set"
  },
  "nb_set:empty_nb_set/1": {
    "body":"empty_nb_set(${1:Set})$2\n$0",
    "description":"empty_nb_set(?Set).\nTrue if Set is a non-backtrackable empty set.",
    "prefix":"empty_nb_set"
  },
  "nb_set:gen_nb_set/2": {
    "body":"gen_nb_set(${1:Set}, ${2:Key})$3\n$0",
    "description":"gen_nb_set(+Set, -Key).\nGenerate all members of Set on backtracking in the standard  order of terms. To test membership, use add_nb_set/3.",
    "prefix":"gen_nb_set"
  },
  "nb_set:nb_set_to_list/2": {
    "body":"nb_set_to_list(${1:Set}, ${2:List})$3\n$0",
    "description":"nb_set_to_list(+Set, -List).\nUnify List with a list of all elements in Set in  the standard order of terms (i.e., an ordered list).",
    "prefix":"nb_set_to_list"
  },
  "nb_set:size_nb_set/2": {
    "body":"size_nb_set(${1:Set}, ${2:Size})$3\n$0",
    "description":"size_nb_set(+Set, -Size).\nUnify Size with the number of elements in Set.",
    "prefix":"size_nb_set"
  },
  "nb_set_dict/3": {
    "body":"nb_set_dict(${1:Key}, ${2:Dict}, ${3:Value})$4\n$0",
    "description":"[det]nb_set_dict(+Key, !Dict, +Value).\nDestructively update the value associated with Key in Dict  to a copy of Value. The update is not undone on  backtracking. This predicate raises an existence error if Key  does not appear in Dict. The update semantics are equivalent to nb_setarg/3  and nb_setval/2.",
    "prefix":"nb_set_dict"
  },
  "nb_setarg/3": {
    "body":"nb_setarg(${1:Arg}, ${2:Term}, ${3:Value})$4\n$0",
    "description":"nb_setarg(+Arg, +Term, +Value).\nAssigns the Arg-th argument of the compound term Term  with the given Value as setarg/3,  but on backtracking the assignment is not reversed. If Value  is not atomic, it is duplicated using duplicate_term/2.  This predicate uses the same technique as nb_setval/2.  We therefore refer to the description of nb_setval/2  for details on non-backtrackable assignment of terms. This predicate is  compatible with GNU-Prolog setarg(A,T,V,false), removing  the type restriction on Value. See also nb_linkarg/3.  Below is an example for counting the number of solutions of a goal. Note  that this implementation is thread-safe, reentrant and capable of  handling exceptions. Realising these features with a traditional  implementation based on assert/retract or flag/3  is much more complicated.  \n\n:- meta_predicate\n        succeeds_n_times(0, -).\n\nsucceeds_n_times(Goal, Times) :-\n        Counter = counter(0),\n        (   Goal,\n            arg(1, Counter, N0),\n            N is N0 + 1,\n            nb_setarg(1, Counter, N),\n            fail\n        ;   arg(1, Counter, Times)\n        ).\n\n ",
    "prefix":"nb_setarg"
  },
  "nb_setval/2": {
    "body":"nb_setval(${1:Name}, ${2:Value})$3\n$0",
    "description":"nb_setval(+Name, +Value).\nAssociates a copy of Value created with duplicate_term/2  with the atom Name. Note that this can be used to set an  initial value other than [] prior to backtrackable  assignment.",
    "prefix":"nb_setval"
  },
  "new_dtd/2": {
    "body":"new_dtd(${1:DocType}, ${2:DTD})$3\n$0",
    "description":"new_dtd(+DocType, -DTD).\nCreates an empty DTD for the named DocType. The returned  DTD-reference is an opaque term that can be used in the other predicates  of this package.",
    "prefix":"new_dtd"
  },
  "new_order_table/2": {
    "body":"new_order_table(${1:Name}, ${2:Options})$3\n$0",
    "description":"new_order_table(+Name, +Options).\nCreate a new, or replace the order-table with the given name (an atom). Options  is a list of options:  \n\ncase_insensitiveMap all  upper- to lowercase characters. iso_latin_1Start with an  ISO-Latin-1 table iso_latin_1_case_insensitiveStart  with a case-insensitive ISO-Latin-1 table copy(+Table)Copy  all entries from Table. tag(+ListOfCodes)Add  these characters to the set of `tag' characters. ignore(+ListOfCodes)Add  these characters to the set of `ignore' characters. break(+ListOfCodes)Add  these characters to the set of `break' characters. +Code1 = +Code2 Map Code1  onto Code2. ",
    "prefix":"new_order_table"
  },
  "new_sgml_parser/2": {
    "body":"new_sgml_parser(${1:Parser}, ${2:Options})$3\n$0",
    "description":"new_sgml_parser(-Parser, +Options).\nCreates a new parser. A parser can be used one or multiple times for  parsing documents or parts thereof. It may be bound to a DTD or the DTD  may be left implicit, in which case it is created from the document  prologue or parsing is performed without a DTD. Options:  dtd(?DTD): If specified with an initialised DTD, this DTD is used for parsing the  document, regardless of the document prologue. If specified using as a  variable, a reference to the created DTD is returned. This DTD may be  created from the document prologue or build implicitely from the  document's content.\n\n ",
    "prefix":"new_sgml_parser"
  },
  "new_table/4": {
    "body":"new_table(${1:File}, ${2:Columns}, ${3:Options}, ${4:Handle})$5\n$0",
    "description":"new_table(+File, +Columns, +Options, -Handle).\nCreate a description of a new table, stored in File. Columns  is a list of descriptions for each column. A column description is of  the form ColumnName(Type [, ColumnOptions])  Type denotes the Prolog type to which the field should be  converted and is one of: \n\n\n\nintegerConvert to a Prolog  integer. The input is treated as a decimal number. hexadecimalConvert to a  Prolog integer. The input is treated as a hex number. floatConvert to a Prolog  floating point number. The input is handled by the C-library function strtod(). atomConvert to a Prolog atom. stringConvert to a SWI-Prolog  string object. code_listConvert to a list of ASCII  codes.   ColumnOptions is a list of additional properties of the  column. Supported values are: \n\n\n\nsortedThe field is strictly  sorted, but may have (adjacent) duplicate entries. If the field is  textual, it should be sorted alphabetically, otherwise it should be  sorted numerically. sorted(+Table)The  (textual) field is sorted using the ordering declared by the named ordering  table. This option may be used to define reverse order,  `dictionary' order or other irregular alphabetical ordering. See new_order_table/2. uniqueThis column has  distinct values for each row in the table. downcaseMap all uppercase in  the field to lowercase before converting to a Prolog atom, string or  code_list. map_space_to_underscoreMap  spaces to underscores before converting to a Prolog atom, string or  code_list. syntaxFor numerical fields.  If the field does not contain a valid number, matching the value fails.  Reading the value returns the value as an atom. width(+Chars)Field  has fixed width of the specified number of characters. The  column-separator is not considered for this column. arg(+Index)For read_table_record/4,  unify the field with the given argument of the record term. Further  fields will be assigned index+1, ... . skipDon't convert this field  to Prolog. The field is simply skipped without checking for consistency.   The Options argument is a list of global options for the  table. Defined options are: \n\n\n\nrecord_separator(+Code)Character  (ASCII) value of the  character separating two records. Default is the newline (ASCII  10). field_separator(+Code)Character  (ASCII) value of the  character separating two fields in a record. Default is the space (ASCII  32), which also has a special meaning. Two fields separated by a space  may be separated by any non-empty sequence of spaces and tab (ASCII  9) characters. For all other separators, a single character separates  the fields. encoding(+Encoding)Text  encoding of the file. Values are iso_latin_1 (default), utf8 or native. The latter uses the native  multibyte to unicode conversion. escape(+Code, +ListOfMap)Sometimes,  a table defines escape sequences to make it possible to use the  separator-characters in text-fields. This options provides a simple way  to handle some standard cases. Code is the ASCII  code of the character that leads the escape sequence. The default is -1, and thus never matched. ListOfMap is a list of From = To character mappings. The  default map table is the identity map, unless Code refers to  the \\ character, in which case \\b, \\e, \\n, \\r and \\t  have their usual meaning. functor(+Head)Functor  used by read_table_record/4.  Default is record using the maximal argument index of the  fields as arity.   If the options are parsed successfully, Handle is unified  with a term that may be used as a handle to the table for future  operations on it. Note that new_table/4  does not access the file system, so its success only indicates the  description could be parsed, not the presence, access or format of the  file.\n\n",
    "prefix":"new_table"
  },
  "nl/1": {
    "body":"nl(${1:Stream})$2\n$0",
    "description":"[ISO]nl(+Stream).\nWrite a newline to Stream.",
    "prefix":"nl"
  },
  "nodebug/0": {
    "body":"nodebug$1\n$0",
    "description":"nodebug.\nStop debugger. Implemented by the Prolog flag debug.  See also debug/0.",
    "prefix":"nodebug"
  },
  "noguitracer/0": {
    "body":"noguitracer$1\n$0",
    "description":"noguitracer.\nDisable the hooks installed by guitracer/0,  reverting to normal text console-based tracing.",
    "prefix":"noguitracer"
  },
  "nonvar/1": {
    "body":"nonvar(${1:Term})$2\n$0",
    "description":"[ISO]nonvar(@Term).\nTrue if Term currently is not a free variable.",
    "prefix":"nonvar"
  },
  "noprofile/2": {
    "body":"noprofile(${1:Name/}, ${2:...})$3\n$0",
    "description":"noprofile(+Name/+Arity, ...).\nDeclares the predicate Name/Arity to be invisible  to the profiler. The time spent in the named predicate is added to the  caller, and the callees are linked directly to the caller. This is  particularly useful for simple meta-predicates such as call/1, ignore/1, catch/3,  etc.",
    "prefix":"noprofile"
  },
  "noprotocol/0": {
    "body":"noprotocol$1\n$0",
    "description":"noprotocol.\nStop making a protocol of the user interaction. Pending output is  flushed on the file.",
    "prefix":"noprotocol"
  },
  "normalize_space/2": {
    "body":"normalize_space(${1:Out}, ${2:In})$3\n$0",
    "description":"normalize_space(-Out, +In).\nNormalize white space in In. All leading and trailing white  space is removed. All non-empty sequences for Unicode white space  characters are replaced by a single space (\\u0020)  character. Out uses the same conventions as with_output_to/2  and format/3.",
    "prefix":"normalize_space"
  },
  "nospy/1": {
    "body":"nospy(${1:Pred})$2\n$0",
    "description":"nospy(+Pred).\nRemove spy point from all predicates meeting the predicate specification Pred.",
    "prefix":"nospy"
  },
  "nospyall/0": {
    "body":"nospyall$1\n$0",
    "description":"nospyall.\nRemove all spy points from the entire program.",
    "prefix":"nospyall"
  },
  "not/1": {
    "body":"not(${1:Goal})$2\n$0",
    "description":"not(:Goal).\nTrue if Goal cannot be proven. Retained for compatibility  only. New code should use \\+/1.",
    "prefix":"not"
  },
  "notrace/0": {
    "body":"notrace$1\n$0",
    "description":"notrace.\nStop the tracer. notrace/0  itself cannot be seen in the tracer.",
    "prefix":"notrace"
  },
  "notrace/1": {
    "body":"notrace(${1:Goal})$2\n$0",
    "description":"notrace(:Goal).\nCall Goal, but suspend the debugger while Goal is  executing. The current implementation cuts the choice points of Goal  after successful completion. See once/1.  Later implementations may have the same semantics as call/1.",
    "prefix":"notrace"
  },
  "nth_clause/3": {
    "body":"nth_clause(${1:Pred}, ${2:Index}, ${3:Reference})$4\n$0",
    "description":"nth_clause(?Pred, ?Index, ?Reference).\nProvides access to the clauses of a predicate using their index number.  Counting starts at 1. If Reference is specified it unifies Pred  with the most general term with the same name/arity as the predicate and Index with the index number of the clause. Otherwise the name  and arity of Pred are used to determine the predicate. If Index  is provided, Reference will be unified with the clause  reference. If Index is unbound, backtracking will yield both  the indexes and the references of all clauses of the predicate. The  following example finds the 2nd clause of append/3:  \n\n?- use_module(library(lists)).\n...\n?- nth_clause(append(_,_,_), 2, Ref), clause(Head, Body, Ref).\nRef = <clause>(0x994290),\nHead = lists:append([_G23|_G24], _G21, [_G23|_G27]),\nBody = append(_G24, _G21, _G27).\n\n ",
    "prefix":"nth_clause"
  },
  "nth_integer_root_and_remainder/4": {
    "body":"nth_integer_root_and_remainder(${1:N}, ${2:I}, ${3:Root}, ${4:Remainder})$5\n$0",
    "description":"nth_integer_root_and_remainder(+N, +I, -Root, -Remainder).\nTrue when Root ** N + Remainder = I. N and I  must be integers.103This predicate  was suggested by Markus Triska. The final name and argument order is by  Richard O'Keefe. The decision to include the remainder is by Jan  Wielemaker. Including the remainder makes this predicate about twice as  slow if Root is not exact. N must be one or more. If I is negative and N is odd, Root and Remainder  are negative, i.e., the following holds for I < 0:  \n\n%   I < 0,\n%   N mod 2 =\\= 0,\n    nth_integer_root_and_remainder(\n        N, I, Root, Remainder),\n    IPos is -I,\n    nth_integer_root_and_remainder(\n        N, IPos, RootPos, RemainderPos),\n    Root =:= -RootPos,\n    Remainder =:= -RemainderPos.\n\n  \n\n",
    "prefix":"nth_integer_root_and_remainder"
  },
  "number/1": {
    "body":"number(${1:Term})$2\n$0",
    "description":"[ISO]number(@Term).\nTrue if Term is bound to an integer or floating point number.50As  rational numbers are not atomic in the current implementation and we do  not want to break the rule that number/1  implies atomic/1, number/1  fails on rational numbers. This will change if rational numbers become  atomic.",
    "prefix":"number"
  },
  "number_chars/2": {
    "body":"number_chars(${1:Number}, ${2:CharList})$3\n$0",
    "description":"[ISO]number_chars(?Number, ?CharList).\nSimilar to atom_chars/2,  but converts between a number and its representation as a list of  one-character atoms. Fails with a syntax_error if Number is unbound or CharList  does not describe a number. Following the ISO standard, it allows for leading white space (including newlines) and does not allow for trailing white space.96ISO  also allows for Prolog comments in leading white space. We--and most  other implementations--believe this is incorrect. We also beleive it  would have been better not to allow for white space, or to allow for  both leading and trailing white space. Prolog syntax-based conversion  can be achieved using format/3  and read_from_chars/2.",
    "prefix":"number_chars"
  },
  "number_codes/2": {
    "body":"number_codes(${1:Number}, ${2:CodeList})$3\n$0",
    "description":"[ISO]number_codes(?Number, ?CodeList).\nAs number_chars/2,  but converts to a list of character codes rather than one-character  atoms. In the mode (-, +), both predicates behave identically to improve  handling of non-ISO source.",
    "prefix":"number_codes"
  },
  "number_string/2": {
    "body":"number_string(${1:Number}, ${2:String})$3\n$0",
    "description":"number_string(?Number, ?String).\nBi-directional conversion between a number and a string. At least one of  the two arguments must be instantiated. Besides the type used to  represent the text, this predicate differs in several ways from its ISO  cousin:136Note that SWI-Prolog's  syntax for numbers is not ISO compatible either.  \n\nIf String does not represent a number, the predicate fails  rather than throwing a syntax error exception.\nLeading white space and Prolog comments are not allowed.\nNumbers may start with '+' or '-'.\nIt is not allowed to have white space between a leading '+'  or '-' and the number.\nFloating point numbers in exponential notation do not require a dot  before exponent, i.e., \"1e10\" is a valid number.\n\n",
    "prefix":"number_string"
  },
  "numbervars/3": {
    "body":"numbervars(${1:Term}, ${2:Start}, ${3:End})$4\n$0",
    "description":"numbervars(+Term, +Start, -End).\nUnify the free variables in Term with a term $VAR(N),  where N is the number of the variable. Counting starts at Start. End is unified with the number that should  be given to the next variable.bugOnly tagged  integers are supported (see the Prolog flag max_tagged_integer).  This suffices to count all variables that can appear in the largest term  that can be represented, but does not support arbitrary large integer  values for Start. On overflow, a representation_error(tagged_integer)  exception is raised. The example below illustrates this.  Note that the toplevel prints '$VAR'(0) as A due  to the numbervars(true) option used to print answers.  \n\n?- Term = f(X,Y,X),\n   numbervars(Term, 0, End),\n   write_canonical(Term), nl.\nf('$VAR'(0),'$VAR'(1),'$VAR'(0))\nTerm = f(A, B, A),\nX = A,\nY = B,\nEnd = 2.\n\n  See also the numbervars option to write_term/3  and numbervars/4.\n\n",
    "prefix":"numbervars"
  },
  "numbervars/4": {
    "body":"numbervars(${1:Term}, ${2:Start}, ${3:End}, ${4:Options})$5\n$0",
    "description":"numbervars(+Term, +Start, -End, +Options).\nAs numbervars/3,  providing the following options:  functor_name(+Atom): Name of the functor to use instead of $VAR.\n\nattvar(+Action): What to do if an attributed variable is encountered. Options are skip, which causes numbervars/3  to ignore the attributed variable, bind which causes it to  treat it as a normal variable and assign the next '$VAR'(N)  term to it, or (default) error which raises a type_error exception.92This  behaviour was decided after a long discussion between David Reitter,  Richard O'Keefe, Bart Demoen and Tom Schrijvers.\n\nsingletons(+Bool): If true (default false), numbervars/4  does singleton detection. Singleton variables are unified with '$VAR'('_'),  causing them to be printed as _ by write_term/2  using the numbervars option. This option is exploited by portray_clause/2  and write_canonical/2.bugCurrently  this option is ignored for cyclic terms.\n\n ",
    "prefix":"numbervars"
  },
  "occurs:contains_term/2": {
    "body": ["contains_term(${1:Sub}, ${2:Term})$3\n$0" ],
    "description":"  contains_term(+Sub, +Term) is semidet.\n\n   Succeeds if Sub is contained in Term (=, deterministically)",
    "prefix":"contains_term"
  },
  "occurs:contains_var/2": {
    "body": ["contains_var(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"contains_var('Param1','Param2')",
    "prefix":"contains_var"
  },
  "occurs:free_of_term/2": {
    "body": ["free_of_term(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"free_of_term('Param1','Param2')",
    "prefix":"free_of_term"
  },
  "occurs:free_of_var/2": {
    "body": ["free_of_var(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"free_of_var('Param1','Param2')",
    "prefix":"free_of_var"
  },
  "occurs:occurrences_of_term/3": {
    "body": [
      "occurrences_of_term(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"occurrences_of_term('Param1','Param2','Param3')",
    "prefix":"occurrences_of_term"
  },
  "occurs:occurrences_of_var/3": {
    "body": [
      "occurrences_of_var(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"occurrences_of_var('Param1','Param2','Param3')",
    "prefix":"occurrences_of_var"
  },
  "occurs:sub_term/2": {
    "body": ["sub_term(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sub_term('Param1','Param2')",
    "prefix":"sub_term"
  },
  "occurs:sub_var/2": {
    "body": ["sub_var(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sub_var('Param1','Param2')",
    "prefix":"sub_var"
  },
  "odbc:odbc_clone_statement/2": {
    "body": ["odbc_clone_statement(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"odbc_clone_statement('Param1','Param2')",
    "prefix":"odbc_clone_statement"
  },
  "odbc:odbc_close_statement/1": {
    "body": ["odbc_close_statement(${1:'Param1'})$2\n$0" ],
    "description":"odbc_close_statement('Param1')",
    "prefix":"odbc_close_statement"
  },
  "odbc:odbc_connect/3": {
    "body": ["odbc_connect(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"odbc_connect('Param1','Param2','Param3')",
    "prefix":"odbc_connect"
  },
  "odbc:odbc_current_connection/2": {
    "body": ["odbc_current_connection(${1:Conn}, ${2:DSN})$3\n$0" ],
    "description":"  odbc_current_connection(?Conn, ?DSN) is nondet.\n\n   True if Conn is an open ODBC connection to DSN.",
    "prefix":"odbc_current_connection"
  },
  "odbc:odbc_current_table/2": {
    "body": ["odbc_current_table(${1:Table}, ${2:Facet})$3\n$0" ],
    "description":"  odbc_current_table(-Table, -Facet)\n\n   Enumerate the existing tables.",
    "prefix":"odbc_current_table"
  },
  "odbc:odbc_current_table/3": {
    "body": [
      "odbc_current_table(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"odbc_current_table('Param1','Param2','Param3')",
    "prefix":"odbc_current_table"
  },
  "odbc:odbc_data_source/2": {
    "body": ["odbc_data_source(${1:DSN}, ${2:Description})$3\n$0" ],
    "description":"  odbc_data_source(?DSN, ?Description)\n\n   Enumerate the available data-sources",
    "prefix":"odbc_data_source"
  },
  "odbc:odbc_debug/1": {
    "body": ["odbc_debug(${1:'Param1'})$2\n$0" ],
    "description":"odbc_debug('Param1')",
    "prefix":"odbc_debug"
  },
  "odbc:odbc_disconnect/1": {
    "body": ["odbc_disconnect(${1:'Param1'})$2\n$0" ],
    "description":"odbc_disconnect('Param1')",
    "prefix":"odbc_disconnect"
  },
  "odbc:odbc_driver_connect/3": {
    "body": [
      "odbc_driver_connect(${1:DriverString}, ${2:Connection}, ${3:Options})$4\n$0"
    ],
    "description":"  odbc_driver_connect(+DriverString, -Connection, +Options) is det.\n\n   Connects to a database using SQLDriverConnect(). This API allows\n   for driver-specific additional options.   DriverString is passed\n   without  checking.  Options  should  *not*  include  =user=  and\n   =password=.\n\n   Whenever possible, applications should   use  odbc_connect/3. If\n   you need this predicate,  please   check  the  documentation for\n   SQLDriverConnect() and the documentation of your driver.\n\n   @tbd    Add facilities to deal with prompted completion of the\n           driver options.",
    "prefix":"odbc_driver_connect"
  },
  "odbc:odbc_end_transaction/2": {
    "body": ["odbc_end_transaction(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"odbc_end_transaction('Param1','Param2')",
    "prefix":"odbc_end_transaction"
  },
  "odbc:odbc_execute/2": {
    "body": ["odbc_execute(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"odbc_execute('Param1','Param2')",
    "prefix":"odbc_execute"
  },
  "odbc:odbc_execute/3": {
    "body": ["odbc_execute(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"odbc_execute('Param1','Param2','Param3')",
    "prefix":"odbc_execute"
  },
  "odbc:odbc_fetch/3": {
    "body": ["odbc_fetch(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"odbc_fetch('Param1','Param2','Param3')",
    "prefix":"odbc_fetch"
  },
  "odbc:odbc_free_statement/1": {
    "body": ["odbc_free_statement(${1:'Param1'})$2\n$0" ],
    "description":"odbc_free_statement('Param1')",
    "prefix":"odbc_free_statement"
  },
  "odbc:odbc_get_connection/2": {
    "body": ["odbc_get_connection(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"odbc_get_connection('Param1','Param2')",
    "prefix":"odbc_get_connection"
  },
  "odbc:odbc_prepare/4": {
    "body": [
      "odbc_prepare(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"odbc_prepare('Param1','Param2','Param3','Param4')",
    "prefix":"odbc_prepare"
  },
  "odbc:odbc_prepare/5": {
    "body": [
      "odbc_prepare(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"odbc_prepare('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"odbc_prepare"
  },
  "odbc:odbc_query/2": {
    "body": ["odbc_query(${1:Connection}, ${2:SQL})$3\n$0" ],
    "description":"  odbc_query(+Connection, +SQL)\n\n   Execute SQL-statement that does not produce a result",
    "prefix":"odbc_query"
  },
  "odbc:odbc_query/3": {
    "body": ["odbc_query(${1:Connection}, ${2:SQL}, ${3:Row})$4\n$0" ],
    "description":"  odbc_query(+Connection, +SQL, -Row)\n\n   Run query without options.",
    "prefix":"odbc_query"
  },
  "odbc:odbc_query/4": {
    "body": [
      "odbc_query(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"odbc_query('Param1','Param2','Param3','Param4')",
    "prefix":"odbc_query"
  },
  "odbc:odbc_set_connection/2": {
    "body": ["odbc_set_connection(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"odbc_set_connection('Param1','Param2')",
    "prefix":"odbc_set_connection"
  },
  "odbc:odbc_statistics/1": {
    "body": ["odbc_statistics(${1:'Param1'})$2\n$0" ],
    "description":"odbc_statistics('Param1')",
    "prefix":"odbc_statistics"
  },
  "odbc:odbc_table_column/3": {
    "body": ["odbc_table_column(${1:Connection}, ${2:Table}, ${3:Column})$4\n$0" ],
    "description":"  odbc_table_column(+Connection, +Table, +Column) is semidet.\n  odbc_table_column(+Connection, +Table, -Column) is nondet.\n\n   True if Column appears in Table on Connection.",
    "prefix":"odbc_table_column"
  },
  "odbc:odbc_table_column/4": {
    "body": [
      "odbc_table_column(${1:Connection}, ${2:Table}, ${3:Column}, ${4:Facet})$5\n$0"
    ],
    "description":"  odbc_table_column(+Connection, +Table, ?Column, -Facet)",
    "prefix":"odbc_table_column"
  },
  "odbc:odbc_table_foreign_key/5": {
    "body": [
      "odbc_table_foreign_key(${1:Connection}, ${2:PkTable}, ${3:PkCol}, ${4:FkTable}, ${5:FkCol})$6\n$0"
    ],
    "description":"  odbc_table_foreign_key(+Connection, ?PkTable, ?PkCol, ?FkTable, ?FkCol)\n\n   Enumerate foreign keys columns",
    "prefix":"odbc_table_foreign_key"
  },
  "odbc:odbc_table_primary_key/3": {
    "body": [
      "odbc_table_primary_key(${1:Connection}, ${2:Table}, ${3:Column})$4\n$0"
    ],
    "description":"  odbc_table_primary_key(+Connection, +Table, ?Column)\n\n   Enumerate columns in primary key for table",
    "prefix":"odbc_table_primary_key"
  },
  "odbc:odbc_type/3": {
    "body": ["odbc_type(${1:Connection}, ${2:TypeSpec}, ${3:Facet})$4\n$0" ],
    "description":"  odbc_type(+Connection, +TypeSpec, ?Facet).",
    "prefix":"odbc_type"
  },
  "odbc_close_statement/1": {
    "body":"odbc_close_statement(${1:Statement})$2\n$0",
    "description":"odbc_close_statement(+Statement).\nloses the given statement (without freeing it). This must be used if not  the whole result-set is retrieved using odbc_fetch/3.",
    "prefix":"odbc_close_statement"
  },
  "odbc_connect/3": {
    "body":"odbc_connect(${1:DSN}, ${2:Connection}, ${3:Options})$4\n$0",
    "description":"odbc_connect(+DSN, -Connection, +Options).\nCreate a new ODBC connection to data-source DSN and return a  handle to this connection in Connection. The connection  handle is either an opaque structure or an atom of the alias  option is used. In addition to the options below, options applicable to odbc_set_connection/2  may be provided.  user(User): Define the user-name for the connection. This option must be present if  the database uses authorization.\n\npassword(Password): Provide a password for the connection. Normally used in combination with user(User).\n\nalias(AliasName): Use AliasName as Connection identifier, making the  connection available as a global resource. A good choice is to use the DSN  as alias.\n\nopen(OpenMode): If OpenMode is once (default if an alias  is provided), a second call to open the same DSN simply  returns the existing connection. If multiple (default if  there is no alias name), a second connection to the same data-source is  opened.\n\nmars(+Bool): If true, use Microsoft SQL server 2005 mars mode.  This is support for multiple concurrent statements on a connection  without requiring the dynamic cursor (which incurs an astounding 20-50x  slowdown of query execution!!). MARS is a new feature in SQL2k5  apparently, and only works if you use the native driver. For the  non-native driver, specifying that it is enabled will have absolutely no  effect.\n\nodbc_version(+Atom): Select the version of the ODBC connection. Default is '3.0'.  The other supported value is '2.0'.\n\n  The following example connects to the WordNet1An  SQL version of WordNet is available from http://wordnet2sql.infocity.cjb.net/ [1] database, using  the connection alias wordnet and opening the connection  only once: \n\n\n\nopen_wordnet :-\n        odbc_connect('WordNet', _,\n                     [ user(jan),\n                       password(xxx),\n                       alias(wordnet),\n                       open(once)\n                     ]).\n\n ",
    "prefix":"odbc_connect"
  },
  "odbc_current_connection/2": {
    "body":"odbc_current_connection(${1:Connection}, ${2:DSN})$3\n$0",
    "description":"odbc_current_connection(?Connection, ?DSN).\nEnumerate the existing ODBC connections.",
    "prefix":"odbc_current_connection"
  },
  "odbc_current_table/2": {
    "body":"odbc_current_table(${1:Connection}, ${2:Table})$3\n$0",
    "description":"odbc_current_table(+Connection, -Table).\nReturn on backtracking the names of all tables in the database  identified by the connection.",
    "prefix":"odbc_current_table"
  },
  "odbc_current_table/3": {
    "body":"odbc_current_table(${1:Connection}, ${2:Table}, ${3:Facet})$4\n$0",
    "description":"odbc_current_table(+Connection, ?Table, ?Facet).\nEnumerate properties of the tables. Defines facets are:  qualifier(Qualifier): owner(Owner): comment(Comment): These facets are defined by SQLTables()\n\narity(Arity): This facet returns the number of columns in a table.\n\n ",
    "prefix":"odbc_current_table"
  },
  "odbc_data_source/2": {
    "body":"odbc_data_source(${1:DSN}, ${2:Description})$3\n$0",
    "description":"odbc_data_source(?DSN, ?Description).\nQuery the defined data sources. It is not required to have any open  connections before calling this predicate. DSN is the name of  the data source as required by odbc_connect/3. Description  is the name of the driver. The driver name may be used to tailor the SQL  statements used on the database. Unfortunately this name depends on the  local installing details and is therefore not universally useful.",
    "prefix":"odbc_data_source"
  },
  "odbc_debug/1": {
    "body":"odbc_debug(${1:Level})$2\n$0",
    "description":"odbc_debug(+Level).\nSet the verbosity-level to Level. Default is 0. Higher levels  make the system print debugging messages.",
    "prefix":"odbc_debug"
  },
  "odbc_disconnect/1": {
    "body":"odbc_disconnect(${1:Connection})$2\n$0",
    "description":"odbc_disconnect(+Connection).\nClose the given Connection. This destroys the connection  alias or, if there is no alias, makes further use of the Connection  handle illegal.",
    "prefix":"odbc_disconnect"
  },
  "odbc_driver_connect/3": {
    "body":"odbc_driver_connect(${1:DriverString}, ${2:Connection}, ${3:Options})$4\n$0",
    "description":"odbc_driver_connect(+DriverString, -Connection, +Options).\nConnects to a database using SQLDriverConnect(). This API allows for  driver-specific additional options. DriverString is passed without  checking. Options should not include user and password.  Whenever possible, applications should use odbc_connect/3.  If you need this predicate, please check the documentation for  SQLDriverConnect() and the documentation of your driver.bugFacilities  to deal with prompted completion of the driver options are not yet  implemented.\n\n",
    "prefix":"odbc_driver_connect"
  },
  "odbc_end_transaction/2": {
    "body":"odbc_end_transaction(${1:Connection}, ${2:Action})$3\n$0",
    "description":"odbc_end_transaction(+Connection, +Action).\nEnd the currently open transaction if there is one. Using Action commit pending updates are made permanent, using rollback they are discarded.",
    "prefix":"odbc_end_transaction"
  },
  "odbc_execute/2": {
    "body":"odbc_execute(${1:Statement}, ${2:ParameterValues})$3\n$0",
    "description":"odbc_execute(+Statement, +ParameterValues).\nLike odbc_query/2,  this predicate is meant to execute simple SQL statements without  interest in the result.",
    "prefix":"odbc_execute"
  },
  "odbc_execute/3": {
    "body":"odbc_execute(${1:Statement}, ${2:ParameterValues}, ${3:RowOrAffected})$4\n$0",
    "description":"odbc_execute(+Statement, +ParameterValues, -RowOrAffected).\nExecute a statement prepared with odbc_prepare/4  with the given ParameterValues and return the rows or number of affected  rows as odbc_query/4.  This predicate may return type_error exceptions if the provided  parameter values cannot be converted to the declared types.  ODBC doesn't appear to allow for multiple cursors on the same  result-set.4Is this right?  This would imply there can only be one active odbc_execute/3  (i.e. with a choice-point) on a prepared statement. Suppose we have a  table age (name char(25), age integer) bound to the  predicate age/2 we cannot write the code  below without special precautions. The ODBC interface therefore creates  a clone of a statement if it discovers the statement is being executed,  which is discarded after the statement is finished.5The  code is prepared to maintain a cache of statements. Practice should tell  us whether it is worthwhile activating this. \n\n\n\nsame_age(X, Y) :-\n        age(X, AgeX),\n        age(Y, AgeY),\n        AgeX = AgeY.\n\n ",
    "prefix":"odbc_execute"
  },
  "odbc_fetch/3": {
    "body":"odbc_fetch(${1:Statement}, ${2:Row}, ${3:Option})$4\n$0",
    "description":"odbc_fetch(+Statement, -Row, +Option).\nFetch a row from the result-set of Statement. Statement  must be created with odbc_prepare/5  using the option fetch(fetch) and be executed using odbc_execute/2. Row  is unified to the fetched row or the atom end_of_file6This  atom was selected to emphasise the similarity to read.  after the end of the data is reached. Calling odbc_fetch/2  after all data is retrieved causes a permission-error exception. Option  is one of:  next: Fetch the next row.\n\nprior: Fetch the result-set going backwards.\n\nfirst: Fetch the first row.\n\nlast: Fetch the last row.\n\nabsolute(Offset): Fetch absolute numbered row. Rows count from one.\n\nrelative(Offset): Fetch relative to the current row. relative(1) is the same  as next(), except that the first row extracted is row 2.\n\nbookmark(Offset): Reserved. Bookmarks are not yet supported in this interface.\n\n  In many cases, depending on the driver and RDBMS, the cursor-type  must be changed using odbc_set_connection/2  for anything different from next() to work. \n\nHere is example code each time skipping a row from a table `test'  holding a single column of integers that represent the row-number. This  test was executed using unixODBC and MySQL on SuSE Linux. \n\n\n\nfetch(Options) :-\n        odbc_set_connection(test, cursor_type(static)),\n        odbc_prepare(test,\n                     'select (testval) from test',\n                     [],\n                     Statement,\n                     [ fetch(fetch)\n                     ]),\n        odbc_execute(Statement, []),\n        fetch(Statement, Options).\n\nfetch(Statement, Options) :-\n        odbc_fetch(Statement, Row, Options),\n        (   Row == end_of_file\n        ->  true\n        ;   writeln(Row),\n            fetch(Statement, Options)\n        ).\n\n ",
    "prefix":"odbc_fetch"
  },
  "odbc_free_statement/1": {
    "body":"odbc_free_statement(${1:Statement})$2\n$0",
    "description":"odbc_free_statement(+Statement).\nDestroy a statement prepared with odbc_prepare/4.  If the statement is currently executing (i.e. odbc_execute/3  left a choice-point), the destruction is delayed until the execution  terminates.",
    "prefix":"odbc_free_statement"
  },
  "odbc_get_connection/2": {
    "body":"odbc_get_connection(${1:Connection}, ${2:Property})$3\n$0",
    "description":"odbc_get_connection(+Connection, ?Property).\nQuery for properties of the connection. Property is a term of  the format Name(Value). If Property  is unbound all defined properties are enumerated on backtracking.  Currently the following properties are defined.  database_name(Atom): Name of the database associated to the connection.\n\ndbms_name(Name): Name of the database engine. This constant can be used to identify the  engine.\n\ndbms_version(Atom): Version identifier from the database engine.\n\ndriver_name(Name): ODBC Dynamic Link Library providing the interface between ODBC and the  database.\n\ndriver_odbc_version(Atom): ODBC version supported by the driver.\n\ndriver_version(Atom): The drivers version identifier.\n\nactive_statements(Integer): Maximum number of statements that can be active at the same time on this  connection. Returns 0 (zero) if this is unlimited.2Microsoft  SQL server can have multiple active statements after setting the option cursor_type  to dynamic. See odbc_set_connection/2.\n\n ",
    "prefix":"odbc_get_connection"
  },
  "odbc_prepare/4": {
    "body":"odbc_prepare(${1:Connection}, ${2:SQL}, ${3:Parameters}, ${4:Statement})$5\n$0",
    "description":"odbc_prepare(+Connection, +SQL, +Parameters, -Statement).\nAs odbc_prepare/5  using [] for Options.",
    "prefix":"odbc_prepare"
  },
  "odbc_prepare/5": {
    "body":"odbc_prepare(${1:Connection}, ${2:SQL}, ${3:Parameters}, ${4:Statement}, ${5:Options})$6\n$0",
    "description":"odbc_prepare(+Connection, +SQL, +Parameters, -Statement, +Options).\nCreate a statement from the given SQL (which may be a format  specification as described with odbc_query/3)  statement that normally has one or more parameter-indicators (?)  and unify Statement with a handle to the created statement. Parameters  is a list of descriptions, one for each parameter. Each parameter  description is one of the following:  default: Uses the ODBC function SQLDescribeParam() to obtain information about  the parameter and apply default rules. See section  2.6 for details. If the interface fails to return a type or the type  is unknown to the ODBC interface a message is printed and the interface  handles the type as text, which implies the user must supply an atom.  The message can be suppressed using the silent(true) option  of odbc_set_connection/2.  An alternative mapping can be selected using the > option  of this predicate described below.\n\nSqlType(Specifier, ...): Declare the parameter to be of type SqlType with the given  specifiers. Specifiers are required for char, varchar,  etc. to specify the field-width. When calling odbc_execute/[2-3],  the user must supply the parameter values in the default Prolog type for  this SQL type. See section 2.6 for  details.\n\nPrologType > SqlType: As above, but supply values of the given PrologType, using  the type-transformation defined by the database driver. For example, if  the parameter is specified as  \n\natom > date\n\n  The use must supply an atom of the format YYYY-MM-DD  rather than a term date(Year,Month,Day). This construct  enhances flexibility and allows for passing values that have no proper  representation in Prolog.\n\n  Options defines a list of options for executing the  statement. See odbc_query/4  for details. In addition, the following option is provided: \n\nfetch(FetchType): Determine the FetchType, which is one of auto  (default) to extract the result-set on backtracking or fetch  to prepare the result-set to be fetched using odbc_fetch/3.\n\n ",
    "prefix":"odbc_prepare"
  },
  "odbc_query/2": {
    "body":"odbc_query(${1:Connection}, ${2:SQL})$3\n$0",
    "description":"odbc_query(+Connection, +SQL).\nAs odbc_query/3,  but used for SQL-statements that should not return result-rows (i.e. all  statements except for SELECT). The predicate prints a  diagnostic message if the query returns a result.",
    "prefix":"odbc_query"
  },
  "odbc_query/3": {
    "body":"odbc_query(${1:Connection}, ${2:SQL}, ${3:RowOrAffected})$4\n$0",
    "description":"odbc_query(+Connection, +SQL, -RowOrAffected).\nSame as odbc_query/4  using [] for Options.",
    "prefix":"odbc_query"
  },
  "odbc_query/4": {
    "body":"odbc_query(${1:Connection}, ${2:SQL}, ${3:RowOrAffected}, ${4:Options})$5\n$0",
    "description":"odbc_query(+Connection, +SQL, -RowOrAffected, +Options).\nFire an SQL query on the database represented by Connection. SQL is any valid SQL statement. SQL statements can be  specified as a plain atom, string or a term of the format Format-Arguments, which is converted using format/2.  If the statement is a SELECT statement the result-set is  returned in RowOrAffected. By default rows are returned  one-by-one on backtracking as terms of the functor row/Arity,  where Arity denotes the number of columns in the result-set.  The library pre-fetches the next value to be able to close the statement  and return deterministic success when returning the last row of the  result-set. Using the option findall/2 (see below) the  result-set is returned as a list of user-specified terms. For other  statements this argument returns affected(Rows), where Rows  represents the number of rows affected by the statement. If you are not  interested in the number of affected rows odbc_query/2  provides a simple interface for sending SQL-statements. \n\nBelow is a small example using the connection created from odbc_connect/3.  Please note that the SQL-statement does not end in the `;'  character. \n\n\n\nlemma(Lemma) :-\n        odbc_query(wordnet,\n                   'SELECT (lemma) FROM word',\n                   row(Lemma)).\n\n  The following example adds a name to a table with parent-relations,  returning the number of rows affected by the statement. Note that the  SQL quote character is the ASCII single quote and, as this SQL  quote is embedded in a single quoted Prolog atom, it must be written as \\'  or '' (two single quotes). We use the first  alternative for better visibility. \n\n\n\ninsert_child(Child, Mother, Father, Affected) :-\n        odbc_query(parents,\n                   'INSERT INTO parents (name,mother,father) \\\n                      VALUES (\\'mary\\', \\'christine\\', \\'bob\\')',\n                   affected(Affected)).\n\n  Options defines the following options. \n\ntypes(ListOfTypes): Determine the Prolog type used to report the column-values. When  omitted, default conversion as described in section  2.6 is implied. A column may specify default to use  default conversion for that column. The length of the type-list must  match the number of columns in the result-set.  For example, in the table word the first column is  defined with the SQL type DECIMAL(6). Using this SQL-type,  ``001'' is distinct from ``1'', but using Prolog integers is a valid  representation for Wordnet wordno identifiers. The  following query extracts rows using Prolog integers: \n\n?- odbc_query(wordnet,\n              'select * from word', X,\n              [ types([integer,default])\n              ]).\n\nX = row(1, entity) ;\nX = row(2, thing) ;\n...\n\n  See also section 2.6 for notes on  type-conversion.\n\nnull(NullSpecifier): Specify SQL NULL representation. See odbc_set_connection/2  for details.\n\nsource(Bool): If true (default false), include the  source-column with each result-value. With this option, each result in  the row/N-term is of the format below. TableName  or ColumnName may be the empty atom if the information is not  available.3This is one possible  interface to this information. In many cases it is more efficient and  convenient to provide this information separately as it is the same for  each result-row. column(TableName, ColumnName, Value)\n\nfindall(Template, row(Column, ... )): Instead of returning rows on backtracking this option makes odbc_query/3  return all rows in a list and close the statement. The option is named  after the Prolog findall/3  predicate, as the it makes odbc_query/3  behave as the commonly used findall/3  construct below.  \n\nlemmas(Lemmas) :-\n        findall(Lemma,\n                odbc_query(wordnet,\n                           'select (lemma) from word',\n                           row(Lemma)),\n                Lemmas).\n\n  Using the findall/2 option the above can be implemented  as below. The number of argument of the row term must match  the number of columns in the result-set. \n\nlemmas(Lemmas) :-\n        odbc_query(wordnet,\n                   'select (lemma) from word',\n                   Lemmas,\n                   [ findall(Lemma, row(Lemma))\n                   ]).\n\n  The current implementation is incomplete. It does not  allow arguments of row(...) to be instantiated. Plain instantiation can always  be avoided using a proper SELECT statement. Potentially useful however  would be the translation of compound terms, especially to translate  date/time/timestamp structures to a format for use by the application.\n\nwide_column_threshold(+Length): Specify threshold column width for using SQLGetData(). See odbc_set_connection/2  for details.\n\n ",
    "prefix":"odbc_query"
  },
  "odbc_set_connection/2": {
    "body":"odbc_set_connection(${1:Connection}, ${2:Option})$3\n$0",
    "description":"odbc_set_connection(+Connection, +Option).\nSet options on an existing connection. All options defined here may also  be specified with odbc_connect/2  in the option-list. Defined options are:  access_mode(Mode): If read, tell the driver we only access the database in  read mode. If update (default), tell the driver we may  execute update commands.\n\nauto_commit(bool): If true (default), each update statement is committed  immediately. If false, an update statement starts a  transaction that can be committed or rolled-back. See section  2.3 for details on transaction management.\n\ncursor_type(CursorType): I haven't found a good description of what this does, but setting it to dynamic  makes it possible to have multiple active statements on the same  connection with Microsoft SQL server. Other values are static, forwards_only  and keyset_driven.\n\nencoding(+Encoding): Define the encoding used to communicate to the driver. Defined values  are given below. The default on MS-Windows is unicode while  on other platforms it is utf8. Below, the *A() functions  refer to the `ansi' ODBC functions that exchange bytes and the *W()  functions refer to the `unicode' ODBC functions that exchange UCS-2  characters.  iso_latin_1Communicate using the *A() functions and pass bytes untranslated.localeCommunicate using the *A() functions and translated between Prolog  Unicode characters and their (possibly) multibyte representation in the  current locale.utf8Communicate using the *A() functions and translated between Prolog  Unicode characters and their UTF-8 encoding.unicodeCommunicate using the *W() functions. \n\nsilent(Bool): If true (default false), statements returning SQL_SUCCESS_WITH_INFO succeed without printing the info.  See also section 2.7.1.\n\nnull(NullSpecifier): Defines how the SQL constant NULL is represented. Without specification,  the default is the atom $null$. NullSpecifier is  an arbitrary Prolog term, though the implementation is optimised for  using an unbound variable, atom and functor with one unbound variable.  The representation null(_) is a commonly used alternative.  The specified default holds for all statements executed on this  connection. Changing the connection default does not affect already  prepared or running statements. The null-value can also be specified at  the statement level. See the option list of odbc_query/4.\n\nwide_column_threshold(+Length): If the width of a column exceeds Length, use the API  SQLGetData() to get the value incrementally rather than using a (large)  buffer allocated with the statement. The default is to use this  alternate interface for columns larger than 1024 bytes. There are two  cases for using this option. In time critical applications with wide  columns it may provide better performance at the cost of a higher memory  usage and to work around bugs in SQLGetData(). The latter applies to  Microsoft SQL Server fetching the definition of a view.\n\n ",
    "prefix":"odbc_set_connection"
  },
  "odbc_statistics/1": {
    "body":"odbc_statistics(${1:Key})$2\n$0",
    "description":"odbc_statistics(?Key).\nGet statistical data on the ODBC interface. Currently defined keys are:  statements(Created, Freed): Number of SQL statements that have been Created and Freed  over all connections. Statements executed with odbc_query/[2-3]  increment Created as the query is created and Freed  if the query is terminated due to deterministic success, failure, cut or  exception. Statements created with odbc_prepare/[4-5]  are freed by odbc_free_statement/1  or due to a fatal error with the statement.\n\n ",
    "prefix":"odbc_statistics"
  },
  "odbc_table_column/3": {
    "body":"odbc_table_column(${1:Connection}, ${2:Table}, ${3:Column})$4\n$0",
    "description":"odbc_table_column(+Connection, ?Table, ?Column).\nOn backtracking, enumerate all columns in all tables.",
    "prefix":"odbc_table_column"
  },
  "odbc_table_column/4": {
    "body":"odbc_table_column(${1:Connection}, ${2:Table}, ${3:Column}, ${4:Facet})$5\n$0",
    "description":"odbc_table_column(+Connection, ?Table, ?Column, ?Facet).\nProvides access to the properties of the table as defined by the ODBC  call SQLColumns(). Defined facets are:  table_qualifier(Qualifier): table_owner(Owner): table_name(Table): See odbc_current_table/3.\n\ndata_type(DataType): type_name(TypeName): precision(Precision): length(Length): scale(Scale): radix(Radix): nullable(Nullable): remarks(Remarks): These facets are defined by SQLColumns()\n\ntype(Type): More prolog-friendly representation of the type properties. See section 2.6.\n\n ",
    "prefix":"odbc_table_column"
  },
  "odbc_table_foreign_key/5": {
    "body":"odbc_table_foreign_key(${1:Connection}, ${2:PkTable}, ${3:PkCol}, ${4:FkTable}, ${5:FkCol})$6\n$0",
    "description":"odbc_table_foreign_key(+Connection, ?PkTable, ?PkCol, ?FkTable, ?FkCol).\nTrue when PkTable/PkCol FkTable/FkCol  is a foreign keys column.",
    "prefix":"odbc_table_foreign_key"
  },
  "odbc_table_primary_key/3": {
    "body":"odbc_table_primary_key(${1:Connection}, ${2:Table}, ${3:Column})$4\n$0",
    "description":"odbc_table_primary_key(+Connection, +Table, ?Column).\nTrue when Column is a primary key in Table.",
    "prefix":"odbc_table_primary_key"
  },
  "odbc_type/3": {
    "body":"odbc_type(${1:Connection}, ${2:TypeSpec}, ${3:Facet})$4\n$0",
    "description":"odbc_type(+Connection, ?TypeSpec, ?Facet).\nQuery the types supported by the data source. TypeSpec is  either an integer type-id, the name of an ODBC SQL type or the constant all_types to enumerate all known types. This predicate  calls SQLGetTypeInfo() and its facet names are derived from the  specification of this ODBC function:  name(Name): Name used by the data-source. Use this in CREATE statements\n\ndata_type(DataType): Numeric identifier of the type\n\nprecision(Precision): When available, maximum precision of the type.\n\nliteral_prefix(Prefix): When available, prefix for literal representation.\n\nliteral_suffix(Suffix): When available, suffix for literal representation.\n\ncreate_params(CreateParams): When available, arguments needed to create the type.\n\nnullable(Bool): Whether the type can be NULL. May be unknown\n\ncase_sensitive(Bool): Whether values for this type are case-sensitive.\n\nsearchable(Searchable): Whether the type can be searched. Values are false, true, like_only or all_except_like.\n\nunsigned(Bool): When available, whether the value is signed. Please note that SWI-Prolog  does not provide unsigned integral values.\n\nmoney(Bool): Whether the type represents money.\n\nauto_increment(Bool): When available, whether the type can be auto-incremented.\n\nlocal_name(LocalName): Name of the type in local language.\n\nminimum_scale(MinScale): Minimum scale of the type.\n\nmaximum_scale(MaxScale): Maximum scale of the type.\n\n ",
    "prefix":"odbc_type"
  },
  "on_signal/3": {
    "body":"on_signal(${1:Signal}, ${2:Old}, ${3:New})$4\n$0",
    "description":"on_signal(+Signal, -Old, :New).\nDetermines the reaction on Signal. Old is unified  with the old behaviour, while the behaviour is switched to New.  As with similar environment control predicates, the current value is  retrieved using on_signal(Signal, Current, Current).  The action description is an atom denoting the name of the predicate  that will be called if Signal arrives. on_signal/3  is a meta-predicate, which implies that <Module>:<Name>  refers to <Name>/1 in module <Module>.  The handler is called with a single argument: the name of the signal as  an atom. The Prolog names for signals are explained below. \n\nTwo predicate names have special meaning. throw implies  Prolog will map the signal onto a Prolog exception as described in section 4.11. default  resets the handler to the settings active before SWI-Prolog manipulated  the handler. \n\nSignals bound to a foreign function through PL_signal()  are reported using the term $foreign_function(Address). \n\nAfter receiving a signal mapped to throw, the exception  raised has the following structure:\n\nerror(signal(<SigName>, <SigNum>), <Context>)  The signal names are defined by the POSIX standard as symbols of the  form SIG<SIGNAME>. The Prolog name for a signal is  the lowercase version of <SIGNAME>. The predicate current_signal/3  may be used to map between names and signals. \n\nInitially, some signals are mapped to throw, while all  other signals are default. The following signals throw an  exception: fpe, alrm, xcpu, xfsz  and vtalrm.\n\n",
    "prefix":"on_signal"
  },
  "once/1": {
    "body":"once(${1:Goal})$2\n$0",
    "description":"[ISO]once(:Goal).\nMake a possibly nondet goal semidet, i.e., succeed at  most once. Defined as:  \n\nonce(Goal) :-\n    call(Goal), !.\n\n  once/1  can in many cases be replaced with ->/2.  The only difference is how the cut behaves (see !/0). The following two  clauses below are identical. Be careful about the interaction with ;/2. The library(apply_macros)  library defines an inline expansion of once/1,  mapping it to (Goal\\send{true};fail). Using the full  if-then-else constructs prevents its semantics from being changed when  embedded in a ;/2  disjunction. \n\n\n\n1) a :- once((b, c)), d.\n2) a :- b, c -> d.\n\n ",
    "prefix":"once"
  },
  "online_help:apropos/1": {
    "body": ["apropos(${1:Pattern})$2\n$0" ],
    "description":"  apropos(Pattern)\n   Give a list of subjects that might be appropriate.",
    "prefix":"apropos"
  },
  "online_help:help/0": {"body": ["help$1\n$0" ], "description":"help", "prefix":"help"},
  "online_help:help/1": {
    "body": ["help(${1:Subject})$2\n$0" ],
    "description":"  help(+Subject)\n\n   Display online help on specified subject.",
    "prefix":"help"
  },
  "op/3": {
    "body":"op(${1:Precedence}, ${2:Type}, ${3:Name})$4\n$0",
    "description":"[ISO]op(+Precedence, +Type, :Name).\nDeclare Name to be an operator of type Type with  precedence Precedence. Name can also be a list of names, in  which case all elements of the list are declared to be identical  operators. Precedence is an integer between 0 and 1200. Precedence 0  removes the declaration. Type is one of: xf, yf, xfx, xfy, yfx, fy or fx. The `f' indicates the position of the  functor, while x and y indicate the position of the  arguments. `y' should be interpreted as ``on this position  a term with precedence lower or equal to the precedence of the functor  should occur''. For `x' the precedence of the argument must  be strictly lower. The precedence of a term is 0, unless its principal  functor is an operator, in which case the precedence is the precedence  of this operator. A term enclosed in parentheses ( ... )  has precedence 0.  The predefined operators are shown in table  5. Operators can be redefined, unless prohibited by one of the  limitations below. Applications must be careful with (re-)defining  operators because changing operators may cause (other) files to be  interpreted differently. Often this will lead to a syntax error. In other  cases, text is read silently into a different term which may lead to  subtle and difficult to track errors. \n\n\n\nIt is not allowed to redefine the comma (',').\nThe bar (|) can only be (re-)defined as infix operator  with priority not less than 1001.\nIt is not allowed to define the empty list ([]) or the  curly-bracket pair ({}) as operators.\n\n  In SWI-Prolog, operators are local to a module (see also section 6.8). Keeping operators  in modules and using controlled import/export of operators as described  with the module/2  directive keep the issues manageable. The module system  provides the operators from table  5 and these operators cannot be modified. Files that are loaded from  the SWI-Prolog directories resolve operators and predicates from this system  module rather than user, which makes the semantics of the  library and development system modules independent of operator changes  to the user module. \n\n\n\n1200xfx-->, :- 1200fx:-, ?- 1150fxdynamic, discontiguous, initialization, meta_predicate, module_transparent, multifile, public, thread_local, thread_initialization, volatile 1100xfy;, | 1050xfy->, *-> 1000xfy, 990xfx:= 900fy\\+ 700xfx<, =, =.., =@=, \\=@=, =:=, =<, ==, =\\=, >, >=, @<, @=<, @>, @>=, \\=, \\==, as, is, >:<, :<600xfy: 500yfx+, -, /\\, \\/, xor 500fx? 400yfx*, /, //, div, rdiv, <<, >>, mod, rem 200xfx** 200xfy^ 200fy+, -, \\ 100yfx. 1fx$  Table 5 : System operators ",
    "prefix":"op"
  },
  "open/3": {
    "body":"open(${1:SrcDest}, ${2:Mode}, ${3:Stream})$4\n$0",
    "description":"[ISO]open(+SrcDest, +Mode, --Stream).\nEquivalent to open/4  with an empty option list.",
    "prefix":"open"
  },
  "open/4": {
    "body":"open(${1:SrcDest}, ${2:Mode}, ${3:Stream}, ${4:Options})$5\n$0",
    "description":"[ISO]open(+SrcDest, +Mode, --Stream, +Options).\nTrue when SrcDest can be opened in Mode and Stream  is an I/O stream to/from the object. SrcDest is normally the  name of a file, represented as an atom or string. Mode is one  of read, write, append or update.  Mode append opens the file for writing, positioning the file  pointer at the end. Mode update opens the file for writing,  positioning the file pointer at the beginning of the file without  truncating the file. Stream is either a variable, in which  case it is bound to an integer identifying the stream, or an atom, in  which case this atom will be the stream identifier.77New  code should use the alias(Alias) option for compatibility  with the ISO standard.  SWI-Prolog also allows SrcDest to be a term pipe(Command).  In this form, Command is started as a child process and if Mode is write, output written to Stream  is sent to the standard input of Command. Viso versa, if Mode  is read, data written by Command to the standard  output may be read from Stream. On Unix systems, Command  is handed to popen() which hands it to the Unix shell. On Windows, Command  is executed directly. See also process_create/3  from library(process). \n\nThe following Options are recognised by open/4: \n\nalias(Atom): Gives the stream a name. Below is an example. Be careful with this  option as stream names are global. See also set_stream/2.  \n\n?- open(data, read, Fd, [alias(input)]).\n\n        ...,\n        read(input, Term),\n        ...\n\n \n\nbom(Bool): Check for a BOM (Byte Order Marker) or write one. If omitted,  the default is true for mode read and false for mode write. See also stream_property/2  and especially section 2.18.1.1  for a discussion of this feature.\n\nbuffer(Buffering): Defines output buffering. The atom full (default) defines  full buffering, line buffering by line, and false  implies the stream is fully unbuffered. Smaller buffering is useful if  another process or the user is waiting for the output as it is being  produced. See also flush_output/[0,1].  This option is not an ISO option.\n\nclose_on_abort(Bool): If true (default), the stream is closed on an abort (see abort/0).  If false, the stream is not closed. If it is an output  stream, however, it will be flushed. Useful for logfiles and if the  stream is associated to a process (using the pipe/1  construct).\n\ncreate(+List): Specifies how a new file is created when opening in write, append or update mode. Currently, List  is a list of atoms that describe the permissions of the created file.78Added  after feedback from Joachim Shimpf and Per Mildner. Defined  values are below. Not recognised values are silently ignored, allowing  for adding platform specific extensions to this set.  readAllow read access to the file.writeAllow write access to the file.executeAllow execution access to the file.defaultAllow read and write access to the file.allAllow any access provided by the OS.  Note that if List is empty, the created file has no  associated access permissions. The create options map to the POSIX mode  option of open(), where read map to 0444, write  to 0222 and execute to 0111. On POSIX systems, the final  permission is defined as (mode & ~umask).\n\nencoding(Encoding): Define the encoding used for reading and writing text to this stream.  The default encoding for type text is derived from the  Prolog flag encoding.  For binary streams the default encoding is octet.  For details on encoding issues, see section  2.18.1.\n\neof_action(Action): Defines what happens if the end of the input stream is reached. Action eof_code makes get0/1  and friends return -1, and read/1  and friends return the atom end_of_file. Repetitive reading  keeps yielding the same result. Action error is like eof_code,  but repetitive reading will raise an error. With action reset,  Prolog will examine the file again and return more data if the file has  grown.\n\nlocale(+Locale): Set the locale that is used by notably format/2  for output on this stream. See section  4.23.\n\nlock(LockingMode): Try to obtain a lock on the open file. Default is none,  which does not lock the file. The value read or shared  means other processes may read the file, but not write it. The value write or exclusive means no other process may  read or write the file.  Locks are acquired through the POSIX function fcntl() using the  command F_SETLKW, which makes a blocked call wait for the lock to  be released. Please note that fcntl() locks are advisory and  therefore only other applications using the same advisory locks honour  your lock. As there are many issues around locking in Unix, especially  related to NFS (network file system), please study the fcntl() manual  page before trusting your locks! The lock option is a SWI-Prolog extension.\n\ntype(Type): Using type text (default), Prolog will write a text file in  an operating system compatible way. Using type binary the  bytes will be read or written without any translation. See also the  option encoding.\n\nwait(Bool): This option can be combined with the lock option. If false (default true), the open call returns  immediately with an exception if the file is locked. The exception has  the format permission_error(lock, source_sink, SrcDest).\n\n  The option reposition is not supported in SWI-Prolog.  All streams connected to a file may be repositioned.\n\n",
    "prefix":"open"
  },
  "open_dde_conversation/3": {
    "body":"open_dde_conversation(${1:Service}, ${2:Topic}, ${3:Handle})$4\n$0",
    "description":"open_dde_conversation(+Service, +Topic, -Handle).\nOpen a conversation with a server supporting the given service name and  topic (atoms). If successful, Handle may be used to send  transactions to the server. If no willing server is found this predicate  fails silently.",
    "prefix":"open_dde_conversation"
  },
  "open_dtd/3": {
    "body":"open_dtd(${1:DTD}, ${2:Options}, ${3:OutStream})$4\n$0",
    "description":"open_dtd(+DTD, +Options, -OutStream).\nOpen a DTD as an output stream. See load_dtd/2  for an example. Defined options are:  dialect(Dialect): Define the DTD dialect. Default is sgml. Using xml  or xmlns processes the DTD case-sensitive.\n\n ",
    "prefix":"open_dtd"
  },
  "open_null_stream/1": {
    "body":"open_null_stream(${1:Stream})$2\n$0",
    "description":"open_null_stream(--Stream).\nOpen an output stream that produces no output. All counting functions  are enabled on such a stream. It can be used to discard output (like  Unix /dev/null) or exploit the counting properties. The  initial encoding of Stream is utf8, enabling  arbitrary Unicode output. The encoding can be changed to determine byte  counts of the output in a particular encoding or validate if output is  possible in a particular encoding. For example, the code below  determines the number of characters emitted when writing Term.  \n\nwrite_length(Term, Len) :-\n        open_null_stream(Out),\n        write(Out, Term),\n        character_count(Out, Len0),\n        close(Out),\n        Len = Len0.\n\n ",
    "prefix":"open_null_stream"
  },
  "open_resource/3": {
    "body":"open_resource(${1:Name}, ${2:Class}, ${3:Stream})$4\n$0",
    "description":"open_resource(+Name, ?Class, -Stream).\nOpens the resource specified by Name and Class. If  the latter is a variable, it will be unified to the class of the first  resource found that has the specified Name. If successful, Stream becomes a handle to a binary input stream, providing  access to the content of the resource.  The predicate open_resource/3  first checks resource/3.  When successful it will open the returned resource source file.  Otherwise it will look in the program's resource database. When creating  a saved state, the system normally saves the resource contents into the  resource archive, but does not save the resource clauses. \n\nThis way, the development environment uses the files (and  modifications) to the resource/3  declarations and/or files containing resource info, thus immediately  affecting the running environment, while the runtime system quickly  accesses the system resources.\n\n",
    "prefix":"open_resource"
  },
  "open_string/2": {
    "body":"open_string(${1:String}, ${2:Stream})$3\n$0",
    "description":"open_string(+String, -Stream).\nTrue when Stream is an input stream that accesses the content  of String. String can be any text representation,  i.e., string, atom, list of codes or list of characters.",
    "prefix":"open_string"
  },
  "open_table/1": {
    "body":"open_table(${1:Handle})$2\n$0",
    "description":"open_table(+Handle).\nOpen the table. This predicate normally does not need to be called  explicitely, as all operations on the table handle will automatically  open the table if this is required. It fails if the file cannot be  accessed or some other error with the required operating-system  resources occurs. The contents of the file is not examined by this  predicate.",
    "prefix":"open_table"
  },
  "option:dict_options/2": {
    "body":"dict_options(${1:Dict}, ${2:Options})$3\n$0",
    "description":"[det]dict_options(?Dict, ?Options).\nConvert between an option list and a dictionary. One of the arguments  must be instantiated. If the option list is created, it is created in  canonical form, i.e., using Option(Value) with the Options  sorted in the standard order of terms. Note that the conversion is not  always possible due to different constraints and convertion may thus  lead to (type) errors.  \n\nDict keys can be integers. This is not allowed in  canonical option lists.\nOptions can hold multiple options with the same key. This  is not allowed in dicts.\nOptions can have more than one value (name(V1,V2)).  This is not allowed in dicts.\n\n  Also note that most system predicates and predicates using this  library for processing the option argument can both work with classical  Prolog options and dicts objects.\n\n",
    "prefix":"dict_options"
  },
  "option:merge_options/3": {
    "body":"merge_options(${1:New}, ${2:Old}, ${3:Merged})$4\n$0",
    "description":"[det]merge_options(+New, +Old, -Merged).\nMerge two option lists. Merged is a sorted list of options  using the canonical format Name(Value) holding all options from New  and Old, after removing conflicting options from Old.  Multi-values options (e.g., proxy(Host, Port)) are  allowed, where both option-name and arity define the identity of the  option.\n\n",
    "prefix":"merge_options"
  },
  "option:meta_options/3": {
    "body":"meta_options(${1:IsMeta}, ${2:Options0}, ${3:Options})$4\n$0",
    "description":"[det]meta_options(+IsMeta, :Options0, -Options).\nPerform meta-expansion on options that are module-sensitive. Whether an  option name is module-sensitive is determined by calling call(IsMeta, Name).  Here is an example:  \n\n        meta_options(is_meta, OptionsIn, Options),\n        ...\n\nis_meta(callback).\n\n  Meta-options must have exactly one argument. This argument will be  qualified. \n\nTo be done: Should be integrated with declarations from predicate_options/3.\n\n ",
    "prefix":"meta_options"
  },
  "option:option/2": {
    "body":"option(${1:Option}, ${2:OptionList})$3\n$0",
    "description":"[semidet]option(?Option, +OptionList).\nGet an Option from OptionList. OptionList  can use the Name=Value as well as the Name(Value) convention. Fails  silently if the option does not appear in OptionList. Option Term of the form  Name(?Value). ",
    "prefix":"option"
  },
  "option:option/3": {
    "body":"option(${1:Option}, ${2:OptionList}, ${3:Default})$4\n$0",
    "description":"[semidet]option(?Option, +OptionList, +Default).\nGet an Option from OptionList. OptionList  can use the Name=Value as well as the Name(Value) convention. Option Term of the form  Name(?Value). ",
    "prefix":"option"
  },
  "option:select_option/3": {
    "body":"select_option(${1:Option}, ${2:Options}, ${3:RestOptions})$4\n$0",
    "description":"[semidet]select_option(?Option, +Options, -RestOptions).\nGet and remove Option from an option list. As option/2,  removing the matching option from Options and unifying the  remaining options with RestOptions.",
    "prefix":"select_option"
  },
  "option:select_option/4": {
    "body":"select_option(${1:Option}, ${2:Options}, ${3:RestOptions}, ${4:Default})$5\n$0",
    "description":"[det]select_option(?Option, +Options, -RestOptions, +Default).\nGet and remove Option with default value. As select_option/3,  but if Option is not in Options, its value is  unified with Default and RestOptions with Options.",
    "prefix":"select_option"
  },
  "optparse:opt_arguments/3": {
    "body":"opt_arguments(${1:OptsSpec}, ${2:Opts}, ${3:PositionalArgs})$4\n$0",
    "description":"[det]opt_arguments(+OptsSpec, -Opts, -PositionalArgs).\nExtract commandline options according to a specification. Convenience  predicate, assuming that command-line arguments can be accessed by current_prolog_flag/2  (as in swi-prolog). For other access mechanisms and/or more control, get  the args and pass them as a list of atoms to opt_parse/4  or opt_parse/5  instead.  Opts is a list of parsed options in the form Key(Value).  Dashed args not in OptsSpec are not permitted and will raise  error (see tip on how to pass unknown flags in the module description). PositionalArgs are the remaining non-dashed args after each  flag has taken its argument (filling in true or false  for booleans). There are no restrictions on non-dashed arguments and  they may go anywhere (although it is good practice to put them last).  Any leading arguments for the runtime (up to and including '--') are  discarded.\n\n",
    "prefix":"opt_arguments"
  },
  "optparse:opt_help/2": {
    "body":"opt_help(${1:OptsSpec}, ${2:Help})$3\n$0",
    "description":"[det]opt_help(+OptsSpec, -Help:atom).\nTrue when Help is a help string synthesized from OptsSpec.",
    "prefix":"opt_help"
  },
  "optparse:opt_parse/4": {
    "body":"opt_parse(${1:OptsSpec}, ${2:ApplArgs}, ${3:Opts}, ${4:PositionalArgs})$5\n$0",
    "description":"[det]opt_parse(+OptsSpec, +ApplArgs, -Opts, -PositionalArgs).\nEquivalent to opt_parse(OptsSpec, ApplArgs, Opts, PositionalArgs, []).",
    "prefix":"opt_parse"
  },
  "optparse:opt_parse/5": {
    "body":"opt_parse(${1:OptsSpec}, ${2:ApplArgs}, ${3:Opts}, ${4:PositionalArgs}, ${5:ParseOptions})$6\n$0",
    "description":"[det]opt_parse(+OptsSpec, +ApplArgs, -Opts, -PositionalArgs, +ParseOptions).\nParse the arguments Args (as list of atoms) according to OptsSpec.  Any runtime arguments (typically terminated by '--') are assumed to be  removed already.  Opts is a list of parsed options in the form Key(Value),  or (with the option functor(Func) given) in the form  Func(Key, Value). Dashed args not in OptsSpec are not  permitted and will raise error (see tip on how to pass unknown flags in  the module description). PositionalArgs are the remaining non-dashed args after each  flag has taken its argument (filling in true or false  for booleans). There are no restrictions on non-dashed arguments and  they may go anywhere (although it is good practice to put them last). ParseOptions are \n\noutput_functor(Func): Set the functor Func of the returned options Func(Key,Value).  Default is the special value 'OPTION' (upper-case), which makes the  returned options have form Key(Value).\n\nduplicated_flags(Keep): Controls how to handle options given more than once on the commad line. Keep is one of keepfirst, keeplast, keepall with  the obvious meaning. Default is keeplast.\n\nallow_empty_flag_spec(Bool): If true (default), a flag specification is not required (it is allowed  that both shortflags and longflags be either [] or absent).  Flagless options cannot be manipulated from the command line and will  not show up in the generated help. This is useful when you have (also)  general configuration parameters in your OptsSpec, especially  if you think they one day might need to be controlled externally. See  example in the module overview. allow_empty_flag_spec(false) gives the more customary  behaviour of raising error on empty flags.\n\n ",
    "prefix":"opt_parse"
  },
  "optparse:parse_type/3": {
    "body":"parse_type(${1:Type}, ${2:Codes}, ${3:Result})$4\n$0",
    "description":"[semidet,multifile]parse_type(+Type, +Codes:list(code), -Result).\nHook to parse option text Codes to an object of type Type.",
    "prefix":"parse_type"
  },
  "order_table_mapping/3": {
    "body":"order_table_mapping(${1:Table}, ${2:From}, ${3:To})$4\n$0",
    "description":"order_table_mapping(+Table, ?From, ?To).\nRead the current mapping. To is a character code or one of  the atoms break, ignore or tag.",
    "prefix":"order_table_mapping"
  },
  "ordsets:is_ordset/1": {
    "body":"is_ordset(${1:Term})$2\n$0",
    "description":"[semidet]is_ordset(@Term).\nTrue if Term is an ordered set. All predicates in this  library expect ordered sets as input arguments. Failing to fullfil this  assumption results in undefined behaviour. Typically, ordered sets are  created by predicates from this library, sort/2  or setof/3.",
    "prefix":"is_ordset"
  },
  "ordsets:list_to_ord_set/2": {
    "body":"list_to_ord_set(${1:List}, ${2:OrdSet})$3\n$0",
    "description":"[det]list_to_ord_set(+List, -OrdSet).\nTransform a list into an ordered set. This is the same as sorting the  list.",
    "prefix":"list_to_ord_set"
  },
  "ordsets:ord_add_element/3": {
    "body":"ord_add_element(${1:Set1}, ${2:Element}, ${3:Set2})$4\n$0",
    "description":"[det]ord_add_element(+Set1, +Element, ?Set2).\nInsert an element into the set. This is the same as ord_union(Set1, [Element], Set2).",
    "prefix":"ord_add_element"
  },
  "ordsets:ord_del_element/3": {
    "body":"ord_del_element(${1:Set}, ${2:Element}, ${3:NewSet})$4\n$0",
    "description":"[det]ord_del_element(+Set, +Element, -NewSet).\nDelete an element from an ordered set. This is the same as ord_subtract(Set, [Element], NewSet).",
    "prefix":"ord_del_element"
  },
  "ordsets:ord_disjoint/2": {
    "body":"ord_disjoint(${1:Set1}, ${2:Set2})$3\n$0",
    "description":"[semidet]ord_disjoint(+Set1, +Set2).\nTrue if Set1 and Set2 have no common elements.  This is the negation of ord_intersect/2.",
    "prefix":"ord_disjoint"
  },
  "ordsets:ord_empty/1": {
    "body":"ord_empty(${1:List})$2\n$0",
    "description":"[semidet]ord_empty(?List).\nTrue when List is the empty ordered set. Simply unifies list  with the empty list. Not part of Quintus.",
    "prefix":"ord_empty"
  },
  "ordsets:ord_intersect/2": {
    "body":"ord_intersect(${1:Set1}, ${2:Set2})$3\n$0",
    "description":"[semidet]ord_intersect(+Set1, +Set2).\nTrue if both ordered sets have a non-empty intersection.",
    "prefix":"ord_intersect"
  },
  "ordsets:ord_intersect/3": {
    "body":"ord_intersect(${1:Set1}, ${2:Set2}, ${3:Intersection})$4\n$0",
    "description":"ord_intersect(+Set1, +Set2, -Intersection).\nIntersection holds the common elements of Set1 and Set2.  deprecated: Use ord_intersection/3\n\n ",
    "prefix":"ord_intersect"
  },
  "ordsets:ord_intersection/2": {
    "body":"ord_intersection(${1:PowerSet}, ${2:Intersection})$3\n$0",
    "description":"ord_intersection(+PowerSet, -Intersection).\nIntersection of a powerset. True when Intersection  is an ordered set holding all elements common to all sets in PowerSet.  Compatibility: sicstus\n\n ",
    "prefix":"ord_intersection"
  },
  "ordsets:ord_intersection/3": {
    "body":"ord_intersection(${1:Set1}, ${2:Set2}, ${3:Intersection})$4\n$0",
    "description":"[det]ord_intersection(+Set1, +Set2, -Intersection).\nIntersection holds the common elements of Set1 and Set2.",
    "prefix":"ord_intersection"
  },
  "ordsets:ord_intersection/4": {
    "body":"ord_intersection(${1:Set1}, ${2:Set2}, ${3:Intersection}, ${4:Difference})$5\n$0",
    "description":"[det]ord_intersection(+Set1, +Set2, ?Intersection, ?Difference).\nIntersection and difference between two ordered sets. Intersection is the intersection between Set1 and Set2,  while Difference is defined by ord_subtract(Set2, Set1, Difference).  See also: ord_intersection/3  and ord_subtract/3.\n\n ",
    "prefix":"ord_intersection"
  },
  "ordsets:ord_memberchk/2": {
    "body":"ord_memberchk(${1:Element}, ${2:OrdSet})$3\n$0",
    "description":"[semidet]ord_memberchk(+Element, +OrdSet).\nTrue if Element is a member of OrdSet, compared  using ==. Note that enumerating elements of an ordered set can be  done using member/2.  Some Prolog implementations also provide ord_member/2,  with the same semantics as ord_memberchk/2.  We believe that having a semidet ord_member/2  is unacceptably inconsistent with the *_chk convention. Portable code  should use ord_memberchk/2  or member/2. \n\nauthor: Richard O'Keefe\n\n ",
    "prefix":"ord_memberchk"
  },
  "ordsets:ord_selectchk/3": {
    "body":"ord_selectchk(${1:Item}, ${2:Set1}, ${3:Set2})$4\n$0",
    "description":"[semidet]ord_selectchk(+Item, ?Set1, ?Set2).\nSelectchk/3, specialised for ordered sets. Is true when select(Item, Set1, Set2) and Set1, Set2  are both sorted lists without duplicates. This implementation is only  expected to work for Item ground and either Set1  or Set2 ground. The \"chk\" suffix is meant to remind you of memberchk/2,  which also expects its first argument to be ground. ord_selectchk(X, S, T)  => ord_memberchk(X, S) & \\+ ord_memberchk(X, T).  author: Richard O'Keefe\n\n ",
    "prefix":"ord_selectchk"
  },
  "ordsets:ord_seteq/2": {
    "body":"ord_seteq(${1:Set1}, ${2:Set2})$3\n$0",
    "description":"[semidet]ord_seteq(+Set1, +Set2).\nTrue if Set1 and Set2 have the same elements. As  both are canonical sorted lists, this is the same as ==/2.  Compatibility: sicstus\n\n ",
    "prefix":"ord_seteq"
  },
  "ordsets:ord_subset/2": {
    "body":"ord_subset(${1:Sub}, ${2:Super})$3\n$0",
    "description":"[semidet]ord_subset(+Sub, +Super).\nIs true if all elements of Sub are in Super",
    "prefix":"ord_subset"
  },
  "ordsets:ord_subtract/3": {
    "body":"ord_subtract(${1:InOSet}, ${2:NotInOSet}, ${3:Diff})$4\n$0",
    "description":"[det]ord_subtract(+InOSet, +NotInOSet, -Diff).\nDiff is the set holding all elements of InOSet  that are not in NotInOSet.",
    "prefix":"ord_subtract"
  },
  "ordsets:ord_symdiff/3": {
    "body":"ord_symdiff(${1:Set1}, ${2:Set2}, ${3:Difference})$4\n$0",
    "description":"[det]ord_symdiff(+Set1, +Set2, ?Difference).\nIs true when Difference is the symmetric difference of Set1  and Set2. I.e., Difference contains all elements that  are not in the intersection of Set1 and Set2. The  semantics is the same as the sequence below (but the actual  implementation requires only a single scan).  \n\n      ord_union(Set1, Set2, Union),\n      ord_intersection(Set1, Set2, Intersection),\n      ord_subtract(Union, Intersection, Difference).\n\n  For example: \n\n\n\n?- ord_symdiff([1,2], [2,3], X).\nX = [1,3].\n\n  \n\n",
    "prefix":"ord_symdiff"
  },
  "ordsets:ord_union/2": {
    "body":"ord_union(${1:SetOfSets}, ${2:Union})$3\n$0",
    "description":"[det]ord_union(+SetOfSets, -Union).\nTrue if Union is the union of all elements in the superset SetOfSets. Each member of SetOfSets must be an  ordered set, the sets need not be ordered in any way.  author: Copied from YAP, probably originally by Richard O'Keefe.\n\n ",
    "prefix":"ord_union"
  },
  "ordsets:ord_union/3": {
    "body":"ord_union(${1:Set1}, ${2:Set2}, ${3:Union})$4\n$0",
    "description":"[det]ord_union(+Set1, +Set2, ?Union).\nUnion is the union of Set1 and Set2",
    "prefix":"ord_union"
  },
  "ordsets:ord_union/4": {
    "body":"ord_union(${1:Set1}, ${2:Set2}, ${3:Union}, ${4:New})$5\n$0",
    "description":"[det]ord_union(+Set1, +Set2, -Union, -New).\nTrue iff ord_union(Set1, Set2, Union) and ord_subtract(Set2, Set1, New).",
    "prefix":"ord_union"
  },
  "oset:oset_addel/3": {
    "body": ["oset_addel(${1:Set}, ${2:El}, ${3:Add})$4\n$0" ],
    "description":" oset_addel(+Set, +El, -Add)\n   ordered set element addition",
    "prefix":"oset_addel"
  },
  "oset:oset_delel/3": {
    "body": ["oset_delel(${1:Set}, ${2:El}, ${3:Del})$4\n$0" ],
    "description":" oset_delel(+Set, +El, -Del)\n   ordered set element deletion",
    "prefix":"oset_delel"
  },
  "oset:oset_diff/3": {
    "body": ["oset_diff(${1:InOSet}, ${2:NotInOSet}, ${3:Diff})$4\n$0" ],
    "description":" oset_diff(+InOSet, +NotInOSet, -Diff)\n   ordered set difference",
    "prefix":"oset_diff"
  },
  "oset:oset_dint/2": {
    "body": ["oset_dint(${1:SetofSets}, ${2:DInt})$3\n$0" ],
    "description":" oset_dint(+SetofSets, -DInt)\n   distributed intersection",
    "prefix":"oset_dint"
  },
  "oset:oset_dunion/2": {
    "body": ["oset_dunion(${1:SetofSets}, ${2:DUnion})$3\n$0" ],
    "description":" oset_dunion(+SetofSets, -DUnion)\n   distributed union",
    "prefix":"oset_dunion"
  },
  "oset:oset_int/3": {
    "body": ["oset_int(${1:OSet1}, ${2:OSet2}, ${3:Int})$4\n$0" ],
    "description":" oset_int(+OSet1, +OSet2, -Int)\n   ordered set intersection",
    "prefix":"oset_int"
  },
  "oset:oset_is/1": {
    "body": ["oset_is(${1:OSet})$2\n$0" ],
    "description":" oset_is(+OSet)\n   check that OSet in correct format (standard order)",
    "prefix":"oset_is"
  },
  "oset:oset_power/2": {
    "body": ["oset_power(${1:Set}, ${2:PSet})$3\n$0" ],
    "description":"  oset_power(+Set, -PSet)\n\n   True when PSet is the powerset of Set. That is, Pset is a set of\n   all subsets of Set, where each subset is a proper ordered set.",
    "prefix":"oset_power"
  },
  "oset:oset_union/3": {
    "body": ["oset_union(${1:OSet1}, ${2:OSet2}, ${3:Union})$4\n$0" ],
    "description":" oset_union(+OSet1, +OSet2, -Union).",
    "prefix":"oset_union"
  },
  "pairs:group_pairs_by_key/2": {
    "body":"group_pairs_by_key(${1:Pairs}, ${2:Joined})$3\n$0",
    "description":"[det]group_pairs_by_key(+Pairs, -Joined:list(Key-Values)).\nGroup values with equivalent (==/2)  consecutive keys. For example:  \n\n?- group_pairs_by_key([a-2, a-1, b-4, a-3], X).\n\nX = [a-[2,1], b-[4], a-[3]]\n\n  Sorting the list of pairs before grouping can be used to group all values associated with a key. For example, finding all values  associated with the largest key: \n\n\n\n?- sort(1, @>=, [a-1, b-2, c-3, a-4, a-5, c-6], Ps),\n   group_pairs_by_key(Ps, [K-Vs|_]).\nK = c,\nVs = [3, 6].\n\n  In this example, sorting by key only (first argument of sort/4  is 1) ensures that the order of the values in the original list of pairs  is maintained.\n\nPairs Key-Value list Joined List of Key-Group,  where Group is the list of Values associated with equivalent  consecutive Keys in the same order as they appear in Pairs. ",
    "prefix":"group_pairs_by_key"
  },
  "pairs:map_list_to_pairs/3": {
    "body":"map_list_to_pairs(${1:Function}, ${2:List}, ${3:Keyed})$4\n$0",
    "description":"map_list_to_pairs(:Function, +List, -Keyed).\nCreate a Key-Value list by mapping each element of List. For  example, if we have a list of lists we can create a list of Length-List  using  \n\n        map_list_to_pairs(length, ListOfLists, Pairs),\n\n  \n\n",
    "prefix":"map_list_to_pairs"
  },
  "pairs:pairs_keys/2": {
    "body":"pairs_keys(${1:Pairs}, ${2:Keys})$3\n$0",
    "description":"[det]pairs_keys(+Pairs, -Keys).\nRemove the values from a list of Key-Value pairs. Same as pairs_keys_values(Pairs, Keys, _)",
    "prefix":"pairs_keys"
  },
  "pairs:pairs_keys_values/3": {
    "body":"pairs_keys_values(${1:Pairs}, ${2:Keys}, ${3:Values})$4\n$0",
    "description":"[det]pairs_keys_values(?Pairs, ?Keys, ?Values).\nTrue if Keys holds the keys of Pairs and Values  the values.  Deterministic if any argument is instantiated to a finite list and  the others are either free or finite lists. All three lists are in the  same order. \n\nSee also: pairs_values/2 and pairs_keys/2.\n\n ",
    "prefix":"pairs_keys_values"
  },
  "pairs:pairs_values/2": {
    "body":"pairs_values(${1:Pairs}, ${2:Values})$3\n$0",
    "description":"[det]pairs_values(+Pairs, -Values).\nRemove the keys from a list of Key-Value pairs. Same as pairs_keys_values(Pairs, _, Values)",
    "prefix":"pairs_values"
  },
  "pairs:transpose_pairs/2": {
    "body":"transpose_pairs(${1:Pairs}, ${2:Transposed})$3\n$0",
    "description":"[det]transpose_pairs(+Pairs, -Transposed).\nSwap Key-Value to Value-Key. The resulting list is sorted using keysort/2 on the  new key.",
    "prefix":"transpose_pairs"
  },
  "parse_time/2": {
    "body":"parse_time(${1:Text}, ${2:Stamp})$3\n$0",
    "description":"parse_time(+Text, -Stamp).\nSame as parse_time(Text, _Format, Stamp). See parse_time/3.",
    "prefix":"parse_time"
  },
  "parse_time/3": {
    "body":"parse_time(${1:Text}, ${2:Format}, ${3:Stamp})$4\n$0",
    "description":"parse_time(+Text, ?Format, -Stamp).\nParse a textual time representation, producing a time-stamp. Supported  formats for Text are in the table below. If the format is  known, it may be given to reduce parse time and avoid ambiguities.  Otherwise, Format is unified with the format encountered.  \n\nNameExample rfc_1123Fri, 08 Dec 2006 15:29:44  GMT Fri, 08 Dec 2006 15:29:44 +0000 iso_86012006-12-08T17:29:44+02:00 20061208T172944+0200 2006-12-08T15:29Z 2006-12-08 20061208 2006-12 2006-W49-5 2006-342 ",
    "prefix":"parse_time"
  },
  "passed/1": {
    "body":"passed(${1:N})$2\n$0",
    "description":"passed(+N).\nProcess suite/tN.rdf and store the resulting triples in suite/ok/tN.pl for later validation by test/0.",
    "prefix":"passed"
  },
  "pce:free/1": {
    "body": ["free(${1:'Param1'})$2\n$0" ],
    "description":"free('Param1')",
    "prefix":"free"
  },
  "pce:get/3": {
    "body": ["get(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"get('Param1','Param2','Param3')",
    "prefix":"get"
  },
  "pce:get/4": {
    "body": [
      "get(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"get('Param1','Param2','Param3','Param4')",
    "prefix":"get"
  },
  "pce:get/5": {
    "body": [
      "get(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"get('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"get"
  },
  "pce:get/6": {
    "body": [
      "get(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"get('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"get"
  },
  "pce:get/7": {
    "body": [
      "get(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'})$8\n$0"
    ],
    "description":"get('Param1','Param2','Param3','Param4','Param5','Param6','Param7')",
    "prefix":"get"
  },
  "pce:get/8": {
    "body": [
      "get(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'})$9\n$0"
    ],
    "description":"get('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8')",
    "prefix":"get"
  },
  "pce:get_class/4": {
    "body": [
      "get_class(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"get_class('Param1','Param2','Param3','Param4')",
    "prefix":"get_class"
  },
  "pce:in_pce_thread/1": {
    "body": ["in_pce_thread(${1:'Param1'})$2\n$0" ],
    "description":"in_pce_thread('Param1')",
    "prefix":"in_pce_thread"
  },
  "pce:in_pce_thread_sync/1": {
    "body": ["in_pce_thread_sync(${1:'Param1'})$2\n$0" ],
    "description":"in_pce_thread_sync('Param1')",
    "prefix":"in_pce_thread_sync"
  },
  "pce:new/2": {
    "body": ["new(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"new('Param1','Param2')",
    "prefix":"new"
  },
  "pce:object/1": {
    "body": ["object(${1:'Param1'})$2\n$0" ],
    "description":"object('Param1')",
    "prefix":"object"
  },
  "pce:object/2": {
    "body": ["object(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"object('Param1','Param2')",
    "prefix":"object"
  },
  "pce:pce_autoload/2": {
    "body": ["pce_autoload(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pce_autoload('Param1','Param2')",
    "prefix":"pce_autoload"
  },
  "pce:pce_autoload_all/0": {
    "body": ["pce_autoload_all$1\n$0" ],
    "description":"pce_autoload_all",
    "prefix":"pce_autoload_all"
  },
  "pce:pce_begin_class_definition/4": {
    "body": [
      "pce_begin_class_definition(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"pce_begin_class_definition('Param1','Param2','Param3','Param4')",
    "prefix":"pce_begin_class_definition"
  },
  "pce:pce_begin_recording/1": {
    "body": ["pce_begin_recording(${1:'Param1'})$2\n$0" ],
    "description":"pce_begin_recording('Param1')",
    "prefix":"pce_begin_recording"
  },
  "pce:pce_catch_error/2": {
    "body": ["pce_catch_error(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pce_catch_error('Param1','Param2')",
    "prefix":"pce_catch_error"
  },
  "pce:pce_compiling/1": {
    "body": ["pce_compiling(${1:'Param1'})$2\n$0" ],
    "description":"pce_compiling('Param1')",
    "prefix":"pce_compiling"
  },
  "pce:pce_compiling/2": {
    "body": ["pce_compiling(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pce_compiling('Param1','Param2')",
    "prefix":"pce_compiling"
  },
  "pce:pce_dispatch/0": {
    "body": ["pce_dispatch$1\n$0" ],
    "description":"pce_dispatch",
    "prefix":"pce_dispatch"
  },
  "pce:pce_end_recording/0": {
    "body": ["pce_end_recording$1\n$0" ],
    "description":"pce_end_recording",
    "prefix":"pce_end_recording"
  },
  "pce:pce_extended_class/1": {
    "body": ["pce_extended_class(${1:'Param1'})$2\n$0" ],
    "description":"pce_extended_class('Param1')",
    "prefix":"pce_extended_class"
  },
  "pce:pce_global/2": {
    "body": ["pce_global(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pce_global('Param1','Param2')",
    "prefix":"pce_global"
  },
  "pce:pce_open/3": {
    "body": ["pce_open(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"pce_open('Param1','Param2','Param3')",
    "prefix":"pce_open"
  },
  "pce:pce_prolog_class/1": {
    "body": ["pce_prolog_class(${1:'Param1'})$2\n$0" ],
    "description":"pce_prolog_class('Param1')",
    "prefix":"pce_prolog_class"
  },
  "pce:pce_prolog_class/2": {
    "body": ["pce_prolog_class(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pce_prolog_class('Param1','Param2')",
    "prefix":"pce_prolog_class"
  },
  "pce:pce_register_class/1": {
    "body": ["pce_register_class(${1:'Param1'})$2\n$0" ],
    "description":"pce_register_class('Param1')",
    "prefix":"pce_register_class"
  },
  "pce:pce_term_expansion/2": {
    "body": ["pce_term_expansion(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pce_term_expansion('Param1','Param2')",
    "prefix":"pce_term_expansion"
  },
  "pce:pce_thread/1": {
    "body": ["pce_thread(${1:Thread})$2\n$0" ],
    "description":"  pce_thread(-Thread) is det.\n\n   True if Thread is the Prolog thread that runs the graphics\n   message loop.\n\n   @see pce_dispatch/1.",
    "prefix":"pce_thread"
  },
  "pce:send/2": {
    "body": ["send(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"send('Param1','Param2')",
    "prefix":"send"
  },
  "pce:send/3": {
    "body": ["send(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"send('Param1','Param2','Param3')",
    "prefix":"send"
  },
  "pce:send/4": {
    "body": [
      "send(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"send('Param1','Param2','Param3','Param4')",
    "prefix":"send"
  },
  "pce:send/5": {
    "body": [
      "send(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"send('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"send"
  },
  "pce:send/6": {
    "body": [
      "send(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"send('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"send"
  },
  "pce:send/7": {
    "body": [
      "send(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'})$8\n$0"
    ],
    "description":"send('Param1','Param2','Param3','Param4','Param5','Param6','Param7')",
    "prefix":"send"
  },
  "pce:send/8": {
    "body": [
      "send(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'})$9\n$0"
    ],
    "description":"send('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8')",
    "prefix":"send"
  },
  "pce:send_class/3": {
    "body": ["send_class(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"send_class('Param1','Param2','Param3')",
    "prefix":"send_class"
  },
  "pce:set_pce_thread/0": {
    "body": ["set_pce_thread$1\n$0" ],
    "description":"set_pce_thread",
    "prefix":"set_pce_thread"
  },
  "pce_class_index:pce_make_library_index/1": {
    "body": ["pce_make_library_index(${1:Dir})$2\n$0" ],
    "description":"  pce_make_library_index(+Dir)\n\n   Create a file CLASSINDEX.pl in Dir holding facts of the format\n\n          class(Name, Super, Summary, File)\n\n   This file can be used for auto-loading as well as supporting\n   cross-referencing and syntax-highlighting.",
    "prefix":"pce_make_library_index"
  },
  "pce_class_index:pce_update_library_index/0": {
    "body": ["pce_update_library_index$1\n$0" ],
    "description":"pce_update_library_index",
    "prefix":"pce_update_library_index"
  },
  "pce_class_template:use_class_template/1": {
    "body": ["use_class_template(${1:TemplateClassName})$2\n$0" ],
    "description":"  use_class_template(+TemplateClassName)\n\n   Handled by the XPCE class compiler.  This version just prints\n   an error message.",
    "prefix":"use_class_template"
  },
  "pce_class_template:use_class_template/2": {
    "body": ["use_class_template(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"use_class_template('Param1','Param2')",
    "prefix":"use_class_template"
  },
  "pce_compatibility_layer:auto_call/1": {
    "body": ["auto_call(${1:Goal})$2\n$0" ],
    "description":"  auto_call(:Goal)\n\n   Autoload Goal and call it.  In   SWI-Prolog,  this  simply means\n   calling it.",
    "prefix":"auto_call"
  },
  "pce_compatibility_layer:callable_predicate/1": {
    "body": ["callable_predicate(${1:Head})$2\n$0" ],
    "description":"  callable_predicate(:Head) is semidet.\n\n   Succeeds if Head can be called without raising an exception for\n   an undefined predicate",
    "prefix":"callable_predicate"
  },
  "pce_compatibility_layer:modified_since_last_loaded/1": {
    "body": ["modified_since_last_loaded(${1:Path})$2\n$0" ],
    "description":"  modified_since_last_loaded(Path) is semidet.\n\n   True is file has been modified since the last time it was loaded.",
    "prefix":"modified_since_last_loaded"
  },
  "pce_compatibility_layer:pce_error/1": {
    "body": ["pce_error(${1:Term})$2\n$0" ],
    "description":"  pce_error(+Term) is det.\n  pce_warn(+Term) is det.\n  pce_info(+Term) is det.\n\n   Portability layer wrappers around print_message/2.",
    "prefix":"pce_error"
  },
  "pce_compatibility_layer:pce_info/1": {
    "body": ["pce_info(${1:Term})$2\n$0" ],
    "description":"  pce_error(+Term) is det.\n  pce_warn(+Term) is det.\n  pce_info(+Term) is det.\n\n   Portability layer wrappers around print_message/2.",
    "prefix":"pce_info"
  },
  "pce_compatibility_layer:pce_warn/1": {
    "body": ["pce_warn(${1:Term})$2\n$0" ],
    "description":"  pce_error(+Term) is det.\n  pce_warn(+Term) is det.\n  pce_info(+Term) is det.\n\n   Portability layer wrappers around print_message/2.",
    "prefix":"pce_warn"
  },
  "pce_config:add_config/2": {
    "body": ["add_config(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"add_config('Param1','Param2')",
    "prefix":"add_config"
  },
  "pce_config:config_attributes/2": {
    "body": ["config_attributes(${1:Key}, ${2:Attributes})$3\n$0" ],
    "description":"  config_attributes(+Key, -Attributes)\n\n   Fetch the (meta) attributes of the given config key.  The special\n   path `config' returns information on the config database itself.\n   The path of the key may be partly instantiated.",
    "prefix":"config_attributes"
  },
  "pce_config:config_term_to_object/2": {
    "body": ["config_term_to_object(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"config_term_to_object('Param1','Param2')",
    "prefix":"config_term_to_object"
  },
  "pce_config:config_term_to_object/3": {
    "body": [
      "config_term_to_object(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"config_term_to_object('Param1','Param2','Param3')",
    "prefix":"config_term_to_object"
  },
  "pce_config:current_config_type/3": {
    "body": [
      "current_config_type(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"current_config_type('Param1','Param2','Param3')",
    "prefix":"current_config_type"
  },
  "pce_config:del_config/2": {
    "body": ["del_config(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"del_config('Param1','Param2')",
    "prefix":"del_config"
  },
  "pce_config:edit_config/1": {
    "body": ["edit_config(${1:'Param1'})$2\n$0" ],
    "description":"edit_config('Param1')",
    "prefix":"edit_config"
  },
  "pce_config:ensure_loaded_config/1": {
    "body": ["ensure_loaded_config(${1:'Param1'})$2\n$0" ],
    "description":"ensure_loaded_config('Param1')",
    "prefix":"ensure_loaded_config"
  },
  "pce_config:get_config/2": {
    "body": ["get_config(${1:Key}, ${2:Value})$3\n$0" ],
    "description":"  get_config(:Key, -Value) is det.\n\n   Get configuration for Key as Value.",
    "prefix":"get_config"
  },
  "pce_config:load_config/1": {
    "body": ["load_config(${1:'Param1'})$2\n$0" ],
    "description":"load_config('Param1')",
    "prefix":"load_config"
  },
  "pce_config:register_config/1": {
    "body": ["register_config(${1:Pred})$2\n$0" ],
    "description":"  register_config(:Pred) is det.\n\n   Register  Pred  to  provide  metadata  about  the  configuration\n   handled in the calling module.  Pred   is  called  as call(Pred,\n   Path, Attributes).",
    "prefix":"register_config"
  },
  "pce_config:register_config_type/2": {
    "body": ["register_config_type(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"register_config_type('Param1','Param2')",
    "prefix":"register_config_type"
  },
  "pce_config:save_config/1": {
    "body": ["save_config(${1:'Param1'})$2\n$0" ],
    "description":"save_config('Param1')",
    "prefix":"save_config"
  },
  "pce_config:set_config/2": {
    "body": ["set_config(${1:Key}, ${2:Value})$3\n$0" ],
    "description":"  set_config(:Key, +Value) is det.\n\n   Set the configuration parameter Key to   Value.  If the value is\n   modified, a broadcast message set_config(Key, Value) is issued.",
    "prefix":"set_config"
  },
  "pce_cpp_header:generate_cpp_class_header_file/0": {
    "body": ["generate_cpp_class_header_file$1\n$0" ],
    "description":"generate_cpp_class_header_file",
    "prefix":"generate_cpp_class_header_file"
  },
  "pce_debug:checkpce/0": {
    "body": ["checkpce$1\n$0" ],
    "description":"checkpce",
    "prefix":"checkpce"
  },
  "pce_debug:debugpce/0": {
    "body": ["debugpce$1\n$0" ],
    "description":"debugpce",
    "prefix":"debugpce"
  },
  "pce_debug:debugpce/1": {
    "body": ["debugpce(${1:Subject})$2\n$0" ],
    "description":"   debugpce(+Subject) is det.\n   nodebugpce(+Subject) is det.\n\n   Start/stop printing debugging messages on `Subject'. System maintenance\n   usage only.",
    "prefix":"debugpce"
  },
  "pce_debug:nodebugpce/0": {
    "body": ["nodebugpce$1\n$0" ],
    "description":"nodebugpce",
    "prefix":"nodebugpce"
  },
  "pce_debug:nodebugpce/1": {
    "body": ["nodebugpce(${1:Subject})$2\n$0" ],
    "description":"   debugpce(+Subject) is det.\n   nodebugpce(+Subject) is det.\n\n   Start/stop printing debugging messages on `Subject'. System maintenance\n   usage only.",
    "prefix":"nodebugpce"
  },
  "pce_debug:nospypce/1": {
    "body": ["nospypce(${1:'Param1'})$2\n$0" ],
    "description":"nospypce('Param1')",
    "prefix":"nospypce"
  },
  "pce_debug:notracepce/1": {
    "body": ["notracepce(${1:'Param1'})$2\n$0" ],
    "description":"notracepce('Param1')",
    "prefix":"notracepce"
  },
  "pce_debug:pce_global_objects/1": {
    "body": ["pce_global_objects(${1:ChainOfGlobalObjects})$2\n$0" ],
    "description":"  pce_global_objects(-ChainOfGlobalObjects)\n   Return a chain with all globally known objects.",
    "prefix":"pce_global_objects"
  },
  "pce_debug:pcerefer/1": {
    "body": ["pcerefer(${1:'Param1'})$2\n$0" ],
    "description":"pcerefer('Param1')",
    "prefix":"pcerefer"
  },
  "pce_debug:pcerefer/2": {
    "body": ["pcerefer(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pcerefer('Param1','Param2')",
    "prefix":"pcerefer"
  },
  "pce_debug:show_slots/1": {
    "body": ["show_slots(${1:Reference})$2\n$0" ],
    "description":"  show_slots(+Reference)\n\n   Show  all   slots of the   named object.  Actually,  this is a\n   terminal version  of   the inspector  tool  provided  with the\n   manual.  Notably used by me if PCE is in such  a bad shape the\n   inspector won't run anymore",
    "prefix":"show_slots"
  },
  "pce_debug:spypce/1": {
    "body": ["spypce(${1:'Param1'})$2\n$0" ],
    "description":"spypce('Param1')",
    "prefix":"spypce"
  },
  "pce_debug:tracepce/1": {
    "body": ["tracepce(${1:'Param1'})$2\n$0" ],
    "description":"tracepce('Param1')",
    "prefix":"tracepce"
  },
  "pce_debug_monitor:prolog_debug_monitor/0": {
    "body": ["prolog_debug_monitor$1\n$0" ],
    "description":"prolog_debug_monitor",
    "prefix":"prolog_debug_monitor"
  },
  "pce_dispatch/1": {
    "body":"pce_dispatch(${1:Options})$2\n$0",
    "description":"pce_dispatch(+Options).\nCreate a Prolog thread with the alias name pce for XPCE  event handling. In the X11 version this call creates a thread that  executes the X11 event-dispatch loop. In MS-Windows it creates a thread  that executes a windows event-dispatch loop. The XPCE event-handling  thread has the alias pce. Options specifies the  thread attributes as thread_create/3.",
    "prefix":"pce_dispatch"
  },
  "pce_dispatch:pce_call/1": {
    "body": ["pce_call(${1:Goal})$2\n$0" ],
    "description":"  pce_call(:Goal) is det.\n\n   Run Goal in the XPCE thread.\n\n   @deprecated New code should used in_pce_thread/1.",
    "prefix":"pce_call"
  },
  "pce_dispatch:pce_dispatch/1": {
    "body": ["pce_dispatch(${1:Options})$2\n$0" ],
    "description":"  pce_dispatch(+Options) is det.\n\n   Create a new thread =pce= that takes   care  of the XPCE message\n   loop. This predicate has no effect  if dispatching is already on\n   another thread than the =main=.  The   loop  can  be ended using\n   pce_end_dispatch/0.",
    "prefix":"pce_dispatch"
  },
  "pce_dispatch:pce_end_dispatch/0": {
    "body": ["pce_end_dispatch$1\n$0" ],
    "description":"  pce_end_dispatch is det.\n\n   End the XPCE dispatcher loop started with pce_dispatch/1.",
    "prefix":"pce_end_dispatch"
  },
  "pce_draw:pcedraw/0": {
    "body": ["pcedraw$1\n$0" ],
    "description":"pcedraw",
    "prefix":"pcedraw"
  },
  "pce_draw:pcedraw/1": {
    "body": ["pcedraw(${1:'Param1'})$2\n$0" ],
    "description":"pcedraw('Param1')",
    "prefix":"pcedraw"
  },
  "pce_draw:save_pcedraw/1": {
    "body": ["save_pcedraw(${1:'Param1'})$2\n$0" ],
    "description":"save_pcedraw('Param1')",
    "prefix":"save_pcedraw"
  },
  "pce_edit:editpce/1": {
    "body": ["editpce(${1:Spec})$2\n$0" ],
    "description":"  editpce(+Spec)\n\n   Edit an xpce `object' from Spec using PceEmacs. Spec is one of:\n\n     - An xpce object that implements <-source\n     - An xpce object, taking its <-class\n     - The name of a class\n     - A term Object->selector\n     - A term Object<-selector\n\n   @see    edit/1 provides the same functionality.",
    "prefix":"editpce"
  },
  "pce_grapher:grapher/1": {
    "body": ["grapher(${1:MessageOrList})$2\n$0" ],
    "description":"  grapher(+MessageOrList)\n\n   Send a message or list of messages to the grapher.  Leaves a\n   choicepoint which undos the modifications if we backtrack into\n   it.",
    "prefix":"grapher"
  },
  "pce_grapher:grapher/2": {
    "body": ["grapher(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"grapher('Param1','Param2')",
    "prefix":"grapher"
  },
  "pce_help_file:pce_help/2": {
    "body": ["pce_help(${1:DataBaseId}, ${2:Label})$3\n$0" ],
    "description":"  pce_help(+DataBaseId, +Label)\n\n   Start @helper/helper on the help module `DataBaseId', searching\n   for a fragment with label `Label'.  Normally invoked through the\n   send directly.",
    "prefix":"pce_help"
  },
  "pce_help_file:pce_help_file/2": {
    "body": ["pce_help_file(${1:DataBaseId}, ${2:FileName})$3\n$0" ],
    "description":"  pce_help_file(+DataBaseId, +FileName).\n\n   Declare `FileName' to hold a helper-format file holding the\n   help-database `DataBaseId'.  FileName will be converted into\n   an absolute filename.  Normally used as a directive.",
    "prefix":"pce_help_file"
  },
  "pce_image:pce_image_directory/1": {
    "body": ["pce_image_directory(${1:'Param1'})$2\n$0" ],
    "description":"pce_image_directory('Param1')",
    "prefix":"pce_image_directory"
  },
  "pce_load_cxx:pce_load_cxx/1": {
    "body": ["pce_load_cxx(${1:'Param1'})$2\n$0" ],
    "description":"pce_load_cxx('Param1')",
    "prefix":"pce_load_cxx"
  },
  "pce_main:dispatch_for_frames/1": {
    "body": ["dispatch_for_frames(${1:'Param1'})$2\n$0" ],
    "description":"dispatch_for_frames('Param1')",
    "prefix":"dispatch_for_frames"
  },
  "pce_main:pce_loop/1": {
    "body": ["pce_loop(${1:Goal})$2\n$0" ],
    "description":"  pce_loop(+Goal).\n  pce_loop(+Goal, +Argv:list).\n\n   Runs `Goal', finds all toplevel frames created and then dispatches\n   events untill the last frame is destroyed.",
    "prefix":"pce_loop"
  },
  "pce_main:pce_loop/2": {
    "body": ["pce_loop(${1:Goal}, ${2:Argv})$3\n$0" ],
    "description":"  pce_loop(+Goal).\n  pce_loop(+Goal, +Argv:list).\n\n   Runs `Goal', finds all toplevel frames created and then dispatches\n   events untill the last frame is destroyed.",
    "prefix":"pce_loop"
  },
  "pce_main:pce_main_loop/1": {
    "body": ["pce_main_loop(${1:Goal})$2\n$0" ],
    "description":"  pce_main_loop(+Goal)\n\n   Simple XPCE runtime toplevel loop.  This goal extracts the command\n   line arguments, calls `call(Goal, CmdLineArgs)' and waits for all\n   frames created by this call to be invisible.  Then it will halt/0.",
    "prefix":"pce_main_loop"
  },
  "pce_make_dialog:make_dialog/2": {
    "body": ["make_dialog(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"make_dialog('Param1','Param2')",
    "prefix":"make_dialog"
  },
  "pce_manual:manpce/0": {
    "body": ["manpce$1\n$0" ],
    "description":"  manpce is det.\n\n   Starts the XPCE manual tools by opening a small window.",
    "prefix":"manpce"
  },
  "pce_manual:manpce/1": {
    "body": ["manpce(${1:Spec})$2\n$0" ],
    "description":"  manpce(+Spec) is det.\n\n   Start the XPCE manual tools, opening   the manual page for Spec.\n   Spec is translated into an   XPCE  object using pce_to_method/2.\n   Examples:\n\n     ==\n     ?- manpce(window).\n     ?- manpce(point->x).\n     ==",
    "prefix":"manpce"
  },
  "pce_meta:classify_class/2": {
    "body": ["classify_class(${1:ClassName}, ${2:Classification})$3\n$0" ],
    "description":"  classify_class(+ClassName, -Classification) is det.\n\n   Classify an XPCE class.  Defined classes are:\n\n     * built_in\n     * file(File)\n     * library(File)\n     * user(File)\n     * user\n     * undefined",
    "prefix":"classify_class"
  },
  "pce_meta:current_class/2": {
    "body": ["current_class(${1:Name}, ${2:Class})$3\n$0" ],
    "description":"  current_class(?Name, ?Class)\n\n   Convert between name and class object.  Insufficient instantation\n   enumerates the classes.",
    "prefix":"current_class"
  },
  "pce_meta:implements/2": {
    "body": ["implements(${1:Class}, ${2:Method})$3\n$0" ],
    "description":"  implements(?Class:atom, ?Method:atom) is nondet.\n  implements(?Class:atom, ?Method:atom, -MethodObj:object) is nondet.\n\n   True if Class implements the method.  If class is a variable,\n   backtracking yields all classes\n\n   `What'  may  be  wrapped  in  self(What)  or  root(What).  Using\n   self(What) returns only those classes  that have a non-inherited\n   implementation of the method,  while   using  root(What) returns\n   only  those  classes  for   which    there   is  no  super-class\n   implementing the requested method.\n\n   @param Class    Name of XPCE class\n   @param Method   One of send(Name) or get(Name)\n   @param MethodObj XPCE Object representing the method",
    "prefix":"implements"
  },
  "pce_meta:implements/3": {
    "body": ["implements(${1:Class}, ${2:Method}, ${3:MethodObj})$4\n$0" ],
    "description":"  implements(?Class:atom, ?Method:atom) is nondet.\n  implements(?Class:atom, ?Method:atom, -MethodObj:object) is nondet.\n\n   True if Class implements the method.  If class is a variable,\n   backtracking yields all classes\n\n   `What'  may  be  wrapped  in  self(What)  or  root(What).  Using\n   self(What) returns only those classes  that have a non-inherited\n   implementation of the method,  while   using  root(What) returns\n   only  those  classes  for   which    there   is  no  super-class\n   implementing the requested method.\n\n   @param Class    Name of XPCE class\n   @param Method   One of send(Name) or get(Name)\n   @param MethodObj XPCE Object representing the method",
    "prefix":"implements"
  },
  "pce_meta:isa_class/2": {
    "body": ["isa_class(${1:Sub}, ${2:Super})$3\n$0" ],
    "description":"  isa_class(?Sub, ?Super)\n\n   Succeeds if Sub is Super or below Super.  Can be used with any\n   instantiation.  If class is instantiated the super-chain is\n   followed.",
    "prefix":"isa_class"
  },
  "pce_meta:pce_library_class/4": {
    "body": [
      "pce_library_class(${1:Name}, ${2:Super}, ${3:Comment}, ${4:File})$5\n$0"
    ],
    "description":"  pce_library_class(?Name, ?Super, ?Comment, ?File)\n\n   Examine the library index for defined classes.",
    "prefix":"pce_library_class"
  },
  "pce_meta:pce_to_method/2": {
    "body": ["pce_to_method(${1:Spec}, ${2:Object})$3\n$0" ],
    "description":"  pce_to_method(+Spec, -Object) is semidet.\n\n   Object is the XPCE object described by Spec.  Spec is one of\n\n           * send(Receiver, Selector)\n           * ->(Receiver, Selector)\n           Find a send-method on Receiver\n           * get(Receiver, Selector)\n           * <-(Receiver, Selector)\n           Find a get-method on Receiver\n           * Receiver-Selector\n           Find an instance variable (slot) on Receiver\n           * ClassName\n           Find a class from its name",
    "prefix":"pce_to_method"
  },
  "pce_meta:pce_to_pl_type/2": {
    "body": ["pce_to_pl_type(${1:PceType}, ${2:PrologType})$3\n$0" ],
    "description":"  pce_to_pl_type(+PceType, -PrologType)\n   Convert an XPCE Type object to our type-checkers type-logic.\n",
    "prefix":"pce_to_pl_type"
  },
  "pce_meta:to_class_name/2": {
    "body": ["to_class_name(${1:AtomOrClass}, ${2:ClassName})$3\n$0" ],
    "description":"  to_class_name(+AtomOrClass, -ClassName)\n\n   Convert a name or class-object into a class name",
    "prefix":"to_class_name"
  },
  "pce_meta:type_accepts_function/1": {
    "body": ["type_accepts_function(${1:Type})$2\n$0" ],
    "description":"  type_accepts_function(+Type)\n\n   Succeeds if Type accepts function arguments",
    "prefix":"type_accepts_function"
  },
  "pce_portray_object:portray_object/1": {
    "body": ["portray_object(${1:Object})$2\n$0" ],
    "description":"  portray_object(@Object)\n\n   Prints the result of portray_object/2 on the display.",
    "prefix":"portray_object"
  },
  "pce_portray_object:portray_object/2": {
    "body": ["portray_object(${1:Object}, ${2:Term})$3\n$0" ],
    "description":"  portray_object(@Object, -Term)\n\n   Expands the object description of  Object   in  a human readable\n   form and returs this in Term.   portray_object/2  uses the rules\n   found under portray_class/2.",
    "prefix":"portray_object"
  },
  "pce_postscript:postscript/2": {
    "body": ["postscript(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"postscript('Param1','Param2')",
    "prefix":"postscript"
  },
  "pce_profile:pce_show_profile/0": {
    "body": ["pce_show_profile$1\n$0" ],
    "description":"  pce_show_profile is det.\n\n   Show already collected profile using a graphical browser.",
    "prefix":"pce_show_profile"
  },
  "pce_progress:progress_checklist/3": {
    "body": ["progress_checklist(${1:Goal}, ${2:List}, ${3:Options})$4\n$0" ],
    "description":"  progress_checklist(:Goal, +List, +Options)\n\n   As checklist/2, but show a progress-bar while processing the\n   elements of the list.",
    "prefix":"progress_checklist"
  },
  "pce_prolog_xref:xref_built_in/1": {
    "body": ["xref_built_in(${1:'Param1'})$2\n$0" ],
    "description":"xref_built_in('Param1')",
    "prefix":"xref_built_in"
  },
  "pce_prolog_xref:xref_called/3": {
    "body": ["xref_called(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"xref_called('Param1','Param2','Param3')",
    "prefix":"xref_called"
  },
  "pce_prolog_xref:xref_clean/1": {
    "body": ["xref_clean(${1:'Param1'})$2\n$0" ],
    "description":"xref_clean('Param1')",
    "prefix":"xref_clean"
  },
  "pce_prolog_xref:xref_current_source/1": {
    "body": ["xref_current_source(${1:'Param1'})$2\n$0" ],
    "description":"xref_current_source('Param1')",
    "prefix":"xref_current_source"
  },
  "pce_prolog_xref:xref_defined/3": {
    "body": ["xref_defined(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"xref_defined('Param1','Param2','Param3')",
    "prefix":"xref_defined"
  },
  "pce_prolog_xref:xref_defined_class/3": {
    "body": [
      "xref_defined_class(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"xref_defined_class('Param1','Param2','Param3')",
    "prefix":"xref_defined_class"
  },
  "pce_prolog_xref:xref_definition_line/2": {
    "body": ["xref_definition_line(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_definition_line('Param1','Param2')",
    "prefix":"xref_definition_line"
  },
  "pce_prolog_xref:xref_done/2": {
    "body": ["xref_done(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_done('Param1','Param2')",
    "prefix":"xref_done"
  },
  "pce_prolog_xref:xref_exported/2": {
    "body": ["xref_exported(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_exported('Param1','Param2')",
    "prefix":"xref_exported"
  },
  "pce_prolog_xref:xref_hook/1": {
    "body": ["xref_hook(${1:'Param1'})$2\n$0" ],
    "description":"xref_hook('Param1')",
    "prefix":"xref_hook"
  },
  "pce_prolog_xref:xref_meta/2": {
    "body": ["xref_meta(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_meta('Param1','Param2')",
    "prefix":"xref_meta"
  },
  "pce_prolog_xref:xref_module/2": {
    "body": ["xref_module(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_module('Param1','Param2')",
    "prefix":"xref_module"
  },
  "pce_prolog_xref:xref_op/2": {
    "body": ["xref_op(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_op('Param1','Param2')",
    "prefix":"xref_op"
  },
  "pce_prolog_xref:xref_public_list/4": {
    "body": [
      "xref_public_list(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"xref_public_list('Param1','Param2','Param3','Param4')",
    "prefix":"xref_public_list"
  },
  "pce_prolog_xref:xref_source/1": {
    "body": ["xref_source(${1:'Param1'})$2\n$0" ],
    "description":"xref_source('Param1')",
    "prefix":"xref_source"
  },
  "pce_prolog_xref:xref_source/2": {
    "body": ["xref_source(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_source('Param1','Param2')",
    "prefix":"xref_source"
  },
  "pce_prolog_xref:xref_source_file/3": {
    "body": [
      "xref_source_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"xref_source_file('Param1','Param2','Param3')",
    "prefix":"xref_source_file"
  },
  "pce_prolog_xref:xref_source_file/4": {
    "body": [
      "xref_source_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"xref_source_file('Param1','Param2','Param3','Param4')",
    "prefix":"xref_source_file"
  },
  "pce_prolog_xref:xref_used_class/2": {
    "body": ["xref_used_class(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_used_class('Param1','Param2')",
    "prefix":"xref_used_class"
  },
  "pce_prompter:prompter/2": {
    "body": ["prompter(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"prompter('Param1','Param2')",
    "prefix":"prompter"
  },
  "pce_qrecompile:qcompile_pce/0": {
    "body": ["qcompile_pce$1\n$0" ],
    "description":"qcompile_pce",
    "prefix":"qcompile_pce"
  },
  "pce_renew:pce_renew/1": {
    "body": ["pce_renew(${1:'Param1'})$2\n$0" ],
    "description":"pce_renew('Param1')",
    "prefix":"pce_renew"
  },
  "pce_require:pce_require/1": {
    "body": ["pce_require(${1:File})$2\n$0" ],
    "description":"  pce_require(+File) is det.\n\n   Compute the require/1 directive for  File   and  print it to the\n   current output.",
    "prefix":"pce_require"
  },
  "pce_require:pce_require/3": {
    "body": ["pce_require(${1:File}, ${2:Directive}, ${3:Message})$4\n$0" ],
    "description":"  pce_require(+File, -Directive, -Message) is det.\n\n   Compute the :- require/1 directive by cross-referencing File.",
    "prefix":"pce_require"
  },
  "pce_server:pce_server/1": {
    "body": ["pce_server(${1:Address})$2\n$0" ],
    "description":"  pce_server(+Address)\n\n   Create a PCE socket and interpret incomming lines as Prolog goals.\n   The Address argument is one of:\n\n           * Atom\n           Unix-domain socket.  Atom is used as filename\n           * Integer\n           Internet socket.  Integer is the port number\n\n   Output send to current_output is send to the client, as are error\n   messages\n\n   @see    The SWI-Prolog library(prolog_server) implements a telnet\n           server that provides a Prolog toplevel.",
    "prefix":"pce_server"
  },
  "pce_shell:pce_shell_command/1": {
    "body": ["pce_shell_command(${1:'Param1'})$2\n$0" ],
    "description":"pce_shell_command('Param1')",
    "prefix":"pce_shell_command"
  },
  "pce_type:pce_define_type/2": {
    "body": ["pce_define_type(${1:Name}, ${2:Type})$3\n$0" ],
    "description":"  pce_define_type(+Name, +Type) is det.\n\n   Create a type alias name, so we can write more readable code.\n   Typical examples make aliases for `name' (name cannot be subclassed),\n   alias for numeric and name-sets.  Here are some examples:\n\n   ==\n   :- pce_define_type(rdf_resource, name).\n   :- pce_define_type(weekday,     {sunday,monday,tuesday,wednesday,\n                                    thursday,friday,saturday}).\n   :- pce_define_type(natural,     '1..').\n   ==",
    "prefix":"pce_define_type"
  },
  "pce_util:chain_list/2": {
    "body": ["chain_list(${1:Chain}, ${2:List})$3\n$0" ],
    "description":"  chain_list(+Chain, -List) is det.\n  chain_list(-Chain, +List) is det.\n\n   Convert between a Prolog list and an XPCE chain object.",
    "prefix":"chain_list"
  },
  "pce_util:default/3": {
    "body": ["default(${1:Argument}, ${2:Default}, ${3:Value})$4\n$0" ],
    "description":"  default(+Argument, +Default, -Value) is det.\n\n   Get the default value for an argument.  Default is either a\n   plain value or a term class_variable(+Object, +Name).",
    "prefix":"default"
  },
  "pce_util:get_chain/3": {
    "body": ["get_chain(${1:Object}, ${2:Selector}, ${3:List})$4\n$0" ],
    "description":"   get_chain(+Object, +Selector, -List:list) is semidet.\n\n   List is a Prolog list constructed from the PCE chain returned by <-Selector\n   on Object.  get_chain/3 returns a list of object names,",
    "prefix":"get_chain"
  },
  "pce_util:get_object/3": {
    "body": ["get_object(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"get_object('Param1','Param2','Param3')",
    "prefix":"get_object"
  },
  "pce_util:get_object/4": {
    "body": [
      "get_object(${1:Object}, ${2:Selector}, ${3:Arg...}, ${4:Output})$5\n$0"
    ],
    "description":"   get_object(+Object, +Selector, +Arg..., -Output) is semidet.\n\n   Succeeds once if Output is the value returned by invoking get method\n   called Selector on Object.  Output is an object description, except for the\n   special objects @nil, @default, @on and @off all of which are both\n   object descriptions and object names.",
    "prefix":"get_object"
  },
  "pce_util:get_object/5": {
    "body": [
      "get_object(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"get_object('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"get_object"
  },
  "pce_util:get_object/6": {
    "body": [
      "get_object(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'})$7\n$0"
    ],
    "description":"get_object('Param1','Param2','Param3','Param4','Param5','Param6')",
    "prefix":"get_object"
  },
  "pce_util:get_object/7": {
    "body": [
      "get_object(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'})$8\n$0"
    ],
    "description":"get_object('Param1','Param2','Param3','Param4','Param5','Param6','Param7')",
    "prefix":"get_object"
  },
  "pce_util:get_object/8": {
    "body": [
      "get_object(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'}, ${6:'Param6'}, ${7:'Param7'}, ${8:'Param8'})$9\n$0"
    ],
    "description":"get_object('Param1','Param2','Param3','Param4','Param5','Param6','Param7','Param8')",
    "prefix":"get_object"
  },
  "pce_util:send_list/2": {
    "body": ["send_list(${1:ListOfObjs}, ${2:ListOfSels})$3\n$0" ],
    "description":"  send_list(+ListOfObjs, +ListOfSels)\n\n   Send a messages to the carthesian product of ListOfObjs and\n   ListOfSels.",
    "prefix":"send_list"
  },
  "pce_util:send_list/3": {
    "body": [
      "send_list(${1:ListOfObjs}, ${2:ListOfSels}, ${3:ListOfArgs})$4\n$0"
    ],
    "description":"   send_list(+ListOfObjs, +ListOfSels, +ListOfArgs)\n\n   Send a messages to the carthesian product of ListOfObjs and\n   ListOfSels.",
    "prefix":"send_list"
  },
  "pce_xref_gui:gxref/0": {
    "body": ["gxref$1\n$0" ],
    "description":"  gxref\n\n   Start graphical cross-referencer on loaded program.  The GUI\n   is started in the XPCE thread.",
    "prefix":"gxref"
  },
  "pce_xref_gui:xref_file_exports/2": {
    "body": ["xref_file_exports(${1:File}, ${2:Exports})$3\n$0" ],
    "description":"  xref_file_exports(+File, -Exports)\n\n   Produce the export-header for non-module files.  Fails if the\n   file is already a module file.",
    "prefix":"xref_file_exports"
  },
  "pce_xref_gui:xref_file_imports/2": {
    "body": ["xref_file_imports(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_file_imports('Param1','Param2')",
    "prefix":"xref_file_imports"
  },
  "pdt_console:pdt_install_console/0": {
    "body": ["pdt_install_console$1\n$0" ],
    "description":"  pdt_install_console\n\n   Support  get_single_char/1  in  PDT    console.  This  predicate\n   modifies =user_input= and =user_output= as follows:\n\n     - If single-char mode is enabled, write \"ESC s\" over the user\n       output and then wait for two characters, returning the\n       first.\n     - Output is changed to emit ESC as ESC ESC.\n\n   This protocol was  designed  for  PDT   by  Lukas  Degener.  The\n   original implementation was partly in Prolog.   This is a full C\n   implementation, both for speed.",
    "prefix":"pdt_install_console"
  },
  "pdt_install_console/0": {
    "body":"pdt_install_console$1\n$0",
    "description":"pdt_install_console.\nSupport get_single_char/1 in PDT console.  This predicate modifies user_input and user_output  as follows:  \n\nIf single-char mode is enabled, write \"ESC s\" over the user output  and then wait for two characters, returning the first.\nOutput is changed to emit ESC as ESC ESC.\n\n  This protocol was designed for PDT by Lukas Degener. The original  implementation was partly in Prolog. This is a full C implementation,  both for speed.\n\n",
    "prefix":"pdt_install_console"
  },
  "peek_byte/1": {
    "body":"peek_byte(${1:Byte})$2\n$0",
    "description":"[ISO]peek_byte(-Byte).\n",
    "prefix":"peek_byte"
  },
  "peek_byte/2": {
    "body":"peek_byte(${1:Stream}, ${2:Byte})$3\n$0",
    "description":"[ISO]peek_byte(+Stream, -Byte).\n",
    "prefix":"peek_byte"
  },
  "peek_char/1": {
    "body":"peek_char(${1:Char})$2\n$0",
    "description":"[ISO]peek_char(-Char).\n",
    "prefix":"peek_char"
  },
  "peek_char/2": {
    "body":"peek_char(${1:Stream}, ${2:Char})$3\n$0",
    "description":"[ISO]peek_char(+Stream, -Char).\nRead the next byte/code/char from the input without removing it. These  predicates do not modify the stream's position or end-of-file status.  These predicates require a buffered stream (see set_stream/2)  and raise a permission error if the stream is unbuffered or the buffer  is too small to hold the longest multi-byte sequence that might need to  be buffered.",
    "prefix":"peek_char"
  },
  "peek_code/1": {
    "body":"peek_code(${1:Code})$2\n$0",
    "description":"[ISO]peek_code(-Code).\n",
    "prefix":"peek_code"
  },
  "peek_code/2": {
    "body":"peek_code(${1:Stream}, ${2:Code})$3\n$0",
    "description":"[ISO]peek_code(+Stream, -Code).\n",
    "prefix":"peek_code"
  },
  "peek_string/3": {
    "body":"peek_string(${1:Stream}, ${2:Len}, ${3:String})$4\n$0",
    "description":"peek_string(+Stream, +Len, -String).\nRead the next Len characters (if the stream is a text stream)  or bytes (if the stream is binary) from Stream without removing the  data. If Len is larger that the stream buffer size, the  buffer size is increased to Len. String can be  shorter than Len if the stream contains less data. This  predicate is intended to guess the content type of data read from  non-repositionable streams.",
    "prefix":"peek_string"
  },
  "pengines:authentication_hook/3": {
    "body":"authentication_hook(${1:Request}, ${2:Application}, ${3:User})$4\n$0",
    "description":"[semidet,multifile]authentication_hook(+Request, +Application, -User).\nThis hook is called from the =/pengine/create= HTTP handler to discover  whether the server is accessed by an authorized user. It can react in  three ways:  \n\nSucceed, binding User to a ground term. The authentity of  the user is available through pengine_user/1.\nFail. The =/create= succeeds, but the pengine is not associated with  a user.\nThrow an exception to prevent creation of the pengine. Two  meaningful exceptions are:  throw(http_reply(authorise(basic(Realm)))) Start a  normal HTTP login challenge (reply 401)throw(http_reply(forbidden(Path)))) Reject the request  using a 403 repply.\n\n  See also: http_authenticate/3 can be used to  implement this hook using default HTTP authentication data.\n\n ",
    "prefix":"authentication_hook"
  },
  "pengines:current_pengine_application/1": {
    "body":"current_pengine_application(${1:Application})$2\n$0",
    "description":"[nondet]current_pengine_application(?Application).\nTrue when Application is a currently defined application.  See also: pengine_application/1\n\n ",
    "prefix":"current_pengine_application"
  },
  "pengines:not_sandboxed/2": {
    "body":"not_sandboxed(${1:User}, ${2:Application})$3\n$0",
    "description":"[semidet,multifile]not_sandboxed(+User, +Application).\nThis hook is called to see whether the Pengine must be executed in a  protected environment. It is only called after authentication_hook/3  has confirmed the authentity of the current user. If this hook succeeds,  both loading the code and executing the query is executed without  enforcing sandbox security. Typically, one should:  \n\nProvide a safe user authentication hook.\nEnable HTTPS in the server or put it behind an HTTPS proxy and  ensure that the network between the proxy and the pengine server can be  trusted.\n\n",
    "prefix":"not_sandboxed"
  },
  "pengines:output/2": {
    "body":"output(${1:ID}, ${2:Term})$3\n$0",
    "description":"[semidet,multifile]output(+ID, +Term).\nHook to handle pengine_output/1  from the remote pengine. If the hook fails, it calls print/1  on Term.",
    "prefix":"output"
  },
  "pengines:pengine_abort/1": {
    "body":"pengine_abort(${1:NameOrID})$2\n$0",
    "description":"[det]pengine_abort(+NameOrID).\nAborts the running query. The pengine goes back to state `2', waiting  for new queries.  See also: pengine_destroy/1.\n\n ",
    "prefix":"pengine_abort"
  },
  "pengines:pengine_application/1": {
    "body":"pengine_application(${1:Application})$2\n$0",
    "description":"[det]pengine_application(+Application).\nDirective that must be used to declare a pengine application module. The  module may not be associated to any file. The default application is pengine_sandbox.  The example below creates a new application address_book  and imports the API defined in the module file adress_book_api.pl  into the application.  \n\n:- pengine_application(address_book).\n:- use_module(address_book:adress_book_api).\n\n ",
    "prefix":"pengine_application"
  },
  "pengines:pengine_ask/3": {
    "body":"pengine_ask(${1:NameOrID}, ${2:Query}, ${3:Options})$4\n$0",
    "description":"[det]pengine_ask(+NameOrID, @Query, +Options).\nAsks pengine NameOrID a query Query.  Options is a list of options: \n\ntemplate(+Template): Template is a variable (or a term containing variables)  shared with the query. By default, the template is identical to the  query.\n\nchunk(+Integer): Retrieve solutions in chunks of Integer rather than one by  one. 1 means no chunking (default). Other integers indicate the maximum  number of solutions to retrieve in one chunk.\n\n  Any remaining options are passed to pengine_send/3. \n\nNote that the predicate pengine_ask/3  is deterministic, even for queries that have more than one solution.  Also, the variables in Query will not be bound. Instead,  results will be returned in the form of event terms. \n\nsuccess(ID, Terms, More): ID is the id of the pengine that succeeded in solving the  query. Terms is a list holding instantiations of Template. More  is either true or false, indicating whether we  can expect the pengine to be able to return more solutions or not, would  we call pengine_next/2.\n\nfailure(ID): ID is the id of the pengine that failed for lack of a  solutions.\n\nerror(ID, Term): ID is the id of the pengine throwing the exception. Term is the exception's error term.\n\noutput(ID, Term): ID is the id of a pengine running the query that called pengine_output/1. Term  is the term that was passed in the first argument of pengine_output/1  when it was called.\n\nprompt(ID, Term): ID is the id of the pengine that called pengine_input/2  and Term is the prompt.\n\n  Defined in terms of pengine_send/3,  like so: \n\n\n\npengine_ask(ID, Query, Options) :-\n    partition(pengine_ask_option, Options, AskOptions, SendOptions),\n    pengine_send(ID, ask(Query, AskOptions), SendOptions).\n\n ",
    "prefix":"pengine_ask"
  },
  "pengines:pengine_create/1": {
    "body":"pengine_create(${1:Options})$2\n$0",
    "description":"[det]pengine_create(:Options).\nCreates a new pengine. Valid options are:  id(-ID): ID gets instantiated to the id of the created pengine. ID  is atomic.\n\nalias(+Name): The pengine is named Name (an atom). A slave pengine (child)  can subsequently be referred to by this name.\n\napplication(+Application): Application in which the pengine runs. See pengine_application/1.\n\nserver(+URL): The pengine will run in (and in the Prolog context of) the pengine  server located at URL.\n\nsrc_list(+List_of_clauses): Inject a list of Prolog clauses into the pengine.\n\nsrc_text(+Atom_or_string): Inject the clauses specified by a source text into the pengine.\n\nsrc_url(+URL): Inject the clauses specified in the file located at URL into  the pengine.\n\nsrc_predicates(+List): Send the local predicates denoted by List to the remote  pengine. List is a list of predicate indicators.\n\n  Remaining options are passed to http_open/3  (meaningful only for non-local pengines) and thread_create/3.  Note that for thread_create/3 only options  changing the stack-sizes can be used. In particular, do not pass the  detached or alias options.. \n\nSuccessful creation of a pengine will return an event term of  the following form: \n\ncreate(ID, Term): ID is the id of the pengine that was created. Term is not used at the moment.\n\n  An error will be returned if the pengine could not be created: \n\nerror(ID, Term): ID is invalid, since no pengine was created. Term is the exception's error term.\n\n ",
    "prefix":"pengine_create"
  },
  "pengines:pengine_debug/2": {
    "body":"pengine_debug(${1:Format}, ${2:Args})$3\n$0",
    "description":"[det]pengine_debug(+Format, +Args).\nCreate a message using format/3 from Format  and Args and send this to the client. The default JavaScript  client will call console.log(Message) if there is a console. The predicate pengine_rpc/3 calls debug(pengine(debug), '~w', [Message]).  The debug topic pengine(debug) is enabled by default.  See also: - debug/1 and nodebug/1  for controlling the pengine(debug) topic  - format/2 for format specifications\n\n ",
    "prefix":"pengine_debug"
  },
  "pengines:pengine_destroy/1": {
    "body":"pengine_destroy(${1:NameOrID})$2\n$0",
    "description":"[det]pengine_destroy(+NameOrID).\n",
    "prefix":"pengine_destroy"
  },
  "pengines:pengine_destroy/2": {
    "body":"pengine_destroy(${1:NameOrID}, ${2:Options})$3\n$0",
    "description":"[det]pengine_destroy(+NameOrID, +Options).\nDestroys the pengine NameOrID. With the option force(true),  the pengine is killed using abort/0 and pengine_destroy/2  succeeds.",
    "prefix":"pengine_destroy"
  },
  "pengines:pengine_event/2": {
    "body": ["pengine_event(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pengine_event('Param1','Param2')",
    "prefix":"pengine_event"
  },
  "pengines:pengine_event_loop/2": {
    "body":"pengine_event_loop(${1:Closure}, ${2:Options})$3\n$0",
    "description":"[det]pengine_event_loop(:Closure, +Options).\nStarts an event loop accepting event terms sent to the current pengine  or thread. For each such event E, calls ignore(call(Closure, E)).  A closure thus acts as a handler for the event. Some events are  also treated specially:  create(ID, Term): The ID is placed in a list of active pengines.\n\ndestroy(ID): The ID is removed from the list of active pengines. When the  last pengine ID is removed, the loop terminates.\n\noutput(ID, Term): The predicate pengine_pull_response/2  is called.\n\n  Valid options are: \n\nautoforward(+To): Forwards received event terms to slaves. To is either all, all_but_sender or a Prolog list of NameOrIDs. [not yet  implemented]\n\n ",
    "prefix":"pengine_event_loop"
  },
  "pengines:pengine_input/2": {
    "body":"pengine_input(${1:Prompt}, ${2:Term})$3\n$0",
    "description":"[det]pengine_input(+Prompt, -Term).\nSends Prompt to the parent pengine and waits for input. Note  that Prompt may be any term, compound as well as atomic.",
    "prefix":"pengine_input"
  },
  "pengines:pengine_next/2": {
    "body":"pengine_next(${1:NameOrID}, ${2:Options})$3\n$0",
    "description":"[det]pengine_next(+NameOrID, +Options).\nAsks pengine NameOrID for the next solution to a query  started by pengine_ask/3. Defined options  are:  chunk(+Count): Modify the chunk-size to Count before asking the next set of  solutions.\n\n  Remaining options are passed to pengine_send/3.  The result of re-executing the current goal is returned to the caller's  message queue in the form of event terms. \n\nsuccess(ID, Terms, More): ID is the id of the pengine that succeeded in finding yet  another solution to the query. Terms is a list holding  instantiations of Template. More is either true or false,  indicating whether we can expect the pengine to be able to return more  solutions or not, would we call pengine_next/2.\n\nfailure(ID): ID is the id of the pengine that failed for lack of more  solutions.\n\nerror(ID, Term): ID is the id of the pengine throwing the exception. Term is the exception's error term.\n\noutput(ID, Term): ID is the id of a pengine running the query that called pengine_output/1. Term  is the term that was passed in the first argument of pengine_output/1  when it was called.\n\nprompt(ID, Term): ID is the id of the pengine that called pengine_input/2  and Term is the prompt.\n\n  Defined in terms of pengine_send/3, as  follows: \n\n\n\npengine_next(ID, Options) :-\n    pengine_send(ID, next, Options).\n\n ",
    "prefix":"pengine_next"
  },
  "pengines:pengine_output/1": {
    "body":"pengine_output(${1:Term})$2\n$0",
    "description":"[det]pengine_output(+Term).\nSends Term to the parent pengine or thread.",
    "prefix":"pengine_output"
  },
  "pengines:pengine_property/2": {
    "body":"pengine_property(${1:Pengine}, ${2:Property})$3\n$0",
    "description":"[nondet]pengine_property(?Pengine, ?Property).\nTrue when Property is a property of the given Pengine.  Enumerates all pengines that are known to the calling Prolog process.  Defined properties are:  self(ID): Identifier of the pengine. This is the same as the first argument, and  can be used to enumerate all known pengines.\n\nalias(Name): Name is the alias name of the pengine, as provided through  the alias option when creating the pengine.\n\nthread(Thread): If the pengine is a local pengine, Thread is the Prolog  thread identifier of the pengine.\n\nremote(Server): If the pengine is remote, the URL of the server.\n\napplication(Application): Pengine runs the given application\n\nmodule(Module): Temporary module used for running the Pengine.\n\ndestroy(Destroy): Destroy is true if the pengines is destroyed  automatically after completing the query.\n\nparent(Queue): Message queue to which the (local) pengine reports.\n\nsource(?SourceID, ?Source): Source is the source code with the given SourceID.  May be present if the setting debug_info is present.\n\n ",
    "prefix":"pengine_property"
  },
  "pengines:pengine_pull_response/2": {
    "body":"pengine_pull_response(${1:Pengine}, ${2:Options})$3\n$0",
    "description":"[det]pengine_pull_response(+Pengine, +Options).\nPulls a response (an event term) from the slave Pengine if Pengine  is a remote process, else does nothing at all.",
    "prefix":"pengine_pull_response"
  },
  "pengines:pengine_respond/3": {
    "body":"pengine_respond(${1:Pengine}, ${2:Input}, ${3:Options})$4\n$0",
    "description":"[det]pengine_respond(+Pengine, +Input, +Options).\nSends a response in the form of the term Input to a slave  pengine that has prompted its master for input.  Defined in terms of pengine_send/3, as  follows: \n\n\n\npengine_respond(Pengine, Input, Options) :-\n    pengine_send(Pengine, input(Input), Options).\n\n ",
    "prefix":"pengine_respond"
  },
  "pengines:pengine_rpc/2": {
    "body":"pengine_rpc(${1:URL}, ${2:Query})$3\n$0",
    "description":"[nondet]pengine_rpc(+URL, +Query).\n",
    "prefix":"pengine_rpc"
  },
  "pengines:pengine_rpc/3": {
    "body":"pengine_rpc(${1:URL}, ${2:Query}, ${3:Options})$4\n$0",
    "description":"[nondet]pengine_rpc(+URL, +Query, +Options).\nSemantically equivalent to the sequence below, except that the query is  executed in (and in the Prolog context of) the pengine server referred  to by URL, rather than locally.  \n\n  copy_term(Query, Copy),\n  call(Copy),                 % executed on server at URL\n  Query = Copy.\n\n  Valid options are: \n\nchunk(+Integer): Can be used to reduce the number of network roundtrips being made. See pengine_ask/3.\n\ntimeout(+Time): Wait at most Time seconds for the next event from the server.  The default is defined by the setting pengines:time_limit.\n\n  Remaining options (except the server option) are passed to pengine_create/1.\n\n",
    "prefix":"pengine_rpc"
  },
  "pengines:pengine_self/1": {
    "body": ["pengine_self(${1:'Param1'})$2\n$0" ],
    "description":"pengine_self('Param1')",
    "prefix":"pengine_self"
  },
  "pengines:pengine_stop/2": {
    "body":"pengine_stop(${1:NameOrID}, ${2:Options})$3\n$0",
    "description":"[det]pengine_stop(+NameOrID, +Options).\nTells pengine NameOrID to stop looking for more solutions to  a query started by pengine_ask/3. Options  are passed to pengine_send/3.  Defined in terms of pengine_send/3,  like so: \n\n\n\npengine_stop(ID, Options) :-\n    pengine_send(ID, stop, Options).\n\n ",
    "prefix":"pengine_stop"
  },
  "pengines:pengine_user/1": {
    "body":"pengine_user(${1:User})$2\n$0",
    "description":"[semidet]pengine_user(-User).\nTrue when the pengine was create by an HTTP request that authorized User.  See also: authentication_hook/3  can be used to extract authorization from the HTTP header.\n\n ",
    "prefix":"pengine_user"
  },
  "pengines:prepare_goal/3": {
    "body":"prepare_goal(${1:Goal0}, ${2:Goal1}, ${3:Options})$4\n$0",
    "description":"[semidet,multifile]prepare_goal(+Goal0, -Goal1, +Options).\nPre-preparation hook for running Goal0. The hook runs in the  context of the pengine. Goal is the raw goal given to ask. The  returned Goal1 is subject to goal expansion (expand_goal/2)  and sandbox validation (safe_goal/1) prior  to execution. If this goal fails, Goal0 is used for further processing. Options provides the options as  given to ask ",
    "prefix":"prepare_goal"
  },
  "pengines:prepare_module/3": {
    "body":"prepare_module(${1:Module}, ${2:Application}, ${3:Options})$4\n$0",
    "description":"[semidet,multifile]prepare_module(+Module, +Application, +Options).\nHook, called to initialize the temporary private module that provides  the working context of a pengine. This hook is executed by the pengine's  thread. Preparing the source consists of three steps:  \n\nAdd Application as (first) default import module for Module\nCall this hook\nCompile the source provided by the the src_text and src_url options\n\n Module is a new temporary  module (see in_temporary_module/3) that may be  (further) prepared by this hook. Application (also a module)  associated to the pengine. Options is passed from the  environment and should (currently) be ignored. ",
    "prefix":"prepare_module"
  },
  "pengines:prompt/3": {
    "body":"prompt(${1:ID}, ${2:Prompt}, ${3:Term})$4\n$0",
    "description":"[semidet,multifile]prompt(+ID, +Prompt, -Term).\nHook to handle pengine_input/2  from the remote pengine. If the hooks fails, pengine_rpc/3  calls read/1 using the current prompt.",
    "prefix":"prompt"
  },
  "pengines:write_result/3": {
    "body":"write_result(${1:Lang}, ${2:Event}, ${3:VarNames})$4\n$0",
    "description":"[semidet,multifile]write_result(+Lang, +Event, +VarNames).\nCalled after write_result/4  for backward compatibility reasons.  deprecated: Use write_result/4.\n\n ",
    "prefix":"write_result"
  },
  "pengines:write_result/4": {
    "body":"write_result(${1:Lang}, ${2:Event}, ${3:VarNames}, ${4:Dict})$5\n$0",
    "description":"[semidet,multifile]write_result(+Lang, +Event, +VarNames, +Dict).\nHook that allows for different output formats. The core Pengines library  supports prolog and various JSON dialects. The hook event_to_json/4 can be used to refine the  JSON dialects. This hook must be used if a completely different output  format is desired.",
    "prefix":"write_result"
  },
  "pengines_io:pengine_bind_io_to_html/1": {
    "body": ["pengine_bind_io_to_html(${1:Module})$2\n$0" ],
    "description":"  pengine_bind_io_to_html(+Module)\n\n   Redefine the built-in predicates for IO   to  send HTML messages\n   using pengine_output/1.",
    "prefix":"pengine_bind_io_to_html"
  },
  "pengines_io:pengine_display/1": {
    "body": ["pengine_display(${1:Term})$2\n$0" ],
    "description":"  pengine_write(+Term) is det.\n  pengine_writeq(+Term) is det.\n  pengine_display(+Term) is det.\n  pengine_print(+Term) is det.\n  pengine_write_canonical(+Term) is det.\n\n   Redirect the corresponding Prolog output predicates.",
    "prefix":"pengine_display"
  },
  "pengines_io:pengine_flush_output/0": {
    "body": ["pengine_flush_output$1\n$0" ],
    "description":"  pengine_flush_output\n\n   No-op.  Pengines do not use output buffering (maybe they should\n   though).",
    "prefix":"pengine_flush_output"
  },
  "pengines_io:pengine_format/1": {
    "body": ["pengine_format(${1:Format})$2\n$0" ],
    "description":"  pengine_format(+Format) is det.\n  pengine_format(+Format, +Args) is det.\n\n   As format/1,2. Emits a series  of   strings  with <br/> for each\n   newline encountered in the string.\n\n   @tbd: handle ~w, ~q, etc using term//2.  How can we do that??",
    "prefix":"pengine_format"
  },
  "pengines_io:pengine_format/2": {
    "body": ["pengine_format(${1:Format}, ${2:Args})$3\n$0" ],
    "description":"  pengine_format(+Format) is det.\n  pengine_format(+Format, +Args) is det.\n\n   As format/1,2. Emits a series  of   strings  with <br/> for each\n   newline encountered in the string.\n\n   @tbd: handle ~w, ~q, etc using term//2.  How can we do that??",
    "prefix":"pengine_format"
  },
  "pengines_io:pengine_io_goal_expansion/2": {
    "body": ["pengine_io_goal_expansion(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"pengine_io_goal_expansion('Param1','Param2')",
    "prefix":"pengine_io_goal_expansion"
  },
  "pengines_io:pengine_io_predicate/1": {
    "body": ["pengine_io_predicate(${1:Head})$2\n$0" ],
    "description":"  pengine_io_predicate(?Head)\n\n   True when Head describes the  head   of  a (system) IO predicate\n   that is redefined by the HTML binding.",
    "prefix":"pengine_io_predicate"
  },
  "pengines_io:pengine_listing/0": {
    "body": ["pengine_listing$1\n$0" ],
    "description":"  pengine_listing is det.\n  pengine_listing(+Spec) is det.\n\n   List the content of the current pengine or a specified predicate\n   in the pengine.",
    "prefix":"pengine_listing"
  },
  "pengines_io:pengine_listing/1": {
    "body": ["pengine_listing(${1:Spec})$2\n$0" ],
    "description":"  pengine_listing is det.\n  pengine_listing(+Spec) is det.\n\n   List the content of the current pengine or a specified predicate\n   in the pengine.",
    "prefix":"pengine_listing"
  },
  "pengines_io:pengine_nl/0": {
    "body": ["pengine_nl$1\n$0" ],
    "description":"  pengine_nl\n\n   Emit a <br/> to the pengine.",
    "prefix":"pengine_nl"
  },
  "pengines_io:pengine_portray_clause/1": {
    "body": ["pengine_portray_clause(${1:'Param1'})$2\n$0" ],
    "description":"pengine_portray_clause('Param1')",
    "prefix":"pengine_portray_clause"
  },
  "pengines_io:pengine_print/1": {
    "body": ["pengine_print(${1:Term})$2\n$0" ],
    "description":"  pengine_write(+Term) is det.\n  pengine_writeq(+Term) is det.\n  pengine_display(+Term) is det.\n  pengine_print(+Term) is det.\n  pengine_write_canonical(+Term) is det.\n\n   Redirect the corresponding Prolog output predicates.",
    "prefix":"pengine_print"
  },
  "pengines_io:pengine_read/1": {
    "body": ["pengine_read(${1:'Param1'})$2\n$0" ],
    "description":"pengine_read('Param1')",
    "prefix":"pengine_read"
  },
  "pengines_io:pengine_write/1": {
    "body": ["pengine_write(${1:Term})$2\n$0" ],
    "description":"  pengine_write(+Term) is det.\n  pengine_writeq(+Term) is det.\n  pengine_display(+Term) is det.\n  pengine_print(+Term) is det.\n  pengine_write_canonical(+Term) is det.\n\n   Redirect the corresponding Prolog output predicates.",
    "prefix":"pengine_write"
  },
  "pengines_io:pengine_write_canonical/1": {
    "body": ["pengine_write_canonical(${1:Term})$2\n$0" ],
    "description":"  pengine_write(+Term) is det.\n  pengine_writeq(+Term) is det.\n  pengine_display(+Term) is det.\n  pengine_print(+Term) is det.\n  pengine_write_canonical(+Term) is det.\n\n   Redirect the corresponding Prolog output predicates.",
    "prefix":"pengine_write_canonical"
  },
  "pengines_io:pengine_write_term/2": {
    "body": ["pengine_write_term(${1:Term}, ${2:Options})$3\n$0" ],
    "description":"  pengine_write_term(+Term, +Options)\n\n   Writes term as <span class=Class>Term<\/span>. In addition to the\n   options of write_term/2, these options are processed:\n\n     - class(+Class)\n       Specifies the class of the element.  Default is =write=.",
    "prefix":"pengine_write_term"
  },
  "pengines_io:pengine_writeln/1": {
    "body": ["pengine_writeln(${1:Term})$2\n$0" ],
    "description":"  pengine_writeln(+Term)\n\n   Emit Term as <span class=writeln>Term<br><\/span>.",
    "prefix":"pengine_writeln"
  },
  "pengines_io:pengine_writeq/1": {
    "body": ["pengine_writeq(${1:Term})$2\n$0" ],
    "description":"  pengine_write(+Term) is det.\n  pengine_writeq(+Term) is det.\n  pengine_display(+Term) is det.\n  pengine_print(+Term) is det.\n  pengine_write_canonical(+Term) is det.\n\n   Redirect the corresponding Prolog output predicates.",
    "prefix":"pengine_writeq"
  },
  "persistency:current_persistent_predicate/1": {
    "body":"current_persistent_predicate(${1:PI})$2\n$0",
    "description":"[nondet]current_persistent_predicate(:PI).\nTrue if PI is a predicate that provides access to the  persistent database DB.",
    "prefix":"current_persistent_predicate"
  },
  "persistency:db_attach/2": {
    "body":"db_attach(${1:File}, ${2:Options})$3\n$0",
    "description":"db_attach(:File, +Options).\nUse File as persistent database for the calling module. The  calling module must defined persistent/1  to declare the database terms. Defined options:  sync(+Sync): One of close (close journal after write), flush  (default, flush journal after write) or none (handle as  fully buffered stream).\n\n ",
    "prefix":"db_attach"
  },
  "persistency:db_detach/0": {
    "body": ["db_detach$1\n$0" ],
    "description":"  db_detach is det.\n\n   Detach persistency from  the  calling   module  and  delete  all\n   persistent clauses from the Prolog database.  Note that the file\n   is not affected. After  this  operation   another  file  may  be\n   attached,  providing  it   satisfies    the   same   persistency\n   declaration.",
    "prefix":"db_detach"
  },
  "persistency:db_sync/1": {
    "body":"db_sync(${1:What})$2\n$0",
    "description":"db_sync(:What).\nSynchronise database with the associated file. What is one  of:  reload: Database is reloaded from file if the file was modified since loaded.\n\nupdate: As reload, but use incremental loading if possible. This  allows for two processes to examine the same database file, where one  writes the database and the other periodycally calls db_sync(update)  to follow the modified data.\n\ngc: Database was re-written, deleting all retractall statements. This is the  same as gc(50).\n\ngc(Percentage): GC DB if the number of deleted terms is the given percentage of the  total number of terms.\n\nclose: Database stream was closed\n\ndetach: Remove all registered persistency for the calling module\n\nnop: No-operation performed\n\n  With unbound What, db_sync/1  reloads the database if it was modified on disk, gc it if it is dirty  and close it if it is opened.\n\n",
    "prefix":"db_sync"
  },
  "persistency:db_sync_all/1": {
    "body":"db_sync_all(${1:What})$2\n$0",
    "description":"db_sync_all(+What).\nSync all registered databases.",
    "prefix":"db_sync_all"
  },
  "persistency:persistent/1": {
    "body": ["persistent(${1:Spec})$2\n$0" ],
    "description":"  persistent(+Spec)\n\n   Declare dynamic database terms. Declarations appear in a\n   directive and have the following format:\n\n   ==\n   :- persistent\n           <callable>,\n           <callable>,\n           ...\n   ==\n\n   Each specification is a callable term, following the conventions\n   of library(record), where each argument is of the form\n\n           name:type\n\n   Types are defined by library(error).",
    "prefix":"persistent"
  },
  "phrase/2": {
    "body":"phrase(${1:DCGBody}, ${2:List})$3\n$0",
    "description":"phrase(:DCGBody, ?List).\nEquivalent to phrase(DCGBody, InputList, []).",
    "prefix":"phrase"
  },
  "phrase/3": {
    "body":"phrase(${1:DCGBody}, ${2:List}, ${3:Rest})$4\n$0",
    "description":"phrase(:DCGBody, ?List, ?Rest).\nTrue when DCGBody applies to the difference List/Rest. Although DCGBody is  typically a callable term that denotes a grammar rule, it can be any term  that is valid as the body of a DCG rule.  The example below calls the rule set integer/3  defined in section 4.13 and available  from library(library(dcg/basics)), binding Rest  to the remainder of the input after matching the integer. \n\n\n\n?- [library(dcg/basics)].\n?- atom_codes('42 times', Codes),\n   phrase(integer(X), Codes, Rest).\nX = 42\nRest = [32, 116, 105, 109, 101, 115]\n\n  The next example exploits a complete body. Given the following  definition of digit_weight1, we can pose the query below. \n\n\n\ndigit_weight(W) -->\n        [D],\n        { code_type(D, digit(W)) }.\n\n  \n\n?- atom_codes('Version 3.4', Codes),\n   phrase((\"Version \",\n           digit_weight(Major),\".\",digit_weight(Minor)),\n          Codes).\nMajor = 3,\nMinor = 4.\n\n  The SWI-Prolog implementation of phrase/3  verifies that the List and Rest arguments are  unbound, bound to the empty list or a list cons cell. Other values raise a type error.65The  ISO standard allows for both raising a type error and accepting any term  as input and output. Note the tail of the list is not checked for  performance reasons. The predicate call_dcg/3  is provided to use grammar rules with terms that are not lists. \n\nNote that the syntax for lists of codes changed in SWI-Prolog version7  (see section 5.2). If a DCG body  is translated, both \"text\" and `text` is a  valid code-list literal in version7. A version7 string (\"text\")  is not acceptable for the second and third arguments of phrase/3.  This is typically not a problem for applications as the input of a DCG  rarely appears in the source code. For testing in the toplevel, one must  use double quoted text in versions prior to7 and back quoted text  in version7 or later. \n\nSee also portray_text/1,  which can be used to print lists of character codes as a string to the  top level and debugger to facilitate debugging DCGs that process  character codes. The library library(apply_macros) compiles phrase/3  if the argument is sufficiently instantiated, eliminating the runtime  overhead of translating DCGBody and meta-calling.\n\n",
    "prefix":"phrase"
  },
  "pio:lazy_list_character_count/3": {
    "body": [
      "lazy_list_character_count(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"lazy_list_character_count('Param1','Param2','Param3')",
    "prefix":"lazy_list_character_count"
  },
  "pio:lazy_list_location/3": {
    "body": [
      "lazy_list_location(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"lazy_list_location('Param1','Param2','Param3')",
    "prefix":"lazy_list_location"
  },
  "pio:phrase_from_file/2": {
    "body": ["phrase_from_file(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"phrase_from_file('Param1','Param2')",
    "prefix":"phrase_from_file"
  },
  "pio:phrase_from_file/3": {
    "body": [
      "phrase_from_file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"phrase_from_file('Param1','Param2','Param3')",
    "prefix":"phrase_from_file"
  },
  "pio:phrase_from_stream/2": {
    "body": ["phrase_from_stream(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"phrase_from_stream('Param1','Param2')",
    "prefix":"phrase_from_stream"
  },
  "pio:stream_to_lazy_list/2": {
    "body": ["stream_to_lazy_list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"stream_to_lazy_list('Param1','Param2')",
    "prefix":"stream_to_lazy_list"
  },
  "pio:syntax_error/3": {
    "body": ["syntax_error(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"syntax_error('Param1','Param2','Param3')",
    "prefix":"syntax_error"
  },
  "pldoc/doc_access:host_access_options/2": {
    "body": ["host_access_options(${1:AllOptions}, ${2:NoAuthOptions})$3\n$0" ],
    "description":"  host_access_options(+AllOptions, -NoAuthOptions) is det.\n\n   Filter the authorization options from   AllOptions,  leaving the\n   remaining options in NoAuthOptions.",
    "prefix":"host_access_options"
  },
  "pldoc/doc_util:atom_pi/2": {
    "body": ["atom_pi(${1:Atom}, ${2:PI})$3\n$0" ],
    "description":"  atom_pi(+Atom, -PI) is det.\n\n   Translate an external predicate indicator   representated  as an\n   atom  into  a  predicate  indicator    term.  If  Atom  contains\n   <module>:, PI is qialified. If no arity is provided it is a term\n   Name/_, i.e., with unbound arity.",
    "prefix":"atom_pi"
  },
  "pldoc/doc_util:ensure_slash_end/2": {
    "body": ["ensure_slash_end(${1:Dir}, ${2:DirSlash})$3\n$0" ],
    "description":"  ensure_slash_end(+Dir, -DirSlash) is det.\n\n   Ensure Dir ends with a /.",
    "prefix":"ensure_slash_end"
  },
  "pldoc/doc_util:expand_alias/2": {
    "body": ["expand_alias(${1:Path0}, ${2:Path})$3\n$0" ],
    "description":"  expand_alias(+Path0, -Path) is det.\n\n   Translate an aliased path to a native path.",
    "prefix":"expand_alias"
  },
  "pldoc/doc_util:insert_alias/2": {
    "body": ["insert_alias(${1:Path0}, ${2:Path})$3\n$0" ],
    "description":"  insert_alias(+Path0, -Path) is det.\n\n   Translate a native path to  an   aliased  path. Path aliases are\n   defined by path_alias/2. Aliased paths   are  re-translated into\n   native form using expand_alias/2.",
    "prefix":"insert_alias"
  },
  "pldoc/pldoc_colours:colour_fragments/2": {
    "body": ["colour_fragments(${1:In}, ${2:Fragments})$3\n$0" ],
    "description":"  colour_fragments(+In, -Fragments:list) is det.\n\n   Create a list of colour fragments from In.\n\n   @param Fragments        List of fragment(Start, End, Class)",
    "prefix":"colour_fragments"
  },
  "pldoc/pldoc_html:(multifile)/2": {
    "body": ["multifile(${1:Obj}, ${2:Options})$3\n$0" ],
    "description":"  multifile(+Obj, +Options) is semidet.\n\n   True if Obj is a multifile predicate.",
    "prefix":"multifile"
  },
  "pldoc/pldoc_html:doc_file_objects/5": {
    "body": [
      "doc_file_objects(${1:FileSpec}, ${2:File}, ${3:Objects}, ${4:FileOptions}, ${5:Options})$6\n$0"
    ],
    "description":"  doc_file_objects(+FileSpec, -File, -Objects, -FileOptions, +Options) is det.\n\n   Extracts  relevant  information  for  FileSpec  from  the  PlDoc\n   database.  FileOptions contains:\n\n           * file(Title:string, Comment:string)\n           * module(Module:atom)\n           * public(Public:list(predicate_indicator)\n\n   Objects contains\n\n           * doc(PI:predicate_indicator, File:Line, Comment)\n\n   We distinguish three different states for FileSpec:\n\n     1. File was cross-referenced with collection enabled.  All\n        information is in the xref database.\n     2. File was loaded. If comments are not loaded,\n        cross-reference the file, while _storing_ the comments\n        as the compiler would do.\n     3. Neither of the above.  In this case we cross-reference the\n        file.\n\n   @param FileSpec File specification as used for load_files/2.\n   @param File     Prolog canonical filename",
    "prefix":"doc_file_objects"
  },
  "pldoc/pldoc_html:doc_for_file/2": {
    "body": ["doc_for_file(${1:File}, ${2:Options})$3\n$0" ],
    "description":"  doc_for_file(+File, +Options) is det\n\n   HTTP  handler  that  writes  documentation  for  File  as  HTML.\n   Options:\n\n           * public_only(+Bool)\n           If =true= (default), only emit documentation for\n           exported predicates.\n\n           * edit(Bool)\n           If =true=, provide edit buttons. Default, these buttons\n           are suppressed.\n\n           * title(+Title)\n           Specify the page title.  Default is the base name of the\n           file.\n\n   @param File     Prolog file specification or xref source id.",
    "prefix":"doc_for_file"
  },
  "pldoc/pldoc_html:doc_for_wiki_file/2": {
    "body": ["doc_for_wiki_file(${1:File}, ${2:Options})$3\n$0" ],
    "description":"  doc_for_wiki_file(+File, +Options) is det.\n\n   Write HTML for the File containing wiki data.",
    "prefix":"doc_for_wiki_file"
  },
  "pldoc/pldoc_html:doc_hide_private/3": {
    "body": ["doc_hide_private(${1:Objs}, ${2:Public}, ${3:Options})$4\n$0" ],
    "description":"  doc_hide_private(+Objs, +Public, +Options)\n\n   Remove the private objects from Objs according to Options.",
    "prefix":"doc_hide_private"
  },
  "pldoc/pldoc_html:doc_page_dom/3": {
    "body": ["doc_page_dom(${1:Title}, ${2:Body}, ${3:DOM})$4\n$0" ],
    "description":"  doc_page_dom(+Title, +Body, -DOM) is det.\n\n   Create the complete HTML DOM from the   Title  and Body. It adds\n   links to the style-sheet and javaScript files.",
    "prefix":"doc_page_dom"
  },
  "pldoc/pldoc_html:doc_resources/3": {
    "body": ["doc_resources(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"doc_resources('Param1','Param2','Param3')",
    "prefix":"doc_resources"
  },
  "pldoc/pldoc_html:doc_tag_title/2": {
    "body": ["doc_tag_title(${1:Tag}, ${2:Title})$3\n$0" ],
    "description":"  doc_tag_title(+Tag, -Title) is det.\n\n   Title is the name to use for Tag in the generated documentation.",
    "prefix":"doc_tag_title"
  },
  "pldoc/pldoc_html:doc_write_html/3": {
    "body": ["doc_write_html(${1:Out}, ${2:Title}, ${3:DOM})$4\n$0" ],
    "description":"  doc_write_html(+Out:stream, +Title:atomic, +DOM) is det.\n\n   Write HTML for the documentation page DOM using Title to Out.",
    "prefix":"doc_write_html"
  },
  "pldoc/pldoc_html:edit_button/4": {
    "body": [
      "edit_button(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"edit_button('Param1','Param2','Param3','Param4')",
    "prefix":"edit_button"
  },
  "pldoc/pldoc_html:ensure_doc_objects/1": {
    "body": ["ensure_doc_objects(${1:File})$2\n$0" ],
    "description":"  ensure_doc_objects(+File) is det.\n\n   Ensure we have documentation about File.  If we have no comments\n   for the file because it was loaded before comment collection was\n   enabled, run the cross-referencer on it  to collect the comments\n   and meta-information.\n\n   @param File is a canonical filename that is loaded.",
    "prefix":"ensure_doc_objects"
  },
  "pldoc/pldoc_html:existing_linked_file/2": {
    "body": ["existing_linked_file(${1:File}, ${2:Path})$3\n$0" ],
    "description":"  existing_linked_file(+File, -Path) is semidet.\n\n   True if File is a path to an existing file relative to the\n   current file.  Path is the absolute location of File.",
    "prefix":"existing_linked_file"
  },
  "pldoc/pldoc_html:file/3": {
    "body": ["file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"file('Param1','Param2','Param3')",
    "prefix":"file"
  },
  "pldoc/pldoc_html:file/4": {
    "body": [
      "file(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"file('Param1','Param2','Param3','Param4')",
    "prefix":"file"
  },
  "pldoc/pldoc_html:file_header/4": {
    "body": [
      "file_header(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"file_header('Param1','Param2','Param3','Param4')",
    "prefix":"file_header"
  },
  "pldoc/pldoc_html:include/5": {
    "body": [
      "include(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"include('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"include"
  },
  "pldoc/pldoc_html:is_op_type/2": {
    "body": ["is_op_type(${1:Atom}, ${2:Type})$3\n$0" ],
    "description":"  is_op_type(+Atom, ?Type)\n\n   True if Atom is an operator of   Type.  Type is one of =prefix=,\n   =infix= or =postfix=.",
    "prefix":"is_op_type"
  },
  "pldoc/pldoc_html:is_pi/1": {
    "body": ["is_pi(${1:Term})$2\n$0" ],
    "description":"  is_pi(@Term) is semidet.\n\n   True if Term is a predicate indicator.",
    "prefix":"is_pi"
  },
  "pldoc/pldoc_html:mode_anchor_name/2": {
    "body": ["mode_anchor_name(${1:Mode}, ${2:Anchor})$3\n$0" ],
    "description":"  mode_anchor_name(+Mode, -Anchor:atom) is det.\n\n   Get the anchor name for a mode.",
    "prefix":"mode_anchor_name"
  },
  "pldoc/pldoc_html:module_info/3": {
    "body": [
      "module_info(${1:File}, ${2:ModuleOptions}, ${3:OtherOptions})$4\n$0"
    ],
    "description":"  module_info(+File, -ModuleOptions, +OtherOptions) is det.\n\n   Add options module(Name),  public(Exports)   to  OtherOptions if\n   File is a module file.",
    "prefix":"module_info"
  },
  "pldoc/pldoc_html:object_edit_button/4": {
    "body": [
      "object_edit_button(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"object_edit_button('Param1','Param2','Param3','Param4')",
    "prefix":"object_edit_button"
  },
  "pldoc/pldoc_html:object_href/2": {
    "body": ["object_href(${1:Object}, ${2:HREF})$3\n$0" ],
    "description":"  object_href(+Object, -HREF) is det.\n  object_href(+Object, -HREF, +Options) is det.\n\n   HREF is the URL to access Object.",
    "prefix":"object_href"
  },
  "pldoc/pldoc_html:object_name/4": {
    "body": [
      "object_name(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"object_name('Param1','Param2','Param3','Param4')",
    "prefix":"object_name"
  },
  "pldoc/pldoc_html:object_page/4": {
    "body": [
      "object_page(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"object_page('Param1','Param2','Param3','Param4')",
    "prefix":"object_page"
  },
  "pldoc/pldoc_html:object_page_footer/4": {
    "body": [
      "object_page_footer(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"object_page_footer('Param1','Param2','Param3','Param4')",
    "prefix":"object_page_footer"
  },
  "pldoc/pldoc_html:object_page_header/4": {
    "body": [
      "object_page_header(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"object_page_header('Param1','Param2','Param3','Param4')",
    "prefix":"object_page_header"
  },
  "pldoc/pldoc_html:object_ref/4": {
    "body": [
      "object_ref(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"object_ref('Param1','Param2','Param3','Param4')",
    "prefix":"object_ref"
  },
  "pldoc/pldoc_html:object_source_button/4": {
    "body": [
      "object_source_button(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"object_source_button('Param1','Param2','Param3','Param4')",
    "prefix":"object_source_button"
  },
  "pldoc/pldoc_html:object_synopsis/4": {
    "body": [
      "object_synopsis(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"object_synopsis('Param1','Param2','Param3','Param4')",
    "prefix":"object_synopsis"
  },
  "pldoc/pldoc_html:object_tree/5": {
    "body": [
      "object_tree(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"object_tree('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"object_tree"
  },
  "pldoc/pldoc_html:objects/4": {
    "body": [
      "objects(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"objects('Param1','Param2','Param3','Param4')",
    "prefix":"objects"
  },
  "pldoc/pldoc_html:pred_anchor_name/3": {
    "body": ["pred_anchor_name(${1:Head}, ${2:PI}, ${3:Anchor})$4\n$0" ],
    "description":"  pred_anchor_name(+Head, -PI:atom/integer, -Anchor:atom) is det.\n\n   Create an HTML anchor name from Head.",
    "prefix":"pred_anchor_name"
  },
  "pldoc/pldoc_html:pred_edit_button/4": {
    "body": [
      "pred_edit_button(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"pred_edit_button('Param1','Param2','Param3','Param4')",
    "prefix":"pred_edit_button"
  },
  "pldoc/pldoc_html:predref/3": {
    "body": ["predref(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"predref('Param1','Param2','Param3')",
    "prefix":"predref"
  },
  "pldoc/pldoc_html:predref/4": {
    "body": [
      "predref(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"predref('Param1','Param2','Param3','Param4')",
    "prefix":"predref"
  },
  "pldoc/pldoc_html:print_html_head/1": {
    "body": ["print_html_head(${1:Out})$2\n$0" ],
    "description":"  print_html_head(+Out:stream) is det.\n\n   Print the =DOCTYPE= line.",
    "prefix":"print_html_head"
  },
  "pldoc/pldoc_html:private/2": {
    "body": ["private(${1:Obj}, ${2:Options})$3\n$0" ],
    "description":"  private(+Obj, +Options) is semidet.\n\n   True if Obj is not  exported   from  Options. This means Options\n   defined a module and Obj is  not   member  of the exports of the\n   module.",
    "prefix":"private"
  },
  "pldoc/pldoc_html:source_button/4": {
    "body": [
      "source_button(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"source_button('Param1','Param2','Param3','Param4')",
    "prefix":"source_button"
  },
  "pldoc/pldoc_html:tags/3": {
    "body": ["tags(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"tags('Param1','Param2','Param3')",
    "prefix":"tags"
  },
  "pldoc/pldoc_html:term/5": {
    "body": [
      "term(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"term('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"term"
  },
  "pldoc/pldoc_html:unquote_filespec/2": {
    "body": ["unquote_filespec(${1:Spec}, ${2:Unquoted})$3\n$0" ],
    "description":"  unquote_filespec(+Spec, -Unquoted) is det.\n\n   Translate       e.g.       library('semweb/rdf_db')         into\n   library(semweb/rdf_db).",
    "prefix":"unquote_filespec"
  },
  "pldoc/pldoc_html:zoom_button/4": {
    "body": [
      "zoom_button(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"zoom_button('Param1','Param2','Param3','Param4')",
    "prefix":"zoom_button"
  },
  "pldoc/pldoc_htmlsrc:source_to_html/3": {
    "body": ["source_to_html(${1:In}, ${2:Out}, ${3:Options})$4\n$0" ],
    "description":"  source_to_html(+In:filename, +Out, :Options) is det.\n\n   Colourise Prolog source as HTML. The idea   is to first create a\n   sequence of fragments and  then  to   apply  these  to the code.\n   Options are:\n\n     * format_comments(+Boolean)\n     If =true= (default), use PlDoc formatting for structured\n     comments.\n\n   Other options are passed to the following predicates:\n\n     * print_html_head/2\n     * print_html_footer/2.\n     * html_fragments/6\n\n   @param In       A filename.  Can also be an abstract name,\n                   which is subject to library(prolog_source)\n                   abstract file handling. See\n                   prolog_open_source/2.  Note that this cannot\n                   be a stream as we need to read the file three\n                   times: (1) xref, (2) assign colours and (3)\n                   generate HTML.\n   @param Out      Term stream(Stream) or file-name specification",
    "prefix":"source_to_html"
  },
  "pldoc/pldoc_index:dir_index/4": {
    "body": [
      "dir_index(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"dir_index('Param1','Param2','Param3','Param4')",
    "prefix":"dir_index"
  },
  "pldoc/pldoc_index:doc_file_href/2": {
    "body": ["doc_file_href(${1:Path}, ${2:HREF})$3\n$0" ],
    "description":"  doc_file_href(+Path, -HREF) is det.\n\n   Create a /doc HREF from Path.  There   are  some nasty things we\n   should take care of.\n\n           * Windows paths may start with =|L:|= (mapped to =|/L:|=)\n           * Paths may contain spaces and other weird stuff",
    "prefix":"doc_file_href"
  },
  "pldoc/pldoc_index:doc_for_dir/2": {
    "body": ["doc_for_dir(${1:Dir}, ${2:Options})$3\n$0" ],
    "description":"  doc_for_dir(+Dir, +Options) is det.\n\n   Write summary index for all files  in   Dir  to  Out. The result\n   consists of the =README= file  (if   any),  a  table holding with\n   links to objects and summary  sentences   and  finaly the =TODO=\n   file (if any).",
    "prefix":"doc_for_dir"
  },
  "pldoc/pldoc_index:doc_links/4": {
    "body": [
      "doc_links(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"doc_links('Param1','Param2','Param3','Param4')",
    "prefix":"doc_links"
  },
  "pldoc/pldoc_index:file_index_header/4": {
    "body": [
      "file_index_header(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"file_index_header('Param1','Param2','Param3','Param4')",
    "prefix":"file_index_header"
  },
  "pldoc/pldoc_index:object_summaries/5": {
    "body": [
      "object_summaries(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"object_summaries('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"object_summaries"
  },
  "pldoc/pldoc_index:places_menu/3": {
    "body": ["places_menu(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"places_menu('Param1','Param2','Param3')",
    "prefix":"places_menu"
  },
  "pldoc/pldoc_index:source_directory/1": {
    "body": ["source_directory(${1:Dir})$2\n$0" ],
    "description":"  source_directory(+Dir) is semidet.\n  source_directory(-Dir) is nondet.\n\n   True if Dir is a directory  from   which  we  have loaded Prolog\n   sources.",
    "prefix":"source_directory"
  },
  "pldoc/pldoc_library:doc_load_library/0": {
    "body": ["doc_load_library$1\n$0" ],
    "description":"  doc_load_library\n\n   Load the SWI-Prolog library, so we can access all comments from\n   the library.",
    "prefix":"doc_load_library"
  },
  "pldoc/pldoc_man:clean_man_index/0": {
    "body": ["clean_man_index$1\n$0" ],
    "description":"  clean_man_index is det.\n\n   Clean already loaded manual index.",
    "prefix":"clean_man_index"
  },
  "pldoc/pldoc_man:current_man_object/1": {
    "body": ["current_man_object(${1:Object})$2\n$0" ],
    "description":"  current_man_object(?Object) is nondet.",
    "prefix":"current_man_object"
  },
  "pldoc/pldoc_man:index_man_directory/2": {
    "body": ["index_man_directory(${1:Dir}, ${2:Options})$3\n$0" ],
    "description":"  index_man_directory(Dir, +Options) is det\n\n   Index  the  HTML  directory   Dir.    Options are:\n\n           * class(Class)\n           Define category of the found objects.\n\n   Remaining Options are passed to absolute_file_name/3.",
    "prefix":"index_man_directory"
  },
  "pldoc/pldoc_man:index_man_file/2": {
    "body": ["index_man_file(${1:Class}, ${2:File})$3\n$0" ],
    "description":"  index_man_file(+Class, +File)\n\n   Collect the documented objects from the SWI-Prolog manual file\n   File.",
    "prefix":"index_man_file"
  },
  "pldoc/pldoc_man:man_content_tree/2": {
    "body": ["man_content_tree(${1:Dir}, ${2:Tree})$3\n$0" ],
    "description":"  man_content_tree(+Dir, -Tree) is det.\n\n   Compute the content tree for a   multi-file HTML document. We do\n   this by processing =Contents.html= for  making the toplevel tree\n   that   links   to   the   individual    files.   Then   we   use\n   html_content_tree/2 to materialize the trees for the files.",
    "prefix":"man_content_tree"
  },
  "pldoc/pldoc_man:man_overview/3": {
    "body": ["man_overview(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"man_overview('Param1','Param2','Param3')",
    "prefix":"man_overview"
  },
  "pldoc/pldoc_man:man_packages_tree/1": {
    "body": ["man_packages_tree(${1:Tree})$2\n$0" ],
    "description":"  man_packages_tree(-Tree) is det.\n\n   Tree is the content tree of all packages",
    "prefix":"man_packages_tree"
  },
  "pldoc/pldoc_man:man_page/4": {
    "body": [
      "man_page(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"man_page('Param1','Param2','Param3','Param4')",
    "prefix":"man_page"
  },
  "pldoc/pldoc_modes:compile_clause/2": {
    "body": ["compile_clause(${1:Term}, ${2:FilePos})$3\n$0" ],
    "description":"  compile_clause(:Term, +FilePos) is det.\n\n   Add a clause to the  compiled   program.  Unlike  assert/1, this\n   associates the clause with the   given source-location, makes it\n   static code and removes the  clause   if  the  file is reloaded.\n   Finally,  as  we  create  clauses   one-by-one,  we  define  our\n   predicates as discontiguous.\n\n   @param Term     Clause-term\n   @param FilePos  Term of the form File:Line, where File is a\n                   canonical filename.",
    "prefix":"compile_clause"
  },
  "pldoc/pldoc_modes:compile_mode/2": {
    "body": ["compile_mode(${1:Mode}, ${2:Compiled})$3\n$0" ],
    "description":"  compile_mode(+Mode, -Compiled) is det.\n\n   Compile  a  PlDoc  mode  declararion   into  a  term  mode(Head,\n   Determinism).\n\n   @param Mode       List if mode-terms.  See process_modes/6.",
    "prefix":"compile_mode"
  },
  "pldoc/pldoc_modes:is_mode/1": {
    "body": ["is_mode(${1:Head})$2\n$0" ],
    "description":"  is_mode(@Head) is semidet.\n\n   True if Head is a valid mode-term.",
    "prefix":"is_mode"
  },
  "pldoc/pldoc_modes:mode/2": {
    "body": ["mode(${1:Head}, ${2:Det})$3\n$0" ],
    "description":"  mode(:Head, ?Det) is nondet.\n\n   True if there is a mode-declaration for Head with Det.\n\n   @param  Head    Callable term.  Arguments are a mode-indicator\n                   followed by a type.\n   @param  Det     One of =unknown=, =det=, =semidet=, or =nondet=.",
    "prefix":"mode"
  },
  "pldoc/pldoc_modes:mode_indicator/1": {
    "body": ["mode_indicator(${1:Ind})$2\n$0" ],
    "description":"  mode_indicator(?Ind:atom) is nondet.\n\n   Our defined argument-mode indicators",
    "prefix":"mode_indicator"
  },
  "pldoc/pldoc_modes:modes_to_predicate_indicators/2": {
    "body": ["modes_to_predicate_indicators(${1:Modes}, ${2:PI})$3\n$0" ],
    "description":"  modes_to_predicate_indicators(+Modes:list, -PI:list) is det.\n\n   Create a list of predicate indicators represented by Modes. Each\n   predicate indicator is  of  the   form  atom/integer  for normal\n   predicates or atom//integer for DCG rules.\n\n   @param Modes    Mode-list as produced by process_modes/5\n   @param PI       List of Name/Arity or Name//Arity without duplicates",
    "prefix":"modes_to_predicate_indicators"
  },
  "pldoc/pldoc_pack:doc_pack/1": {
    "body": ["doc_pack(${1:Pack})$2\n$0" ],
    "description":"  doc_pack(+Pack)\n\n   Generate stand-alone documentation for  the   package  Pack. The\n   documentation is generated in a directory =doc= inside the pack.\n   The  index  page  consists  of  the    content  of  =readme=  or\n   =|readme.txt|= in the main directory of the pack and an index of\n   all files and their public predicates.",
    "prefix":"doc_pack"
  },
  "pldoc/pldoc_process:doc_comment/4": {
    "body": ["doc_comment(${1:Objects}, ${2:Pos}, ${3:\n%}, ${4:Comment})$5\n$0" ],
    "description":"  doc_comment(?Objects, -Pos,\n              -Summary:string, -Comment:string) is nondet.\n\n   True if Comment is the  comment   describing  object. Comment is\n   returned as a string object  containing   the  original from the\n   source-code.  Object is one of\n\n           * Name/Arity\n           Predicate indicator\n\n           * Name//Arity\n           DCG rule indicator.  Same as Name/Arity+2\n\n           * module(ModuleTitle)\n           Comment appearing in a module.\n\n   If Object is  unbound  and  multiple   objects  share  the  same\n   description, Object is unified with a   list  of terms described\n   above.\n\n   @param Summary  First sentence.  Normalised spacing.\n   @param Comment  Comment string from the source-code (untranslated)",
    "prefix":"doc_comment"
  },
  "pldoc/pldoc_process:doc_file_has_comments/1": {
    "body": ["doc_file_has_comments(${1:Source})$2\n$0" ],
    "description":"  doc_file_has_comments(+Source:atom) is semidet.\n\n   True if we have loaded comments from Source.",
    "prefix":"doc_file_has_comments"
  },
  "pldoc/pldoc_process:doc_file_name/3": {
    "body": ["doc_file_name(${1:Source}, ${2:Doc}, ${3:Options})$4\n$0" ],
    "description":"  doc_file_name(+Source:atom, -Doc:atom, +Options:list) is det.\n\n   Doc is the name of the file for documenting Source.\n\n   @param Source   Prolog source to be documented\n   @param Doc      the name of the file documenting Source.\n   @param Options  Option list:\n\n                   * format(+Format)\n                   Output format.  One of =html= or =tex=\n\n   @error  permission_error(overwrite, Source)",
    "prefix":"doc_file_name"
  },
  "pldoc/pldoc_process:is_structured_comment/2": {
    "body": ["is_structured_comment(${1:Comment}, ${2:\n%})$3\n$0" ],
    "description":"  is_structured_comment(+Comment:string,\n                        -Prefixes:list(codes)) is semidet.\n\n   True if Comment is a structured comment that should use Prefixes\n   to extract the plain text using indented_lines/3.",
    "prefix":"is_structured_comment"
  },
  "pldoc/pldoc_process:parse_comment/3": {
    "body": ["parse_comment(${1:Comment}, ${2:FilePos}, ${3:Parsed})$4\n$0" ],
    "description":"  parse_comment(+Comment, +FilePos, -Parsed) is semidet.\n\n   True when Comment is a  structured   comment  and  Parsed is its\n   parsed representation. Parsed is a list of the following terms:\n\n     * section(Id, Title, Comment)\n     Generated from /** <module> Title Comment */ comments.\n     * predicate(PI, Summary, Comment)\n     Comment for predicate PI\n     * link(FromPI, ToPI)\n     Indicate that FromPI shares its comment with ToPI.  The actual\n     comment is in ToPI.\n     * mode(Head, Determinism)\n     Mode declaration.  Head is a term with Mode(Type) terms and\n     Determinism describes the associated determinism (=det=,\n     etc.).",
    "prefix":"parse_comment"
  },
  "pldoc/pldoc_process:process_comments/3": {
    "body": ["process_comments(${1:Comments}, ${2:TermPos}, ${3:File})$4\n$0" ],
    "description":"  process_comments(+Comments:list, +TermPos, +File) is det.\n\n   Processes comments returned by read_term/3 using the =comments=\n   option.  It creates clauses of the form\n\n           * '$mode'(Head, Det)\n           * '$pldoc'(Id, Pos, Summary, Comment)\n           * '$pldoc_link'(Id0, Id)\n\n   where Id is one of\n\n           * module(Title)\n           Generated from /** <module> Title */\n           * Name/Arity\n           Generated from Name(Arg, ...)\n           * Name//Arity\n           Generated from Name(Arg, ...)//\n\n   @param Comments is a list Pos-Comment returned by read_term/3\n   @param TermPos is the start-location of the actual term\n   @param File is the file that is being loaded.",
    "prefix":"process_comments"
  },
  "pldoc/pldoc_register:process_stored_comments/0": {
    "body": ["process_stored_comments$1\n$0" ],
    "description":"process_stored_comments",
    "prefix":"process_stored_comments"
  },
  "pldoc/pldoc_search:matching_object_table/4": {
    "body": [
      "matching_object_table(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"matching_object_table('Param1','Param2','Param3','Param4')",
    "prefix":"matching_object_table"
  },
  "pldoc/pldoc_search:search_form/3": {
    "body": ["search_form(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"search_form('Param1','Param2','Param3')",
    "prefix":"search_form"
  },
  "pldoc/pldoc_search:search_reply/4": {
    "body": [
      "search_reply(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"search_reply('Param1','Param2','Param3','Param4')",
    "prefix":"search_reply"
  },
  "pldoc/pldoc_wiki:autolink_extension/2": {
    "body": ["autolink_extension(${1:Ext}, ${2:Type})$3\n$0" ],
    "description":"  autolink_extension(?Ext, ?Type) is nondet.\n\n   True if Ext is a filename extensions that create automatic links\n   in the documentation.",
    "prefix":"autolink_extension"
  },
  "pldoc/pldoc_wiki:autolink_file/2": {
    "body": ["autolink_file(${1:File}, ${2:Type})$3\n$0" ],
    "description":"  autolink_file(?File, -Type) is nondet.\n\n   Files to which we automatically create links, regardless of the\n   extension.",
    "prefix":"autolink_file"
  },
  "pldoc/pldoc_wiki:normalise_white_space/3": {
    "body": [
      "normalise_white_space(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"normalise_white_space('Param1','Param2','Param3')",
    "prefix":"normalise_white_space"
  },
  "pldoc/pldoc_wiki:section_comment_header/3": {
    "body": [
      "section_comment_header(${1:Lines}, ${2:Header}, ${3:RestLines})$4\n$0"
    ],
    "description":"  section_comment_header(+Lines, -Header, -RestLines) is semidet.\n\n   Processes   /**   <section>   comments.   Header   is   a   term\n   \\section(Type, Title), where  Title  is   an  atom  holding  the\n   section title and Type is an atom holding the text between <>.\n\n   @param Lines    List of Indent-Codes.\n   @param Header   DOM term of the format \\section(Type, Title),\n                   where Type is an atom from <type> and Title is\n                   a string holding the type.",
    "prefix":"section_comment_header"
  },
  "pldoc/pldoc_wiki:strip_leading_par/2": {
    "body": ["strip_leading_par(${1:Dom0}, ${2:Dom})$3\n$0" ],
    "description":"  strip_leading_par(+Dom0, -Dom) is det.\n\n   Remove the leading paragraph for  environments where a paragraph\n   is not required.",
    "prefix":"strip_leading_par"
  },
  "pldoc/pldoc_wiki:wiki_codes_to_dom/3": {
    "body": ["wiki_codes_to_dom(${1:String}, ${2:Args}, ${3:DOM})$4\n$0" ],
    "description":"  wiki_codes_to_dom(+String, +Args, -DOM) is det.\n\n   Translate a plain text into a DOM term.\n\n   @param String   Plain text.  Either a string or a list of codes.",
    "prefix":"wiki_codes_to_dom"
  },
  "pldoc:doc_collect/1": {
    "body": ["doc_collect(${1:Bool})$2\n$0" ],
    "description":"  doc_collect(+Bool) is det.\n\n   Switch collecting comments true/false.   This autoload predicate\n   can be used to force loading  the   pldoc  library. In a typical\n   development setup loading pldoc  is   normally  triggered  using\n   doc_server/1.",
    "prefix":"doc_collect"
  },
  "pldoc:pldoc_loading/0": {
    "body": ["pldoc_loading$1\n$0" ],
    "description":"  pldoc_loading is semidet.\n\n   True if we are loading the  PlDoc libraries. Required internally\n   to avoid undefined predicates  while   re-loading  and  document\n   itself.",
    "prefix":"pldoc_loading"
  },
  "pldoc_files:doc_pack/1": {
    "body": ["doc_pack(${1:'Param1'})$2\n$0" ],
    "description":"doc_pack('Param1')",
    "prefix":"doc_pack"
  },
  "pldoc_files:doc_save/2": {
    "body": ["doc_save(${1:FileOrDir}, ${2:Options})$3\n$0" ],
    "description":"  doc_save(+FileOrDir, +Options)\n\n   Save documentation for FileOrDir to file(s).  Options include\n\n           * format(+Format)\n           Currently only supports =html=.\n\n           * doc_root(+Dir)\n           Save output to the given directory.  Default is to save\n           the documentation for a file in the same directory as\n           the file and for a directory in a subdirectory =doc=.\n\n           * title(+Title)\n           Title is an atom that provides the HTML title of the\n           main (index) page.  Only meaningful when generating\n           documentation for a directory.\n\n           * man_server(+RootURL)\n           Root of a manual server used for references to built-in\n           predicates. Default is\n           =|http://www.swi-prolog.org/pldoc/|=\n\n           * index_file(+Base)\n           Filename for directory indices.  Default is =index=.\n\n           * if(Condition)\n           What to do with files in a directory.  =loaded= (default)\n           only documents files loaded into the Prolog image.  =true=\n           documents all files.\n\n           * recursive(+Bool)\n           If =true=, recurse into subdirectories.\n\n           * css(+Mode)\n           If =copy=, copy the CSS file to created directories.\n           Using =inline=, include the CSS file into the created\n           files.  Currently, only the default =copy= is supported.\n\n   The typical use-case is to document the Prolog files that belong\n   to a project in the  current  directory.   To  do  this load the\n   Prolog  files  and  run  the   goal    below.   This  creates  a\n   sub-directory  =doc=  with  an  index  file  =|index.html|=.  It\n   replicates the directory structure  of   the  source  directory,\n   creating an HTML file for each Prolog file and an index file for\n   each sub-directory. A  copy  of  the   required  CSS  and  image\n   resources is copied to the =doc= directory.\n\n     ==\n     ?- doc_save(., [recursive(true)]).\n     ==",
    "prefix":"doc_save"
  },
  "pldoc_http:doc_browser/0": {
    "body": ["doc_browser$1\n$0" ],
    "description":"  doc_browser is det.\n  doc_browser(+What) is semidet.\n\n   Open user's default browser on the documentation server.",
    "prefix":"doc_browser"
  },
  "pldoc_http:doc_browser/1": {
    "body": ["doc_browser(${1:What})$2\n$0" ],
    "description":"  doc_browser is det.\n  doc_browser(+What) is semidet.\n\n   Open user's default browser on the documentation server.",
    "prefix":"doc_browser"
  },
  "pldoc_http:doc_server/1": {
    "body": ["doc_server(${1:Port})$2\n$0" ],
    "description":"  doc_server(?Port) is det.\n  doc_server(?Port, +Options) is det.\n\n   Start a documentation server in the  current Prolog process. The\n   server is started in a seperate   thread.  Options are handed to\n   http_server/2.  In  addition,   the    following   options   are\n   recognised:\n\n           * allow(HostOrIP)\n           Allow connections from HostOrIP.  If HostOrIP is an atom\n           it is matched to the hostname.  It if starts with a .,\n           suffix match is done, matching the domain.  Finally it\n           can be a term ip(A,B,C,D). See tcp_host_to_address/2 for\n           details.\n\n           * deny(HostOrIP)\n           See allow(HostOrIP).\n\n           * edit(Bool)\n           Allow editing from localhost connections? Default:\n           =true=.\n\n   The predicate doc_server/1 is defined as below, which provides a\n   good default for development.\n\n   ==\n   doc_server(Port) :-\n           doc_server(Port,\n                      [ workers(1),\n                        allow(localhost)\n                      ]).\n   ==\n\n   @see    doc_browser/1",
    "prefix":"doc_server"
  },
  "pldoc_http:doc_server/2": {
    "body": ["doc_server(${1:Port}, ${2:Options})$3\n$0" ],
    "description":"  doc_server(?Port) is det.\n  doc_server(?Port, +Options) is det.\n\n   Start a documentation server in the  current Prolog process. The\n   server is started in a seperate   thread.  Options are handed to\n   http_server/2.  In  addition,   the    following   options   are\n   recognised:\n\n           * allow(HostOrIP)\n           Allow connections from HostOrIP.  If HostOrIP is an atom\n           it is matched to the hostname.  It if starts with a .,\n           suffix match is done, matching the domain.  Finally it\n           can be a term ip(A,B,C,D). See tcp_host_to_address/2 for\n           details.\n\n           * deny(HostOrIP)\n           See allow(HostOrIP).\n\n           * edit(Bool)\n           Allow editing from localhost connections? Default:\n           =true=.\n\n   The predicate doc_server/1 is defined as below, which provides a\n   good default for development.\n\n   ==\n   doc_server(Port) :-\n           doc_server(Port,\n                      [ workers(1),\n                        allow(localhost)\n                      ]).\n   ==\n\n   @see    doc_browser/1",
    "prefix":"doc_server"
  },
  "pldoc_latex:doc_latex/3": {
    "body": ["doc_latex(${1:Spec}, ${2:OutFile}, ${3:Options})$4\n$0" ],
    "description":"  doc_latex(+Spec, +OutFile, +Options) is det.\n\n   Process one or  more  objects,  writing   the  LaTeX  output  to\n   OutFile.  Spec is one of:\n\n     - Name/Arity\n       Generate documentation for predicate\n     - Name//Arity\n       Generate documentation for DCG rule\n     - File\n       If File is a prolog file (as defined by\n       user:prolog_file_type/2), process using\n       latex_for_file/3, otherwise process using\n       latex_for_wiki_file/3.\n\n   Typically Spec is either a  list  of   filenames  or  a  list of\n   predicate indicators.   Defined options are:\n\n     - stand_alone(+Bool)\n       If =true= (default), create a document that can be run\n       through LaTeX.  If =false=, produce a document to be\n       included in another LaTeX document.\n     - public_only(+Bool)\n       If =true= (default), only emit documentation for\n       exported predicates.\n     - section_level(+Level)\n       Outermost section level produced. Level is the\n       name of a LaTeX section command.  Default is =section=.\n     - summary(+File)\n       Write summary declarations to the named File.\n     - modules(+List)\n       If [[Name/Arity]] needs to be resolved, search for the\n       predicates in the given modules.\n     - module(+Module)\n       Same as modules([Module]).",
    "prefix":"doc_latex"
  },
  "pldoc_latex:latex_for_file/3": {
    "body": ["latex_for_file(${1:File}, ${2:Out}, ${3:Options})$4\n$0" ],
    "description":"  latex_for_file(+File, +Out, +Options) is det.\n\n   Generate a LaTeX description of all commented predicates in\n   File, writing the LaTeX text to the stream Out. Supports\n   the options =stand_alone=, =public_only= and =section_level=.\n   See doc_latex/3 for a description of the options.",
    "prefix":"latex_for_file"
  },
  "pldoc_latex:latex_for_predicates/3": {
    "body": ["latex_for_predicates(${1:PI}, ${2:Out}, ${3:Options})$4\n$0" ],
    "description":"  latex_for_predicates(+PI:list, +Out, +Options) is det.\n\n   Generate LaTeX for a list  of   predicate  indicators. This does\n   *not*   produce   the    \\begin{description}...\\end{description}\n   environment, just a plain list   of \\predicate, etc. statements.\n   The current implementation ignores Options.",
    "prefix":"latex_for_predicates"
  },
  "pldoc_latex:latex_for_wiki_file/3": {
    "body": ["latex_for_wiki_file(${1:File}, ${2:Out}, ${3:Options})$4\n$0" ],
    "description":"  latex_for_wiki_file(+File, +Out, +Options) is det.\n\n   Write a LaTeX translation of  a  Wiki   file  to  the steam Out.\n   Supports   the   options   =stand_alone=,    =public_only=   and\n   =section_level=.  See  doc_latex/3  for  a  description  of  the\n   options.",
    "prefix":"latex_for_wiki_file"
  },
  "plunit:begin_tests/1": {
    "body": ["begin_tests(${1:UnitName})$2\n$0" ],
    "description":"  begin_tests(+UnitName:atom) is det.\n  begin_tests(+UnitName:atom, Options) is det.\n\n   Start a test-unit. UnitName is the  name   of  the test set. the\n   unit is ended by :- end_tests(UnitName).",
    "prefix":"begin_tests"
  },
  "plunit:begin_tests/2": {
    "body": ["begin_tests(${1:UnitName}, ${2:Options})$3\n$0" ],
    "description":"  begin_tests(+UnitName:atom) is det.\n  begin_tests(+UnitName:atom, Options) is det.\n\n   Start a test-unit. UnitName is the  name   of  the test set. the\n   unit is ended by :- end_tests(UnitName).",
    "prefix":"begin_tests"
  },
  "plunit:end_tests/1": {
    "body": ["end_tests(${1:Name})$2\n$0" ],
    "description":"  end_tests(+Name) is det.\n\n   Close a unit-test module.\n\n   @tbd    Run tests/clean module?\n   @tbd    End of file?",
    "prefix":"end_tests"
  },
  "plunit:load_test_files/1": {
    "body": ["load_test_files(${1:Options})$2\n$0" ],
    "description":"  load_test_files(+Options) is det.\n\n   Load .plt test-files related to loaded source-files.",
    "prefix":"load_test_files"
  },
  "plunit:run_tests/0": {
    "body": ["run_tests$1\n$0" ],
    "description":"  run_tests is semidet.\n  run_tests(+TestSet) is semidet.\n\n   Run  tests  and  report  about    the   results.  The  predicate\n   run_tests/0 runs all known  tests  that   are  not  blocked. The\n   predicate run_tests/1 takes a  specification   of  tests to run.\n   This  is  either  a  single   specification    or   a   list  of\n   specifications. Each single specification is  either the name of\n   a test-unit or a term <test-unit>:<test>, denoting a single test\n   within a unit.",
    "prefix":"run_tests"
  },
  "plunit:run_tests/1": {
    "body": ["run_tests(${1:TestSet})$2\n$0" ],
    "description":"  run_tests is semidet.\n  run_tests(+TestSet) is semidet.\n\n   Run  tests  and  report  about    the   results.  The  predicate\n   run_tests/0 runs all known  tests  that   are  not  blocked. The\n   predicate run_tests/1 takes a  specification   of  tests to run.\n   This  is  either  a  single   specification    or   a   list  of\n   specifications. Each single specification is  either the name of\n   a test-unit or a term <test-unit>:<test>, denoting a single test\n   within a unit.",
    "prefix":"run_tests"
  },
  "plunit:running_tests/0": {
    "body": ["running_tests$1\n$0" ],
    "description":"  running_tests is det.\n\n   Print the currently running test.",
    "prefix":"running_tests"
  },
  "plunit:set_test_options/1": {
    "body": ["set_test_options(${1:Options})$2\n$0" ],
    "description":"  set_test_options(+Options)\n\n   Specifies how to deal with test suites.  Defined options are:\n\n           * load(+Load)\n           Whether or not the tests must be loaded.  Values are\n           =never=, =always=, =normal= (only if not optimised)\n\n           * run(+When)\n           When the tests are run.  Values are =manual=, =make=\n           or make(all).\n\n           * silent(+Bool)\n           If =true= (default =false=), report successful tests\n           using message level =silent=, only printing errors and\n           warnings.\n\n           * sto(+Bool)\n           How to test whether code is subject to occurs check\n           (STO).  If =false= (default), STO is not considered.\n           If =true= and supported by the hosting Prolog, code\n           is run in all supported unification mode and reported\n           if the results are inconsistent.\n\n           * cleanup(+Bool)\n           If =true= (default =false), cleanup report at the end\n           of run_tests/1.  Used to improve cooperation with\n           memory debuggers such as dmalloc.",
    "prefix":"set_test_options"
  },
  "plunit:test_report/1": {
    "body": ["test_report(${1:What})$2\n$0" ],
    "description":"  test_report(What) is det.\n\n   Produce reports on test results after the run.",
    "prefix":"test_report"
  },
  "plus/3": {
    "body":"plus(${1:Int1}, ${2:Int2}, ${3:Int3})$4\n$0",
    "description":"plus(?Int1, ?Int2, ?Int3).\nTrue if Int3 = Int1 + Int2.  At least two of the three arguments must be instantiated to integers.",
    "prefix":"plus"
  },
  "popcount/1": {
    "body":"popcount(${1:IntExpr})$2\n$0",
    "description":"popcount(+IntExpr).\nReturn the number of 1s in the binary representation of the non-negative  integer IntExpr.",
    "prefix":"popcount"
  },
  "porter_stem/2": {
    "body":"porter_stem(${1:In}, ${2:Stem})$3\n$0",
    "description":"porter_stem(+In, -Stem).\nDetermine the stem of In. In must represent ISO  Latin-1 text. The porter_stem/2  predicate first maps In to lower case, then removes all  accents as in unaccent_atom/2  and finally applies the Porter stem algorithm.",
    "prefix":"porter_stem"
  },
  "porter_stem:atom_to_stem_list/2": {
    "body": ["atom_to_stem_list(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"atom_to_stem_list('Param1','Param2')",
    "prefix":"atom_to_stem_list"
  },
  "porter_stem:porter_stem/2": {
    "body": ["porter_stem(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"porter_stem('Param1','Param2')",
    "prefix":"porter_stem"
  },
  "porter_stem:tokenize_atom/2": {
    "body": ["tokenize_atom(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"tokenize_atom('Param1','Param2')",
    "prefix":"tokenize_atom"
  },
  "porter_stem:unaccent_atom/2": {
    "body": ["unaccent_atom(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"unaccent_atom('Param1','Param2')",
    "prefix":"unaccent_atom"
  },
  "portray/1": {
    "body":"portray(${1:Term})$2\n$0",
    "description":"portray(+Term).\nA dynamic predicate, which can be defined by the user to change the  behaviour of print/1  on (sub)terms. For each subterm encountered that is not a variable print/1  first calls portray/1  using the term as argument. For lists, only the list as a whole is given  to portray/1.  If portray/1  succeeds print/1  assumes the term has been written.",
    "prefix":"portray"
  },
  "portray_clause/1": {
    "body":"portray_clause(${1:Clause})$2\n$0",
    "description":"portray_clause(+Clause).\nPretty print a clause. A clause should be specified as a term `<Head>  :- <Body>'. Facts are represented as `<Head>  :- true' or simply <Head>.  Variables in the clause are written as A, B, ... .  Singleton variables are written as _. See also portray_clause/2.",
    "prefix":"portray_clause"
  },
  "portray_clause/2": {
    "body":"portray_clause(${1:Stream}, ${2:Clause})$3\n$0",
    "description":"portray_clause(+Stream, +Clause).\nPretty print a clause to Stream. See portray_clause/1  for details.",
    "prefix":"portray_clause"
  },
  "portray_text:portray_text/1": {
    "body": ["portray_text(${1:Boolean})$2\n$0" ],
    "description":"  portray_text(+Boolean) is det.\n\n   If =true=, write lists of character   codes as \"...\" to simplify\n   debugging.",
    "prefix":"portray_text"
  },
  "portray_text:set_portray_text/2": {
    "body": ["set_portray_text(${1:Name}, ${2:Value})$3\n$0" ],
    "description":"  set_portray_text(+Name, +Value) is det.\n\n   Set options for writing lists as strings.  Options are\n\n       * min_length\n       Only consider lists that are at least this long\n       * ellipsis\n       Write strings that are longer as \"start...end\"",
    "prefix":"set_portray_text"
  },
  "powm/3": {
    "body":"powm(${1:IntExprBase}, ${2:IntExprExp}, ${3:IntExprMod})$4\n$0",
    "description":"powm(+IntExprBase, +IntExprExp, +IntExprMod).\nResult = (IntExprBase**IntExprExp)  modulo IntExprMod. Only available when compiled with  unbounded integer support. This formula is required for Diffie-Hellman  key-exchange, a technique where two parties can establish a secret key  over a public network. IntExprBase and IntExprExp must be non-negative (>=0), IntExprMod must be positive (>0).107The  underlying GMP mpz_powm() function allows negative values under some  conditions. As the conditions are expensive to pre-compute, error  handling from GMP is non-trivial and negative values are not needed for  Diffie-Hellman key-exchange we do not support these.",
    "prefix":"powm"
  },
  "predicate_options:assert_predicate_options/4": {
    "body":"assert_predicate_options(${1:PI}, ${2:Arg}, ${3:Options}, ${4:New})$5\n$0",
    "description":"[semidet]assert_predicate_options(:PI, +Arg, +Options, ?New).\nAs predicate_options(:PI, +Arg, +Options). New  is a boolean indicating whether the declarations have changed. If New  is provided and false, the predicate becomes semidet and  fails without modifications if modifications are required.",
    "prefix":"assert_predicate_options"
  },
  "predicate_options:check_predicate_option/3": {
    "body":"check_predicate_option(${1:PI}, ${2:Arg}, ${3:Option})$4\n$0",
    "description":"[det]check_predicate_option(:PI, +Arg, +Option).\nVerify predicate options at runtime. Similar to current_predicate_option/3,  but intended to support runtime checking.  Errors: - existence_error(option, OptionName) if the option is not  supported by PI.  - type_error(Type, Value) if the option is supported but  the value does not match the option type. See must_be/2.\n\n ",
    "prefix":"check_predicate_option"
  },
  "predicate_options:check_predicate_options/0": {
    "body": ["check_predicate_options$1\n$0" ],
    "description":"  check_predicate_options is det.\n\n   Analyse loaded program for  erroneous   options.  This predicate\n   decompiles  the  current  program  and  searches  for  calls  to\n   predicates that process  options.  For   each  option  list,  it\n   validates  whether  the  provided  options   are  supported  and\n   validates the argument type.  This   predicate  performs partial\n   dataflow analysis to track option-lists inside a clause.\n\n   @see    derive_predicate_options/0 can be used to derive\n           declarations for predicates that pass options. This\n           predicate should normally be called before\n           check_predicate_options/0.",
    "prefix":"check_predicate_options"
  },
  "predicate_options:check_predicate_options/1": {
    "body": ["check_predicate_options(${1:PredicateIndicator})$2\n$0" ],
    "description":"  check_predicate_options(:PredicateIndicator) is det.\n\n   Verify calls to predicates that have   options in all clauses of\n   the predicate indicated by PredicateIndicator.",
    "prefix":"check_predicate_options"
  },
  "predicate_options:current_option_arg/2": {
    "body":"current_option_arg(${1:PI}, ${2:Arg})$3\n$0",
    "description":"[nondet]current_option_arg(:PI, ?Arg).\nTrue when Arg of PI processes predicate options.  Which options are processed can be accessed using current_predicate_option/3.",
    "prefix":"current_option_arg"
  },
  "predicate_options:current_predicate_option/3": {
    "body":"current_predicate_option(${1:PI}, ${2:Arg}, ${3:Option})$4\n$0",
    "description":"[nondet]current_predicate_option(:PI, ?Arg, ?Option).\nTrue when Arg of PI processes Option.  For example, the following is true:  \n\n?- current_predicate_option(open/4, 4, type(text)).\ntrue.\n\n  This predicate is intended to support conditional compilation using if/1  ... endif/0. The  predicate current_predicate_options/3  can be used to access the full capabilities of a predicate.\n\n",
    "prefix":"current_predicate_option"
  },
  "predicate_options:current_predicate_options/3": {
    "body":"current_predicate_options(${1:PI}, ${2:Arg}, ${3:Options})$4\n$0",
    "description":"[nondet]current_predicate_options(:PI, ?Arg, ?Options).\nTrue when Options is the current active option declaration  for PI on Arg. See predicate_options/3  for the argument descriptions. If PI is ground and refers to  an undefined predicate, the autoloader is used to obtain a definition of  the predicate.",
    "prefix":"current_predicate_options"
  },
  "predicate_options:derive_predicate_options/0": {
    "body": ["derive_predicate_options$1\n$0" ],
    "description":"  derive_predicate_options is det.\n\n   Derive  new  predicate  option    declarations.  This  predicate\n   analyses the loaded program to find clauses that process options\n   using one of  the  predicates   from  library(option)  or passes\n   options to other predicates that are   known to process options.\n   The process is repeated until no new declarations are retrieved.\n\n   @see autoload/0 may be used to complete the loaded program.",
    "prefix":"derive_predicate_options"
  },
  "predicate_options:derived_predicate_options/1": {
    "body":"derived_predicate_options(${1:Module})$2\n$0",
    "description":"[det]derived_predicate_options(+Module).\nDerive predicate option declarations for a module. The derived options  are printed to the current_output stream.",
    "prefix":"derived_predicate_options"
  },
  "predicate_options:derived_predicate_options/3": {
    "body":"derived_predicate_options(${1:PI}, ${2:Arg}, ${3:Options})$4\n$0",
    "description":"[nondet]derived_predicate_options(:PI, ?Arg, ?Options).\nDerive option arguments using static analysis. True when Options  is the current derived active option declaration for PI  on Arg.",
    "prefix":"derived_predicate_options"
  },
  "predicate_options:predicate_options/3": {
    "body":"predicate_options(${1:PI}, ${2:Arg}, ${3:Options})$4\n$0",
    "description":"[det]predicate_options(:PI, +Arg, +Options).\nDeclare that the predicate PI processes options on Arg. Options  is a list of options processed. Each element is one of:  \n\nOption(ModeAndType) PI processes Option. The option-value must comply to  ModeAndType. Mode is one of + or - and Type is a type as accepted by must_be/2.\npass_to(:PI,Arg) The option-list is passed to  the indicated predicate.\n\n  Below is an example that processes the option header(boolean)  and passes all options to open/4: \n\n\n\n:- predicate_options(write_xml_file/3, 3,\n                     [ header(boolean),\n                       pass_to(open/4, 4)\n                     ]).\n\nwrite_xml_file(File, XMLTerm, Options) :-\n    open(File, write, Out, Options),\n    (   option(header(true), Option, true)\n    ->  write_xml_header(Out)\n    ;   true\n    ),\n    ...\n\n  This predicate may only be used as a directive and is  processed by expand_term/2.  Option processing can be specified at runtime using assert_predicate_options/3,  which is intended to support program analysis.\n\n",
    "prefix":"predicate_options"
  },
  "predicate_options:retractall_predicate_options/0": {
    "body": ["retractall_predicate_options$1\n$0" ],
    "description":"  retractall_predicate_options is det.\n\n   Remove all dynamically (derived) predicate options.",
    "prefix":"retractall_predicate_options"
  },
  "predicate_property/2": {
    "body":"predicate_property(${1:Head}, ${2:Property})$3\n$0",
    "description":"predicate_property(:Head, ?Property).\nTrue when Head refers to a predicate that has property Property. With sufficiently instantiated Head, predicate_property/2  tries to resolve the predicate the same way as calling it would do: if  the predicate is not defined it scans the default modules (see default_module/2)  and finally tries the autoloader. Unlike calling, failure to find the  target predicate causes predicate_property/2  to fail silently. If Head is not sufficiently bound, only  currently locally defined and already imported predicates are  enumerated. See current_predicate/1  for enumerating all predicates. A common issue concerns generating  all built-in predicates. This can be achieved using the code below:  \n\ngenerate_built_in(Name/Arity) :-\n    predicate_property(system:Head, built_in),\n    functor(Head, Name, Arity),\n    \\+ sub_atom(Name, 0, _, _, $).   % discard reserved names\n\n  Property is one of: \n\nautoload(File): True if the predicate can be autoloaded from the file File.  Like undefined, this property is not generated.\n\nbuilt_in: True if the predicate is locked as a built-in predicate. This implies it  cannot be redefined in its definition module and it can normally not be  seen in the tracer.\n\ndefined: True if the predicate is defined. This property is aware of sources  being reloaded, in which case it claims the predicate defined  only if it is defined in another source or it has seen a definition in  the current source. See compile_aux_clauses/1.\n\ndynamic: True if assert/1  and retract/1  may be used to modify the predicate. This property is set using dynamic/1.\n\nexported: True if the predicate is in the public list of the context module.\n\nimported_from(Module): Is true if the predicate is imported into the context module from module Module.\n\nfile(FileName): Unify FileName with the name of the source file in which the  predicate is defined. See also source_file/2  and the property line_count. Note that this reports the file of the first  clause of a predicate. A more robust interface can be achieved using nth_clause/3  and clause_property/2.\n\nforeign: True if the predicate is defined in the C language.\n\nimplementation_module(-Module): True when Module is the module in which Head is or  will be defined. Resolving this property goes through the same search  mechanism as when the an undefined predicate is encountered, but does  not perform any loading. It searches (1) the module inheritence  hierarchy (see default_module/2)  and (2) the autoload index if the unknown  flag is not set to fail in the target module.\n\nindexed(Indexes): Indexes75This predicate  property should be used for analysis and statistics only. The exact  representation of Indexes may change between versions.  is a list of additional (hash) indexes on the predicate. Each element of  the list is a term ArgSpec-Index. Currently ArgSpec is an  integer denoting the argument position and Index is a term hash(Buckets, Speedup, IsList). Here Buckets is  the number of buckets in the hash and Speedup is the expected  speedup relative to trying all clauses linearly. IsList  indicates that a list is created for all clauses with the same key. This  is currently not used.\n\ninterpreted: True if the predicate is defined in Prolog. We return true on this  because, although the code is actually compiled, it is completely  transparent, just like interpreted code.\n\niso: True if the predicate is covered by the ISO standard (ISO/IEC 13211-1).\n\nline_count(LineNumber): Unify LineNumber with the line number of the first clause of  the predicate. Fails if the predicate is not associated with a file. See  also source_file/2.  See also the file property above, notably the reference to clause_property/2.\n\nmultifile: True if there may be multiple (or no) files providing clauses for the  predicate. This property is set using multifile/1.\n\nmeta_predicate(Head): If the predicate is declared as a meta-predicate using meta_predicate/1,  unify Head with the head-pattern. The head-pattern is a  compound term with the same name and arity as the predicate where each  argument of the term is a meta-predicate specifier. See meta_predicate/1  for details.\n\nnodebug: Details of the predicate are not shown by the debugger. This is the  default for built-in predicates. User predicates can be compiled this  way using the Prolog flag generate_debug_info.\n\nnotrace: Do not show ports of this predicate in the debugger.\n\nnumber_of_clauses(ClauseCount): Unify ClauseCount to the number of clauses associated with  the predicate. Fails for foreign predicates.\n\nnumber_of_rules(RuleCount): Unify RuleCount to the number of clauses associated with the  predicate. A rule is defined as a clauses that has a body that  is not just true (i.e., a fact). Fails for foreign  predicates. This property is used to avoid analysing predicates with  only facts in library(prolog_codewalk).\n\npublic: Predicate is declared public using public/1.  Note that without further definition, public predicates are considered  undefined and this property is not reported.\n\nquasi_quotation_syntax: The predicate (with arity4) is declared to provide quasi quotation  syntax with quasi_quotation_syntax/1.\n\nstatic: The definition can not be modified using assertz/1  and friends. This property is the opposite from dynamic,  i.e., for each defined predicate, either static or dynamic  is true but never both.\n\nthread_local: If true (only possible on the multithreaded version) each thread has its  own clauses for the predicate. This property is set using thread_local/1.\n\ntransparent: True if the predicate is declared transparent using the module_transparent/1  or meta_predicate/1  declaration. In the latter case the property meta_predicate(Head)  is also provided. See chapter 6  for details.\n\nundefined: True if a procedure definition block for the predicate exists, but there  are no clauses for it and it is not declared dynamic or multifile. This  is true if the predicate occurs in the body of a loaded predicate, an  attempt to call it has been made via one of the meta-call predicates,  the predicate has been declared as e.g., a meta-predicate or the  predicate had a definition in the past. Originally used to find missing  predicate definitions. The current implementation of list_undefined/0  used cross-referencing. Deprecated.\n\nvisible: True when predicate can be called without raising a predicate existence  error. This means that the predicate is (1) defined, (2) can be  inherited from one of the default modules (see default_module/2)  or (3) can be autoloaded. The behaviour is logically consistent iff the  property visible is provided explicitly. If the property is left  unbound, only defined predicates are enumerated.\n\nvolatile: If true, the clauses are not saved into a saved state by qsave_program/[1,2].  This property is set using volatile/1.\n\n ",
    "prefix":"predicate_property"
  },
  "predsort/3": {
    "body":"predsort(${1:Pred}, ${2:List}, ${3:Sorted})$4\n$0",
    "description":"predsort(+Pred, +List, -Sorted).\nSorts similar to sort/2,  but determines the order of two terms by calling Pred(-Delta,  +E1, +E2) . This call must unify Delta  with one of <, >  or =. If the built-in predicate compare/3  is used, the result is the same as sort/2.  See also keysort/2.",
    "prefix":"predsort"
  },
  "prefix_string/3": {
    "body":"prefix_string(${1:Table}, ${2:Prefix}, ${3:String})$4\n$0",
    "description":"prefix_string(+Table, +Prefix, +String).\nSucceeds if Prefix is a prefix of String using the  named Table.",
    "prefix":"prefix_string"
  },
  "prefix_string/4": {
    "body":"prefix_string(${1:Table}, ${2:Prefix}, ${3:Rest}, ${4:String})$5\n$0",
    "description":"prefix_string(+Table, +Prefix, -Rest, +String).\nSucceeds if Prefix is a prefix of String using the  named Table, and Rest is unified with the remainder of String that is not matched. Please note that the existence of  an order-table implies simple contatenation using atom_concat/3  cannot be used to determine the non-matched part of the string.",
    "prefix":"prefix_string"
  },
  "print/1": {
    "body":"print(${1:Term})$2\n$0",
    "description":"print(+Term).\nPrint a term for debugging purposes. The predicate print/1  acts as if defined as below.  \n\nprint(Term) :-\n    current_prolog_flag(print_write_options, Options), !,\n    write_term(Term, Options).\nprint(Term) :-\n    write_term(Term, [ portray(true),\n                       numbervars(true),\n                       quoted(true)\n                     ]).\n\n  The print/1  predicate is used primarily through the ~p escape sequence  of format/2,  which is commonly used in the recipies used by print_message/2  to emit messages. \n\nThe classical definition of this predicate is equivalent to the ISO  predicate write_term/2  using the options portray(true) and numbervars(true). The portray(true) option  allows the user to implement application-specific printing of terms  printed during debugging to facilitate easy understanding of the output.  See also portray/1  and library(portray_text). SWI-Prolog adds quoted(true)  to (1) facilitate the copying/pasting of terms that are not affected by portray/1  and to (2) allow numbers, atoms and strings to be more easily  distinguished, e.g., 42, '42' and \"42\".\n\n",
    "prefix":"print"
  },
  "print/2": {
    "body":"print(${1:Stream}, ${2:Term})$3\n$0",
    "description":"print(+Stream, +Term).\nPrint Term to Stream.",
    "prefix":"print"
  },
  "print_message/2": {
    "body":"print_message(${1:Kind}, ${2:Term})$3\n$0",
    "description":"print_message(+Kind, +Term).\nThe predicate print_message/2  is used by the system and libraries to print messages. Kind  describes the nature of the message, while Term is a Prolog term that describes the content. Printing  messages through this indirection instead of using format/3  to the stream user_error allows displaying the message  appropriate to the application (terminal, logfile, graphics), acting on  messages based on their content instead of a string (see message_hook/3)  and creating language specific versions of the messages. See also section 4.11.3.1. The following  message kinds are known:  banner: The system banner message. Banner messages can be suppressed by setting  the Prolog flag verbose  to silent.\n\ndebug(Topic): Message from library(debug). See debug/3.\n\nerror: The message indicates an erroneous situation. This kind is used to print  uncaught exceptions of type error(Formal, Context). See  section introduction (section  4.11.3).\n\nhelp: User requested help message, for example after entering `h' or `?' to a  prompt.\n\ninformation: Information that is requested by the user. An example is statistics/0.\n\ninformational: Typically messages of events are progres that are considered useful to a  developer. Such messages can be suppressed by setting the Prolog flag verbose  to silent.\n\nsilent: Message that is normally not printed. Applications may define message_hook/3  to act upon such messages.\n\ntrace: Messages from the (command line) tracer.\n\nwarning: The message indicates something dubious that is not considered fatal.  For example, discontiguous predicates (see discontiguous/1).\n\n  The predicate print_message/2  first translates the Term into a list of `message lines' (see print_message_lines/3  for details). Next, it calls the hook message_hook/3  to allow the user to intercept the message. If message_hook/3  fails it prints the message unless Kind is silent. \n\nThe print_message/2  predicate and its rules are in the file <plhome>/boot/messages.pl, which may be  inspected for more information on the error messages and related error  terms. If you need to write messages from your own predicates, it is  recommended to reuse the existing message terms if applicable. If no  existing message term is applicable, invent a fairly unique term that  represents the event and define a rule for the multifile predicate  prolog:message//1. See section 4.11.3.1 for a deeper  discussion and examples. \n\nSee also message_to_string/2.\n\n",
    "prefix":"print_message"
  },
  "print_message_lines/3": {
    "body":"print_message_lines(${1:Stream}, ${2:Prefix}, ${3:Lines})$4\n$0",
    "description":"print_message_lines(+Stream, +Prefix, +Lines).\nPrint a message (see print_message/2)  that has been translated to a list of message elements. The elements of  this list are:  <Format>-<Args>: Where Format is an atom and Args is a list of  format arguments. Handed to format/3.\n\nflush: If this appears as the last element, Stream is flushed (see flush_output/1)  and no final newline is generated. This is combined with a subsequent  message that starts with at_same_line to complete the line.\n\nat_same_line: If this appears as first element, no prefix is printed for the first  line and the line position is not forced to 0 (see format/1, ~N).\n\nansi(+Attributes, +Format, +Args): This message may be intercepted by means of the hook  prolog:message_line_element/2. The library library(ansi_term)  implements this hook to achieve coloured output. If it is not  intercepted it invokes format(Stream, Format, Args).\n\nnl: A new line is started. If the message is not complete, Prefix is printed before the remainder of the message.\n\nbegin(Kind, Var): end(Var): The entire message is headed by begin(Kind, Var) and ended  by end(Var). This feature is used by, e.g., library library(ansi_term)  to colour entire messages.\n\n<Format>: Handed to format/3  as format(Stream, Format,[]). Deprecated because it is  ambiguous if Format collides with one of the atomic commands.\n\n  See also print_message/2  and message_hook/3.\n\n",
    "prefix":"print_message_lines"
  },
  "process:is_process/1": {
    "body":"is_process(${1:PID})$2\n$0",
    "description":"[semidet]is_process(+PID).\nTrue if PID might be a process. Succeeds for any positive  integer.",
    "prefix":"is_process"
  },
  "process:process_create/3": {
    "body":"process_create(${1:Exe}, ${2:Args}, ${3:Options})$4\n$0",
    "description":"[det]process_create(+Exe, +Args:list, +Options).\nCreate a new process running the file Exe and using arguments  from the given list. Exe is a file specification as handed to absolute_file_name/3. Typically one use  the path file alias to specify an executable file on the  current PATH. Args is a list of arguments that are handed to  the new process. On Unix systems, each element in the list becomes a  seperate argument in the new process. In Windows, the arguments are  simply concatenated to form the commandline. Each argument itself is  either a primitive or a list of primitives. A primitive is either atomic  or a term file(Spec). Using file(Spec), the  system inserts a filename using the OS filename conventions which is  properly quoted if needed.  Options: \n\nstdin(Spec): stdout(Spec): stderr(Spec): Bind the standard streams of the new process. Spec is one of  the terms below. If pipe(Pipe) is used, the Prolog stream  is a stream in text-mode using the encoding of the default locale. The  encoding can be changed using set_stream/2.  The options stdout and stderr may use the same  stream, in which case both output streams are connected to the same  Prolog stream.  stdJust share with the Prolog I/O streamsnullBind to a null stream. Reading from such a stream returns  end-of-file, writing produces no outputpipe(-Stream)Attach input and/or output to a Prolog stream. \n\ncwd(+Directory): Run the new process in Directory. Directory can be  a compound specification, which is converted using absolute_file_name/3.\n\nenv(+List): Specify the environment for the new process. List is a list  of Name=Value terms. Note that the current implementation does not pass  any environment variables. If unspecified, the environment is inherited  from the Prolog process.\n\nprocess(-PID): Unify PID with the process id of the created process.\n\ndetached(+Bool): In Unix: If true, detach the process from the terminal  Currently mapped to setsid(); Also creates a new process  group for the child In Windows: If true, detach the process  from the current job via the CREATE_BREAKAWAY_FROM_JOB flag. In Vista  and beyond, processes launched from the shell directly have the  'compatibility assistant' attached to them automatically unless they  have a UAC manifest embedded in them. This means that you will get a  permission denied error if you try and assign the newly-created PID to a  job you create yourself.\n\nwindow(+Bool): If true, create a window for the process (Windows only)\n\npriority(+Priority): In Unix: specifies the process priority for the newly created process. Priority  must be an integer between -20 and 19. Positive values are nicer to  others, and negative values are less so. The default is zero. Users are  free to lower their own priority. Only the super-user may raise  it to less-than zero.\n\n  If the user specifies the process(-PID) option, he must  call process_wait/2 to reclaim the  process. Without this option, the system will wait for completion of the  process after the last pipe stream is closed. \n\nIf the process is not waited for, it must succeed with status 0. If  not, an process_error is raised. \n\nWindows notes \n\nOn Windows this call is an interface to the CreateProcess() API. The  commandline consists of the basename of Exe and the arguments  formed from Args. Arguments are separated by a single space.  If all characters satisfy iswalnum() it is unquoted. If the  argument contains a double-quote it is quoted using single quotes. If  both single and double quotes appear a domain_error is raised, otherwise  double-quote are used. \n\nThe CreateProcess() API has many options. Currently only the CREATE_NO_WINDOW options is supported through the window(+Bool) option. If omitted, the default is to use  this option if the application has no console. Future versions are  likely to support more window specific options and replace win_exec/2. \n\nExamples \n\nFirst, a very simple example that behaves the same as shell('ls -l'), except for error handling: \n\n\n\n?- process_create(path(ls), ['-l'], []).\n\n  The following example uses grep to find all matching lines in a file. \n\n\n\ngrep(File, Pattern, Lines) :-\n        setup_call_cleanup(\n            process_create(path(grep), [ Pattern, file(File) ],\n                           [ stdout(pipe(Out))\n                           ]),\n            read_lines(Out, Lines),\n            close(Out)).\n\nread_lines(Out, Lines) :-\n        read_line_to_codes(Out, Line1),\n        read_lines(Line1, Out, Lines).\n\nread_lines(end_of_file, _, []) :- !.\nread_lines(Codes, Out, [Line|Lines]) :-\n        atom_codes(Line, Codes),\n        read_line_to_codes(Out, Line2),\n        read_lines(Line2, Out, Lines).\n\n  Errors: process_error(Exe, Status) where Status is one of exit(Code) or killed(Signal). Raised if the  process does not exit with status 0.\n\n ",
    "prefix":"process_create"
  },
  "process:process_group_kill/1": {
    "body":"process_group_kill(${1:PID})$2\n$0",
    "description":"[det]process_group_kill(+PID).\n",
    "prefix":"process_group_kill"
  },
  "process:process_group_kill/2": {
    "body":"process_group_kill(${1:PID}, ${2:Signal})$3\n$0",
    "description":"[det]process_group_kill(+PID, +Signal).\nSend signal to the group containing process PID. Default is term. See process_wait/1 for  a description of signal handling. In Windows, the same restriction on PID  applies: it must have been created from process_create/3,  and the the group is terminated via the TerminateJobObject API.",
    "prefix":"process_group_kill"
  },
  "process:process_id/1": {
    "body":"process_id(${1:PID})$2\n$0",
    "description":"[det]process_id(-PID).\nTrue if PID is the process id of the running Prolog process.  deprecated: Use current_prolog_flag(pid, PID)\n\n ",
    "prefix":"process_id"
  },
  "process:process_id/2": {
    "body":"process_id(${1:Process}, ${2:PID})$3\n$0",
    "description":"[det]process_id(+Process, -PID).\nPID is the process id of Process. Given that they  are united in SWI-Prolog, this is a simple unify.",
    "prefix":"process_id"
  },
  "process:process_kill/1": {
    "body":"process_kill(${1:PID})$2\n$0",
    "description":"[det]process_kill(+PID).\n",
    "prefix":"process_kill"
  },
  "process:process_kill/2": {
    "body":"process_kill(${1:PID}, ${2:Signal})$3\n$0",
    "description":"[det]process_kill(+PID, +Signal).\nSend signal to process PID. Default is term. Signal  is an integer, Unix signal name (e.g. SIGSTOP) or the more  Prolog friendly variation one gets after removing SIG and  downcase the result: stop. On Windows systems, Signal  is ignored and the process is terminated using the TerminateProcess()  API. On Windows systems PID must be obtained from process_create/3,  while any PID is allowed on Unix systems.  Compatibility: SICStus does not accept the prolog friendly version. We choose to do so  for compatibility with on_signal/3.\n\n ",
    "prefix":"process_kill"
  },
  "process:process_release/1": {
    "body":"process_release(${1:PID})$2\n$0",
    "description":"process_release(+PID).\nRelease process handle. In this implementation this is the same as process_wait(PID, _).",
    "prefix":"process_release"
  },
  "process:process_wait/2": {
    "body":"process_wait(${1:PID}, ${2:Status})$3\n$0",
    "description":"[det]process_wait(+PID, -Status).\n",
    "prefix":"process_wait"
  },
  "process:process_wait/3": {
    "body":"process_wait(${1:PID}, ${2:Status}, ${3:Options})$4\n$0",
    "description":"[det]process_wait(+PID, -Status, +Options).\nTrue if PID completed with Status. This call  normally blocks until the process is finished. Options:  timeout(+Timeout): Default: infinite. If this option is a number, the waits  for a maximum of Timeout seconds and unifies Status  with timeout if the process does not terminate within Timeout. In this case PID is not  invalidated. On Unix systems only timeout 0 and infinite  are supported. A 0-value can be used to poll the status of the process.\n\nrelease(+Bool): Do/do not release the process. We do not support this flag and a  domain_error is raised if release(false) is provided.\n\n  Status is one of exit(Code)  or killed(Signal), where Code and Signal are integers. ",
    "prefix":"process_wait"
  },
  "process_rdf/3": {
    "body":"process_rdf(${1:Input}, ${2:OnTriples}, ${3:Options})$4\n$0",
    "description":"process_rdf(+Input, :OnTriples, +Options).\n Exploits the call-back interface of sgml2pl, calling OnTriples(Triples, File:Line) with the list of  triples resulting from a single top level RDF object for each RDF  element in the input as well as the source-location where the  description started. Input is either a file name or term stream(Stream).  When using a stream all triples are associated to the value of the base_uri option. This predicate can be used to process  arbitrary large RDF files as the file is processed object-by-object. The  example below simply asserts all triples into the database: \n\n\n\nassert_list([], _).\nassert_list([H|T], Source) :-\n        assert(H),\n        assert_list(T, Source).\n\n?- process_rdf('structure,rdf', assert_list, []).\n\n  Options are described with load_rdf/3.  The option expand_foreach is not supported as the container may be in  a different description. Additional it provides embedded: \n\nembedded(Boolean): The predicate process_rdf/3  processes arbitrary XML documents, only interpreting the content of rdf:RDF  elements. If this option is false (default), it gives a  warning on elements that are not processed. The option embedded(true)  can be used to process RDF embedded in xhtml without warnings.\n\n  \n\n",
    "prefix":"process_rdf"
  },
  "profile/1": {
    "body":"profile(${1:Goal})$2\n$0",
    "description":"profile(:Goal).\nExecute Goal just like once/1,  collecting profiling statistics, and call show_profile([]).  With XPCE installed this opens a graphical interface to examine the  collected profiling data.",
    "prefix":"profile"
  },
  "profile/2": {
    "body":"profile(${1:Goal}, ${2:Options})$3\n$0",
    "description":"profile(:Goal, +Options).\nExecute Goal just like once/1.  Collect profiling statistics according to Options and call show_profile/1  with Options. The default collects CPU profiling and opens a  graphical interface when provided, printing the `plain' time usage of  the top 25 predicates as a ballback. Options are described below.  Remaining options are passed to show_profile/1.  time(+Which): If Which is cpu (default), collect CPU timing  statistics. If wall, collect wall time statistics based on  a 5 millisecond sampling rate. Wall time statistics can be useful if Goal  calls blocking system calls.\n\n ",
    "prefix":"profile"
  },
  "profiler/2": {
    "body":"profiler(${1:Old}, ${2:New})$3\n$0",
    "description":"profiler(-Old, +New).\nQuery or change the status of the profiler. The status is one of  false: The profiler is not activated.\n\ncputime: The profiler collects CPU statistics.\n\nwalltime: The profiler collects wall time statistics.\n\n  The value true is accepted as a synonym for cputime  for compatibility reasons.\n\n",
    "prefix":"profiler"
  },
  "project_attributes/2": {
    "body":"project_attributes(${1:QueryVars}, ${2:ResidualVars})$3\n$0",
    "description":"project_attributes(+QueryVars, +ResidualVars).\nA hook that can be defined in each module to project constraints on  newly introduced variables back to the query variables. QueryVars is the list of variables occurring in the query and ResidualVars is a list of variables that have attributes  attached. There may be variables that occur in both lists. If possible, project_attributes/2  should change the attributes so that all constraints are expressed as  residual goals that refer only to QueryVars, while other variables are existentially  quantified.",
    "prefix":"project_attributes"
  },
  "prolog/0": {
    "body":"prolog$1\n$0",
    "description":"prolog.\nThis goal starts the default interactive top level. Queries are read  from the stream user_input. See also the Prolog flag history. The prolog/0  predicate is terminated (succeeds) by typing the end-of-file character  (typically control-D).",
    "prefix":"prolog"
  },
  "prolog_autoload:autoload/0": {
    "body": ["autoload$1\n$0" ],
    "description":"  autoload is det.\n  autoload(+Options) is det.\n\n   Force all necessary autoloading to be done _now_.  Options:\n\n       * verbose(+Boolean)\n       If =true=, report on the files loaded.\n       * undefined(+Action)\n       Action defines what happens if the analysis finds a\n       definitely undefined predicate.  One of =ignore= or\n       =error=.",
    "prefix":"autoload"
  },
  "prolog_autoload:autoload/1": {
    "body": ["autoload(${1:Options})$2\n$0" ],
    "description":"  autoload is det.\n  autoload(+Options) is det.\n\n   Force all necessary autoloading to be done _now_.  Options:\n\n       * verbose(+Boolean)\n       If =true=, report on the files loaded.\n       * undefined(+Action)\n       Action defines what happens if the analysis finds a\n       definitely undefined predicate.  One of =ignore= or\n       =error=.",
    "prefix":"autoload"
  },
  "prolog_breakpoints:breakpoint_property/2": {
    "body": ["breakpoint_property(${1:Id}, ${2:Property})$3\n$0" ],
    "description":"  breakpoint_property(?Id, ?Property) is nondet.\n\n   True when Property is a property of the breakpoint Id.  Defined\n   properties are:\n\n       * file(File)\n       Provided if the breakpoint is in a clause associated to a\n       file.  May not be known.\n       * line_count(Line)\n       Line of the breakpoint.  May not be known.\n       * character_range(Start, Len)\n       One-based character offset of the break-point.  May not be\n       known.\n       * clause(Reference)\n       Reference of the clause in which the breakpoint resides.",
    "prefix":"breakpoint_property"
  },
  "prolog_breakpoints:delete_breakpoint/1": {
    "body": ["delete_breakpoint(${1:Id})$2\n$0" ],
    "description":"  delete_breakpoint(+Id) is det.\n\n   Delete   breakpoint   with    given     Id.    If    successful,\n   print_message(breakpoint(delete, Id)) is called.   Message hooks\n   working on this message may still call breakpoint_property/2.\n\n   @error existence_error(breakpoint, Id).",
    "prefix":"delete_breakpoint"
  },
  "prolog_breakpoints:set_breakpoint/4": {
    "body": ["set_breakpoint(${1:File}, ${2:Line}, ${3:Char}, ${4:Id})$5\n$0" ],
    "description":"  set_breakpoint(+File, +Line, +Char, -Id) is det.\n  set_breakpoint(+Owner, +File, +Line, +Char, -Id) is det.\n\n   Put a breakpoint at the  indicated   source-location.  File is a\n   current sourcefile (as reported by   source_file/1). Line is the\n   1-based line in which Char  is.  Char   is  the  position of the\n   break.\n\n   First, '$clause_from_source'/4 uses the SWI-Prolog clause-source\n   information to find  the  last   clause  starting  before  Line.\n   '$break_pc' generated (on backtracking),  a   list  of  possible\n   break-points.\n\n   Note that in addition to  setting   the  break-point, the system\n   must be in debug mode. With threading enabled, there are various\n   different ways this may  be  done.   See  debug/0,  tdebug/0 and\n   tdebug/1. Therefore, this predicate  does   *not*  enable  debug\n   mode.\n\n   @arg  Owner  denotes  the   file    that   _owns_   the  clause.\n   set_breakpoint/5 is used to set breakpoints  in an included file\n   in   the   context    of    the     Owner    main    file.   See\n   source_file_property/2.",
    "prefix":"set_breakpoint"
  },
  "prolog_breakpoints:set_breakpoint/5": {
    "body": [
      "set_breakpoint(${1:Owner}, ${2:File}, ${3:Line}, ${4:Char}, ${5:Id})$6\n$0"
    ],
    "description":"  set_breakpoint(+File, +Line, +Char, -Id) is det.\n  set_breakpoint(+Owner, +File, +Line, +Char, -Id) is det.\n\n   Put a breakpoint at the  indicated   source-location.  File is a\n   current sourcefile (as reported by   source_file/1). Line is the\n   1-based line in which Char  is.  Char   is  the  position of the\n   break.\n\n   First, '$clause_from_source'/4 uses the SWI-Prolog clause-source\n   information to find  the  last   clause  starting  before  Line.\n   '$break_pc' generated (on backtracking),  a   list  of  possible\n   break-points.\n\n   Note that in addition to  setting   the  break-point, the system\n   must be in debug mode. With threading enabled, there are various\n   different ways this may  be  done.   See  debug/0,  tdebug/0 and\n   tdebug/1. Therefore, this predicate  does   *not*  enable  debug\n   mode.\n\n   @arg  Owner  denotes  the   file    that   _owns_   the  clause.\n   set_breakpoint/5 is used to set breakpoints  in an included file\n   in   the   context    of    the     Owner    main    file.   See\n   source_file_property/2.",
    "prefix":"set_breakpoint"
  },
  "prolog_choice_attribute/3": {
    "body":"prolog_choice_attribute(${1:ChoicePoint}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"prolog_choice_attribute(+ChoicePoint, +Key, -Value).\nExtract attributes of a choice point. ChoicePoint is a  reference to a choice point as passed to prolog_trace_interception/4  on the 3rd argument or obtained using prolog_current_choice/1. Key  specifies the requested information:  parent: Requests a reference to the first older choice point.\n\nframe: Requests a reference to the frame to which the choice point refers.\n\ntype: Requests the type. Defined values are clause (the goal has  alternative clauses), foreign (non-deterministic foreign  predicate), jump (clause internal choice point), top  (first dummy choice point), catch (catch/3  to allow for undo), debug (help the debugger), or none (has been  deleted).\n\n  This predicate is used for the graphical debugger to show the choice  point stack.\n\n",
    "prefix":"prolog_choice_attribute"
  },
  "prolog_clause:clause_info/4": {
    "body": [
      "clause_info(${1:ClauseRef}, ${2:File}, ${3:TermPos}, ${4:VarOffsets})$5\n$0"
    ],
    "description":"  clause_info(+ClauseRef, -File, -TermPos, -VarOffsets) is semidet.\n  clause_info(+ClauseRef, -File, -TermPos, -VarOffsets, +Options) is semidet.\n\n   Fetches source information for the  given   clause.  File is the\n   file from which the clause  was   loaded.  TermPos describes the\n   source layout in a format   compatible  to the subterm_positions\n   option  of  read_term/2.  VarOffsets  provides   access  to  the\n   variable allocation in a stack-frame.   See  make_varnames/5 for\n   details.\n\n   Note that positions are  _|character   positions|_,  i.e., _not_\n   bytes. Line endings count as a   single character, regardless of\n   whether the actual ending is =|\\n|= or =|\\r\\n|_.\n\n   Defined options are:\n\n     * variable_names(-Names)\n     Unify Names with the variable names list (Name=Var) as\n     returned by read_term/3.  This argument is intended for\n     reporting source locations and refactoring based on\n     analysis of the compiled code.",
    "prefix":"clause_info"
  },
  "prolog_clause:clause_name/2": {
    "body": ["clause_name(${1:Ref}, ${2:Name})$3\n$0" ],
    "description":"  clause_name(+Ref, -Name)\n\n   Provide a suitable description of the indicated clause.",
    "prefix":"clause_name"
  },
  "prolog_clause:initialization_layout/4": {
    "body": [
      "initialization_layout(${1:SourceLocation}, ${2:InitGoal}, ${3:\n%}, ${4:TermPos})$5\n$0"
    ],
    "description":"  initialization_layout(+SourceLocation, ?InitGoal,\n                        -ReadGoal, -TermPos) is semidet.\n\n   Find term-layout of :- initialization directives.",
    "prefix":"initialization_layout"
  },
  "prolog_clause:predicate_name/2": {
    "body": ["predicate_name(${1:Head}, ${2:PredName})$3\n$0" ],
    "description":"  predicate_name(:Head, -PredName:string) is det.\n\n   Describe a predicate as [Module:]Name/Arity.",
    "prefix":"predicate_name"
  },
  "prolog_codewalk:prolog_program_clause/2": {
    "body": ["prolog_program_clause(${1:ClauseRef}, ${2:Options})$3\n$0" ],
    "description":"  prolog_program_clause(-ClauseRef, +Options) is nondet.\n\n   True when ClauseRef is a reference   for  clause in the program.\n   Options   is   a   subset   of    the   options   processed   by\n   prolog_walk_code/1. The logic for deciding   on which clauses to\n   enumerate is shared with prolog_walk_code/1.\n\n     * module(?Module)\n     * module_class(+list(Classes))",
    "prefix":"prolog_program_clause"
  },
  "prolog_codewalk:prolog_walk_code/1": {
    "body": ["prolog_walk_code(${1:Options})$2\n$0" ],
    "description":"  prolog_walk_code(+Options) is det.\n\n   Walk over all loaded (user) Prolog code. The following code is\n   processed:\n\n     1. The bodies of all clauses in all user and library modules.\n        This steps collects, but does not scan multifile predicates\n        to avoid duplicate work.\n     2. All multi-file predicates collected.\n     3. All goals registered with initialization/1\n\n   Options processed:\n\n     * undefined(+Action)\n     Action defines what happens if the analysis finds a\n     definitely undefined predicate.  One of =ignore= or\n     =error=.\n\n     * autoload(+Boolean)\n     Try to autoload code while walking. This is enabled by default\n     to obtain as much as possible information about goals and find\n     references from autoloaded libraries.\n\n     * clauses(+ListOfClauseReferences)\n     Only process the given clauses.  Can be used to find clauses\n     quickly using source(false) and then process only interesting\n     clauses with source information.\n\n     * module(+Module)\n     Only process the given module\n\n     * module_class(+ModuleClass)\n     Limit processing to modules of this class. See\n     module_property/2 for details on module classes.  Default\n     is to scan the classes =user= and =library=.\n\n     * infer_meta_predicates(+BooleanOrAll)\n     Use infer_meta_predicate/2 on predicates with clauses that\n     call known meta-predicates.  The analysis is restarted until\n     a fixed point is reached.  If =true= (default), analysis is\n     only restarted if the inferred meta-predicate contains a\n     callable argument.  If =all=, it will be restarted until no\n     more new meta-predicates can be found.\n\n     * trace_reference(Callable)\n     Print all calls to goals that subsume Callable. Goals are\n     represented as Module:Callable (i.e., they are always\n     qualified).  See also subsumes_term/2.\n\n     * on_trace(:OnTrace)\n     If a reference to =trace_reference= is found, call\n     call(OnTrace, Callee, Caller, Location), where Location is one\n     of these:\n\n       - clause_term_position(+ClauseRef, +TermPos)\n       - clause(+ClauseRef)\n       - file_term_position(+Path, +TermPos)\n       - file(+File, +Line, -1, _)\n       - a variable (unknown)\n\n     Caller is the qualified head of the calling clause or the\n     atom '<initialization>'.\n\n     * source(+Boolean)\n     If =false= (default =true=), to not try to obtain detailed\n     source information for printed messages.\n\n     @compat OnTrace was called using Caller-Location in older\n             versions.",
    "prefix":"prolog_walk_code"
  },
  "prolog_colour:prolog_colourise_query/3": {
    "body": [
      "prolog_colourise_query(${1:Query}, ${2:SourceId}, ${3:ColourItem})$4\n$0"
    ],
    "description":"  prolog_colourise_query(+Query:string, +SourceId, :ColourItem)\n\n   Colourise a query, to be executed in the context of SourceId.\n\n   @arg    SourceId Execute Query in the context of\n           the cross-referenced environment SourceID.",
    "prefix":"prolog_colourise_query"
  },
  "prolog_colour:prolog_colourise_stream/3": {
    "body": [
      "prolog_colourise_stream(${1:Stream}, ${2:SourceID}, ${3:ColourItem})$4\n$0"
    ],
    "description":"  prolog_colourise_stream(+Stream, +SourceID, :ColourItem) is det.\n\n   Determine colour fragments for the data   on Stream. SourceID is\n   the  canonical  identifier  of  the  input    as  known  to  the\n   cross-referencer, i.e., as created using xref_source(SourceID).\n\n   ColourItem is a closure  that  is   called  for  each identified\n   fragment with three additional arguments:\n\n     * The syntactical category\n     * Start position (character offset) of the fragment\n     * Length of the fragment (in characters).",
    "prefix":"prolog_colourise_stream"
  },
  "prolog_colour:prolog_colourise_term/4": {
    "body": [
      "prolog_colourise_term(${1:Stream}, ${2:SourceID}, ${3:ColourItem}, ${4:Options})$5\n$0"
    ],
    "description":"  prolog_colourise_term(+Stream, +SourceID, :ColourItem, +Options)\n\n   Colourise    the    next     term      on     Stream.     Unlike\n   prolog_colourise_stream/3, this predicate assumes  it is reading\n   a single term rather than the   entire stream. This implies that\n   it cannot adjust syntax according to directives that preceed it.\n\n   Options:\n\n     * subterm_positions(-TermPos)\n     Return complete term-layout.  If an error is read, this is a\n     term error_position(StartClause, EndClause, ErrorPos)",
    "prefix":"prolog_colourise_term"
  },
  "prolog_colour:syntax_colour/2": {
    "body": ["syntax_colour(${1:Class}, ${2:Attributes})$3\n$0" ],
    "description":"  syntax_colour(?Class, ?Attributes) is nondet.\n\n   True when a range  classified  Class   must  be  coloured  using\n   Attributes.  Attributes is a list of:\n\n     * colour(ColourName)\n     * background(ColourName)\n     * bold(Boolean)\n     * underline(Boolean)\n\n   Attributes may be the empty list. This   is used for cases where\n   -for example- a  menu  is  associated   with  the  fragment.  If\n   syntax_colour/2 fails, no fragment is created for the region.",
    "prefix":"syntax_colour"
  },
  "prolog_colour:syntax_message/3": {
    "body": ["syntax_message(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"syntax_message('Param1','Param2','Param3')",
    "prefix":"syntax_message"
  },
  "prolog_cover:show_coverage/1": {
    "body": ["show_coverage(${1:Goal})$2\n$0" ],
    "description":"  show_coverage(:Goal)\n\n   Report on coverage by Goal.  Goal is executed as in once/1.",
    "prefix":"show_coverage"
  },
  "prolog_current_choice/1": {
    "body":"prolog_current_choice(${1:Choice})$2\n$0",
    "description":"[semidet]prolog_current_choice(-Choice).\nUnify Choice with an integer provided a reference to the last  choice point. Fails if the current environment has no choice points. See  also prolog_choice_attribute/3.",
    "prefix":"prolog_current_choice"
  },
  "prolog_current_frame/1": {
    "body":"prolog_current_frame(${1:Frame})$2\n$0",
    "description":"[det]prolog_current_frame(-Frame).\nUnify Frame with an integer providing a reference to the  parent of the current local stack frame. A pointer to the current local  frame cannot be provided as the predicate succeeds deterministically and  therefore its frame is destroyed immediately after succeeding.",
    "prefix":"prolog_current_frame"
  },
  "prolog_cut_to/1": {
    "body":"prolog_cut_to(${1:Choice})$2\n$0",
    "description":"prolog_cut_to(+Choice).\nPrunes all choice points created since Choice. Can be used  together with prolog_current_choice/1  to implement ancestral cuts. This predicate is in the hackers  corner because it should not be used in normal Prolog code. It may be  used to create new high level control structures, particularly for  compatibility purposes.  Note that in the current implementation, the pruned choice points and  environment frames are not reclaimed. As a consequence, where  predicates that are deterministic due to clause indexing, normal cuts or (if\\send{then};else) and and tail recursive run in bounded  local stack space, predicates using prolog_cut_to/1  will run out of stack.\n\n",
    "prefix":"prolog_cut_to"
  },
  "prolog_debug/1": {
    "body":"prolog_debug(${1:Topic})$2\n$0",
    "description":"prolog_debug(+Topic).\n",
    "prefix":"prolog_debug"
  },
  "prolog_debug:assertion/1": {
    "body": ["assertion(${1:Goal})$2\n$0" ],
    "description":"  assertion(:Goal) is det.\n\n   Acts similar to C assert()  macro.  It   has  no  effect if Goal\n   succeeds. If Goal fails or throws    an exception, the following\n   steps are taken:\n\n     * call prolog:assertion_failed/2.  If prolog:assertion_failed/2\n       fails, then:\n\n       - If this is an interactive toplevel thread, print a\n         message, the stack-trace, and finally trap the debugger.\n       - Otherwise, throw error(assertion_error(Reason, G),_) where\n         Reason is one of =fail= or the exception raised.",
    "prefix":"assertion"
  },
  "prolog_debug:debug/1": {
    "body": ["debug(${1:Topic})$2\n$0" ],
    "description":"  debug(+Topic) is det.\n  nodebug(+Topic) is det.\n\n   Add/remove a topic from being   printed.  nodebug(_) removes all\n   topics. Gives a warning if the topic is not defined unless it is\n   used from a directive. The latter allows placing debug topics at\n   the start of a (load-)file without warnings.\n\n   For debug/1, Topic can be  a  term   Topic  >  Out, where Out is\n   either a stream or  stream-alias  or   a  filename  (atom). This\n   redirects debug information on this topic to the given output.",
    "prefix":"debug"
  },
  "prolog_debug:debug/3": {
    "body": ["debug(${1:Topic}, ${2:Format}, ${3:Args})$4\n$0" ],
    "description":"  debug(+Topic, +Format, :Args) is det.\n\n   Format a message if debug topic  is enabled. Similar to format/3\n   to =user_error=, but only prints if   Topic is activated through\n   debug/1. Args is a  meta-argument  to   deal  with  goal for the\n   @-command.   Output   is   first    handed     to    the    hook\n   prolog:debug_print_hook/3.  If  this  fails,    Format+Args   is\n   translated  to  text   using    the   message-translation   (see\n   print_message/2) for the  term  debug(Format,   Args)  and  then\n   printed to every matching destination   (controlled  by debug/1)\n   using print_message_lines/3.\n\n   The message is preceded by '% ' and terminated with a newline.\n\n   @see    format/3.",
    "prefix":"debug"
  },
  "prolog_debug:debug_message_context/1": {
    "body": ["debug_message_context(${1:What})$2\n$0" ],
    "description":"  debug_message_context(+What) is det.\n\n   Specify additional context for debug messages.   What  is one of\n   +Context or -Context, and Context is  one of =thread=, =time= or\n   time(Format),  where  Format  is    a  format specification  for\n   format_time/3 (default is =|%T.%3f|=).  Initially, debug/3 shows\n   only thread information.",
    "prefix":"debug_message_context"
  },
  "prolog_debug:debugging/1": {
    "body": ["debugging(${1:Topic})$2\n$0" ],
    "description":"  debugging(+Topic) is semidet.\n  debugging(-Topic) is nondet.\n  debugging(?Topic, ?Bool) is nondet.\n\n   Examine debug topics. The form debugging(+Topic)  may be used to\n   perform more complex debugging tasks.   A typical usage skeleton\n   is:\n\n     ==\n           (   debugging(mytopic)\n           ->  <perform debugging actions>\n           ;   true\n           ),\n           ...\n     ==\n\n   The other two calls are intended to examine existing and enabled\n   debugging tokens and are typically not used in user programs.",
    "prefix":"debugging"
  },
  "prolog_debug:debugging/2": {
    "body": ["debugging(${1:Topic}, ${2:Bool})$3\n$0" ],
    "description":"  debugging(+Topic) is semidet.\n  debugging(-Topic) is nondet.\n  debugging(?Topic, ?Bool) is nondet.\n\n   Examine debug topics. The form debugging(+Topic)  may be used to\n   perform more complex debugging tasks.   A typical usage skeleton\n   is:\n\n     ==\n           (   debugging(mytopic)\n           ->  <perform debugging actions>\n           ;   true\n           ),\n           ...\n     ==\n\n   The other two calls are intended to examine existing and enabled\n   debugging tokens and are typically not used in user programs.",
    "prefix":"debugging"
  },
  "prolog_debug:list_debug_topics/0": {
    "body": ["list_debug_topics$1\n$0" ],
    "description":"  list_debug_topics is det.\n\n   List currently known debug topics and their setting.",
    "prefix":"list_debug_topics"
  },
  "prolog_debug:nodebug/1": {
    "body": ["nodebug(${1:Topic})$2\n$0" ],
    "description":"  debug(+Topic) is det.\n  nodebug(+Topic) is det.\n\n   Add/remove a topic from being   printed.  nodebug(_) removes all\n   topics. Gives a warning if the topic is not defined unless it is\n   used from a directive. The latter allows placing debug topics at\n   the start of a (load-)file without warnings.\n\n   For debug/1, Topic can be  a  term   Topic  >  Out, where Out is\n   either a stream or  stream-alias  or   a  filename  (atom). This\n   redirects debug information on this topic to the given output.",
    "prefix":"nodebug"
  },
  "prolog_dialect:exists_source/1": {
    "body": ["exists_source(${1:Source})$2\n$0" ],
    "description":"  exists_source(+Source) is semidet.\n\n   True if Source (a term  valid   for  load_files/2) exists. Fails\n   without error if this is not the case. The predicate is intended\n   to be used with  :-  if,  as   in  the  example  below. See also\n   source_exports/2.\n\n   ==\n   :- if(exists_source(library(error))).\n   :- use_module_library(error).\n   :- endif.\n   ==",
    "prefix":"exists_source"
  },
  "prolog_dialect:expects_dialect/1": {
    "body": ["expects_dialect(${1:Dialect})$2\n$0" ],
    "description":"  expects_dialect(+Dialect:atom) is det.\n\n   Tell Prolog all subsequent code to the   end  of the file or the\n   next :- expects_dialect/1 directive is written for the indicated\n   Dialect.   The   current   dialect     is    available   through\n   prolog_load_context/2.\n\n   @tbd    Should we setup the dialect module only as autoload for\n           the current module?",
    "prefix":"expects_dialect"
  },
  "prolog_dialect:source_exports/2": {
    "body": ["source_exports(${1:Source}, ${2:Export})$3\n$0" ],
    "description":"  source_exports(+Source, +Export) is semidet.\n  source_exports(+Source, -Export) is nondet.\n\n   True if Source exports Export. Fails   without  error if this is\n   not the case.  See also exists_source/1.\n\n   @tbd    Should we also allow for source_exports(-Source, +Export)?",
    "prefix":"source_exports"
  },
  "prolog_edit:edit/0": {
    "body": ["edit$1\n$0" ],
    "description":"  edit\n\n   Edit associated or script file.  This is the Prolog file opened\n   by double-clicking or the file loaded using\n\n     ==\n     % swipl [-s] file.pl\n     ==",
    "prefix":"edit"
  },
  "prolog_edit:edit/1": {
    "body": ["edit(${1:Spec})$2\n$0" ],
    "description":"  edit(+Spec)\n\n   Edit indicated object.",
    "prefix":"edit"
  },
  "prolog_exception_hook/4": {
    "body":"prolog_exception_hook(${1:ExceptionIn}, ${2:ExceptionOut}, ${3:Frame}, ${4:CatcherFrame})$5\n$0",
    "description":"prolog_exception_hook(+ExceptionIn, -ExceptionOut, +Frame, +CatcherFrame).\nThis hook predicate, if defined in the module user, is  between raising an exception and handling it. It is intended to allow a  program adding additional context to an exception to simplify diagnosing  the problem. ExceptionIn is the exception term as raised by throw/1  or one of the built-in predicates. The output argument ExceptionOut  describes the exception that is actually raised. Frame is the  innermost frame. See prolog_frame_attribute/3  and the library library(prolog_stack) for getting information from this. CatcherFrame is a reference to the frame calling the matching catch/3, none  if the exception is not caught or 'C' if the exception is  caught in C calling Prolog using the flag PL_Q_CATCH_EXCEPTION.  The hook is run in `nodebug' mode. If it succeeds, ExceptionOut  is considered the current exception. If it fails, ExceptionIn  is used for further processing. The hook is never called  recursively. The hook is not allowed to modify ExceptionOut  in such a way that it no longer unifies with the catching frame. \n\nTypically, prolog_exception_hook/4  is used to fill the second argument of error(Formal, Context)  exceptions. Formal is defined by the ISO standard, while  SWI-Prolog defines Context as a term context(Location,  Message). Location is bound to a term <name>/<arity>  by the kernel. This hook can be used to add more information on the  calling context, such as a full stack trace. \n\nApplications that use exceptions as part of normal processing must do  a quick test of the environment before starting expensive gathering  information on the state of the program. \n\nThe hook can call trace/0  to enter trace mode immediately. For example, imagine an application  performing an unwanted division by zero while all other errors are  expected and handled. We can force the debugger using the hook  definition below. Run the program in debug mode (see debug/0)  to preserve as much as possible of the error context. \n\n\n\nuser:prolog_exception_hook(\n         error(evaluation_error(zero_divisor), _),\n         _, _, _) :-\n        trace, fail.\n\n  \n\n",
    "prefix":"prolog_exception_hook"
  },
  "prolog_explain:explain/1": {
    "body": ["explain(${1:Term})$2\n$0" ],
    "description":"  explain(@Term) is det\n\n   Write all information known about Term to the current output.",
    "prefix":"explain"
  },
  "prolog_explain:explain/2": {
    "body": ["explain(${1:Term}, ${2:Explanation})$3\n$0" ],
    "description":"  explain(@Term, -Explanation) is nondet.\n\n   Explanation describes information about Term.",
    "prefix":"explain"
  },
  "prolog_file_type/2": {
    "body":"prolog_file_type(${1:Extension}, ${2:Type})$3\n$0",
    "description":"prolog_file_type(?Extension, ?Type).\nThis dynamic multifile predicate defined in module user  determines the extensions considered by file_search_path/2. Extension is the filename extension without the leading dot,  and Type denotes the type as used by the file_type(Type)  option of file_search_path/2.  Here is the initial definition of prolog_file_type/2:  \n\nuser:prolog_file_type(pl,       prolog).\nuser:prolog_file_type(Ext,      prolog) :-\n        current_prolog_flag(associate, Ext),\n        Ext \\== pl.\nuser:prolog_file_type(qlf,      qlf).\nuser:prolog_file_type(Ext,      executable) :-\n        current_prolog_flag(shared_object_extension, Ext).\n\n  Users can add extensions for Prolog source files to avoid conflicts  (for example with perl) as well as to be compatible with another  Prolog implementation. We suggest using .pro for avoiding  conflicts with perl. Overriding the system definitions can stop  the system from finding libraries.\n\n",
    "prefix":"prolog_file_type"
  },
  "prolog_format:format_spec/2": {
    "body": ["format_spec(${1:Format}, ${2:Spec})$3\n$0" ],
    "description":"  format_spec(+Format, -Spec:list) is semidet.\n\n   Parse a format string. Each element of Spec is one of the following:\n\n    * text(Text)\n    Text sent to the output as is\n    * escape(Num,Colon,Action)\n    A format escape. Num represents the optional numeric portion of\n    an esape. Colon represents the optional colon in an escape.\n    Action is an atom representing the action to be take by this\n    escape.",
    "prefix":"format_spec"
  },
  "prolog_format:format_spec/3": {
    "body": ["format_spec(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"format_spec('Param1','Param2','Param3')",
    "prefix":"format_spec"
  },
  "prolog_format:format_types/2": {
    "body": ["format_types(${1:Format}, ${2:Types})$3\n$0" ],
    "description":"  format_types(+Format:text, -Types:list) is det.\n\n   True when Format requires an argument list   with  terms of the type\n   specified by Types. The  length  of  this   list  is  the  number of\n   arguments required. Each value of Types is   a  type as described by\n   error:has_type/2.",
    "prefix":"format_types"
  },
  "prolog_frame_attribute/3": {
    "body":"prolog_frame_attribute(${1:Frame}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"prolog_frame_attribute(+Frame, +Key, :Value).\nObtain information about the local stack frame Frame. Frame  is a frame reference as obtained through prolog_current_frame/1, prolog_trace_interception/4  or this predicate. The key values are described below.  alternative: Value is unified with an integer reference to the local stack  frame in which execution is resumed if the goal associated with Frame fails. Fails if the frame has no alternative frame.\n\nhas_alternatives: Value is unified with true if Frame  still is a candidate for backtracking; false otherwise.\n\ngoal: Value is unified with the goal associated with Frame.  If the definition module of the active predicate is not the calling  context, the goal is represented as <module>:<goal>.  Do not instantiate variables in this goal unless you know what  you are doing! Note that the returned term may contain references to the  frame and should be discarded before the frame terminates.176The  returned term is actually an illegal Prolog term that may hold  references from the global to the local stack to preserve the variable  names.\n\nparent_goal: If Value is instantiated to a callable term, find a frame  executing the predicate described by Value and unify the  arguments of Value to the goal arguments associated with the  frame. This is intended to check the current execution context. The user  must ensure the checked parent goal is not removed from the stack due to  last-call optimisation and be aware of the slow operation on deeply  nested calls.\n\npredicate_indicator: Similar to goal, but only returning the [<module>:]<name>/<arity>  term describing the term, not the actual arguments. It avoids creating  an illegal term as goal and is used by the library library(prolog_stack).\n\nclause: Value is unified with a reference to the currently running  clause. Fails if the current goal is associated with a foreign (C)  defined predicate. See also nth_clause/3  and clause_property/2.\n\nlevel: Value is unified with the recursion level of Frame.  The top level frame is at level `0'.\n\nparent: Value is unified with an integer reference to the parent  local stack frame of Frame. Fails if Frame is the  top frame.\n\ncontext_module: Value is unified with the name of the context module of the  environment.\n\ntop: Value is unified with true if Frame  is the top Prolog goal from a recursive call back from the foreign  language; false otherwise.\n\nhidden: Value is unified with true if the frame is  hidden from the user, either because a parent has the hide-childs  attribute (all system predicates), or the system has no trace-me  attribute.\n\nskipped: Value is true if this frame was skipped in the  debugger.\n\npc: Value is unified with the program pointer saved on behalf of  the parent goal if the parent goal is not owned by a foreign predicate  or belongs to a compound meta-call (e.g., call((a,b))).\n\nargument(N): Value is unified with the N-th slot of the frame.  Argument 1 is the first argument of the goal. Arguments above the arity  refer to local variables. Fails silently if N is out of  range.\n\n ",
    "prefix":"prolog_frame_attribute"
  },
  "prolog_history:prolog_history/1": {
    "body": ["prolog_history(${1:Action})$2\n$0" ],
    "description":"  prolog_history(+Action) is det.\n\n   Execute Action on  the  history.   Action is one of\n\n     * enable\n     Enable history. First loads history for the current directory.\n     Loading the history is done at most once.\n     * disable\n     Sets the Prolog flag =save_history= to =false=, such that the\n     history is not saved on halt.",
    "prefix":"prolog_history"
  },
  "prolog_hotfix:load_hotfixes/1": {
    "body": ["load_hotfixes(${1:Dir})$2\n$0" ],
    "description":"  load_hotfixes(+Dir) is det.\n\n   Load all hotfixes that  have  not   yet  been  applied  into the\n   current state.",
    "prefix":"load_hotfixes"
  },
  "prolog_ide/1": {
    "body":"prolog_ide(${1:Action})$2\n$0",
    "description":"prolog_ide(+Action).\nThis predicate ensures the IDE-enabling XPCE component is loaded,  creates the XPCE class and sends Action to its one and only  instance @prolog_ide. Action is one of the  following:  open_navigator(+Directory): Open the Prolog Navigator (see section  3.6) in the given Directory.\n\nopen_debug_status: Open a window to edit spy and trace points.\n\nopen_query_window: Open a little window to run Prolog queries from a GUI component.\n\nthread_monitor: Open a graphical window indicating existing threads and their status.\n\ndebug_monitor: Open a graphical front-end for the library(debug) library  that provides an overview of the topics and catches messages.\n\nxref: Open a graphical front-end for the cross-referencer that provides an  overview of predicates and their callers.\n\n ",
    "prefix":"prolog_ide"
  },
  "prolog_install:qcompile_libraries/0": {
    "body": ["qcompile_libraries$1\n$0" ],
    "description":"  qcompile_libraries\n\n   Quick-load compilation of the Prolog libraries.",
    "prefix":"qcompile_libraries"
  },
  "prolog_list_goal/1": {
    "body":"prolog_list_goal(${1:Goal})$2\n$0",
    "description":"prolog_list_goal(:Goal).\nHook, normally not defined. This hook is called by the 'L' command of  the tracer in the module user to list the currently called  predicate. This hook may be defined to list only relevant clauses of the  indicated Goal and/or show the actual source code in an  editor. See also portray/1  and multifile/1.",
    "prefix":"prolog_list_goal"
  },
  "prolog_listing:listing/0": {
    "body": ["listing$1\n$0" ],
    "description":"  listing\n\n   Lists all predicates defined  in   the  calling module. Imported\n   predicates are not listed. To  list   the  content of the module\n   =mymodule=, use:\n\n     ==\n     ?- mymodule:listing.\n     ==",
    "prefix":"listing"
  },
  "prolog_listing:listing/1": {
    "body": ["listing(${1:What})$2\n$0" ],
    "description":"  listing(:What)\n\n   List matching clauses. What is either a plain specification or a\n   list of specifications. Plain specifications are:\n\n     * Predicate indicator (Name/Arity or Name//Arity)\n     Lists the indicated predicate.  This also outputs relevant\n     _declarations_, such as multifile/1 or dynamic/1.\n\n     * A _Head_ term.  In this case, only clauses whose head\n     unify with _Head_ are listed.  This is illustrated in the\n     query below that only lists the first clause of append/3.\n\n       ==\n       ?- listing(append([], _, _)).\n       lists:append([], A, A).\n       ==",
    "prefix":"listing"
  },
  "prolog_listing:portray_clause/1": {
    "body": ["portray_clause(${1:Clause})$2\n$0" ],
    "description":"  portray_clause(+Clause) is det.\n  portray_clause(+Out:stream, +Clause) is det.\n  portray_clause(+Out:stream, +Clause, +Options) is det.\n\n   Portray `Clause' on the current  output   stream.  Layout of the\n   clause is to our best standards.   As  the actual variable names\n   are not available we use A, B, ... Deals with ';', '|', '->' and\n   calls via meta-call predicates as determined using the predicate\n   property   meta_predicate.   If   Clause   contains   attributed\n   variables, these are treated as normal variables.\n\n   If  Options  is  provided,   the    option-list   is  passed  to\n   write_term/3 that does the final writing of arguments.",
    "prefix":"portray_clause"
  },
  "prolog_listing:portray_clause/2": {
    "body": ["portray_clause(${1:Out}, ${2:Clause})$3\n$0" ],
    "description":"  portray_clause(+Clause) is det.\n  portray_clause(+Out:stream, +Clause) is det.\n  portray_clause(+Out:stream, +Clause, +Options) is det.\n\n   Portray `Clause' on the current  output   stream.  Layout of the\n   clause is to our best standards.   As  the actual variable names\n   are not available we use A, B, ... Deals with ';', '|', '->' and\n   calls via meta-call predicates as determined using the predicate\n   property   meta_predicate.   If   Clause   contains   attributed\n   variables, these are treated as normal variables.\n\n   If  Options  is  provided,   the    option-list   is  passed  to\n   write_term/3 that does the final writing of arguments.",
    "prefix":"portray_clause"
  },
  "prolog_listing:portray_clause/3": {
    "body": ["portray_clause(${1:Out}, ${2:Clause}, ${3:Options})$4\n$0" ],
    "description":"  portray_clause(+Clause) is det.\n  portray_clause(+Out:stream, +Clause) is det.\n  portray_clause(+Out:stream, +Clause, +Options) is det.\n\n   Portray `Clause' on the current  output   stream.  Layout of the\n   clause is to our best standards.   As  the actual variable names\n   are not available we use A, B, ... Deals with ';', '|', '->' and\n   calls via meta-call predicates as determined using the predicate\n   property   meta_predicate.   If   Clause   contains   attributed\n   variables, these are treated as normal variables.\n\n   If  Options  is  provided,   the    option-list   is  passed  to\n   write_term/3 that does the final writing of arguments.",
    "prefix":"portray_clause"
  },
  "prolog_load_context/2": {
    "body":"prolog_load_context(${1:Key}, ${2:Value})$3\n$0",
    "description":"prolog_load_context(?Key, ?Value).\nObtain context information during compilation. This predicate can be  used from directives appearing in a source file to get information about  the file being loaded as well as by the term_expansion/2  and goal_expansion/2  hooks. See also source_location/2  and if/1.  The following keys are defined:  \n\nKeyDescription directory Directory in which source  lives dialect Compatibility mode.  See expects_dialect/1. file Similar to source,  but returns the file being included when called while an include file is  being processed module Module into which file  is loaded reload true if  the file is being reloaded. Not present on first load script Boolean that indicates  whether the file is loaded as a script file (see -s) source File being loaded. If  the system is processing an included file, the value is the main  file. Returns the original Prolog file when loading a .qlf file. stream Stream identifier (see current_input/1) term_position Start position  of last term read. See also stream_property/2  (position property and stream_position_data/3.46Up  to version 7.1.22, the position term carried fake data except for the line_count  and had five arguments, where the position property of a stream  only has four. term Term being expanded by expand_term/2. variable_namesA list of `Name  = Var' of the last term read. See read_term/2  for details.   The directory is commonly used to add rules to file_search_path/2,  setting up a search path for finding files with absolute_file_name/3.  For example: \n\n\n\n:- dynamic user:file_search_path/2.\n:- multifile user:file_search_path/2.\n\n:- prolog_load_context(directory, Dir),\n   asserta(user:file_search_path(my_program_home, Dir)).\n\n    ...\n    absolute_file_name(my_program_home('README.TXT'), ReadMe,\n                       [ access(read) ]),\n    ...\n\n ",
    "prefix":"prolog_load_context"
  },
  "prolog_load_file/2": {
    "body":"prolog_load_file(${1:Spec}, ${2:Options})$3\n$0",
    "description":"prolog_load_file(+Spec, +Options).\nLoad a single object. If this call succeeds, load_files/2  assumes the action has been taken care of. This hook is only called if Options  does not contain the stream(Input) option. The hook must be  defined in the module user.  This can be used to load from unusual places. For example, library library(http/http_load) loads Prolog directly from an HTTP  server. It can also be used to load source in unusual forms, such as  loading compressed files without decompressing them first. There is  currently no example of that.\n\n",
    "prefix":"prolog_load_file"
  },
  "prolog_main:argv_options/3": {
    "body": ["argv_options(${1:Argv}, ${2:RestArgv}, ${3:Options})$4\n$0" ],
    "description":"  argv_options(+Argv, -RestArgv, -Options) is det.\n\n   Generic transformation of long commandline arguments to options.\n   Each --Name=Value is mapped to Name(Value).   Each plain name is\n   mapped to Name(true), unless Name starts  with =|no-|=, in which\n   case the option is mapped to  Name(false). Numeric option values\n   are mapped to Prolog numbers.\n\n   @see library(optparse) provides a more involved option library,\n   providing both short and long options, help and error handling.\n   This predicate is more for quick-and-dirty scripts.",
    "prefix":"argv_options"
  },
  "prolog_main:main/0": {
    "body": ["main$1\n$0" ],
    "description":"  main\n\n   Call main/1 using the passed command-line arguments.",
    "prefix":"main"
  },
  "prolog_metainference:infer_meta_predicate/2": {
    "body": ["infer_meta_predicate(${1:Head}, ${2:MetaSpec})$3\n$0" ],
    "description":"  infer_meta_predicate(:Head, -MetaSpec) is semidet\n\n   True  when  MetaSpec  is  a  meta-predicate  specifier  for  the\n   predicate Head. Derived meta-predicates are   collected and made\n   available through inferred_meta_predicate/2.",
    "prefix":"infer_meta_predicate"
  },
  "prolog_metainference:inferred_meta_predicate/2": {
    "body": ["inferred_meta_predicate(${1:Head}, ${2:MetaSpec})$3\n$0" ],
    "description":"  inferred_meta_predicate(:Head, ?MetaSpec) is nondet.\n\n   True when MetaSpec is an   inferred meta-predicate specification\n   for Head.",
    "prefix":"inferred_meta_predicate"
  },
  "prolog_nodebug/1": {
    "body":"prolog_nodebug(${1:Topic})$2\n$0",
    "description":"prolog_nodebug(+Topic).\nEnable/disable a debug topic. Topic is an atom that  identifies the desired topic. The available topics are defined in src/pl-debug.h. Please search the sources to find out what  is actually printed and when. We highlight one topic here:  chk_secure(chk_secure): dd many expensive consistency checks to the system. This should  typically be used when the system crashes, notably in the garbage  collector. Garbage collection crashes are in most cases caused by  invalid data on the Prolog stacks. This debug topic may help locating  how the invalid data was created.\n\n ",
    "prefix":"prolog_nodebug"
  },
  "prolog_operator:pop_operators/0": {
    "body": ["pop_operators$1\n$0" ],
    "description":"  pop_operators is det.\n\n   Revert all changes to the operator table realised since the last\n   push_operators/1.",
    "prefix":"pop_operators"
  },
  "prolog_operator:pop_operators/1": {
    "body": ["pop_operators(${1:Undo})$2\n$0" ],
    "description":"  pop_operators(+Undo) is det.\n\n   Reset operators as pushed by push_operators/2.",
    "prefix":"pop_operators"
  },
  "prolog_operator:push_op/3": {
    "body": ["push_op(${1:Precedence}, ${2:Type}, ${3:Name})$4\n$0" ],
    "description":"  push_op(+Precedence, +Type, :Name) is det.\n\n   As op/3, but this call must  appear between push_operators/1 and\n   pop_operators/0.  The  change  is   undone    by   the  call  to\n   pop_operators/0",
    "prefix":"push_op"
  },
  "prolog_operator:push_operators/1": {
    "body": ["push_operators(${1:New})$2\n$0" ],
    "description":"  push_operators(:New) is det.\n  push_operators(:New, -Undo) is det.\n\n   Installs the operators from New, where New is a list of op(Prec,\n   Type, :Name). The modifications to the operator table are undone\n   in a matching call to pop_operators/0.",
    "prefix":"push_operators"
  },
  "prolog_operator:push_operators/2": {
    "body": ["push_operators(${1:New}, ${2:Undo})$3\n$0" ],
    "description":"  push_operators(:New) is det.\n  push_operators(:New, -Undo) is det.\n\n   Installs the operators from New, where New is a list of op(Prec,\n   Type, :Name). The modifications to the operator table are undone\n   in a matching call to pop_operators/0.",
    "prefix":"push_operators"
  },
  "prolog_pack:environment/2": {
    "body":"environment(${1:Name}, ${2:Value})$3\n$0",
    "description":"[nondet,multifile]environment(-Name, -Value).\nHook to define the environment for building packs. This Multifile hook  extends the process environment for building foreign extensions. A value  provided by this hook overrules defaults provided by def_environment/2.  In addition to changing the environment, this may be used to pass  additional values to the environment, as in:  \n\nprolog_pack:environment('USER', User) :-\n    getenv('USER', User).\n\n  Name is an atom denoting a  valid variable name Value is either an atom or  number representing the value of the variable. ",
    "prefix":"environment"
  },
  "prolog_pack:pack_info/1": {
    "body":"pack_info(${1:Pack})$2\n$0",
    "description":"pack_info(+Pack).\nPrint more detailed information about Pack.",
    "prefix":"pack_info"
  },
  "prolog_pack:pack_install/1": {
    "body":"pack_install(${1:Spec})$2\n$0",
    "description":"[det]pack_install(+Spec:atom).\nInstall a package. Spec is one of  \n\nArchive file name\nHTTP URL of an archive file name. This URL may contain a star (*)  for the version. In this case pack_install asks for the deirectory  content and selects the latest version.\nGIT URL (not well supported yet)\nA local directory name given as file:// URL.\nA package name. This queries the package repository at http://www.swi-prolog.org\n\n  After resolving the type of package, pack_install/2  is used to do the actual installation.\n\n",
    "prefix":"pack_install"
  },
  "prolog_pack:pack_install/2": {
    "body":"pack_install(${1:Name}, ${2:Options})$3\n$0",
    "description":"[det]pack_install(+Name, +Options).\nInstall package Name. Processes the options below. Default  options as would be used by pack_install/1  are used to complete the provided Options.  url(+URL): Source for downloading the package\n\npackage_directory(+Dir): Directory into which to install the package\n\ninteractive(+Boolean): Use default answer without asking the user if there is a default action.\n\nsilent(+Boolean): If true (default false), suppress informational progress  messages.\n\nupgrade(+Boolean): If true (default false), upgrade package if it  is already installed.\n\ngit(+Boolean): If true (default false unless URL  ends with =.git=), assume the URL is a GIT repository.\n\n  Non-interactive installation can be established using the option interactive(false). It is adviced to install from a  particular trusted URL instead of the plain pack name for unattented  operation.\n\n",
    "prefix":"pack_install"
  },
  "prolog_pack:pack_list/1": {
    "body":"pack_list(${1:Query})$2\n$0",
    "description":"[det]pack_list(+Query).\nQuery package server and installed packages and display  results. Query is matches case-insensitively against the name and  title of known and installed packages. For each matching package, a  single line is displayed that provides:  \n\nInstallation status  p: package, not installedi: installed package; up-to-date with public versionU: installed package; can be upgradedA: installed package; newer than publically availablel: installed package; not on server  \nName@Version\nName@Version(ServerVersion)\nTitle\n\n  Hint: ?- pack_list(''). lists all packages. \n\nThe predicates pack_list/1  and pack_search/1  are synonyms. Both contact the package server at http://www.swi-prolog.org  to find available packages. \n\nSee also: pack_list_installed/0  to list installed packages without contacting the server.\n\n ",
    "prefix":"pack_list"
  },
  "prolog_pack:pack_list_installed/0": {
    "body": ["pack_list_installed$1\n$0" ],
    "description":"  pack_list_installed is det.\n\n   List currently installed  packages.   Unlike  pack_list/1,  only\n   locally installed packages are displayed   and  no connection is\n   made to the internet.\n\n   @see Use pack_list/1 to find packages.",
    "prefix":"pack_list_installed"
  },
  "prolog_pack:pack_property/2": {
    "body":"pack_property(${1:Pack}, ${2:Property})$3\n$0",
    "description":"[nondet]pack_property(?Pack, ?Property).\nTrue when Property is a property of Pack. This  interface is intended for programs that wish to interact with the  package manager. Defined properties are:  directory(Directory): Directory into which the package is installed\n\nversion(Version): Installed version\n\ntitle(Title): Full title of the package\n\nauthor(Author): Registered author\n\ndownload(URL): Official download URL\n\nreadme(File): Package README file (if present)\n\ntodo(File): Package TODO file (if present)\n\n ",
    "prefix":"pack_property"
  },
  "prolog_pack:pack_rebuild/0": {
    "body": ["pack_rebuild$1\n$0" ],
    "description":"  pack_rebuild is det.\n\n   Rebuild foreign components of all packages.",
    "prefix":"pack_rebuild"
  },
  "prolog_pack:pack_rebuild/1": {
    "body":"pack_rebuild(${1:Pack})$2\n$0",
    "description":"[det]pack_rebuild(+Pack).\nRebuilt possible foreign components of Pack.",
    "prefix":"pack_rebuild"
  },
  "prolog_pack:pack_remove/1": {
    "body":"pack_remove(${1:Name})$2\n$0",
    "description":"[det]pack_remove(+Name).\nRemove the indicated package.",
    "prefix":"pack_remove"
  },
  "prolog_pack:pack_search/1": {
    "body":"pack_search(${1:Query})$2\n$0",
    "description":"[det]pack_search(+Query).\n",
    "prefix":"pack_search"
  },
  "prolog_pack:pack_upgrade/1": {
    "body":"pack_upgrade(${1:Pack})$2\n$0",
    "description":"[semidet]pack_upgrade(+Pack).\nTry to upgrade the package Pack.  To be done: Update dependencies when updating a pack from git?\n\n ",
    "prefix":"pack_upgrade"
  },
  "prolog_pack:pack_url_file/2": {
    "body":"pack_url_file(${1:URL}, ${2:File})$3\n$0",
    "description":"[det]pack_url_file(+URL, -File).\nTrue if File is a unique id for the referenced pack and  version. Normally, that is simply the base name, but GitHub archives  destroy this picture. Needed by the pack manager.",
    "prefix":"pack_url_file"
  },
  "prolog_preferences:prolog_edit_preferences/1": {
    "body": ["prolog_edit_preferences(${1:What})$2\n$0" ],
    "description":"  prolog_edit_preferences(+What) is det.\n\n   Edit the specified user preference file.  What is one of\n\n       * =xpce=\n       * =prolog=\n\n   The UI components are started asynchronously in the XPCE thread.",
    "prefix":"prolog_edit_preferences"
  },
  "prolog_pretty_print:print_term/2": {
    "body": ["print_term(${1:Term}, ${2:Options})$3\n$0" ],
    "description":"  print_term(+Term, +Options) is det.\n\n   Pretty print a Prolog term. The following options are processed:\n\n     * output(+Stream)\n     Define the output stream.  Default is =user_output=\n     * right_margin(+Integer)\n     Width of a line.  Default is 72 characters.\n     * left_margin(+Integer)\n     Left margin for continuation lines.  Default is 0.\n     * tab_width(+Integer)\n     Distance between tab-stops.  Default is 8 characters.\n     * indent_arguments(+Spec)\n     Defines how arguments of compound terms are placed.  Defined\n     values are:\n       $ =false= :\n       Simply place them left to right (no line-breaks)\n       $ =true= :\n       Place them vertically, aligned with the open bracket (not\n       implemented)\n       $ =auto= (default) :\n       As horizontal if line-width is not exceeded, vertical\n       otherwise.\n       $ An integer :\n       Place them vertically aligned, <N> spaces to the right of\n       the beginning of the head.\n     * operators(+Boolean)\n     This is the inverse of the write_term/3 option =ignore_ops=.\n     Default is to respect them.\n     * write_options(+List)\n     List of options passed to write_term/3 for terms that are\n     not further processed.  Default:\n       ==\n           [ numbervars(true),\n             quoted(true),\n             portray(true)\n           ]\n       ==",
    "prefix":"print_term"
  },
  "prolog_server:prolog_server/2": {
    "body": ["prolog_server(${1:Port}, ${2:Options})$3\n$0" ],
    "description":"  prolog_server(?Port, +Options)\n\n   Create a TCP/IP based server  on  the   given  Port,  so you can\n   telnet into Prolog and run an  interactive session. This library\n   is intended to provide access for   debugging  and management of\n   embedded servers.\n\n   Currently defined options are:\n\n           * allow(IP)\n           Allow access from IP, a term of the format ip(A,B,C,D).\n           Multiple of such terms can exist and access is granted\n           if the peer IP address unifies to one of them.  If no\n           allow option is provided access is only granted from\n           ip(127,0,0,1) (localhost).\n\n   For example:\n\n           ==\n           ?- prolog_server(4000, []).\n\n           % telnet localhost 4000\n           Welcome to the SWI-Prolog server on thread 3\n\n           1 ?-\n           ==\n\n   @bug As the connection does not involve a terminal, command history\n   and completion are not provided. Neither are interrupts\n   (Control-C).  To terminate the Prolog shell one must enter the\n   command \"end_of_file.\"",
    "prefix":"prolog_server"
  },
  "prolog_skip_frame/1": {
    "body":"prolog_skip_frame(${1:Frame})$2\n$0",
    "description":"prolog_skip_frame(-Frame).\nIndicate Frame as a skipped frame and set the `skip level'  (see prolog_skip_level/2  to the recursion depth of Frame. The effect of the skipped  flag is that a redo on a child of this frame is handled differently.  First, a redo trace is called for the child, where the skip  level is set to redo_in_skip. Next, the skip level is set  to skip level of the skipped frame.",
    "prefix":"prolog_skip_frame"
  },
  "prolog_skip_level/2": {
    "body":"prolog_skip_level(${1:Old}, ${2:New})$3\n$0",
    "description":"prolog_skip_level(-Old, +New).\nUnify Old with the old value of `skip level' and then set  this level according to New. New is an integer,  the atom very_deep (meaning don't skip) or the atom skip_in_redo  (see prolog_skip_frame/1).  The `skip level' is a setting of each Prolog thread that disables the  debugger on all recursion levels deeper than the level of the variable.  See also prolog_skip_frame/1.",
    "prefix":"prolog_skip_level"
  },
  "prolog_source:directory_source_files/3": {
    "body": [
      "directory_source_files(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"directory_source_files('Param1','Param2','Param3')",
    "prefix":"directory_source_files"
  },
  "prolog_source:file_alias_path/2": {
    "body": ["file_alias_path(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"file_alias_path('Param1','Param2')",
    "prefix":"file_alias_path"
  },
  "prolog_source:file_name_on_path/2": {
    "body": ["file_name_on_path(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"file_name_on_path('Param1','Param2')",
    "prefix":"file_name_on_path"
  },
  "prolog_source:load_quasi_quotation_syntax/2": {
    "body": ["load_quasi_quotation_syntax(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"load_quasi_quotation_syntax('Param1','Param2')",
    "prefix":"load_quasi_quotation_syntax"
  },
  "prolog_source:path_segments_atom/2": {
    "body": ["path_segments_atom(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"path_segments_atom('Param1','Param2')",
    "prefix":"path_segments_atom"
  },
  "prolog_source:prolog_canonical_source/2": {
    "body": ["prolog_canonical_source(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"prolog_canonical_source('Param1','Param2')",
    "prefix":"prolog_canonical_source"
  },
  "prolog_source:prolog_close_source/1": {
    "body": ["prolog_close_source(${1:'Param1'})$2\n$0" ],
    "description":"prolog_close_source('Param1')",
    "prefix":"prolog_close_source"
  },
  "prolog_source:prolog_open_source/2": {
    "body": ["prolog_open_source(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"prolog_open_source('Param1','Param2')",
    "prefix":"prolog_open_source"
  },
  "prolog_source:prolog_read_source_term/4": {
    "body": [
      "prolog_read_source_term(${1:In}, ${2:Term}, ${3:Expanded}, ${4:Options})$5\n$0"
    ],
    "description":"  prolog_read_source_term(+In, -Term, -Expanded, +Options) is det.\n\n   Read a term from a Prolog source-file.  Options is a option list\n   that is forwarded to read_clause/3.\n\n   This predicate is intended to read the   file from the start. It\n   tracks  directives  to  update  its   notion  of  the  currently\n   effective syntax (e.g., declared operators).\n\n   @param Term     Term read\n   @param Expanded Result of term-expansion on the term\n   @see   read_source_term_at_location/3 for reading at an\n          arbitrary location.",
    "prefix":"prolog_read_source_term"
  },
  "prolog_source:read_source_term_at_location/3": {
    "body": [
      "read_source_term_at_location(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"read_source_term_at_location('Param1','Param2','Param3')",
    "prefix":"read_source_term_at_location"
  },
  "prolog_stack:backtrace/1": {
    "body": ["backtrace(${1:MaxDepth})$2\n$0" ],
    "description":"  backtrace(+MaxDepth)\n\n   Get and print a stacktrace to the user_error stream.",
    "prefix":"backtrace"
  },
  "prolog_stack:get_prolog_backtrace/2": {
    "body": ["get_prolog_backtrace(${1:MaxDepth}, ${2:Backtrace})$3\n$0" ],
    "description":"  get_prolog_backtrace(+MaxDepth, -Backtrace) is det.\n  get_prolog_backtrace(+MaxDepth, -Backtrace, +Options) is det.\n\n   Obtain a backtrace from the current location. The backtrace is a\n   list of frames. Each  frame  is  an   opaque  term  that  can be\n   inspected using the predicate  prolog_stack_frame_property/2 can\n   be used to extract  information  from   these  frames.  Most use\n   scenarios will pass the stack   to print_prolog_backtrace/2. The\n   following options are provided:\n\n     * frame(Frame)\n     Start at Frame instead of the current frame.\n     * goal_depth(+Depth)\n     If Depth > 0, include a shallow copy of the goal arguments\n     into the stack.  Default is set by the Prolog flag\n     =backtrace_goal_depth=, set to =2= initially, showing the\n     goal and toplevel of any argument.\n\n   @param Frame is the frame to start from. See prolog_current_frame/1.\n   @param MaxDepth defines the maximum number of frames returned.\n   @compat get_prolog_backtrace/3 used to have the parameters\n   +Frame, +MaxDepth, -Backtrace. A call that matches this\n   signature is mapped to get_prolog_backtrace(MaxDepth, Backtrace,\n   [frame(Frame)]).",
    "prefix":"get_prolog_backtrace"
  },
  "prolog_stack:get_prolog_backtrace/3": {
    "body": [
      "get_prolog_backtrace(${1:MaxDepth}, ${2:Backtrace}, ${3:Options})$4\n$0"
    ],
    "description":"  get_prolog_backtrace(+MaxDepth, -Backtrace) is det.\n  get_prolog_backtrace(+MaxDepth, -Backtrace, +Options) is det.\n\n   Obtain a backtrace from the current location. The backtrace is a\n   list of frames. Each  frame  is  an   opaque  term  that  can be\n   inspected using the predicate  prolog_stack_frame_property/2 can\n   be used to extract  information  from   these  frames.  Most use\n   scenarios will pass the stack   to print_prolog_backtrace/2. The\n   following options are provided:\n\n     * frame(Frame)\n     Start at Frame instead of the current frame.\n     * goal_depth(+Depth)\n     If Depth > 0, include a shallow copy of the goal arguments\n     into the stack.  Default is set by the Prolog flag\n     =backtrace_goal_depth=, set to =2= initially, showing the\n     goal and toplevel of any argument.\n\n   @param Frame is the frame to start from. See prolog_current_frame/1.\n   @param MaxDepth defines the maximum number of frames returned.\n   @compat get_prolog_backtrace/3 used to have the parameters\n   +Frame, +MaxDepth, -Backtrace. A call that matches this\n   signature is mapped to get_prolog_backtrace(MaxDepth, Backtrace,\n   [frame(Frame)]).",
    "prefix":"get_prolog_backtrace"
  },
  "prolog_stack:print_prolog_backtrace/2": {
    "body": ["print_prolog_backtrace(${1:Stream}, ${2:Backtrace})$3\n$0" ],
    "description":"  print_prolog_backtrace(+Stream, +Backtrace) is det.\n  print_prolog_backtrace(+Stream, +Backtrace, +Options) is det.\n\n   Print a stacktrace in human readable form to Stream.\n   Options is an option list that accepts:\n\n       * subgoal_positions(+Boolean)\n       If =true=, print subgoal line numbers.  The default depends\n       on the Prolog flag =backtrace_show_lines=.\n\n   @arg Backtrace is a list of frame(Depth,Location,Goal) terms.",
    "prefix":"print_prolog_backtrace"
  },
  "prolog_stack:print_prolog_backtrace/3": {
    "body": [
      "print_prolog_backtrace(${1:Stream}, ${2:Backtrace}, ${3:Options})$4\n$0"
    ],
    "description":"  print_prolog_backtrace(+Stream, +Backtrace) is det.\n  print_prolog_backtrace(+Stream, +Backtrace, +Options) is det.\n\n   Print a stacktrace in human readable form to Stream.\n   Options is an option list that accepts:\n\n       * subgoal_positions(+Boolean)\n       If =true=, print subgoal line numbers.  The default depends\n       on the Prolog flag =backtrace_show_lines=.\n\n   @arg Backtrace is a list of frame(Depth,Location,Goal) terms.",
    "prefix":"print_prolog_backtrace"
  },
  "prolog_stack:prolog_stack_frame_property/2": {
    "body": ["prolog_stack_frame_property(${1:Frame}, ${2:Property})$3\n$0" ],
    "description":"  prolog_stack_frame_property(+Frame, ?Property) is nondet.\n\n   True when Property is a property of   Frame. Frame is an element\n   of a stack-trace as produced by get_prolog_backtrace/2.  Defined\n   properties are:\n\n     * level(Level)\n     * predicate(PI)\n     * location(File:Line)",
    "prefix":"prolog_stack_frame_property"
  },
  "prolog_stack_property/2": {
    "body":"prolog_stack_property(${1:Stack}, ${2:KeyValue})$3\n$0",
    "description":"prolog_stack_property(?Stack, ?KeyValue).\nTrue if KeyValue is a current property of Stack.  See set_prolog_stack/2  for defined properties.",
    "prefix":"prolog_stack_property"
  },
  "prolog_statistics:profile/1": {
    "body": ["profile(${1:Goal})$2\n$0" ],
    "description":"  profile(:Goal).\n  profile(:Goal, +Options).\n\n   Run Goal under the execution profiler.  Defined options are:\n\n     * time(Which)\n     Profile =cpu= or =wall= time.  The default is CPU time.\n     * top(N)\n     When generating a textual report, show the top N predicates.\n     * cumulative(Bool)\n     If =true= (default =false=), show cumulative output in\n     a textual report.",
    "prefix":"profile"
  },
  "prolog_statistics:profile/2": {
    "body": ["profile(${1:Goal}, ${2:Options})$3\n$0" ],
    "description":"  profile(:Goal).\n  profile(:Goal, +Options).\n\n   Run Goal under the execution profiler.  Defined options are:\n\n     * time(Which)\n     Profile =cpu= or =wall= time.  The default is CPU time.\n     * top(N)\n     When generating a textual report, show the top N predicates.\n     * cumulative(Bool)\n     If =true= (default =false=), show cumulative output in\n     a textual report.",
    "prefix":"profile"
  },
  "prolog_statistics:show_profile/1": {
    "body": ["show_profile(${1:Options})$2\n$0" ],
    "description":"  show_profile(+Options)\n\n   Display last collected profiling data.  Options are\n\n     * top(N)\n     When generating a textual report, show the top N predicates.\n     * cumulative(Bool)\n     If =true= (default =false=), show cumulative output in\n     a textual report.",
    "prefix":"show_profile"
  },
  "prolog_statistics:statistics/0": {
    "body": ["statistics$1\n$0" ],
    "description":"  statistics is det.\n\n   Print information about resource usage using print_message/2.\n\n   @see    All statistics printed are obtained through statistics/2.",
    "prefix":"statistics"
  },
  "prolog_statistics:statistics/1": {
    "body": ["statistics(${1:Stats})$2\n$0" ],
    "description":"  statistics(-Stats:dict) is det.\n\n   Stats  is  a  dict   representing    the   same  information  as\n   statistics/0. This convience function is   primarily intended to\n   pass  statistical  information  to  e.g.,  a  web  client.  Time\n   critical code that wishes to   collect statistics typically only\n   need a small subset  and  should   use  statistics/2  to  obtain\n   exactly the data they need.",
    "prefix":"statistics"
  },
  "prolog_statistics:thread_statistics/2": {
    "body": ["thread_statistics(${1:Thread}, ${2:Stats})$3\n$0" ],
    "description":"  thread_statistics(?Thread, -Stats:dict) is nondet.\n\n   Obtain statistical information about a single thread.  Fails\n   silently of the Thread is no longer alive.\n\n   @arg    Stats is a dict containing status, time and stack-size\n           information about Thread.",
    "prefix":"thread_statistics"
  },
  "prolog_statistics:time/1": {
    "body": ["time(${1:Goal})$2\n$0" ],
    "description":"  time(:Goal) is nondet.\n\n   Execute Goal, reporting statistics to the user. If Goal succeeds\n   non-deterministically,  retrying  reports  the   statistics  for\n   providing the next answer.\n\n   Statistics  are  retrieved  using   thread_statistics/3  on  the\n   calling   thread.   Note   that   not    all   systems   support\n   thread-specific CPU time. Notable, this is lacking on MacOS X.\n\n   @bug Inference statistics are often a few off.\n   @see statistics/2 for obtaining statistics in your program and\n        understanding the reported values.",
    "prefix":"time"
  },
  "prolog_stream:open_prolog_stream/4": {
    "body":"open_prolog_stream(${1:Module}, ${2:Mode}, ${3:Stream}, ${4:Options})$5\n$0",
    "description":"open_prolog_stream(+Module, +Mode, -Stream, +Options).\nCreate a new stream that implements its I/O by calling predicates in Module.  The called predicates are:  Module : stream_write(+Stream,  +String): Called for a Mode = write stream if data is available. String contains the (textual) data that is written to Stream.  The callback is called if the buffer of Stream overflows, the user calls flush_output(Stream)  or Stream is closed and there is buffered data.\n\nModule : stream_read(+Stream,  -Term): Called for a Mode == read stream to get new data. On  success the stream extracts text from the provided Term. Term is typically a string, atom, code or character list. If  term is not one of the above, it is handed to writeq/1.  To signal end-of-file, unify stream with an empty text, e.g., stream_read(Stream, \"\").\n\nModule : stream_close(+Stream): Called when the stream is closed. This predicate must succeed. The  callback can be used to cleanup associated resources.\n\n  The current implementation only deals with text streams. The stream  uses the wchar_t encoding. The buffer size must be a  multiple of wchar_t, i.e., a multiple of four for  portability. The newline mode of the stream is posix  on all platforms, disabling the translation \"\\n\" --> \"\\r\\n\".\n\nOptions is currently ignored.   bug: Futher versions might require additional callbacks. As we demand all  callbacks to be defined, existing code needs to implement the new  callbacks.\n\n ",
    "prefix":"open_prolog_stream"
  },
  "prolog_stream:udp_broadcast_initialize/2": {
    "body":"udp_broadcast_initialize(${1:IPAddress}, ${2:SubnetMask})$3\n$0",
    "description":"[semidet]udp_broadcast_initialize(+IPAddress, +SubnetMask).\ncauses any required runtime initialization to occur. At present, proper  operation of UDP broadcast depends on local information that is not  easily obtained mechanically. In order to determine the appropriate UDP  broadcast address, you must supply the IPAddress and SubnetMask for the node that is  running this module. These data are supplied in the form of ip/4  terms. This is now required to be included in an applications  intialization directive.",
    "prefix":"udp_broadcast_initialize"
  },
  "prolog_to_os_filename/2": {
    "body":"prolog_to_os_filename(${1:PrologPath}, ${2:OsPath})$3\n$0",
    "description":"prolog_to_os_filename(?PrologPath, ?OsPath).\nConvert between the internal Prolog path name conventions and the  operating system path name conventions. The internal conventions follow  the POSIX standard, which implies that this predicate is equivalent to  =/2 (unify) on POSIX (e.g., Unix) systems. On Windows systems it changes  the directory separator from \\ into /.",
    "prefix":"prolog_to_os_filename"
  },
  "prolog_trace_interception/4": {
    "body":"prolog_trace_interception(${1:Port}, ${2:Frame}, ${3:Choice}, ${4:Action})$5\n$0",
    "description":"prolog_trace_interception(+Port, +Frame, +Choice, -Action).\nDynamic predicate, normally not defined. This predicate is called from  the SWI-Prolog debugger just before it would show a port. If this  predicate succeeds, the debugger assumes that the trace action has been  taken care of and continues execution as described by Action.  Otherwise the normal Prolog debugger actions are performed.  Port denotes the reason to activate the tracer (`port' in  the 4/5-port, but with some additions): \n\ncall: Normal entry through the call port of the 4-port debugger.\n\nredo(PC): Normal entry through the redo port of the 4-port debugger. The redo port signals resuming a predicate to generate  alternative solutions. If PC is 0 (zero), clause indexing has  found another clause that will be tried next. Otherwise, PC  is the program counter in the current clause where execution continues.  This implies we are dealing with an in-clause choice point left by,  e.g., ;/2. Note that  non-determinism in foreign predicates are also handled using an  in-clause choice point.\n\nunify: The unify port represents the neck instruction, signalling the  end of the head-matching process. This port is normally invisible. See leash/1  and visible/1.\n\nexit: The exit port signals the goal is proved. It is possible for the goal to  have alternatives. See prolog_frame_attribute/3  to examine the goal stack.\n\nfail: The fail port signals final failure of the goal.\n\nexception(Except): An exception is raised and still pending. This port is activated on each  parent frame of the frame generating the exception until the exception  is caught or the user restarts normal computation using retry. Except is the pending exception term.\n\nbreak(PC): A break instruction is executed. PC is program  counter. This port is used by the graphical debugger.\n\ncut_call(PC): A cut is encountered at PC. This port is used by the  graphical debugger to visualise the effect of the cut.\n\ncut_exit(PC): A cut has been executed. See cut_call(PC) for more  information.\n\n  Frame is a reference to the current local stack frame,  which can be examined using prolog_frame_attribute/3. Choice  is a reference to the last choice point and can be examined using prolog_choice_attribute/3. Action  must be unified with a term that specifies how execution must continue.  The following actions are defined: \n\nabort: Abort execution. See abort/0.\n\ncontinue: Continue (i.e., creep in the command line debugger).\n\nfail: Make the current goal fail.\n\nignore: Step over the current goal without executing it.\n\nnodebug: Continue execution in normal nodebugging mode. See nodebug/0.\n\nretry: Retry the current frame.\n\nretry(Frame): Retry the given frame. This must be a parent of the current frame.\n\nskip: Skip over the current goal (i.e., skip in the command line  debugger).\n\nup: Skip to the parent goal (i.e., up in the command line  debugger).\n\n  Together with the predicates described in section  4.39 and the other predicates of this chapter, this predicate  enables the Prolog user to define a complete new debugger in Prolog.  Besides this, it enables the Prolog programmer to monitor the execution  of a program. The example below records all goals trapped by the tracer  in the database. \n\n\n\nprolog_trace_interception(Port, Frame, _PC, continue) :-\n        prolog_frame_attribute(Frame, goal, Goal),\n        prolog_frame_attribute(Frame, level, Level),\n        recordz(trace, trace(Port, Level, Goal)).\n\n  To trace the execution of `go' this way the following query should be  given: \n\n\n\n?- trace, go, notrace.\n\n ",
    "prefix":"prolog_trace_interception"
  },
  "prolog_vm:vm_list/1": {
    "body": ["vm_list(${1:Spec})$2\n$0" ],
    "description":"  vm_list(:Spec) is det.\n\n   Lists  the  definition  of  the   predicates  matching  Spec  to\n   =current_output=. Spec is also allowed to be a clause-reference.",
    "prefix":"vm_list"
  },
  "prolog_xref:xref_built_in/1": {
    "body":"xref_built_in(${1:Callable})$2\n$0",
    "description":"xref_built_in(?Callable).\nTrue if Callable is a built-in predicate. Currently this is  assumed for all predicates defined in the system module and  having the property built_in. Built-in predicates are not  registered as `called'.",
    "prefix":"xref_built_in"
  },
  "prolog_xref:xref_called/3": {
    "body":"xref_called(${1:Source}, ${2:Callable}, ${3:By})$4\n$0",
    "description":"xref_called(?Source, ?Callable, ?By).\nCallable is called in Source by By.",
    "prefix":"xref_called"
  },
  "prolog_xref:xref_called/4": {
    "body": ["xref_called(${1:Source}, ${2:Called}, ${3:By}, ${4:Cond})$5\n$0" ],
    "description":"  xref_called(?Source, ?Called, ?By) is nondet.\n  xref_called(?Source, ?Called, ?By, ?Cond) is nondet.\n\n   Enumerate the predicate-call relations. Predicate called by\n   directives have a By '<directive>'.",
    "prefix":"xref_called"
  },
  "prolog_xref:xref_clean/1": {
    "body":"xref_clean(${1:Source})$2\n$0",
    "description":"xref_clean(+Source).\nRemove the information gathered for Source",
    "prefix":"xref_clean"
  },
  "prolog_xref:xref_comment/3": {
    "body": ["xref_comment(${1:Source}, ${2:Title}, ${3:Comment})$4\n$0" ],
    "description":"  xref_comment(?Source, ?Title, ?Comment) is nondet.\n\n   Is true when Source has a section comment with Title and Comment",
    "prefix":"xref_comment"
  },
  "prolog_xref:xref_comment/4": {
    "body": [
      "xref_comment(${1:Source}, ${2:Head}, ${3:Summary}, ${4:Comment})$5\n$0"
    ],
    "description":"  xref_comment(?Source, ?Head, ?Summary, ?Comment) is nondet.\n\n   Is true when Head in Source has the given PlDoc comment.",
    "prefix":"xref_comment"
  },
  "prolog_xref:xref_current_source/1": {
    "body":"xref_current_source(${1:Source})$2\n$0",
    "description":"xref_current_source(?Source).\nSource has been processed.",
    "prefix":"xref_current_source"
  },
  "prolog_xref:xref_defined/3": {
    "body":"xref_defined(${1:Source}, ${2:Callable}, ${3:How})$4\n$0",
    "description":"xref_defined(?Source, ?Callable, -How).\nCallable is defined in Source. How is  one of dynamic(Line) Declared  dynamic at Line thread_local(Line) Declared  thread local at Line multifile(Line) Declared  multifile at Line local(Line) First clause at Line foreign(Line) Foreign library  loaded at Line constraint(Line) CHR  Constraint at Line imported(File) Imported from File ",
    "prefix":"xref_defined"
  },
  "prolog_xref:xref_defined_class/3": {
    "body": [
      "xref_defined_class(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"xref_defined_class('Param1','Param2','Param3')",
    "prefix":"xref_defined_class"
  },
  "prolog_xref:xref_definition_line/2": {
    "body": ["xref_definition_line(${1:How}, ${2:Line})$3\n$0" ],
    "description":"  xref_definition_line(+How, -Line)\n\n   If the 3th argument of xref_defined contains line info, return\n   this in Line.",
    "prefix":"xref_definition_line"
  },
  "prolog_xref:xref_done/2": {
    "body": ["xref_done(${1:Source}, ${2:Time})$3\n$0" ],
    "description":"  xref_done(+Source, -Time) is det.\n\n   Cross-reference executed at Time",
    "prefix":"xref_done"
  },
  "prolog_xref:xref_exported/2": {
    "body":"xref_exported(${1:Source}, ${2:Callable})$3\n$0",
    "description":"xref_exported(?Source, ?Callable).\nCallable is public (exported from the module).",
    "prefix":"xref_exported"
  },
  "prolog_xref:xref_hook/1": {
    "body": ["xref_hook(${1:Callable})$2\n$0" ],
    "description":"  xref_hook(?Callable)\n\n   Definition of known hooks.  Hooks  that   can  be  called in any\n   module are unqualified.  Other  hooks   are  qualified  with the\n   module where they are called.",
    "prefix":"xref_hook"
  },
  "prolog_xref:xref_meta/2": {
    "body": ["xref_meta(${1:Head}, ${2:Called})$3\n$0" ],
    "description":"  xref_meta(+Head, -Called) is semidet.\n  xref_meta_src(+Head, -Called, +Src) is semidet.\n\n   True when Called is a  list  of   terms  called  from Head. Each\n   element in Called can be of the  form Term+Int, which means that\n   Term must be extended with Int additional arguments. The variant\n   xref_meta/3 first queries the local context.\n\n   @tbd    Split predifined in several categories.  E.g., the ISO\n           predicates cannot be redefined.\n   @tbd    Rely on the meta_predicate property for many predicates.\n   @deprecated     New code should use xref_meta/3.",
    "prefix":"xref_meta"
  },
  "prolog_xref:xref_meta/3": {
    "body": ["xref_meta(${1:Source}, ${2:Head}, ${3:Called})$4\n$0" ],
    "description":"  xref_meta(+Source, +Head, -Called) is semidet.\n\n   True when Head calls Called in Source.\n\n   @arg    Called is a list of called terms, terms of the form\n           Term+Extra or terms of the form //(Term).",
    "prefix":"xref_meta"
  },
  "prolog_xref:xref_mode/3": {
    "body": ["xref_mode(${1:Source}, ${2:Mode}, ${3:Det})$4\n$0" ],
    "description":"  xref_mode(?Source, ?Mode, ?Det) is nondet.\n\n   Is  true  when  Source  provides  a   predicate  with  Mode  and\n   determinism.",
    "prefix":"xref_mode"
  },
  "prolog_xref:xref_module/2": {
    "body":"xref_module(${1:Source}, ${2:Module})$3\n$0",
    "description":"xref_module(?Source, ?Module).\nSource is a module file defining the given module.",
    "prefix":"xref_module"
  },
  "prolog_xref:xref_op/2": {
    "body": ["xref_op(${1:Source}, ${2:Op})$3\n$0" ],
    "description":"  xref_op(?Source, Op) is nondet.\n\n   Give the operators active inside the module. This is intended to\n   setup the environment for incremental parsing of a term from the\n   source-file.\n\n   @param Op       Term of the form op(Priority, Type, Name)",
    "prefix":"xref_op"
  },
  "prolog_xref:xref_option/2": {
    "body": ["xref_option(${1:Source}, ${2:Option})$3\n$0" ],
    "description":"  xref_option(?Source, ?Option) is nondet.\n\n   True when Source was processed using Option. Options are defined\n   with xref_source/2.",
    "prefix":"xref_option"
  },
  "prolog_xref:xref_prolog_flag/4": {
    "body": [
      "xref_prolog_flag(${1:Source}, ${2:Flag}, ${3:Value}, ${4:Line})$5\n$0"
    ],
    "description":"  xref_prolog_flag(?Source, ?Flag, ?Value, ?Line) is nondet.\n\n   True when Flag is set  to  Value   at  Line  in  Source. This is\n   intended to support incremental  parsing  of   a  term  from the\n   source-file.",
    "prefix":"xref_prolog_flag"
  },
  "prolog_xref:xref_public_list/3": {
    "body": ["xref_public_list(${1:Spec}, ${2:Source}, ${3:Options})$4\n$0" ],
    "description":"  xref_public_list(+Spec, +Source, +Options) is semidet.\n\n   Find meta-information about File. This predicate reads all terms\n   upto the first term that is not  a directive. It uses the module\n   and  meta_predicate  directives  to   assemble  the  information\n   in Options.  Options processed:\n\n     * path(-Path)\n     Path is the full path name of the referenced file.\n     * module(-Module)\n     Module is the module defines in Spec.\n     * exports(-Exports)\n     Exports is a list of predicate indicators and operators\n     collected from the module/2 term and reexport declarations.\n     * public(-Public)\n     Public declarations of the file.\n     * meta(-Meta)\n     Meta is a list of heads as they appear in meta_predicate/1\n     declarations.\n     * silent(+Boolean)\n     Do not print any messages or raise exceptions on errors.\n\n   @param Source is the file from which Spec is referenced.",
    "prefix":"xref_public_list"
  },
  "prolog_xref:xref_public_list/4": {
    "body": [
      "xref_public_list(${1:File}, ${2:Path}, ${3:Export}, ${4:Src})$5\n$0"
    ],
    "description":"  xref_public_list(+File, -Path, -Export, +Src) is semidet.\n  xref_public_list(+File, -Path, -Module, -Export, -Meta, +Src) is semidet.\n  xref_public_list(+File, -Path, -Module, -Export, -Public, -Meta, +Src) is semidet.\n\n   Find meta-information about File. This predicate reads all terms\n   upto the first term that is not  a directive. It uses the module\n   and  meta_predicate  directives  to   assemble  the  information\n   described below.\n\n   These predicates fail if File is not a module-file.\n\n   @param  Path is the canonical path to File\n   @param  Module is the module defined in Path\n   @param  Export is a list of predicate indicators.\n   @param  Meta is a list of heads as they appear in\n           meta_predicate/1 declarations.\n   @param  Src is the place from which File is referenced.\n   @deprecated New code should use xref_public_list/3, which\n           unifies all variations using an option list.",
    "prefix":"xref_public_list"
  },
  "prolog_xref:xref_public_list/6": {
    "body": [
      "xref_public_list(${1:File}, ${2:Path}, ${3:Module}, ${4:Export}, ${5:Meta}, ${6:Src})$7\n$0"
    ],
    "description":"  xref_public_list(+File, -Path, -Export, +Src) is semidet.\n  xref_public_list(+File, -Path, -Module, -Export, -Meta, +Src) is semidet.\n  xref_public_list(+File, -Path, -Module, -Export, -Public, -Meta, +Src) is semidet.\n\n   Find meta-information about File. This predicate reads all terms\n   upto the first term that is not  a directive. It uses the module\n   and  meta_predicate  directives  to   assemble  the  information\n   described below.\n\n   These predicates fail if File is not a module-file.\n\n   @param  Path is the canonical path to File\n   @param  Module is the module defined in Path\n   @param  Export is a list of predicate indicators.\n   @param  Meta is a list of heads as they appear in\n           meta_predicate/1 declarations.\n   @param  Src is the place from which File is referenced.\n   @deprecated New code should use xref_public_list/3, which\n           unifies all variations using an option list.",
    "prefix":"xref_public_list"
  },
  "prolog_xref:xref_public_list/7": {
    "body": [
      "xref_public_list(${1:File}, ${2:Path}, ${3:Module}, ${4:Export}, ${5:Public}, ${6:Meta}, ${7:Src})$8\n$0"
    ],
    "description":"  xref_public_list(+File, -Path, -Export, +Src) is semidet.\n  xref_public_list(+File, -Path, -Module, -Export, -Meta, +Src) is semidet.\n  xref_public_list(+File, -Path, -Module, -Export, -Public, -Meta, +Src) is semidet.\n\n   Find meta-information about File. This predicate reads all terms\n   upto the first term that is not  a directive. It uses the module\n   and  meta_predicate  directives  to   assemble  the  information\n   described below.\n\n   These predicates fail if File is not a module-file.\n\n   @param  Path is the canonical path to File\n   @param  Module is the module defined in Path\n   @param  Export is a list of predicate indicators.\n   @param  Meta is a list of heads as they appear in\n           meta_predicate/1 declarations.\n   @param  Src is the place from which File is referenced.\n   @deprecated New code should use xref_public_list/3, which\n           unifies all variations using an option list.",
    "prefix":"xref_public_list"
  },
  "prolog_xref:xref_source/1": {
    "body":"xref_source(${1:Source})$2\n$0",
    "description":"xref_source(+Source).\nGather information on Source. If Source has  already been processed and is still up-to-date according to the file  timestamp, no action is taken. This predicate must be called on a file  before information can be gathered.",
    "prefix":"xref_source"
  },
  "prolog_xref:xref_source/2": {
    "body": ["xref_source(${1:Source}, ${2:Options})$3\n$0" ],
    "description":"  xref_source(+Source) is det.\n  xref_source(+Source, +Options) is det.\n\n   Generate the cross-reference data  for   Source  if  not already\n   done and the source is not modified.  Checking for modifications\n   is only done for files.  Options processed:\n\n     * silent(+Boolean)\n     If =true= (default =false=), emit warning messages.\n     * module(+Module)\n     Define the initial context module to work in.\n     * register_called(+Which)\n     Determines which calls are registerd.  Which is one of\n     =all=, =non_iso= or =non_built_in=.\n     * comments(+CommentHandling)\n     How to handle comments.  If =store=, comments are stored into\n     the database as if the file was compiled. If =collect=,\n     comments are entered to the xref database and made available\n     through xref_mode/2 and xref_comment/4.  If =ignore=,\n     comments are simply ignored. Default is to =collect= comments.\n     * process_include(+Boolean)\n     Process the content of included files (default is `true`).\n\n   @param Source   File specification or XPCE buffer",
    "prefix":"xref_source"
  },
  "prolog_xref:xref_source_file/3": {
    "body": ["xref_source_file(${1:Spec}, ${2:File}, ${3:Src})$4\n$0" ],
    "description":"  xref_source_file(+Spec, -File, +Src) is semidet.\n  xref_source_file(+Spec, -File, +Src, +Options) is semidet.\n\n   Find named source file from Spec, relative to Src.",
    "prefix":"xref_source_file"
  },
  "prolog_xref:xref_source_file/4": {
    "body": [
      "xref_source_file(${1:Spec}, ${2:File}, ${3:Src}, ${4:Options})$5\n$0"
    ],
    "description":"  xref_source_file(+Spec, -File, +Src) is semidet.\n  xref_source_file(+Spec, -File, +Src, +Options) is semidet.\n\n   Find named source file from Spec, relative to Src.",
    "prefix":"xref_source_file"
  },
  "prolog_xref:xref_used_class/2": {
    "body": ["xref_used_class(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xref_used_class('Param1','Param2')",
    "prefix":"xref_used_class"
  },
  "prolog_xref:xref_uses_file/3": {
    "body": ["xref_uses_file(${1:Source}, ${2:Spec}, ${3:Path})$4\n$0" ],
    "description":"  xref_uses_file(?Source, ?Spec, ?Path) is nondet.\n\n   True when Source tries to load a file using Spec.\n\n   @param Spec is a specification for absolute_file_name/3\n   @param Path is either an absolute file name of the target\n          file or the atom =|<not_found>|=.",
    "prefix":"xref_uses_file"
  },
  "prompt/2": {
    "body":"prompt(${1:Old}, ${2:New})$3\n$0",
    "description":"prompt(-Old, +New).\nSet prompt associated with read/1  and its derivatives. Old is first unified with the current  prompt. On success the prompt will be set to New if this is  an atom. Otherwise an error message is displayed. A prompt is printed if  one of the read predicates is called and the cursor is at the left  margin. It is also printed whenever a newline is given and the term has  not been terminated. Prompts are only printed when the current input  stream is user.",
    "prefix":"prompt"
  },
  "prompt1/1": {
    "body":"prompt1(${1:Prompt})$2\n$0",
    "description":"prompt1(+Prompt).\nSets the prompt for the next line to be read. Continuation lines will be  read using the prompt defined by prompt/2.",
    "prefix":"prompt1"
  },
  "protobufs:protobuf_message/2": {
    "body":"protobuf_message(${1:Template}, ${2:Wire_stream})$3\n$0",
    "description":"[semidet]protobuf_message(?Template, ?Wire_stream).\n",
    "prefix":"protobuf_message"
  },
  "protobufs:protobuf_message/3": {
    "body":"protobuf_message(${1:Template}, ${2:Wire_stream}, ${3:Rest})$4\n$0",
    "description":"[nondet]protobuf_message(?Template, ?Wire_stream, ?Rest).\nMarshalls and unmarshalls byte streams encoded using Google's Protobuf  grammars. protobuf_message/2  provides a bi-directional parser that marshalls a Prolog structure to Wire_stream,  according to rules specified by Template. It can also  unmarshall Wire_stream into a Prolog structure according to  the same grammar. protobuf_message/3  provides a difference list version. Template is a protobuf grammar  specification. On decode, unbound variables in the Template  are unified with their respective values in the Wire_stream.  On encode, Template must be ground. Wire_stream is a code list that  was generated by a protobuf encoder using an equivalent template. ",
    "prefix":"protobuf_message"
  },
  "protocol/1": {
    "body":"protocol(${1:File})$2\n$0",
    "description":"protocol(+File).\nStart protocolling on file File. If there is already a  protocol file open, then close it first. If File exists it is  truncated.",
    "prefix":"protocol"
  },
  "protocola/1": {
    "body":"protocola(${1:File})$2\n$0",
    "description":"protocola(+File).\nEquivalent to protocol/1,  but does not truncate the File if it exists.",
    "prefix":"protocola"
  },
  "protocolling/1": {
    "body":"protocolling(${1:File})$2\n$0",
    "description":"protocolling(-File).\nTrue if a protocol was started with protocol/1  or protocola/1  and unifies File with the current protocol output file.",
    "prefix":"protocolling"
  },
  "pui_help:prolog_apropos/1": {
    "body": ["prolog_apropos(${1:Keyword})$2\n$0" ],
    "description":"  prolog_apropos(+Keyword) is det.\n\n   Do a keyword search on the manual through the object summaries.",
    "prefix":"prolog_apropos"
  },
  "pui_help:prolog_explain/1": {
    "body": ["prolog_explain(${1:Term})$2\n$0" ],
    "description":"  prolog_explain(+Term) is det.\n\n   Provide all information Prolog knows about Term.",
    "prefix":"prolog_explain"
  },
  "pui_help:prolog_help/0": {
    "body": ["prolog_help$1\n$0" ],
    "description":"  prolog_help is det.\n\n   Open SWI-Prolog graphical reference manual.",
    "prefix":"prolog_help"
  },
  "pui_help:prolog_help/1": {
    "body": ["prolog_help(${1:Topic})$2\n$0" ],
    "description":"  prolog_help(+Topic) is semidet.\n\n   Open SWI-Prolog graphical reference manual   on  Topic. Fails if\n   Topic is not in the manual.",
    "prefix":"prolog_help"
  },
  "pui_help:prolog_help_topic/1": {
    "body": ["prolog_help_topic(${1:'Param1'})$2\n$0" ],
    "description":"prolog_help_topic('Param1')",
    "prefix":"prolog_help_topic"
  },
  "pure_input:lazy_list_character_count/1": {
    "body":"lazy_list_character_count(${1:CharCount})$2\n$0",
    "description":"lazy_list_character_count(-CharCount)//.\nTrue when CharCount is the current character count in the  Lazy list. The character count is computed by finding the distance to  the next frozen tail of the lazy list. CharCount is one of:  \n\nAn integer\nA term end_of_file-Count\n\n  See also: lazy_list_location/3 provides full details  of the location for error reporting.\n\n ",
    "prefix":"lazy_list_character_count"
  },
  "pure_input:lazy_list_character_count/3": {
    "body": [
      "lazy_list_character_count(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"lazy_list_character_count('Param1','Param2','Param3')",
    "prefix":"lazy_list_character_count"
  },
  "pure_input:lazy_list_location/1": {
    "body":"lazy_list_location(${1:Location})$2\n$0",
    "description":"[det]lazy_list_location(-Location)//.\nDetermine current (error) location in a lazy list. True when Location is an (error) location term that represents the  current location in the DCG list. Location is a term file(Name, Line, LinePos, CharNo)  or stream(Stream, Line, LinePos, CharNo) if no file is  associated to the stream RestLazyList. Finally, if the Lazy list is  fully materialized (ends in []), Location is  unified with end_of_file-CharCount.   See also: lazy_list_character_count/3 only provides  the character count.\n\n ",
    "prefix":"lazy_list_location"
  },
  "pure_input:lazy_list_location/3": {
    "body": [
      "lazy_list_location(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"lazy_list_location('Param1','Param2','Param3')",
    "prefix":"lazy_list_location"
  },
  "pure_input:phrase_from_file/2": {
    "body":"phrase_from_file(${1:Grammar}, ${2:File})$3\n$0",
    "description":"[nondet]phrase_from_file(:Grammar, +File).\nProcess the content of File using the DCG rule Grammar.  The space usage of this mechanism depends on the length of the not  committed part of Grammar. Committed parts of the temporary  list are reclaimed by the garbage collector, while the list is extended  on demand due to unification of the attributed tail variable. Below is  an example that counts the number of times a string appears in a file.  The library dcg/basics provides string/3 matching an arbitrary string and remainder/3  which matches the remainder of the input without parsing.  \n\n:- use_module(library(dcg/basics)).\n\nfile_contains(File, Pattern) :-\n        phrase_from_file(match(Pattern), File).\n\nmatch(Pattern) -->\n        string(_),\n        string(Pattern),\n        remainder(_).\n\nmatch_count(File, Pattern, Count) :-\n        aggregate_all(count, file_contains(File, Pattern), Count).\n\n  This can be called as (note that the pattern must be a string (code  list)): \n\n\n\n?- match_count('pure_input.pl', `file`, Count).\n\n ",
    "prefix":"phrase_from_file"
  },
  "pure_input:phrase_from_file/3": {
    "body":"phrase_from_file(${1:Grammar}, ${2:File}, ${3:Options})$4\n$0",
    "description":"[nondet]phrase_from_file(:Grammar, +File, +Options).\nAs phrase_from_file/2,  providing additional Options. Options are passed  to open/4.",
    "prefix":"phrase_from_file"
  },
  "pure_input:phrase_from_stream/2": {
    "body":"phrase_from_stream(${1:Grammer}, ${2:Stream})$3\n$0",
    "description":"phrase_from_stream(:Grammer, +Stream).\nRun Grammer against the character codes on Stream. Stream  must be buffered.",
    "prefix":"phrase_from_stream"
  },
  "pure_input:stream_to_lazy_list/2": {
    "body":"stream_to_lazy_list(${1:Stream}, ${2:List})$3\n$0",
    "description":"[det]stream_to_lazy_list(+Stream, -List).\nCreate a lazy list representing the character codes in Stream. List is a partial list ending in an attributed variable.  Unifying this variable reads the next block of data. The block is stored  with the attribute value such that there is no need to re-read it.  Compatibility: Unlike the previous version of this predicate this version does not  require a repositionable stream. It does require a buffer size of at  least the maximum number of bytes of a multi-byte sequence (6).\n\n ",
    "prefix":"stream_to_lazy_list"
  },
  "pure_input:syntax_error/1": {
    "body":"syntax_error(${1:Error})$2\n$0",
    "description":"syntax_error(+Error)//.\nThrow the syntax error Error at the current location of the  input. This predicate is designed to be called from the handler of phrase_from_file/3.  throws: error(syntax_error(Error), Location)\n\n ",
    "prefix":"syntax_error"
  },
  "pure_input:syntax_error/3": {
    "body": ["syntax_error(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"syntax_error('Param1','Param2','Param3')",
    "prefix":"syntax_error"
  },
  "put/1": {
    "body":"put(${1:Char})$2\n$0",
    "description":"put(+Char).\nWrite Char to the current output stream. Char is  either an integer expression evaluating to a character code or an atom  of one character. Deprecated. New code should use put_char/1  or put_code/1.",
    "prefix":"put"
  },
  "put/2": {
    "body":"put(${1:Stream}, ${2:Char})$3\n$0",
    "description":"put(+Stream, +Char).\nWrite Char to Stream. See put/1  for details.",
    "prefix":"put"
  },
  "put_attr/3": {
    "body":"put_attr(${1:Var}, ${2:Module}, ${3:Value})$4\n$0",
    "description":"put_attr(+Var, +Module, +Value).\nIf Var is a variable or attributed variable, set the value  for the attribute named Module to Value. If an  attribute with this name is already associated with Var, the  old value is replaced. Backtracking will restore the old value (i.e., an  attribute is a mutable term; see also setarg/3).  This predicate raises an uninstantiation error if Var is not a variable, and a type error if Module  is not an atom.",
    "prefix":"put_attr"
  },
  "put_attrs/2": {
    "body":"put_attrs(${1:Var}, ${2:Attributes})$3\n$0",
    "description":"put_attrs(+Var, -Attributes).\nSet all attributes of Var. See get_attrs/2  for a description of Attributes.",
    "prefix":"put_attrs"
  },
  "put_byte/1": {
    "body":"put_byte(${1:Byte})$2\n$0",
    "description":"[ISO]put_byte(+Byte).\nWrite a single byte to the output. Byte must be an integer  between 0 and 255.",
    "prefix":"put_byte"
  },
  "put_byte/2": {
    "body":"put_byte(${1:Stream}, ${2:Byte})$3\n$0",
    "description":"[ISO]put_byte(+Stream, +Byte).\nWrite a single byte to Stream. Byte must be an  integer between 0 and 255.",
    "prefix":"put_byte"
  },
  "put_char/1": {
    "body":"put_char(${1:Char})$2\n$0",
    "description":"[ISO]put_char(+Char).\nWrite a character to the current output, obeying the encoding defined  for the current output stream. Note that this may raise an exception if  the encoding of the output stream cannot represent Char.",
    "prefix":"put_char"
  },
  "put_char/2": {
    "body":"put_char(${1:Stream}, ${2:Char})$3\n$0",
    "description":"[ISO]put_char(+Stream, +Char).\nWrite a character to Stream, obeying the encoding defined for Stream. Note that this may raise an exception if the encoding  of Stream cannot represent Char.",
    "prefix":"put_char"
  },
  "put_code/1": {
    "body":"put_code(${1:Code})$2\n$0",
    "description":"[ISO]put_code(+Code).\nSimilar to put_char/1,  but using a character code. Code is a non-negative  integer. Note that this may raise an exception if the encoding of the  output stream cannot represent Code.",
    "prefix":"put_code"
  },
  "put_code/2": {
    "body":"put_code(${1:Stream}, ${2:Code})$3\n$0",
    "description":"[ISO]put_code(+Stream, +Code).\nSame as put_code/1  but directing Code to Stream.",
    "prefix":"put_code"
  },
  "put_dict/3": {
    "body":"put_dict(${1:New}, ${2:DictIn}, ${3:DictOut})$4\n$0",
    "description":"put_dict(+New, +DictIn, -DictOut).\nDictOut is a new dict created by replacing or adding  key-value pairs from New to Dict. New  is either a dict or a valid input for dict_create/3.  This predicate is normally accessed using the functional notation. Below  are some examples:  \n\n?- A = point{x:1, y:2}.put(_{x:3}).\nA = point{x:3, y:2}.\n\n?- A = point{x:1, y:2}.put([x=3]).\nA = point{x:3, y:2}.\n\n?- A = point{x:1, y:2}.put([x=3,z=0]).\nA = point{x:3, y:2, z:0}.\n\n ",
    "prefix":"put_dict"
  },
  "put_dict/4": {
    "body":"put_dict(${1:Key}, ${2:DictIn}, ${3:Value}, ${4:DictOut})$5\n$0",
    "description":"put_dict(+Key, +DictIn, +Value, -DictOut).\nDictOut is a new dict created by replacing or adding Key-Value to DictIn. This predicate is  normally accessed using the functional notation. Below is an example:  \n\n?- A = point{x:1, y:2}.put(x, 3).\nA = point{x:3, y:2}.\n\n ",
    "prefix":"put_dict"
  },
  "pwp:html_write/3": {
    "body":"html_write(${1:Stream}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"html_write(+Stream, +Term, +Options).\nSame as sgml_write/3,  but passes the HTML DTD as obtained from dtd/2.  The Options are described with xml_write/3.",
    "prefix":"html_write"
  },
  "pwp:pwp_files/2": {
    "body":"pwp_files(${1:In}, ${2:Out})$3\n$0",
    "description":"[det]pwp_files(:In:atom, +Out:atom).\nloads an Xml document from the file named In, transforms it  using the PWP attributes, and writes the transformed version to the new  file named Out.",
    "prefix":"pwp_files"
  },
  "pwp:pwp_stream/3": {
    "body":"pwp_stream(${1:Input}, ${2:Output}, ${3:Context})$4\n$0",
    "description":"[det]pwp_stream(:Input:input_stream, +Output:output_stream, +Context:list).\nLoads an Xml document from the given Input stream, transforms  it using the PWP attributes, and writes the transformed version to the  given Output stream. Context provides initial  contextual variables and is a list of Name=Value.",
    "prefix":"pwp_stream"
  },
  "pwp:pwp_xml/3": {
    "body":"pwp_xml(${1:In}, ${2:Out}, ${3:Context})$4\n$0",
    "description":"pwp_xml(:In:list(xml), -Out:list(xml), +Context).\nmaps down a list of XML items, acting specially on elements and copying  everything else unchanged, including white space. The Context  is a list of 'VariableName'=CurrentValue bindings.",
    "prefix":"pwp_xml"
  },
  "pwp:sgml_register_catalog_file/2": {
    "body":"sgml_register_catalog_file(${1:File}, ${2:Location})$3\n$0",
    "description":"sgml_register_catalog_file(+File, +Location).\nRegister the indicated File as a catalog file. Location  is either start or end and defines whether the  catalog is considered first or last. This predicate has no effect if File  is already part of the catalog.  If no files are registered using this predicate, the first query on  the catalog examines SGML_CATALOG_FILES and fills the  catalog with all files in this path.\n\n",
    "prefix":"sgml_register_catalog_file"
  },
  "pwp:sgml_write/3": {
    "body":"sgml_write(${1:Stream}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"sgml_write(+Stream, +Term, +Options).\nWrite the SGML DOCTYPE header and the content of the  document as represented by Term to Stream. The Options  are described with xml_write/3.",
    "prefix":"sgml_write"
  },
  "pwp:xml_name/1": {
    "body":"xml_name(${1:In})$2\n$0",
    "description":"xml_name(+In).\nBackward compatibility version for xml_name/2.  Assumes ascii encoding.",
    "prefix":"xml_name"
  },
  "pwp:xml_name/2": {
    "body":"xml_name(${1:In}, ${2:Encoding})$3\n$0",
    "description":"xml_name(+In, +Encoding).\nSucceed if In is an atom or string that satisfies the rules  for a valid XML element or attribute name. As with the other predicates  in this group, if Encoding cannot represent one of the  characters, this function fails. Character classification is based on http://www.w3.org/TR/2006/REC-xml-20060816.",
    "prefix":"xml_name"
  },
  "pwp:xml_quote_attribute/2": {
    "body":"xml_quote_attribute(${1:In}, ${2:Quoted})$3\n$0",
    "description":"xml_quote_attribute(+In, -Quoted).\nBackward compatibility version for xml_quote_attribute/3.  Assumes ascii encoding.",
    "prefix":"xml_quote_attribute"
  },
  "pwp:xml_quote_attribute/3": {
    "body":"xml_quote_attribute(${1:In}, ${2:Quoted}, ${3:Encoding})$4\n$0",
    "description":"xml_quote_attribute(+In, -Quoted, +Encoding).\nMap the characters that may not appear in XML attributes to entities.  Currently these are <>&\".4Older  versions also mapped ' to &apos;.  Characters that cannot represented in Encoding are mapped to  XML character entities.",
    "prefix":"xml_quote_attribute"
  },
  "pwp:xml_quote_cdata/2": {
    "body":"xml_quote_cdata(${1:In}, ${2:Quoted})$3\n$0",
    "description":"xml_quote_cdata(+In, -Quoted).\nBackward compatibility version for xml_quote_cdata/3.  Assumes ascii encoding.",
    "prefix":"xml_quote_cdata"
  },
  "pwp:xml_quote_cdata/3": {
    "body":"xml_quote_cdata(${1:In}, ${2:Quoted}, ${3:Encoding})$4\n$0",
    "description":"xml_quote_cdata(+In, -Quoted, +Encoding).\nVery similar to xml_quote_attribute/3,  but does not quote the single- and double-quotes.",
    "prefix":"xml_quote_cdata"
  },
  "pwp:xml_write/3": {
    "body":"xml_write(${1:Stream}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"xml_write(+Stream, +Term, +Options).\nWrite the XML header with encoding information and the content of the  document as represented by Term to Stream. This  predicate deals with XML with or without namespaces. If namespace  identifiers are not provided they are generated. This predicate defines  the following Options  dtd(DTD): Specify the DTD. In SGML documents the DTD is required to distinguish  between elements that are declared empty in the DTD and elements that  just happen to have no content. Further optimisation (shortref, omitted  tags, etc.) could be considered in the future. The DTD is also used to  find the declared named character entities.\n\ndoctype(Doctype): Document type to include in the header. When omitted it is taken from  the outer element.\n\nheader(Bool): If Bool is false, the XML header is suppressed.  Useful for embedding in other XML streams.\n\nlayout(Bool): Do/do not emit layout characters to make the output readable, Default is  to emit layout. With layout enabled, elements only containing other  elements are written using increasing indentation. This introduces  (depending on the mode and defined whitespace handling) CDATA sequences  with only layout between elements when read back in. If false,  no layout characters are added. As this mode does not need to analyse  the document it is faster and guarantees correct output when read back.  Unfortunately the output is hardly human readable and causes problems  with many editors.\n\nindent(Integer): Set the initial element indentation. It more than zero, the indent is  written before the document.\n\nnsmap(Map): Set the initial namespace map. Map is a list of Name = URI. This option, together with header  and ident is added to use xml_write/3  to generate XML that is embedded in a larger XML document.\n\nnet(Bool): Use/do not use Null End Tags. For XML, this applies only to  empty elements, so you get <foo/> (default, net(true)) or <foo><\/foo> (net(false)).  For SGML, this applies to empty elements, so you get <foo>  (if foo is declared to be EMPTY in the DTD), <foo><\/foo> (default, net(false))  or <foo// (net(true)). In SGML code, short  character content not containing / can be  emitted as <b>xxx<\/b> (default, net(false)  or <b/xxx/ (net(true))\n\n ",
    "prefix":"xml_write"
  },
  "pwp:xsd_number_string/2": {
    "body":"xsd_number_string(${1:Number}, ${2:String})$3\n$0",
    "description":"[det]xsd_number_string(?Number, ?String).\nThis predicate is similar to number_string/2,  but accepts floating point numbers according to the XML syntax rather  than the Prolog syntax. In particular, XML does not require a `0' (zero)  before and after the decimal dot and accepts the constants NaN  and INF. If a Prolog float is converted into a string it  returns the XML canonical form. This form always has one digit before  the decimal dot, at least one digit after it and an exponential  component using the capital E. This predicate behaves as number_string/2  for integers.  Throws a syntax_error(xsd_number) if String  is given and is not a well-formed XSD number.\n\n",
    "prefix":"xsd_number_string"
  },
  "pwp:xsd_time_string/3": {
    "body":"xsd_time_string(${1:DateTime}, ${2:Type}, ${3:String})$4\n$0",
    "description":"[det]xsd_time_string(?DateTime, ?Type, ?String).\nSerialize and deserialize the XSD date and time formats. The converion  is represented by the table below.  \n\nProlog term Type XSD  string date(Y,M,D)xsd:dateYYYY-MM-DD date_time(Y,M,D,H,Mi,S)xsd:dateTimeYYYY-MM-DDTHH-MM-SS date_time(Y,M,D,H,Mi,S,0)xsd:dateTimeYYYY-MM-DDTHH-MM-SSZ date_time(Y,M,D,H,Mi,S,TZ)xsd:dateTimeYYYY-MM-DDTHH-MM-SS[+-]HH:MM time(H,M,S)xsd:timeHH:MM:SS year_month(Y,M)xsd:gYearMonthYYYY-MM month_day(M,D)xsd:gMonthDayMM-DD Dxsd:gDayDD Mxsd:gMonthMM Yxsd:gYearYYYY   For the Prolog term all variables denote integers except for S, which represents seconds as either an integer or float.  The TZ argument is the offset from UTC in seconds. The Type is written as xsd:name, but is in fact the  full URI of the XSD data type, e.g., http://www.w3.org/2001/XMLSchema#date.  In the XSD string notation, the letters YMDHS denote digits. The  notation SS is either a two-digit integer or a decimal number with two  digits before the floating point, e.g. 05.3 to denote 5.3  seconds. \n\nFor most conversions, Type may be specified unbound and is  unified with the resulting type. For ambiguous conversions, Type  must be specified or an instantiation_error is raised. When converting  from Prolog to XSD serialization, D, M and Y are ambiguous. When  convertion from XSD serialization to Prolog, only DD and MM are  ambiguous. If Type and String are both given and String  is a valid XSD date/time representation but not matching Type  a syntax error with the shape syntax_error(Type) is raised.  If DateTime and Type are both given and DateTime  does not satisfy Type a domain_error of the shape domain_error(xsd_time(Type), DateTime) is raised. \n\nThe domain of numerical values is verified and a corresponding  domain_error exception is raised if the domain is violated. There is no  test for the existence of a date and thus \"2016-02-31\",  although non-existing is accepted as valid.\n\n",
    "prefix":"xsd_time_string"
  },
  "qcompile/1": {
    "body":"qcompile(${1:File})$2\n$0",
    "description":"qcompile(:File).\nTakes a file specification as consult/1,  etc., and, in addition to the normal compilation, creates a Quick  Load File from File. The file extension of this file is .qlf.  The basename of the Quick Load File is the same as the input file.  If the file contains `:- consult(+File)', `:-  [+File]' or `:- load_files(+File,  [qcompile(part), ...])' statements, the referred files are  compiled into the same .qlf file. Other directives will be  stored in the .qlf file and executed in the same fashion as when loading  the .pl file. \n\nFor term_expansion/2,  the same rules as described in section 2.10 apply. \n\nConditional execution or optimisation may test the predicate compiling/0. \n\nSource references (source_file/2)  in the Quick Load File refer to the Prolog source file from which the  compiled code originates.\n\n",
    "prefix":"qcompile"
  },
  "qcompile/2": {
    "body":"qcompile(${1:File}, ${2:Options})$3\n$0",
    "description":"qcompile(:File, +Options).\nAs qcompile/1,  but processes additional options as defined by load_files/2.bugOption  processing is currently incomplete.",
    "prefix":"qcompile"
  },
  "qp_foreign:load_foreign_files/0": {
    "body": ["load_foreign_files$1\n$0" ],
    "description":"  load_foreign_files is det.\n  load_foreign_files(:Files, +Libs) is det.\n  load_foreign_files(+SharedObject, :Files, +Libs) is det.\n\n   Calls make_foreign_wrapper_file(+File), compiles the wrapper\n   and loads the predicates.",
    "prefix":"load_foreign_files"
  },
  "qp_foreign:load_foreign_files/2": {
    "body": ["load_foreign_files(${1:Files}, ${2:Libs})$3\n$0" ],
    "description":"  load_foreign_files is det.\n  load_foreign_files(:Files, +Libs) is det.\n  load_foreign_files(+SharedObject, :Files, +Libs) is det.\n\n   Calls make_foreign_wrapper_file(+File), compiles the wrapper\n   and loads the predicates.",
    "prefix":"load_foreign_files"
  },
  "qp_foreign:load_foreign_files/3": {
    "body": [
      "load_foreign_files(${1:SharedObject}, ${2:Files}, ${3:Libs})$4\n$0"
    ],
    "description":"  load_foreign_files is det.\n  load_foreign_files(:Files, +Libs) is det.\n  load_foreign_files(+SharedObject, :Files, +Libs) is det.\n\n   Calls make_foreign_wrapper_file(+File), compiles the wrapper\n   and loads the predicates.",
    "prefix":"load_foreign_files"
  },
  "qp_foreign:load_foreign_resource/2": {
    "body": ["load_foreign_resource(${1:Resource}, ${2:Dir})$3\n$0" ],
    "description":"  load_foreign_resource(:Resource, +Dir)\n\n   Load a foreign module. First try to  load from the same direcory\n   as the Prolog file. Otherwise   load  using SWI-Prolog's default\n   search path.",
    "prefix":"load_foreign_resource"
  },
  "qp_foreign:make_foreign_resource_wrapper/3": {
    "body": [
      "make_foreign_resource_wrapper(${1:Resource}, ${2:ResBase}, ${3:FileBase})$4\n$0"
    ],
    "description":"  make_foreign_resource_wrapper(:Resource, +ResBase, +FileBase)\n\n   Create a wrapper-file for the given foreign resource",
    "prefix":"make_foreign_resource_wrapper"
  },
  "qp_foreign:make_foreign_wrapper_file/1": {
    "body": ["make_foreign_wrapper_file(${1:OutFile})$2\n$0" ],
    "description":"  make_foreign_wrapper_file(:OutFile) is det.\n  make_foreign_wrapper_file(:Files, +OutFile) is det.\n\n   Just output the wrapper file to the named .c file.  May be used\n   to prepare for static linking or the preparation of the native\n   SWI-Prolog foreign-file.",
    "prefix":"make_foreign_wrapper_file"
  },
  "qp_foreign:make_foreign_wrapper_file/2": {
    "body": ["make_foreign_wrapper_file(${1:Files}, ${2:OutFile})$3\n$0" ],
    "description":"  make_foreign_wrapper_file(:OutFile) is det.\n  make_foreign_wrapper_file(:Files, +OutFile) is det.\n\n   Just output the wrapper file to the named .c file.  May be used\n   to prepare for static linking or the preparation of the native\n   SWI-Prolog foreign-file.",
    "prefix":"make_foreign_wrapper_file"
  },
  "qp_foreign:make_shared_object/3": {
    "body": ["make_shared_object(${1:Object}, ${2:Files}, ${3:Libs})$4\n$0" ],
    "description":"  make_shared_object(+Object, :Files, +Libs) is det.\n\n   Generate  a  wrapper  and  link  it  using  plld  to  the  given\n   SharedObject.",
    "prefix":"make_shared_object"
  },
  "qsave:qsave_program/1": {
    "body": ["qsave_program(${1:File})$2\n$0" ],
    "description":"  qsave_program(+File) is det.\n  qsave_program(+File, :Options) is det.\n\n   Make a saved state in file `File'.",
    "prefix":"qsave_program"
  },
  "qsave:qsave_program/2": {
    "body": ["qsave_program(${1:File}, ${2:Options})$3\n$0" ],
    "description":"  qsave_program(+File) is det.\n  qsave_program(+File, :Options) is det.\n\n   Make a saved state in file `File'.",
    "prefix":"qsave_program"
  },
  "qsave_program/1": {
    "body":"qsave_program(${1:File})$2\n$0",
    "description":"qsave_program(+File).\nEquivalent to qsave_program(File, []).",
    "prefix":"qsave_program"
  },
  "qsave_program/2": {
    "body":"qsave_program(${1:File}, ${2:Options})$3\n$0",
    "description":"qsave_program(+File, +Options).\nSaves the current state of the program to the file File. The  result is a resource archive containing a saved state that expresses all  Prolog data from the running program and all user-defined resources.  Depending on the stand_alone option, the resource is headed  by the emulator, a Unix shell script or nothing. Options is a  list of additional options:  local(+KBytes): Limit for the local stack. See section  2.4.3.\n\nglobal(+KBytes): Limit for the global stack. See section  2.4.3.\n\ntrail(+KBytes): Limit for the trail stack. See section  2.4.3.\n\ngoal(:Callable): Initialization goal for the new executable (see -g).\n\ntoplevel(:Callable): Top-level goal for the new executable (see -t).\n\ninit_file(+Atom): Default initialization file for the new executable. See -f.\n\nclass(+Class): If runtime, only read resources from the state (default).  If kernel, lock all predicates as system predicates. If development, save the predicates in their current state and  keep reading resources from their source (if present). See also resource/3.\n\nautoload(+Boolean): If true (default), run autoload/0  first.\n\nmap(+File): Dump a human-readable trace of what has been saved in File.\n\nop(+Action): One of save (default) to save the current operator table or standard  to use the initial table of the emulator.\n\nstand_alone(+Boolean): If true, the emulator is the first part of the state. If  the emulator is started it will test whether a boot file (state) is  attached to the emulator itself and load this state. Provided the  application has all libraries loaded, the resulting executable is  completely independent of the runtime environment or location where it  was built. See also section 2.10.2.4.\n\nemulator(+File): File to use for the emulator. Default is the running Prolog image.\n\nforeign(+Action): If save, include shared objects (DLLs) into the saved  state. See current_foreign_library/2.  If the program strip is available, this is first used to reduce  the size of the shared object. If a state is started, use_foreign_library/1  first tries to locate the foreign resource in the executable. When found  it copies the content of the resource to a temporary file and loads it.  If possible (Unix), the temporary object is deleted immediately after  opening.173This option is  experimental and currently disabled by default. It will become the  default if it proves robust.\n\n ",
    "prefix":"qsave_program"
  },
  "quasi_quotations:phrase_from_quasi_quotation/2": {
    "body":"phrase_from_quasi_quotation(${1:Grammar}, ${2:Content})$3\n$0",
    "description":"[det]phrase_from_quasi_quotation(:Grammar, +Content).\nProcess the quasi quotation using the DCG Grammar. Failure of  the grammer is interpreted as a syntax error.  See also: with_quasi_quotation_input/3  for processing quotations from stream.\n\n ",
    "prefix":"phrase_from_quasi_quotation"
  },
  "quasi_quotations:quasi_quotation_syntax/1": {
    "body":"quasi_quotation_syntax(${1:SyntaxName})$2\n$0",
    "description":"[det]quasi_quotation_syntax(:SyntaxName).\nDeclare the predicate SyntaxName/4 to implement the the quasi  quote syntax SyntaxName. Normally used as a directive.",
    "prefix":"quasi_quotation_syntax"
  },
  "quasi_quotations:quasi_quotation_syntax_error/1": {
    "body":"quasi_quotation_syntax_error(${1:Error})$2\n$0",
    "description":"quasi_quotation_syntax_error(+Error).\nReport syntax_error(Error) using the current location in  the quasi quoted input parser.  throws: error(syntax_error(Error), Position)\n\n ",
    "prefix":"quasi_quotation_syntax_error"
  },
  "quasi_quotations:with_quasi_quotation_input/3": {
    "body":"with_quasi_quotation_input(${1:Content}, ${2:Stream}, ${3:Goal})$4\n$0",
    "description":"[det]with_quasi_quotation_input(+Content, -Stream, :Goal).\nProcess the quasi-quoted Content using Stream  parsed by Goal. Stream is a temporary stream with the following properties:  \n\nIts initial position represents the position of the start of  the quoted material.\nIt is a text stream, using utf8 encoding.\nIt allows for repositioning\nIt will be closed after Goal completes.\n\n Goal is executed as once(Goal). Goal  must succeed. Failure or exceptions from Goal are interpreted  as syntax errors.   See also: phrase_from_quasi_quotation/2  can be used to process a quotation using a grammar.\n\n ",
    "prefix":"with_quasi_quotation_input"
  },
  "quintus:abs/2": {
    "body": ["abs(${1:Number}, ${2:Absolute})$3\n$0" ],
    "description":"  abs(+Number, -Absolute)\n   Unify `Absolute' with the absolute value of `Number'.",
    "prefix":"abs"
  },
  "quintus:acos/2": {
    "body": ["acos(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"acos('Param1','Param2')",
    "prefix":"acos"
  },
  "quintus:asin/2": {
    "body": ["asin(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"asin('Param1','Param2')",
    "prefix":"asin"
  },
  "quintus:atan/2": {
    "body": ["atan(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"atan('Param1','Param2')",
    "prefix":"atan"
  },
  "quintus:atan2/3": {
    "body": ["atan2(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"atan2('Param1','Param2','Param3')",
    "prefix":"atan2"
  },
  "quintus:atom_char/2": {
    "body": ["atom_char(${1:Char}, ${2:Code})$3\n$0" ],
    "description":"  atom_char(+Char, -Code) is det.\n  atom_char(-Char, +Code) is det.\n\n   Same as ISO char_code/2.",
    "prefix":"atom_char"
  },
  "quintus:ceiling/2": {
    "body": ["ceiling(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"ceiling('Param1','Param2')",
    "prefix":"ceiling"
  },
  "quintus:compile/1": {
    "body": ["compile(${1:Files})$2\n$0" ],
    "description":"  compile(+Files) is det.\n\n   Compile   files.   SWI-Prolog   doesn't    distinguish   between\n   compilation and consult.\n\n   @see load_files/2.",
    "prefix":"compile"
  },
  "quintus:cos/2": {
    "body": ["cos(${1:Angle}, ${2:Sine})$3\n$0" ],
    "description":"  sin(+Angle, -Sine) is det.\n  cos(+Angle, -Cosine) is det.\n  tan(+Angle, -Tangent) is det.\n  log(+X, -NatLog) is det.\n  log10(+X, -Log) is det.\n\n   Math library predicates. SWI-Prolog (and   ISO) support these as\n   functions under is/2, etc.",
    "prefix":"cos"
  },
  "quintus:current_stream/3": {
    "body": ["current_stream(${1:Object}, ${2:Mode}, ${3:Stream})$4\n$0" ],
    "description":"  current_stream(?Object, ?Mode, ?Stream)\n\n   SICStus/Quintus and backward compatible predicate.  New code should\n   be using the ISO compatible stream_property/2.",
    "prefix":"current_stream"
  },
  "quintus:date/1": {
    "body": ["date(${1:Date})$2\n$0" ],
    "description":"  date(-Date) is det.\n\n   Get current date as date(Y,M,D)",
    "prefix":"date"
  },
  "quintus:floor/2": {
    "body": ["floor(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"floor('Param1','Param2')",
    "prefix":"floor"
  },
  "quintus:genarg/3": {
    "body": ["genarg(${1:Index}, ${2:Term}, ${3:Arg})$4\n$0" ],
    "description":"  genarg(?Index, +Term, ?Arg) is nondet.\n\n   Generalised version of ISO arg/3.  SWI-Prolog's arg/3 is already\n   genarg/3.",
    "prefix":"genarg"
  },
  "quintus:log/2": {
    "body": ["log(${1:Angle}, ${2:Sine})$3\n$0" ],
    "description":"  sin(+Angle, -Sine) is det.\n  cos(+Angle, -Cosine) is det.\n  tan(+Angle, -Tangent) is det.\n  log(+X, -NatLog) is det.\n  log10(+X, -Log) is det.\n\n   Math library predicates. SWI-Prolog (and   ISO) support these as\n   functions under is/2, etc.",
    "prefix":"log"
  },
  "quintus:log10/2": {
    "body": ["log10(${1:Angle}, ${2:Sine})$3\n$0" ],
    "description":"  sin(+Angle, -Sine) is det.\n  cos(+Angle, -Cosine) is det.\n  tan(+Angle, -Tangent) is det.\n  log(+X, -NatLog) is det.\n  log10(+X, -Log) is det.\n\n   Math library predicates. SWI-Prolog (and   ISO) support these as\n   functions under is/2, etc.",
    "prefix":"log10"
  },
  "quintus:midstring/3": {
    "body": ["midstring(${1:ABC}, ${2:B}, ${3:AC})$4\n$0" ],
    "description":"  midstring(?ABC, ?B, ?AC) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA, LenB) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA, LenB, LenC) is nondet.\n\n   Too difficult to explain.  See the Quintus docs.  As far as I\n   understand them the code below emulates this function just fine.",
    "prefix":"midstring"
  },
  "quintus:midstring/4": {
    "body": ["midstring(${1:ABC}, ${2:B}, ${3:AC}, ${4:LenA})$5\n$0" ],
    "description":"  midstring(?ABC, ?B, ?AC) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA, LenB) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA, LenB, LenC) is nondet.\n\n   Too difficult to explain.  See the Quintus docs.  As far as I\n   understand them the code below emulates this function just fine.",
    "prefix":"midstring"
  },
  "quintus:midstring/5": {
    "body": ["midstring(${1:ABC}, ${2:B}, ${3:AC}, ${4:LenA}, ${5:LenB})$6\n$0" ],
    "description":"  midstring(?ABC, ?B, ?AC) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA, LenB) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA, LenB, LenC) is nondet.\n\n   Too difficult to explain.  See the Quintus docs.  As far as I\n   understand them the code below emulates this function just fine.",
    "prefix":"midstring"
  },
  "quintus:midstring/6": {
    "body": [
      "midstring(${1:ABC}, ${2:B}, ${3:AC}, ${4:LenA}, ${5:LenB}, ${6:LenC})$7\n$0"
    ],
    "description":"  midstring(?ABC, ?B, ?AC) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA, LenB) is nondet.\n  midstring(?ABC, ?B, ?AC, LenA, LenB, LenC) is nondet.\n\n   Too difficult to explain.  See the Quintus docs.  As far as I\n   understand them the code below emulates this function just fine.",
    "prefix":"midstring"
  },
  "quintus:mode/1": {
    "body": ["mode(${1:ModeDecl})$2\n$0" ],
    "description":"  mode(+ModeDecl) is det.\n\n   Ignore a DEC10/Quintus `:-   mode(Head)`  declaration. Typically\n   these declarations are written in   operator  form. The operator\n   declaration is not part of the   Quintus  emulation library. The\n   following declaration is compatible with Quintus:\n\n     ==\n     :- op(1150, fx, [(mode)]).\n     ==",
    "prefix":"mode"
  },
  "quintus:no_style_check/1": {
    "body": ["no_style_check(${1:Style})$2\n$0" ],
    "description":"  no_style_check(Style) is det.\n\n   Same as SWI-Prolog =|style_check(-Style)|=.   The Quintus option\n   =single_var= is mapped to =singleton=.\n\n   @see style_check/1.",
    "prefix":"no_style_check"
  },
  "quintus:on_exception/3": {
    "body": ["on_exception(${1:Template}, ${2:Goal}, ${3:Recover})$4\n$0" ],
    "description":"  on_exception(+Template, :Goal, :Recover)",
    "prefix":"on_exception"
  },
  "quintus:otherwise/0": {
    "body": ["otherwise$1\n$0" ],
    "description":"  otherwise\n\n   For (A -> B ; otherwise -> C)",
    "prefix":"otherwise"
  },
  "quintus:pow/3": {
    "body": ["pow(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"pow('Param1','Param2','Param3')",
    "prefix":"pow"
  },
  "quintus:prolog_flag/2": {
    "body": ["prolog_flag(${1:Flag}, ${2:Value})$3\n$0" ],
    "description":"  prolog_flag(?Flag, ?Value) is nondet.\n\n   Same as ISO current_prolog_flag/2.  Maps =version=.\n\n   @bug    Should map relevant Quintus flag identifiers.",
    "prefix":"prolog_flag"
  },
  "quintus:raise_exception/1": {
    "body": ["raise_exception(${1:Term})$2\n$0" ],
    "description":"  raise_exception(+Term)\n\n   Quintus compatible exception handling",
    "prefix":"raise_exception"
  },
  "quintus:round/2": {
    "body": ["round(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"round('Param1','Param2')",
    "prefix":"round"
  },
  "quintus:sign/2": {
    "body": ["sign(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sign('Param1','Param2')",
    "prefix":"sign"
  },
  "quintus:simple/1": {
    "body": ["simple(${1:Term})$2\n$0" ],
    "description":"  simple(@Term) is semidet.\n\n   Term is atomic or a variable.",
    "prefix":"simple"
  },
  "quintus:sin/2": {
    "body": ["sin(${1:Angle}, ${2:Sine})$3\n$0" ],
    "description":"  sin(+Angle, -Sine) is det.\n  cos(+Angle, -Cosine) is det.\n  tan(+Angle, -Tangent) is det.\n  log(+X, -NatLog) is det.\n  log10(+X, -Log) is det.\n\n   Math library predicates. SWI-Prolog (and   ISO) support these as\n   functions under is/2, etc.",
    "prefix":"sin"
  },
  "quintus:skip_line/0": {
    "body": ["skip_line$1\n$0" ],
    "description":"  skip_line is det.\n  skip_line(Stream) is det.\n\n   Skip  the  rest  of  the  current  line  (on  Stream).  Same  as\n   =|skip(0'\\n)|=.",
    "prefix":"skip_line"
  },
  "quintus:skip_line/1": {
    "body": ["skip_line(${1:Stream})$2\n$0" ],
    "description":"  skip_line is det.\n  skip_line(Stream) is det.\n\n   Skip  the  rest  of  the  current  line  (on  Stream).  Same  as\n   =|skip(0'\\n)|=.",
    "prefix":"skip_line"
  },
  "quintus:sqrt/2": {
    "body": ["sqrt(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sqrt('Param1','Param2')",
    "prefix":"sqrt"
  },
  "quintus:stream_position/3": {
    "body": ["stream_position(${1:Stream}, ${2:Old}, ${3:New})$4\n$0" ],
    "description":"  stream_position(+Stream, -Old, +New)\n\n   True when Old is the current position   in Stream and the stream\n   has been repositioned to New.\n\n   @deprecated New code should use the ISO predicates\n   stream_property/2 and set_stream_position/2.",
    "prefix":"stream_position"
  },
  "quintus:tan/2": {
    "body": ["tan(${1:Angle}, ${2:Sine})$3\n$0" ],
    "description":"  sin(+Angle, -Sine) is det.\n  cos(+Angle, -Cosine) is det.\n  tan(+Angle, -Tangent) is det.\n  log(+X, -NatLog) is det.\n  log10(+X, -Log) is det.\n\n   Math library predicates. SWI-Prolog (and   ISO) support these as\n   functions under is/2, etc.",
    "prefix":"tan"
  },
  "quintus:unix/1": {
    "body": ["unix(${1:Action})$2\n$0" ],
    "description":"  unix(+Action)\n   interface to  Unix.",
    "prefix":"unix"
  },
  "random/1": {
    "body":"random(${1:IntExpr})$2\n$0",
    "description":"random(+IntExpr).\nEvaluate to a random integer i for which 0 =< i < IntExpr.  The system has two implementations. If it is compiled with support for  unbounded arithmetic (default) it uses the GMP library random functions.  In this case, each thread keeps its own random state. The default  algorithm is the Mersenne Twister algorithm. The seed is set  when the first random number in a thread is generated. If available, it  is set from /dev/random. Otherwise it is set from the  system clock. If unbounded arithmetic is not supported, random numbers  are shared between threads and the seed is initialised from the clock  when SWI-Prolog was started. The predicate set_random/1  can be used to control the random number generator.",
    "prefix":"random"
  },
  "random:getrand/1": {
    "body":"getrand(${1:State})$2\n$0",
    "description":"[det]getrand(-State).\nQuery/set the state of the random generator. This is intended for  restarting the generator at a known state only. The predicate setrand/1  accepts an opaque term returned by getrand/1. This term  may be asserted, written and read. The application may not make other  assumptions about this term.  For compatibility reasons with older versions of this library, setrand/1 also accepts  a term rand(A,B,C), where A, B and C are integers in the  range 1..30,000. This argument is used to seed the random generator.  Deprecated. \n\nErrors: existence_error(random_state, _) is raised if the  underlying infrastructure cannot fetch the random state. This is  currently the case if SWI-Prolog is not compiled with the GMP library.\n\nSee also: set_random/1 and random_property/1  provide the SWI-Prolog native implementation.\n\n ",
    "prefix":"getrand"
  },
  "random:maybe/0": {
    "body": ["maybe$1\n$0" ],
    "description":"  maybe is semidet.\n\n   Succeed/fail with equal probability (variant of maybe/1).",
    "prefix":"maybe"
  },
  "random:maybe/1": {
    "body":"maybe(${1:P})$2\n$0",
    "description":"[semidet]maybe(+P).\nSucceed with probability P, fail with probability 1-P",
    "prefix":"maybe"
  },
  "random:maybe/2": {
    "body":"maybe(${1:K}, ${2:N})$3\n$0",
    "description":"[semidet]maybe(+K, +N).\nSucceed with probability K/N (variant of maybe/1)",
    "prefix":"maybe"
  },
  "random:random/1": {
    "body":"random(${1:R})$2\n$0",
    "description":"[det]random(-R:float).\nBinds R to a new random float in the open interval  (0.0,1.0).  See also: - setrand/1, getrand/1  may be used to fetch/set the state.  - In SWI-Prolog, random/1  is implemented by the function random_float/0.\n\n ",
    "prefix":"random"
  },
  "random:random/3": {
    "body":"random(${1:L}, ${2:U}, ${3:R})$4\n$0",
    "description":"[det]random(+L:float, +U:float, -R:float).\nGenerate a random integer or float in a range. If L and U  are both integers, R is a random integer in the half open  interval [L,U). If L and U  are both floats, R is a float in the open interval (L,U).  deprecated: Please use random/1 for  generating a random float and random_between/3  for generating a random integer. Note that the random_between/3  includes the upper bound, while this predicate excludes the upper bound.\n\n ",
    "prefix":"random"
  },
  "random:random_between/3": {
    "body":"random_between(${1:L}, ${2:U}, ${3:R})$4\n$0",
    "description":"[semidet]random_between(+L:int, +U:int, -R:int).\nBinds R to a random integer in [L,U]  (i.e., including both L and U). Fails silently if U<L.",
    "prefix":"random_between"
  },
  "random:random_member/2": {
    "body":"random_member(${1:X}, ${2:List})$3\n$0",
    "description":"[semidet]random_member(-X, +List:list).\nX is a random member of List. Equivalent to  random_between(1, |List|), followed by nth1/3.  Fails of List is the empty list.  Compatibility: Quintus and SICStus libraries.\n\n ",
    "prefix":"random_member"
  },
  "random:random_perm2/4": {
    "body":"random_perm2(${1:A}, ${2:B}, ${3:X}, ${4:Y})$5\n$0",
    "description":"[semidet]random_perm2(?A, ?B, ?X, ?Y).\nDoes X=A,Y=B or X=B,Y=A  with equal probability.",
    "prefix":"random_perm2"
  },
  "random:random_permutation/2": {
    "body":"random_permutation(${1:List}, ${2:Permutation})$3\n$0",
    "description":"[det]random_permutation(-List, +Permutation).\nPermutation is a random permutation of List. This  is intended to process the elements of List in random order.  The predicate is symmetric.  Errors: instantiation_error, type_error(list, _).\n\n ",
    "prefix":"random_permutation"
  },
  "random:random_select/3": {
    "body":"random_select(${1:X}, ${2:List}, ${3:Rest})$4\n$0",
    "description":"[det]random_select(+X, -List, +Rest).\nRandomly select or insert an element. Either List or Rest  must be a list. Fails if List is the empty list.  Compatibility: Quintus and SICStus libraries.\n\n ",
    "prefix":"random_select"
  },
  "random:randseq/3": {
    "body":"randseq(${1:K}, ${2:N}, ${3:List})$4\n$0",
    "description":"[det]randseq(+K:int, +N:int, -List:list(int)).\nS is a list of K unique random integers in the range 1..N.  The order is random. Works as if defined by the following code.  \n\nrandseq(K, N, List) :-\n      randset(K, N, Set),\n      random_permutation(Set, List).\n\n  See also: randset/3.\n\n ",
    "prefix":"randseq"
  },
  "random:randset/3": {
    "body":"randset(${1:K}, ${2:N}, ${3:S})$4\n$0",
    "description":"[det]randset(+K:int, +N:int, -S:list(int)).\nS is a sorted list of K unique random integers in  the range 1..N. Implemented by enumerating 1..N  and deciding whether or not the number should be part of the set. For  example:  \n\n?- randset(5, 5, S).\nS = [1, 2, 3, 4, 5].          (always)\n?- randset(5, 20, S).\nS = [2, 7, 10, 19, 20].\n\n  See also: randseq/3.\n\nbug: Slow if N is large and K is small.\n\n ",
    "prefix":"randset"
  },
  "random:setrand/1": {
    "body":"setrand(${1:State})$2\n$0",
    "description":"[det]setrand(+State).\n",
    "prefix":"setrand"
  },
  "random_float/0": {
    "body":"random_float$1\n$0",
    "description":"random_float.\nEvaluate to a random float I for which 0.0 < i <  1.0. This function shares the random state with random/1.  All remarks with the function random/1  also apply for random_float/0.  Note that both sides of the domain are open. This avoids  evaluation errors on, e.g., log/1  or //2 while no  practical application can expect 0.0.105Richard  O'Keefe said: ``If you are generating IEEE doubles with the  claimed uniformity, then 0 has a 1 in 2^53 = 1 in  9,007,199,254,740,992 chance of turning up. No program that  expects [0.0,1.0) is going to be surprised when 0.0 fails to turn up in  a few millions of millions of trials, now is it? But a program that  expects (0.0,1.0) could be devastated if 0.0 did turn up.''",
    "prefix":"random_float"
  },
  "random_property/1": {
    "body":"random_property(${1:Option})$2\n$0",
    "description":"random_property(?Option).\nTrue when Option is a current property of the random  generator. Currently, this predicate provides access to the state. This  predicate is not present on systems where the state is inaccessible.  state(-State): Describes the current state of the random generator. State is a normal  Prolog term that can be asserted or written to a file. Applications  should make no other assumptions about its representation. The only  meaningful operation is to use as argument to set_random/1  using the state(State) option.bugGMP  provides no portable mechanism to fetch and restore the state. The  current implementation works, but the state depends on the platform.  I.e., it is generally not possible to reuse the state with another  version of GMP or on a CPU with different datasizes or endian-ness.\n\n ",
    "prefix":"random_property"
  },
  "rational/1": {
    "body":"rational(${1:Term})$2\n$0",
    "description":"rational(@Term).\nTrue if Term is bound to a rational number. Rational numbers  include integers.",
    "prefix":"rational"
  },
  "rational/3": {
    "body":"rational(${1:Term}, ${2:Numerator}, ${3:Denominator})$4\n$0",
    "description":"rational(@Term, -Numerator, -Denominator).\nTrue if Term is a rational number with given Numerator  and Denominator. The Numerator and Denominator  are in canonical form, which means Denominator is a positive  integer and there are no common divisors between Numerator  and Denominator.",
    "prefix":"rational"
  },
  "rationalize/1": {
    "body":"rationalize(${1:Expr})$2\n$0",
    "description":"rationalize(+Expr).\nConvert the Expr to a rational number or integer. The  function is similar to rational/1,  but the result is only accurate within the rounding error of floating  point numbers, generally producing a much smaller denominator.106The  names rational/1  and rationalize/1  as well as their semantics are inspired by Common Lisp.  \n\n?- A is rationalize(0.25).\n\nA = 1 rdiv 4\n?- A is rationalize(0.1).\n\nA = 1 rdiv 10\n\n ",
    "prefix":"rationalize"
  },
  "rbtrees:is_rbtree/1": {
    "body": ["is_rbtree(${1:Term})$2\n$0" ],
    "description":"  is_rbtree(@Term) is semidet.\n\n   True if Term is a valide Red-Black tree.\n\n   @tbd    Catch variables.",
    "prefix":"is_rbtree"
  },
  "rbtrees:list_to_rbtree/2": {
    "body": ["list_to_rbtree(${1:List}, ${2:Tree})$3\n$0" ],
    "description":"  list_to_rbtree(+List, -Tree) is det.\n\n   Tree is the red-black tree  corresponding   to  the mapping in List,\n   which should be a list of Key-Value   pairs. List should not contain\n   more than one entry for each distinct key.",
    "prefix":"list_to_rbtree"
  },
  "rbtrees:ord_list_to_rbtree/2": {
    "body": ["ord_list_to_rbtree(${1:List}, ${2:Tree})$3\n$0" ],
    "description":"  ord_list_to_rbtree(+List, -Tree) is det.\n\n   Tree is the red-black tree  corresponding   to  the  mapping in list\n   List, which should be a list  of   Key-Value  pairs. List should not\n   contain more than one entry for each   distinct key. List is assumed\n   to be sorted according to the standard order of terms.",
    "prefix":"ord_list_to_rbtree"
  },
  "rbtrees:rb_apply/4": {
    "body": ["rb_apply(${1:Tree}, ${2:Key}, ${3:G}, ${4:NewTree})$5\n$0" ],
    "description":"  rb_apply(+Tree, +Key, :G, -NewTree) is semidet.\n\n   If the value associated  with  key  Key   is  Val0  in  Tree, and if\n   call(G,Val0,ValF) holds, then NewTree differs from Tree only in that\n   Key is associated with value  ValF  in   tree  NewTree.  Fails if it\n   cannot find Key in Tree, or if call(G,Val0,ValF) is not satisfiable.",
    "prefix":"rb_apply"
  },
  "rbtrees:rb_clone/3": {
    "body": ["rb_clone(${1:TreeIn}, ${2:TreeOut}, ${3:Pairs})$4\n$0" ],
    "description":"  rb_clone(+TreeIn, -TreeOut, -Pairs) is det.\n\n   `Clone' the red-back tree TreeIn into a   new  tree TreeOut with the\n   same keys as the original but with all values set to unbound values.\n   Pairs is a list containing all new nodes as pairs K-V.",
    "prefix":"rb_clone"
  },
  "rbtrees:rb_del_max/4": {
    "body": ["rb_del_max(${1:Tree}, ${2:Key}, ${3:Val}, ${4:NewTree})$5\n$0" ],
    "description":"  rb_del_max(+Tree, -Key, -Val, -NewTree)\n\n   Delete the largest element from  the   tree  Tree, returning the key\n   Key, the value Val associated with the key and a new tree NewTree.",
    "prefix":"rb_del_max"
  },
  "rbtrees:rb_del_min/4": {
    "body": ["rb_del_min(${1:Tree}, ${2:Key}, ${3:Val}, ${4:NewTree})$5\n$0" ],
    "description":"  rb_del_min(+Tree, -Key, -Val, -NewTree)\n\n   Delete the least element from the tree  Tree, returning the key Key,\n   the value Val associated with the key and a new tree NewTree.",
    "prefix":"rb_del_min"
  },
  "rbtrees:rb_delete/3": {
    "body": ["rb_delete(${1:Tree}, ${2:Key}, ${3:NewTree})$4\n$0" ],
    "description":"  rb_delete(+Tree, +Key, -NewTree).\n  rb_delete(+Tree, +Key, -Val, -NewTree).\n\n   Delete element with key Key from the  tree Tree, returning the value\n   Val associated with the key and a new tree NewTree.",
    "prefix":"rb_delete"
  },
  "rbtrees:rb_delete/4": {
    "body": ["rb_delete(${1:Tree}, ${2:Key}, ${3:Val}, ${4:NewTree})$5\n$0" ],
    "description":"  rb_delete(+Tree, +Key, -NewTree).\n  rb_delete(+Tree, +Key, -Val, -NewTree).\n\n   Delete element with key Key from the  tree Tree, returning the value\n   Val associated with the key and a new tree NewTree.",
    "prefix":"rb_delete"
  },
  "rbtrees:rb_empty/1": {
    "body": ["rb_empty(${1:Tree})$2\n$0" ],
    "description":"  rb_empty(?Tree) is semidet.\n\n   Succeeds if Tree is an empty Red-Black tree.",
    "prefix":"rb_empty"
  },
  "rbtrees:rb_fold/4": {
    "body": ["rb_fold(${1:Goal}, ${2:Tree}, ${3:State0}, ${4:State})$5\n$0" ],
    "description":"  rb_fold(:Goal, +Tree, +State0, -State) is det.\n\n   Fold the given predicate  over  all   the  key-value  pairs in Tree,\n   starting with initial state State0  and   returning  the final state\n   State. Pred is called as\n\n       call(Pred, Key-Value, State1, State2)",
    "prefix":"rb_fold"
  },
  "rbtrees:rb_in/3": {
    "body": ["rb_in(${1:Key}, ${2:Value}, ${3:Tree})$4\n$0" ],
    "description":"  rb_in(?Key, ?Value, +Tree) is nondet.\n\n   True when Key-Value is a key-value pair in red-black tree Tree. Same\n   as below, but does not materialize the pairs.\n\n        rb_visit(Tree, Pairs), member(Key-Value, Pairs)",
    "prefix":"rb_in"
  },
  "rbtrees:rb_insert/4": {
    "body": ["rb_insert(${1:Tree}, ${2:Key}, ${3:Value}, ${4:NewTree})$5\n$0" ],
    "description":"  rb_insert(+Tree, +Key, ?Value, -NewTree) is det.\n\n   Add an element with key Key and Value   to  the tree Tree creating a\n   new red-black tree NewTree. If Key is  a key in Tree, the associated\n   value is replaced by Value. See also rb_insert_new/4.",
    "prefix":"rb_insert"
  },
  "rbtrees:rb_insert_new/4": {
    "body": [
      "rb_insert_new(${1:Tree}, ${2:Key}, ${3:Value}, ${4:NewTree})$5\n$0"
    ],
    "description":"  rb_insert_new(+Tree, +Key, ?Value, -NewTree) is semidet.\n\n   Add a new element with key Key and Value to the tree Tree creating a\n   new red-black tree NewTree. Fails if Key is a key in Tree.",
    "prefix":"rb_insert_new"
  },
  "rbtrees:rb_keys/2": {
    "body": ["rb_keys(${1:Tree}, ${2:Keys})$3\n$0" ],
    "description":"  rb_keys(+Tree, -Keys)\n\n   Keys is unified with an ordered list   of  all keys in the Red-Black\n   tree Tree.",
    "prefix":"rb_keys"
  },
  "rbtrees:rb_lookup/3": {
    "body": ["rb_lookup(${1:Key}, ${2:Value}, ${3:Tree})$4\n$0" ],
    "description":"  rb_lookup(+Key, -Value, +Tree) is semidet.\n\n   True when Value is associated with Key   in the Red-Black tree Tree.\n   The given Key may include variables, in   which  case the RB tree is\n   searched for a key with equivalent,   as  in (==)/2, variables. Time\n   complexity is O(log N) in the number of elements in the tree.",
    "prefix":"rb_lookup"
  },
  "rbtrees:rb_map/2": {
    "body": ["rb_map(${1:T}, ${2:Goal})$3\n$0" ],
    "description":"  rb_map(+T, :Goal) is semidet.\n\n   True if call(Goal, Value) is true for all nodes in T.",
    "prefix":"rb_map"
  },
  "rbtrees:rb_map/3": {
    "body": ["rb_map(${1:Tree}, ${2:G}, ${3:NewTree})$4\n$0" ],
    "description":"  rb_map(+Tree, :G, -NewTree) is semidet.\n\n   For all nodes Key in the tree Tree, if the value associated with key\n   Key is Val0 in tree Tree, and   if call(G,Val0,ValF) holds, then the\n   value  associated  with  Key  in   NewTree    is   ValF.   Fails  if\n   call(G,Val0,ValF) is not satisfiable for all Val0.",
    "prefix":"rb_map"
  },
  "rbtrees:rb_max/3": {
    "body": ["rb_max(${1:Tree}, ${2:Key}, ${3:Value})$4\n$0" ],
    "description":"  rb_max(+Tree, -Key, -Value) is semidet.\n\n   Key is the maximal key in Tree, and is associated with Val.",
    "prefix":"rb_max"
  },
  "rbtrees:rb_min/3": {
    "body": ["rb_min(${1:Tree}, ${2:Key}, ${3:Value})$4\n$0" ],
    "description":"  rb_min(+Tree, -Key, -Value) is semidet.\n\n   Key is the minimum key in Tree, and is associated with Val.",
    "prefix":"rb_min"
  },
  "rbtrees:rb_new/1": {
    "body": ["rb_new(${1:Tree})$2\n$0" ],
    "description":"  rb_new(-Tree) is det.\n\n   Create a new Red-Black tree Tree.\n\n   @deprecated     Use rb_empty/1.",
    "prefix":"rb_new"
  },
  "rbtrees:rb_next/4": {
    "body": ["rb_next(${1:Tree}, ${2:Key}, ${3:Next}, ${4:Value})$5\n$0" ],
    "description":"  rb_next(+Tree, +Key, -Next, -Value) is semidet.\n\n   Next is the next element after Key   in Tree, and is associated with\n   Val.",
    "prefix":"rb_next"
  },
  "rbtrees:rb_partial_map/4": {
    "body": ["rb_partial_map(${1:Tree}, ${2:Keys}, ${3:G}, ${4:NewTree})$5\n$0" ],
    "description":"  rb_partial_map(+Tree, +Keys, :G, -NewTree)\n\n   For all nodes Key in Keys, if the   value associated with key Key is\n   Val0 in tree Tree, and if   call(G,Val0,ValF)  holds, then the value\n   associated  with  Key  in  NewTree   is    ValF.   Fails  if  or  if\n   call(G,Val0,ValF) is not satisfiable for all  Val0. Assumes keys are\n   not repeated.",
    "prefix":"rb_partial_map"
  },
  "rbtrees:rb_previous/4": {
    "body": ["rb_previous(${1:Tree}, ${2:Key}, ${3:Previous}, ${4:Value})$5\n$0" ],
    "description":"  rb_previous(+Tree, +Key, -Previous, -Value) is semidet.\n\n   Previous  is  the  previous  element  after  Key  in  Tree,  and  is\n   associated with Val.",
    "prefix":"rb_previous"
  },
  "rbtrees:rb_size/2": {
    "body": ["rb_size(${1:Tree}, ${2:Size})$3\n$0" ],
    "description":"  rb_size(+Tree, -Size) is det.\n\n   Size is the number of elements in Tree.",
    "prefix":"rb_size"
  },
  "rbtrees:rb_update/4": {
    "body": ["rb_update(${1:Tree}, ${2:Key}, ${3:NewVal}, ${4:NewTree})$5\n$0" ],
    "description":"  rb_update(+Tree, +Key, +NewVal, -NewTree) is semidet.\n  rb_update(+Tree, +Key, ?OldVal, +NewVal, -NewTree) is semidet.\n\n   Tree NewTree is tree Tree, but with   value  for Key associated with\n   NewVal. Fails if it cannot find Key in Tree.",
    "prefix":"rb_update"
  },
  "rbtrees:rb_update/5": {
    "body": [
      "rb_update(${1:Tree}, ${2:Key}, ${3:OldVal}, ${4:NewVal}, ${5:NewTree})$6\n$0"
    ],
    "description":"  rb_update(+Tree, +Key, +NewVal, -NewTree) is semidet.\n  rb_update(+Tree, +Key, ?OldVal, +NewVal, -NewTree) is semidet.\n\n   Tree NewTree is tree Tree, but with   value  for Key associated with\n   NewVal. Fails if it cannot find Key in Tree.",
    "prefix":"rb_update"
  },
  "rbtrees:rb_visit/2": {
    "body": ["rb_visit(${1:Tree}, ${2:Pairs})$3\n$0" ],
    "description":"  rb_visit(+Tree, -Pairs)\n\n   Pairs is an infix visit of tree Tree, where each element of Pairs is\n   of the form Key-Value.",
    "prefix":"rb_visit"
  },
  "rdf:load_rdf/2": {
    "body": ["load_rdf(${1:File}, ${2:Triples})$3\n$0" ],
    "description":"  load_rdf(+File, -Triples) is det.\n  load_rdf(+File, -Triples, :Options) is det.\n\n   Parse an XML file holding an RDF term into a list of RDF triples.\n   see rdf_triple.pl for a definition of the output format. Options:\n\n           * base_uri(+URI)\n           URI to use as base\n\n           * expand_foreach(+Bool)\n           Apply each(Container, Pred, Object) on the members of\n           Container\n\n           * namespaces(-Namespaces:list(NS=URL))\n           Return list of namespaces declared using xmlns:NS=URL in\n           the document.  This can be used to update the namespace\n           list with rdf_register_ns/2.\n\n   @see    Use process_rdf/3 for processing large documents in\n           _|call-back|_ style.",
    "prefix":"load_rdf"
  },
  "rdf:load_rdf/3": {
    "body": ["load_rdf(${1:File}, ${2:Triples}, ${3:Options})$4\n$0" ],
    "description":"  load_rdf(+File, -Triples) is det.\n  load_rdf(+File, -Triples, :Options) is det.\n\n   Parse an XML file holding an RDF term into a list of RDF triples.\n   see rdf_triple.pl for a definition of the output format. Options:\n\n           * base_uri(+URI)\n           URI to use as base\n\n           * expand_foreach(+Bool)\n           Apply each(Container, Pred, Object) on the members of\n           Container\n\n           * namespaces(-Namespaces:list(NS=URL))\n           Return list of namespaces declared using xmlns:NS=URL in\n           the document.  This can be used to update the namespace\n           list with rdf_register_ns/2.\n\n   @see    Use process_rdf/3 for processing large documents in\n           _|call-back|_ style.",
    "prefix":"load_rdf"
  },
  "rdf:process_rdf/3": {
    "body": ["process_rdf(${1:Input}, ${2:OnObject}, ${3:Options})$4\n$0" ],
    "description":"  process_rdf(+Input, :OnObject, :Options)\n\n   Process RDF from Input. Input is either an atom or a term of the\n   format stream(Handle). For each   encountered  description, call\n   OnObject(+Triples) to handle the  triples   resulting  from  the\n   description. Defined Options are:\n\n           * base_uri(+URI)\n           Determines the reference URI.\n\n           * db(DB)\n           When loading from a stream, the source is taken from\n           this option or -if non-existent- from base_uri.\n\n           * lang(LanguageID)\n           Set initial language (as xml:lang)\n\n           * convert_typed_literal(:Convertor)\n           Call Convertor(+Type, +Content, -RDFObject) to create\n           a triple rdf(S, P, RDFObject) instead of rdf(S, P,\n           literal(type(Type, Content)).\n\n           *  namespaces(-Namespaces:list(NS=URL))\n           Return list of namespaces declared using xmlns:NS=URL in\n           the document.  This can be used to update the namespace\n           list with rdf_register_ns/2.\n\n           * entity(Name, Value)\n           Overrule entity values found in the file\n\n           * embedded(Boolean)\n           If =true=, do not give warnings if rdf:RDF is embedded\n           in other XML data.",
    "prefix":"process_rdf"
  },
  "rdf:xml_to_rdf/3": {
    "body": ["xml_to_rdf(${1:XML}, ${2:Triples}, ${3:Options})$4\n$0" ],
    "description":"  xml_to_rdf(+XML, -Triples, +Options)",
    "prefix":"xml_to_rdf"
  },
  "rdf_diagram:rdf_diagram_from_file/1": {
    "body": ["rdf_diagram_from_file(${1:File})$2\n$0" ],
    "description":"  rdf_diagram_from_file(+File)\n\n   Show the triples from File in a window.",
    "prefix":"rdf_diagram_from_file"
  },
  "rdf_ntriples_old:load_rdf_ntriples/2": {
    "body": ["load_rdf_ntriples(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"load_rdf_ntriples('Param1','Param2')",
    "prefix":"load_rdf_ntriples"
  },
  "rdf_ntriples_old:rdf_ntriple_part/4": {
    "body": [
      "rdf_ntriple_part(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"rdf_ntriple_part('Param1','Param2','Param3','Param4')",
    "prefix":"rdf_ntriple_part"
  },
  "rdf_parser:element_to_plrdf/3": {
    "body": ["element_to_plrdf(${1:DOM}, ${2:RDFTerm}, ${3:State})$4\n$0" ],
    "description":"  element_to_plrdf(+DOM, -RDFTerm, +State)\n\n   Rewrite a single XML element.",
    "prefix":"element_to_plrdf"
  },
  "rdf_parser:make_rdf_state/3": {
    "body": ["make_rdf_state(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"make_rdf_state('Param1','Param2','Param3')",
    "prefix":"make_rdf_state"
  },
  "rdf_parser:rdf_modify_state/3": {
    "body": [
      "rdf_modify_state(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_modify_state('Param1','Param2','Param3')",
    "prefix":"rdf_modify_state"
  },
  "rdf_parser:rdf_name_space/1": {
    "body": ["rdf_name_space(${1:URL})$2\n$0" ],
    "description":"  rdf_name_space(?URL) is nondet.\n\n   True if URL must be handled  as rdf: Determines special handling\n   of rdf:about, rdf:resource, etc.",
    "prefix":"rdf_name_space"
  },
  "rdf_parser:xml_to_plrdf/3": {
    "body": [
      "xml_to_plrdf(${1:RDFElementOrObject}, ${2:RDFTerm}, ${3:State})$4\n$0"
    ],
    "description":"  xml_to_plrdf(+RDFElementOrObject, -RDFTerm, +State)\n\n   Translate an XML (using namespaces)  term   into  an Prolog term\n   representing the RDF data.  This  term   can  then  be  fed into\n   rdf_triples/[2,3] to create a list of   RDF triples. State is an\n   instance of an rdf_state record.",
    "prefix":"xml_to_plrdf"
  },
  "rdf_triple:anon_prefix/1": {
    "body": ["anon_prefix(${1:Prefix})$2\n$0" ],
    "description":"  anon_prefix(-Prefix) is semidet.\n\n   If defined, it is the prefix used to generate a blank node.",
    "prefix":"anon_prefix"
  },
  "rdf_triple:rdf_end_file/1": {
    "body": ["rdf_end_file(${1:Cleanup})$2\n$0" ],
    "description":"  rdf_end_file(:Cleanup) is det.\n\n   Cleanup reaching the end of an RDF file.",
    "prefix":"rdf_end_file"
  },
  "rdf_triple:rdf_reset_ids/0": {
    "body": ["rdf_reset_ids$1\n$0" ],
    "description":"  rdf_reset_ids is det.\n\n   Utility predicate to reset the gensym counters for the various\n   generated identifiers.  This simplifies debugging and matching\n   output with the stored desired output (see rdf_test.pl).",
    "prefix":"rdf_reset_ids"
  },
  "rdf_triple:rdf_start_file/2": {
    "body": ["rdf_start_file(${1:Options}, ${2:Cleanup})$3\n$0" ],
    "description":"  rdf_start_file(+Options, -Cleanup) is det.\n\n   Initialise for the translation of a file.",
    "prefix":"rdf_start_file"
  },
  "rdf_triple:rdf_triples/2": {
    "body": ["rdf_triples(${1:Term}, ${2:Triples})$3\n$0" ],
    "description":"  rdf_triples(+Term, -Triples) is det.\n  rdf_triples(+Term, -Tridpples, +Tail) is det.\n\n   Convert an object as parsed by rdf.pl into a list of rdf/3\n   triples.  The identifier of the main object created is returned\n   by rdf_triples/3.\n\n   Input is the `content' of the RDF element in the format as\n   generated by load_structure(File, Term, [dialect(xmlns)]).\n   rdf_triples/3 can process both individual descriptions as\n   well as the entire content-list of an RDF element.  The first\n   mode is suitable when using library(sgml) in `call-back' mode.",
    "prefix":"rdf_triples"
  },
  "rdf_triple:rdf_triples/3": {
    "body": ["rdf_triples(${1:Term}, ${2:Tridpples}, ${3:Tail})$4\n$0" ],
    "description":"  rdf_triples(+Term, -Triples) is det.\n  rdf_triples(+Term, -Tridpples, +Tail) is det.\n\n   Convert an object as parsed by rdf.pl into a list of rdf/3\n   triples.  The identifier of the main object created is returned\n   by rdf_triples/3.\n\n   Input is the `content' of the RDF element in the format as\n   generated by load_structure(File, Term, [dialect(xmlns)]).\n   rdf_triples/3 can process both individual descriptions as\n   well as the entire content-list of an RDF element.  The first\n   mode is suitable when using library(sgml) in `call-back' mode.",
    "prefix":"rdf_triples"
  },
  "rdf_write_xml/2": {
    "body":"rdf_write_xml(${1:Stream}, ${2:Triples})$3\n$0",
    "description":"rdf_write_xml(+Stream, +Triples).\nWrite an RDF/XML document to Stream from the list of Triples. Stream must use one of the following Prolog stream encodings: ascii, iso_latin_1 or utf8.  Characters that cannot be represented in the encoding are represented as  XML entities. Using ASCII is a good idea for documents that can be  represented almost completely in ASCII. For more international documents  using UTF-8 creates a more compact document that is easier to read.  \n\nrdf_write(File, Triples) :-\n        open(File, write, Out, [encoding(utf8)]),\n        call_cleanup(rdf_write_xml(Out, Triples),\n                     close(Out)).\n\n  \n\n",
    "prefix":"rdf_write_xml"
  },
  "read/1": {
    "body":"read(${1:Term})$2\n$0",
    "description":"[ISO]read(-Term).\nRead the next Prolog term from the current input stream and unify it  with Term. On a syntax error read/1  displays an error message, attempts to skip the erroneous term and  fails. On reaching end-of-file Term is unified with the atom end_of_file.",
    "prefix":"read"
  },
  "read/2": {
    "body":"read(${1:Stream}, ${2:Term})$3\n$0",
    "description":"[ISO]read(+Stream, -Term).\nRead Term from Stream.",
    "prefix":"read"
  },
  "read_clause/3": {
    "body":"read_clause(${1:Stream}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"read_clause(+Stream, -Term, +Options).\nEquivalent to read_term/3,  but sets options according to the current compilation context and  optionally processes comments. Defined options:  syntax_errors(+Atom): See read_term/3,  but the default is dec10 (report and restart).\n\nterm_position(-TermPos): Same as for read_term/3.\n\nsubterm_positions(-TermPos): Same as for read_term/3.\n\nvariable_names(-Bindings): Same as for read_term/3.\n\nprocess_comment(+Boolean): If true (default), call prolog:comment_hook(Comments, TermPos, Term) if this  multifile hook is defined (see prolog:comment_hook/3). This is used to  drive PlDoc.\n\ncomments(-Comments): If provided, unify Comments with the comments encountered  while reading Term. This option implies process_comment(false).\n\n  The singletons option of read_term/3  is initialised from the active style-checking mode. The module  option is initialised to the current compilation module (see prolog_load_context/2).\n\n",
    "prefix":"read_clause"
  },
  "read_history/6": {
    "body":"read_history(${1:Show}, ${2:Help}, ${3:Special}, ${4:Prompt}, ${5:Term}, ${6:Bindings})$7\n$0",
    "description":"read_history(+Show, +Help, +Special, +Prompt, -Term, -Bindings).\nSimilar to read_term/2  using the option variable_names, but allows for history  substitutions. read_history/6  is used by the top level to read the user's actions. Show is  the command the user should type to show the saved events. Help  is the command to get an overview of the capabilities. Special  is a list of commands that are not saved in the history. Prompt  is the first prompt given. Continuation prompts for more lines are  determined by prompt/2.  A %w in the prompt is substituted by the event number. See section 2.7 for available  substitutions.  SWI-Prolog calls read_history/6  as follows: \n\n\n\nread_history(h, '!h', [trace], '%w ?- ', Goal, Bindings)\n\n ",
    "prefix":"read_history"
  },
  "read_link/3": {
    "body":"read_link(${1:File}, ${2:Link}, ${3:Target})$4\n$0",
    "description":"read_link(+File, -Link, -Target).\nIf File points to a symbolic link, unify Link with  the value of the link and Target to the file the link is  pointing to. Target points to a file, directory or non-existing entry in  the file system, but never to a link. Fails if File is not a  link. Fails always on systems that do not support symbolic links.",
    "prefix":"read_link"
  },
  "read_pending_chars/3": {
    "body":"read_pending_chars(${1:StreamIn}, ${2:Chars}, ${3:Tail})$4\n$0",
    "description":"read_pending_chars(+StreamIn, -Chars, ?Tail).\nAs read_pending_codes/3,  but returns a difference list of one-character atoms.",
    "prefix":"read_pending_chars"
  },
  "read_pending_codes/3": {
    "body":"read_pending_codes(${1:StreamIn}, ${2:Codes}, ${3:Tail})$4\n$0",
    "description":"read_pending_codes(+StreamIn, -Codes, ?Tail).\nRead input pending in the input buffer of StreamIn and return  it in the difference list Codes-Tail. That is, the  available characters codes are used to create the list Codes  ending in the tail Tail. On encountering end-of-file, both Codes and Tail are unified with the empty list (\\[]).  This predicate is intended for efficient unbuffered copying and  filtering of input coming from network connections or devices. It also  enables the library library(pure_input), which processes  input from files and streams using a DCG. \n\nThe following code fragment realises efficient non-blocking copying  of data from an input to an output stream. The at_end_of_stream/1  call checks for end-of-stream and fills the input buffer. Note that the  use of a get_code/2  and put_code/2  based loop requires a flush_output/1  call after each put_code/2.  The copy_stream_data/2  does not allow for inspection of the copied data and suffers from the  same buffering issues. \n\n\n\ncopy(In, Out) :-\n        repeat,\n            fill_buffer(In),\n            read_pending_codes(In, Chars, Tail),\n            \\+ \\+ ( Tail = [],\n                    format(Out, '~s', [Chars]),\n                    flush_output(Out)\n                  ),\n            (   Tail == []\n            ->  !\n            ;   fail\n            ).\n\n ",
    "prefix":"read_pending_codes"
  },
  "read_string/3": {
    "body":"read_string(${1:Stream}, ${2:Length}, ${3:String})$4\n$0",
    "description":"read_string(+Stream, ?Length, -String).\nRead at most Length characters from Stream and  return them in the string String. If Length is  unbound, Stream is read to the end and Length is  unified with the number of characters read.",
    "prefix":"read_string"
  },
  "read_string/5": {
    "body":"read_string(${1:Stream}, ${2:SepChars}, ${3:PadChars}, ${4:Sep}, ${5:String})$6\n$0",
    "description":"read_string(+Stream, +SepChars, +PadChars, -Sep, -String).\nRead a string from Stream, providing functionality similar to split_string/4.  The predicate performs the following steps:  \n\nSkip all characters that match PadChars\nRead up to a character that matches SepChars or end of  file\nDiscard trailing characters that match PadChars from the  collected input\nUnify String with a string created from the input and Sep with the separator character read. If input was  terminated by the end of the input, Sep is unified with -1.\n\n  The predicate read_string/5  called repeatedly on an input until Sep is -1 (end of file) is equivalent to reading the entire  file into a string and calling split_string/4,  provided that SepChars and PadChars are not partially  overlapping.137Behaviour that  is fully compatible would requite unlimited look-ahead.  Below are some examples: \n\n\n\n% Read a line\nread_string(Input, \"\\n\", \"\\r\", End, String)\n% Read a line, stripping leading and trailing white space\nread_string(Input, \"\\n\", \"\\r\\t \", End, String)\n% Read upto , or ), unifying End with 0', or 0')\nread_string(Input, \",)\", \"\\t \", End, String)\n\n ",
    "prefix":"read_string"
  },
  "read_table_fields/4": {
    "body":"read_table_fields(${1:Handle}, ${2:Start}, ${3:Next}, ${4:Fields})$5\n$0",
    "description":"read_table_fields(+Handle, +Start, -Next, -Fields).\nAs read_table_record/4,  but Fields is a list of terms +Name(-Value), and the Values will be  unified with the values of the specified field.",
    "prefix":"read_table_fields"
  },
  "read_table_record/4": {
    "body":"read_table_record(${1:Handle}, ${2:Start}, ${3:Next}, ${4:Record})$5\n$0",
    "description":"read_table_record(+Handle, +Start, -Next, -Record).\nRead a record from the table. Handle is a handle as returned  by new_table/4. Start  is the location of a record. If Start does not point to the  start of a record, this predicate searches backwards for the starting  position. Record is unified with a term constructed from the functor  associated with the table (default name record and arity  the number of not-skipped columns), each of the arguments containing the  converted data. An error is raised if the data could not be converted. Next  is unified with the start position for the next record.",
    "prefix":"read_table_record"
  },
  "read_table_record_data/4": {
    "body":"read_table_record_data(${1:Handle}, ${2:Start}, ${3:Next}, ${4:Record})$5\n$0",
    "description":"read_table_record_data(+Handle, +Start, -Next, -Record).\nSimilar to read_table_record/4,  but unifies record with a Prolog string containing the data of the  record unparsed. The returned record does not contain the  terminating record-separator.  \n\n",
    "prefix":"read_table_record_data"
  },
  "read_term/2": {
    "body":"read_term(${1:Term}, ${2:Options})$3\n$0",
    "description":"[ISO]read_term(-Term, +Options).\nRead a term from the current input stream and unify the term with Term. The reading is controlled by options from the list of Options. If this list is empty, the behaviour is the same as  for read/1.  The options are upward compatible with Quintus Prolog. The argument  order is according to the ISO standard. Syntax errors are always  reported using exception-handling (see catch/3).  Options:  backquoted_string(Bool): If true, read `...` to a string  object (see section 5.2). The default depends  on the Prolog flag back_quotes.\n\ncharacter_escapes(Bool): Defines how to read \\ escape sequences in quoted atoms. See  the Prolog flag character_escapes  in current_prolog_flag/2.  (SWI-Prolog).\n\ncomments(-Comments): Unify Comments with a list of Position-Comment,  where Position is a stream position object (see stream_position_data/3)  indicating the start of a comment and Comment is a string  object containing the text including delimiters of a comment. It returns  all comments from where the read_term/2  call started up to the end of the term read.\n\ncycles(Bool): If true (default false), re-instantiate  templates as produced by the corresponding write_term/2  option. Note that the default is false to avoid  misinterpretation of @(Template, Substutions), while the  default of write_term/2  is true because emitting cyclic terms without using the  template construct produces an infinitely large term (read: it will  generate an error after producing a huge amount of output).\n\ndotlists(Bool): If true (default false), read .(a,[])  as a list, even if lists are internally nor constructed using the dot as  functor. This is primarily intended to read the output from write_canonical/1  from other Prolog systems. See section  5.1.\n\ndouble_quotes(Atom): Defines how to read \" ... \" strings. See the Prolog flag double_quotes.  (SWI-Prolog).\n\nmodule(Module): Specify Module for operators, character_escapes  flag and double_quotes  flag. The value of the latter two is overruled if the corresponding read_term/3  option is provided. If no module is specified, the current `source  module' is used. (SWI-Prolog).\n\nquasi_quotations(-List): If present, unify List with the quasi quotations (see section A.27) instead of  evaluating quasi quotations. Each quasi quotation is a term quasi_quotation(+Syntax,  +Quotation, +VarDict, -Result), where Syntax is the  term in {|Syntax||..|}, Quotation is a list of character  codes that represent the quotation, VarDict is a list of Name=Variable and Result is a variable  that shares with the place where the quotation must be inserted. This  option is intended to support tools that manipulate Prolog source text.\n\nsingletons(Vars): As variable_names, but only reports the variables occurring  only once in the Term read. Variables starting with an  underscore (`_') are not included in this list. (ISO). If Vars  is the constant warning, singleton variables are reported  using print_message/2.  The variables appear in the order they have been read.\n\nsyntax_errors(Atom): If error (default), throw an exception on a syntax error.  Other values are fail, which causes a message to be printed  using print_message/2,  after which the predicate fails, quiet which causes the  predicate to fail silently, and dec10 which causes syntax  errors to be printed, after which read_term/[2,3]  continues reading the next term. Using dec10, read_term/[2,3]  never fails. (Quintus, SICStus).\n\nsubterm_positions(TermPos): Describes the detailed layout of the term. The formats for the various  types of terms are given below. All positions are character positions.  If the input is related to a normal stream, these positions are relative  to the start of the input; when reading from the terminal, they are  relative to the start of the term.  From-ToUsed for primitive types (atoms, numbers, variables).string_position(From, To)Used to indicate the position of a string enclosed in double quotes (\").brace_term_position(From, To, Arg)Term of the form {...}, as used in DCG rules. Arg  describes the argument.list_position(From, To, Elms, Tail)A list. Elms describes the positions of the elements. If the  list specifies the tail as |<TailTerm> , Tail  is unified with the term position of the tail, otherwise with the atom none.term_position(From, To, FFrom, FTo, SubPos)Used for a compound term not matching one of the above. FFrom  and FTo describe the position of the functor. SubPos  is a list, each element of which describes the term position of the  corresponding subterm.dict_position(From, To, TagFrom, TagTo, KeyValuePosList)Used for a dict (see section 5.4).  The position of the key-value pairs is described by KeyValuePosList,  which is a list of key_value_position/7 terms. The key_value_position/7  terms appear in the order of the input. Because maps to not preserve  ordering, the key is provided in the position description.key_value_position(From, To, SepFrom, SepTo, Key, KeyPos, ValuePos)Used for key-value pairs in a map (see section  5.4). It is similar to the term_position/5 that would  be created, except that the key and value positions do not need an  intermediate list and the key is provided in Key to enable  synchronisation of the file position data with the data structure.parentheses_term_position(From, To, ContentPos)Used for terms between parentheses. This is an extension compared to the  original Quintus specification that was considered necessary for secure  refactoring of terms.quasi_quotation_position(From, To, SyntaxFrom, SyntaxTo, ContentPos)Used for quasi quotations. \n\nterm_position(Pos): Unifies Pos with the starting position of the term read. Pos  is of the same format as used by stream_property/2.\n\nvar_prefix(Bool): If true, demand variables to start with an underscore. See section 2.15.1.7.\n\nvariables(Vars): Unify Vars with a list of variables in the term. The  variables appear in the order they have been read. See also term_variables/2.  (ISO).\n\nvariable_names(Vars): Unify Vars with a list of `Name = Var',  where Name is an atom describing the variable name and Var  is a variable that shares with the corresponding variable in Term.  (ISO). The variables appear in the order they have been read.\n\n ",
    "prefix":"read_term"
  },
  "read_term/3": {
    "body":"read_term(${1:Stream}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"[ISO]read_term(+Stream, -Term, +Options).\nRead term with options from Stream. See read_term/2.",
    "prefix":"read_term"
  },
  "read_term_from_atom/3": {
    "body":"read_term_from_atom(${1:Atom}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"read_term_from_atom(+Atom, -Term, +Options).\nUse read_term/3  to read the next term from Atom. Atom is either an  atom or a string object (see section  5.2). It is not required for Atom to end with a  full-stop. This predicate supersedes atom_to_term/3.",
    "prefix":"read_term_from_atom"
  },
  "read_util:read_file_to_codes/3": {
    "body": ["read_file_to_codes(${1:Spec}, ${2:Codes}, ${3:Options})$4\n$0" ],
    "description":"  read_file_to_codes(+Spec, -Codes, +Options) is det.\n\n   Read the file Spec into a list   of Codes. Options is split into\n   options for absolute_file_name/3 and open/4.   In  addition, the\n   following option is provided:\n\n     * tail(?Tail)\n     Read the data into a _difference list_ Codes\\Tail.\n\n   @see phrase_from_file/3 and read_file_to_string/3.",
    "prefix":"read_file_to_codes"
  },
  "read_util:read_file_to_string/3": {
    "body": ["read_file_to_string(${1:Spec}, ${2:String}, ${3:Options})$4\n$0" ],
    "description":"  read_file_to_string(+Spec, -String, +Options) is det.\n\n   Read the file Spec into a the   string  String. Options is split\n   into options for absolute_file_name/3 and open/4.\n\n   @see phrase_from_file/3 and read_file_to_codes/3.",
    "prefix":"read_file_to_string"
  },
  "read_util:read_file_to_terms/3": {
    "body": ["read_file_to_terms(${1:Spec}, ${2:Terms}, ${3:Options})$4\n$0" ],
    "description":"  read_file_to_terms(+Spec, -Terms, +Options) is det.\n\n   Read the file Spec into a list   of terms. Options is split over\n   absolute_file_name/3, open/4 and  read_term/3.  In addition, the\n   following option is processed:\n\n     * tail(?Tail)\n     If present, Terms\\Tail forms a _difference list_.\n\n   Note  that  the  `output'  options    of  read_term/3,  such  as\n   =variable_names=    or    =subterm_positions=      will    cause\n   read_file_to_terms/3 to fail if  Spec   contains  multiple terms\n   because the values for the different terms will not unify.",
    "prefix":"read_file_to_terms"
  },
  "read_util:read_line_to_codes/2": {
    "body": ["read_line_to_codes(${1:In}, ${2:Line})$3\n$0" ],
    "description":"  read_line_to_codes(+In:stream, -Line:codes) is det.\n\n   Read a line of input from  In   into  a list of character codes.\n   Trailing newline and  or  return   are  deleted.  Upon  reaching\n   end-of-file Line is unified to the atom =end_of_file=.",
    "prefix":"read_line_to_codes"
  },
  "read_util:read_line_to_codes/3": {
    "body": ["read_line_to_codes(${1:Stream}, ${2:Line}, ${3:Tail})$4\n$0" ],
    "description":"  read_line_to_codes(+Stream, -Line, ?Tail) is det.\n\n   Read a line of input as a   difference list. This should be used\n   to read multiple lines  efficiently.   On  reaching end-of-file,\n   Tail is bound to the empty list.",
    "prefix":"read_line_to_codes"
  },
  "read_util:read_line_to_string/2": {
    "body": ["read_line_to_string(${1:Stream}, ${2:String})$3\n$0" ],
    "description":"  read_line_to_string(+Stream, -String) is det.\n\n   Read the next line from  Stream   into  String.  String does not\n   contain the line terminator. String is   unified with the _atom_\n   end_of_file if the end of the file is reached.\n\n   @see    read_string/5 can be used to read lines with separated\n           records without creating intermediate strings.",
    "prefix":"read_line_to_string"
  },
  "read_util:read_stream_to_codes/2": {
    "body": ["read_stream_to_codes(${1:Stream}, ${2:Codes})$3\n$0" ],
    "description":"  read_stream_to_codes(+Stream, -Codes) is det.\n  read_stream_to_codes(+Stream, -Codes, ?Tail) is det.\n\n   Read input from Stream to a list of character codes. The version\n   read_stream_to_codes/3 creates a difference-list.",
    "prefix":"read_stream_to_codes"
  },
  "read_util:read_stream_to_codes/3": {
    "body": ["read_stream_to_codes(${1:Stream}, ${2:Codes}, ${3:Tail})$4\n$0" ],
    "description":"  read_stream_to_codes(+Stream, -Codes) is det.\n  read_stream_to_codes(+Stream, -Codes, ?Tail) is det.\n\n   Read input from Stream to a list of character codes. The version\n   read_stream_to_codes/3 creates a difference-list.",
    "prefix":"read_stream_to_codes"
  },
  "readline:rl_add_history/1": {
    "body":"rl_add_history(${1:Line})$2\n$0",
    "description":"[det]rl_add_history(+Line).\nAdd a line to the history.",
    "prefix":"rl_add_history"
  },
  "readline:rl_read_history/1": {
    "body":"rl_read_history(${1:File})$2\n$0",
    "description":"[det]rl_read_history(+File).\nRead a saved history from File.",
    "prefix":"rl_read_history"
  },
  "readline:rl_read_init_file/1": {
    "body":"rl_read_init_file(${1:File})$2\n$0",
    "description":"[det]rl_read_init_file(+File).\nRead a GNU readline config file. See the GNU readline manual for  details.",
    "prefix":"rl_read_init_file"
  },
  "readline:rl_write_history/1": {
    "body":"rl_write_history(${1:File})$2\n$0",
    "description":"[det]rl_write_history(+File).\nSave the history to File. This can be reloaded in a next  session using rl_read_history/1.",
    "prefix":"rl_write_history"
  },
  "readln:readln/1": {
    "body": ["readln(${1:'Param1'})$2\n$0" ],
    "description":"readln('Param1')",
    "prefix":"readln"
  },
  "readln:readln/2": {
    "body": ["readln(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"readln('Param1','Param2')",
    "prefix":"readln"
  },
  "readln:readln/5": {
    "body": [
      "readln(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"readln('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"readln"
  },
  "readutil:read_file_to_codes/3": {
    "body":"read_file_to_codes(${1:Spec}, ${2:Codes}, ${3:Options})$4\n$0",
    "description":"read_file_to_codes(+Spec, -Codes, +Options).\nRead a file to a list of character codes. Spec is a file  specification for absolute_file_name/3. Codes  is the resulting code list. Options is a list of options for absolute_file_name/3  and open/4.  In addition, the option tail(Tail) is defined, forming a difference-list.",
    "prefix":"read_file_to_codes"
  },
  "readutil:read_file_to_terms/3": {
    "body":"read_file_to_terms(${1:Spec}, ${2:Terms}, ${3:Options})$4\n$0",
    "description":"read_file_to_terms(+Spec, -Terms, +Options).\nRead a file to a list of Prolog terms (see read/1). Spec  is a file specification for absolute_file_name/3. Terms  is the resulting list of Prolog terms. Options is a list of  options for absolute_file_name/3  and open/4.  In addition, the option tail(Tail) is defined, forming a difference-list.",
    "prefix":"read_file_to_terms"
  },
  "readutil:read_line_to_codes/2": {
    "body":"read_line_to_codes(${1:Stream}, ${2:Codes})$3\n$0",
    "description":"read_line_to_codes(+Stream, -Codes).\nRead the next line of input from Stream and unify the result  with Codes after the line has been read. A line is ended  by a newline character or end-of-file. Unlike read_line_to_codes/3,  this predicate removes a trailing newline character.  On end-of-file the atom end_of_file is returned. See  also at_end_of_stream/[0,1].\n\n",
    "prefix":"read_line_to_codes"
  },
  "readutil:read_line_to_codes/3": {
    "body":"read_line_to_codes(${1:Stream}, ${2:Codes}, ${3:Tail})$4\n$0",
    "description":"read_line_to_codes(+Stream, -Codes, ?Tail).\nDifference-list version to read an input line to a list of character  codes. Reading stops at the newline or end-of-file character, but unlike read_line_to_codes/2,  the newline is retained in the output. This predicate is especially  useful for reading a block of lines up to some delimiter. The following  example reads an HTTP header ended by a blank line:  \n\nread_header_data(Stream, Header) :-\n        read_line_to_codes(Stream, Header, Tail),\n        read_header_data(Header, Stream, Tail).\n\nread_header_data(\"\\r\\n\", _, _) :- !.\nread_header_data(\"\\n\", _, _) :- !.\nread_header_data(\"\", _, _) :- !.\nread_header_data(_, Stream, Tail) :-\n        read_line_to_codes(Stream, Tail, NewTail),\n        read_header_data(Tail, Stream, NewTail).\n\n ",
    "prefix":"read_line_to_codes"
  },
  "readutil:read_stream_to_codes/2": {
    "body":"read_stream_to_codes(${1:Stream}, ${2:Codes})$3\n$0",
    "description":"read_stream_to_codes(+Stream, -Codes).\nRead all input until end-of-file and unify the result to Codes.",
    "prefix":"read_stream_to_codes"
  },
  "readutil:read_stream_to_codes/3": {
    "body":"read_stream_to_codes(${1:Stream}, ${2:Codes}, ${3:Tail})$4\n$0",
    "description":"read_stream_to_codes(+Stream, -Codes, ?Tail).\nDifference-list version of read_stream_to_codes/2.",
    "prefix":"read_stream_to_codes"
  },
  "record:current_record/2": {
    "body": ["current_record(${1:Name}, ${2:Term})$3\n$0" ],
    "description":"  current_record(?Name, :Term)\n\n   True if Name is the  name  of   a  record  defined in the module\n   associated with Term  and  Term   is  the  user-provided  record\n   declaration.",
    "prefix":"current_record"
  },
  "record:current_record_predicate/2": {
    "body": ["current_record_predicate(${1:Record}, ${2:PI})$3\n$0" ],
    "description":"  current_record_predicate(?Record, ?PI) is nondet.\n\n   True if PI is the predicate indicator for an access predicate to\n   Record. This predicate is intended   to support cross-referencer\n   tools.",
    "prefix":"current_record_predicate"
  },
  "record:record/1": {
    "body":"record(${1:Spec})$2\n$0",
    "description":"record(+Spec).\nThe construct :- record Spec, ... is used to define access  to named fields in a compound. It is subject to term-expansion (see expand_term/2)  and cannot be called as a predicate. See section A.30 for details.",
    "prefix":"record"
  },
  "recorda/2": {
    "body":"recorda(${1:Key}, ${2:Term})$3\n$0",
    "description":"recorda(+Key, +Term).\nEquivalent to recorda(Key, Term, _).",
    "prefix":"recorda"
  },
  "recorda/3": {
    "body":"recorda(${1:Key}, ${2:Term}, ${3:Reference})$4\n$0",
    "description":"recorda(+Key, +Term, -Reference).\nAssert Term in the recorded database under key Key. Key is a small integer (range min_tagged_integer  ...max_tagged_integer,  atom or compound term. If the key is a compound term, only the name and  arity define the key. Reference is unified with an opaque handle to the record (see erase/1).",
    "prefix":"recorda"
  },
  "recorded/2": {
    "body":"recorded(${1:Key}, ${2:Value})$3\n$0",
    "description":"recorded(+Key, -Value).\nEquivalent to recorded(Key, Value, _).",
    "prefix":"recorded"
  },
  "recorded/3": {
    "body":"recorded(${1:Key}, ${2:Value}, ${3:Reference})$4\n$0",
    "description":"recorded(?Key, ?Value, ?Reference).\nTrue if Value is recorded under Key and has the  given database Reference. If Reference is given,  this predicate is semi-deterministic. Otherwise, it must be considered  non-deterministic. If neither Reference nor Key is  given, the triples are generated as in the code snippet below.70Note  that, without a given Key, some implementations return  triples in the order defined by recorda/2  and recordz/2.  See also current_key/1.  \n\n        current_key(Key),\n        recorded(Key, Value, Reference)\n\n ",
    "prefix":"recorded"
  },
  "recordz/2": {
    "body":"recordz(${1:Key}, ${2:Term})$3\n$0",
    "description":"recordz(+Key, +Term).\nEquivalent to recordz(Key, Term, _).",
    "prefix":"recordz"
  },
  "recordz/3": {
    "body":"recordz(${1:Key}, ${2:Term}, ${3:Reference})$4\n$0",
    "description":"recordz(+Key, +Term, -Reference).\nEquivalent to recorda/3,  but puts the Term at the tail of the terms recorded under Key.",
    "prefix":"recordz"
  },
  "redefine_system_predicate/1": {
    "body":"redefine_system_predicate(${1:Head})$2\n$0",
    "description":"redefine_system_predicate(+Head).\nThis directive may be used both in module user and in  normal modules to redefine any system predicate. If the system  definition is redefined in module user, the new definition  is the default definition for all sub-modules. Otherwise the  redefinition is local to the module. The system definition remains in  the module system.  Redefining system predicate facilitates the definition of  compatibility packages. Use in other contexts is discouraged.\n\n",
    "prefix":"redefine_system_predicate"
  },
  "reexport/1": {
    "body":"reexport(${1:Files})$2\n$0",
    "description":"reexport(+Files).\nLoad and import predicates as use_module/1  and re-export all imported predicates. The reexport declarations must  immediately follow the module declaration.",
    "prefix":"reexport"
  },
  "reexport/2": {
    "body":"reexport(${1:File}, ${2:Import})$3\n$0",
    "description":"reexport(+File, +Import).\nImport from File as use_module/2  and re-export the imported predicates. The reexport declarations must  immediately follow the module declaration.",
    "prefix":"reexport"
  },
  "regex/engine/regex_engine_pp:engine_match/5": {
    "body": [
      "engine_match(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"engine_match('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"engine_match"
  },
  "regex/regex_parser:re/4": {
    "body": [
      "re(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"re('Param1','Param2','Param3','Param4')",
    "prefix":"re"
  },
  "regex/regex_state:adjust_case/3": {
    "body": ["adjust_case(${1:Options}, ${2:Code0}, ${3:Code})$4\n$0" ],
    "description":" adjust_case(+Options, +Code0, -Code) is det.\n\n  True if Code represents the same letter as Code0 but with case\n  adjusted to compensate for the 'i' regular expression option (aka\n  case insensitive).",
    "prefix":"adjust_case"
  },
  "regex/regex_state:new_state/3": {
    "body": ["new_state(${1:OptionSugar}, ${2:CaptureSugar}, ${3:State})$4\n$0" ],
    "description":" new_state(+OptionSugar, +CaptureSugar, -State) is semidet\n\n  True if State is an opaque value representing the regular expression\n  state described by OptionSugar and CapturesSugar. OptionSugar\n  should be a list or an atom. If it's an atom it should\n  be something like 'ims', 'xi', etc. Fails if OptionSugar contains an\n  unknown option.",
    "prefix":"new_state"
  },
  "regex/regex_state:numbered_captures/2": {
    "body": ["numbered_captures(${1:State}, ${2:Captures})$3\n$0" ],
    "description":" numbered_captures(+State, -Captures:list) is det.\n\n  True if Captures is a list of numbered captures in State.",
    "prefix":"numbered_captures"
  },
  "regex/regex_state:push_capture/3": {
    "body": ["push_capture(${1:Capture}, ${2:State0}, ${3:State})$4\n$0" ],
    "description":" push_capture(+Capture, +State0, -State) is semidet\n\n  Adds Capture to State0 giving a new State. Capture may be\n  `Name=Value` or just `Value`. Pushing a named capture pushes both a\n  named and a numbered capture.",
    "prefix":"push_capture"
  },
  "regex/regex_state:singleline_mode/1": {
    "body": ["singleline_mode(${1:Options})$2\n$0" ],
    "description":"\tsingleline_mode(+Options) is semidet.\n\n\tTrue if Options request single-line mode (`/s`).",
    "prefix":"singleline_mode"
  },
  "regex:regex/4": {
    "body": ["regex(${1:Pattern}, ${2:Options}, ${3:Text}, ${4:Captures})$5\n$0" ],
    "description":"  regex(+Pattern:text,+Options,+Text:text,?Captures:list) is semidet\n\n   True if Text matches the regular expression Pattern. The pattern's\n   behavior is influenced by Options (see below). The values of any\n   capturing subgroups are unified with Captures (see below). A `text`\n   value may either be an atom or a list of codes.\n\n   Options can either be an atom or a list of options. If an atom, it's\n   split into a list of single character atoms which is used as the\n   Options value.  This allows on to use `is`, for example, instead of\n   `[i,s]`.  Acceptable options are:\n\n     * `i` - case-insensitive (default false)\n     * `s` - let `.` match `\\n` (default false)\n\n   Captures is unified with a list of captured values, with the\n   leftmost capture first, etc. Each captured value is a list of codes.\n   For example,\n\n       ?- regex('(a+)(b*)', [], 'aaabbbbb', [A,B]).\n       A = \"aaa\",\n       B = \"bbbbb\".\n\n   Named captures are also supported. In that case, Captures must be\n   a list of pairs like `['A'=A,'B'=B]`. Every named capture in the\n   pattern must have a corresponding key in Captures. (This is a\n   temporary restriction and will be removed later).\n\n   A brief word on argument order. Prolog convention prefers to place\n   an Options argument as the final argument or as the last one before\n   outputs. However, widely followed regular expression\n   convention places options immediately after the pattern. I chose to\n   follow the latter convention. This argument order\n   benefits higher-order calls like maplist/3 which can do things\n   like:\n\n       ?- maplist(regex('(a+)(b+)', i), [ab, aab, abb], L).\n       L = [[\"a\", \"b\"], [\"aa\", \"b\"], [\"a\", \"bb\"]].",
    "prefix":"regex"
  },
  "regex_compat:regex_convert_file/1": {
    "body": ["regex_convert_file(${1:File})$2\n$0" ],
    "description":"  regex_convert_file(+File)\n\n   Convert a single file, creating  <File>.new   on  success. It is\n   adviced the inspect the changes before   moving  the .new to the\n   original file.",
    "prefix":"regex_convert_file"
  },
  "regex_compat:regex_emacs_to_advanced/2": {
    "body": ["regex_emacs_to_advanced(${1:Old}, ${2:New})$3\n$0" ],
    "description":"  regex_emacs_to_advanced(+Old, -New)\n\n   Convert a single regular expression.",
    "prefix":"regex_emacs_to_advanced"
  },
  "regex_compat:regex_main/0": {
    "body": ["regex_main$1\n$0" ],
    "description":"regex_main",
    "prefix":"regex_main"
  },
  "registry:registry_delete_key/1": {
    "body":"registry_delete_key(${1:Path})$2\n$0",
    "description":"registry_delete_key(+Path).\nDelete the indicated key.",
    "prefix":"registry_delete_key"
  },
  "registry:registry_get_key/2": {
    "body":"registry_get_key(${1:Path}, ${2:Value})$3\n$0",
    "description":"registry_get_key(+Path, -Value).\nGet the principal (default) value associated to this key. Fails silently  if the key does not exist.",
    "prefix":"registry_get_key"
  },
  "registry:registry_get_key/3": {
    "body":"registry_get_key(${1:Path}, ${2:Name}, ${3:Value})$4\n$0",
    "description":"registry_get_key(+Path, +Name, -Value).\nGet a named value associated to this key.",
    "prefix":"registry_get_key"
  },
  "registry:registry_set_key/2": {
    "body":"registry_set_key(${1:Path}, ${2:Value})$3\n$0",
    "description":"registry_set_key(+Path, +Value).\nSet the principal (default) value of this key. Creates (a path to) the  key if it does not already exist.",
    "prefix":"registry_set_key"
  },
  "registry:registry_set_key/3": {
    "body":"registry_set_key(${1:Path}, ${2:Name}, ${3:Value})$4\n$0",
    "description":"registry_set_key(+Path, +Name, +Value).\nAssociate a named value to this key. Creates (a path to) the key if it  does not already exist.",
    "prefix":"registry_set_key"
  },
  "registry:shell_register_dde/6": {
    "body":"shell_register_dde(${1:Type}, ${2:Action}, ${3:Service}, ${4:Topic}, ${5:Command}, ${6:IfNotRunning})$7\n$0",
    "description":"shell_register_dde(+Type, +Action, +Service, +Topic, +Command, +IfNotRunning).\nAssociate DDE actions to a type. Type is the same type as  used for the 2nd argument of shell_register_file_type/4, Action  is the action to perform, Service and Topic  specify the DDE topic to address, and Command is the command  to execute on this topic. Finally, IfNotRunning defines the  command to execute if the required DDE server is not present.",
    "prefix":"shell_register_dde"
  },
  "registry:shell_register_file_type/4": {
    "body":"shell_register_file_type(${1:Ext}, ${2:Type}, ${3:Name}, ${4:OpenAction})$5\n$0",
    "description":"shell_register_file_type(+Ext, +Type, +Name, +OpenAction).\nRegister a file-type. Ext is the extension to associate. Type is the type name, often something like prolog.type. Name is the name visible in the Windows file-type browser.  Finally, OpenAction defines the action to execute when a file  with this extension is opened in the Windows explorer.",
    "prefix":"shell_register_file_type"
  },
  "registry:shell_register_prolog/1": {
    "body":"shell_register_prolog(${1:Ext})$2\n$0",
    "description":"shell_register_prolog(+Ext).\nDefault registration of SWI-Prolog, which is invoked as part of the  initialisation process on Windows systems. As the source also includes  the above predicates, it is given as an example:  \n\nshell_register_prolog(Ext) :-\n        current_prolog_flag(argv, [Me|_]),\n        atomic_list_concat(['\"', Me, '\" \"%1\"'], OpenCommand),\n        shell_register_file_type(\n            Ext, 'prolog.type', 'Prolog Source', OpenCommand),\n        shell_register_dde(\n            'prolog.type', consult,\n            prolog, control, 'consult(''%1'')', Me),\n        shell_register_dde(\n            'prolog.type', edit,\n            prolog, control, 'edit(''%1'')', Me).\n\n  \n\n",
    "prefix":"shell_register_prolog"
  },
  "reload_library_index/0": {
    "body":"reload_library_index$1\n$0",
    "description":"reload_library_index.\nForce reloading the index after modifying the set of library directories  by changing the rules for library_directory/1, file_search_path/2,  adding or deleting INDEX.pl files. This predicate does not  update the INDEX.pl files. Check make_library_index/[1,2]  and make/0  for updating the index files.  Normally, the index is reloaded automatically if a predicate cannot  be found in the index and the set of library directories has changed.  Using reload_library_index/0  is necessary if directories are removed or the order of the library  directories is changed.\n\n",
    "prefix":"reload_library_index"
  },
  "rename_file/2": {
    "body":"rename_file(${1:File1}, ${2:File2})$3\n$0",
    "description":"rename_file(+File1, +File2).\nRename File1 as File2. The semantics is compatible  to the POSIX semantics of the rename() system call as far as the  operating system allows. Notably, if File2 exists, the  operation succeeds (except for possible permission errors) and is atomic  (meaning there is no window where File2 does not exist).",
    "prefix":"rename_file"
  },
  "require/1": {
    "body":"require(${1:ListOfNameAndArity})$2\n$0",
    "description":"require(+ListOfNameAndArity).\nDeclare that this file/module requires the specified predicates to be  defined ``with their commonly accepted definition''. This predicate  originates from the Prolog portability layer for XPCE. It is intended to  provide a portable mechanism for specifying that this module requires  the specified predicates.  The implementation normally first verifies whether the predicate is  already defined. If not, it will search the libraries and load the  required library. \n\nSWI-Prolog, having autoloading, does not load the library.  Instead it creates a procedure header for the predicate if it does not  exist. This will flag the predicate as `undefined'. See also check/0  and autoload/0.\n\n",
    "prefix":"require"
  },
  "reset/3": {
    "body":"reset(${1:Goal}, ${2:Ball}, ${3:Continuation})$4\n$0",
    "description":"reset(:Goal, ?Ball, -Continuation).\nCall Goal. If Goal calls shift/1  and the argument of shift/1  can be unified with Ball,62The  argument order described in Schrijvers et  al., 2013 is reset(Goal,Continuation,Ball).  We swapped the argument order for compatibility with catch/3 shift/1  causes reset/3  to return, unifying Continuation with a goal that represents the continuation  after shift/1.  In other words, meta-calling Continuation completes the  execution where shift it. If Goal does not call shift/1,  both Ball and Continuation are unified with the integer 0  (zero).",
    "prefix":"reset"
  },
  "reset_profiler/0": {
    "body":"reset_profiler$1\n$0",
    "description":"reset_profiler.\nSwitches the profiler to false and clears all collected  statistics.",
    "prefix":"reset_profiler"
  },
  "resource/3": {
    "body":"resource(${1:Name}, ${2:Class}, ${3:FileSpec})$4\n$0",
    "description":"resource(+Name, +Class, +FileSpec).\nThis predicate is defined as a dynamic predicate in the module user. Clauses for it may be defined in any module,  including the user module. Name is the name of the resource  (an atom). A resource name may contain any character, except for $ and  :, which are reserved for internal usage by the resource library. Class  describes the kind of object stored in the resource. In the current  implementation, it is just an atom. FileSpec is a file  specification that may exploit file_search_path/2  (see absolute_file_name/2).  Normally, resources are defined as unit clauses (facts), but the  definition of this predicate also allows for rules. For proper  generation of the saved state, it must be possible to enumerate the  available resources by calling this predicate with all its arguments  unbound. \n\nDynamic rules are useful to turn all files in a certain directory  into resources, without specifying a resource for each file. For  example, assume the file_search_path/2 icons  refers to the resource directory containing icon files. The following  definition makes all these images available as resources: \n\n\n\nresource(Name, image, icons(XpmName)) :-\n        atom(Name), !,\n        file_name_extension(Name, xpm, XpmName).\nresource(Name, image, XpmFile) :-\n        var(Name),\n        absolute_file_name(icons(.), [type(directory)], Dir)\n        concat(Dir, '/*.xpm', Pattern),\n        expand_file_name(Pattern, XpmFiles),\n        member(XpmFile, XpmFiles).\n\n ",
    "prefix":"resource"
  },
  "retract/1": {
    "body":"retract(${1:Term})$2\n$0",
    "description":"[ISO,nondet]retract(+Term).\nWhen Term is an atom or a term it is unified with the first  unifying fact or clause in the database. The fact or clause is removed  from the database. The retract/1  predicate respects the logical update view. This implies that retract/1  succeeds for all clauses that match Term when the predicate  was called. The example below illustrates that the first call  to retract/1  succeeds on bee on backtracking despite the fact that bee  is already retracted.68Example by  Jan Burse.  \n\n:- dynamic insect/1.\ninsect(ant).\ninsect(bee).\n\n?- (   retract(insect(I)),\n       writeln(I),\n       retract(insect(bee)),\n       fail\n   ;   true\n   ).\nant ;\nbee.\n\n  If multiple threads start a retract on the same predicate at the same  time their notion of the entry generation is adjusted such that  they do not retract the same first clause. This implies that, if  multiple threads use once(retract(Term)), no two threads  will retract the same clause. Note that on backtracking over retract/1,  multiple threads may retract the same clause as both threads respect the  logical update view.\n\n",
    "prefix":"retract"
  },
  "retractall/1": {
    "body":"retractall(${1:Head})$2\n$0",
    "description":"[ISO,det]retractall(+Head).\nAll facts or clauses in the database for which the head  unifies with Head are removed. If Head refers to a  predicate that is not defined, it is implicitly created as a dynamic  predicate. See also dynamic/1.69The  ISO standard only allows using dynamic/1  as a directive.",
    "prefix":"retractall"
  },
  "rewrite:rew_goal_expansion/2": {
    "body": ["rew_goal_expansion(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rew_goal_expansion('Param1','Param2')",
    "prefix":"rew_goal_expansion"
  },
  "rewrite:rew_term_expansion/2": {
    "body": ["rew_term_expansion(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rew_term_expansion('Param1','Param2')",
    "prefix":"rew_term_expansion"
  },
  "rewrite:rewrite/2": {
    "body": ["rewrite(${1:To}, ${2:From})$3\n$0" ],
    "description":"  rewrite(:To, +From)\n\n   Invoke the term-rewriting system",
    "prefix":"rewrite"
  },
  "round/1": {
    "body":"round(${1:Expr})$2\n$0",
    "description":"[ISO]round(+Expr).\nEvaluate Expr and round the result to the nearest integer.  According to ISO, round/1  is defined as floor(Expr+1/2), i.e., rounding down. This is an  unconventional choice and under which the relation round(Expr) == -round(-Expr) does not hold. SWI-Prolog  rounds outward, e.g., round(1.5) =:= 2 and round round(-1.5) =:= -2.",
    "prefix":"round"
  },
  "run_tests/0": {
    "body":"run_tests$1\n$0",
    "description":"run_tests.\nRun all test-units.",
    "prefix":"run_tests"
  },
  "run_tests/1": {
    "body":"run_tests(${1:Spec})$2\n$0",
    "description":"run_tests(+Spec).\nRun only the specified tests. Spec can be a list to run  multiple tests. A single specification is either the name of a test unit  or a term <Unit>:<Tests>, running only  the specified test. <Tests> is either the name of a  test or a list of names. Running particular tests is particularly useful  for tracing a test:6Unfortunately  the body of the test is called through meta-calling, so it cannot be  traced. The called user-code can be traced normally though.  \n\n?- gtrace, run_tests(lists:member).\n\n  \n\n",
    "prefix":"run_tests"
  },
  "running_tests/0": {
    "body":"running_tests$1\n$0",
    "description":"running_tests.\nPrint all currently running tests to the terminal. It can be used to  find running thread in multi-threaded test operation or find the  currently running test if a test appears to be blocking.",
    "prefix":"running_tests"
  },
  "same_file/2": {
    "body":"same_file(${1:File1}, ${2:File2})$3\n$0",
    "description":"same_file(+File1, +File2).\nTrue if both filenames refer to the same physical file. That is, if File1 and File2 are the same string or both names  exist and point to the same file (due to hard or symbolic links and/or  relative vs. absolute paths). On systems that provide stat() with  meaningful values for st_dev and st_inode, same_file/2  is implemented by comparing the device and inode identifiers. On  Windows, same_file/2  compares the strings returned by the GetFullPathName() system call.",
    "prefix":"same_file"
  },
  "same_term/2": {
    "body":"same_term(${1:T1}, ${2:T2})$3\n$0",
    "description":"[semidet]same_term(@T1, @T2).\nTrue if T1 and T2 are equivalent and will remain  equivalent, even if setarg/3  is used on either of them. This means T1 and T2 are the same variable, equivalent atomic  data or a compound term allocated at the same address.",
    "prefix":"same_term"
  },
  "saml:saml_authenticate/4": {
    "body": [
      "saml_authenticate(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"saml_authenticate('Param1','Param2','Param3','Param4')",
    "prefix":"saml_authenticate"
  },
  "sandbox:safe_call/1": {
    "body": ["safe_call(${1:Goal})$2\n$0" ],
    "description":"  safe_call(:Goal)\n\n   Call Goal if it  complies  with   the  sandboxing  rules. Before\n   calling   Goal,   it   performs   expand_goal/2,   followed   by\n   safe_goal/1. Expanding is done explicitly  because situations in\n   which safe_call/1 typically concern goals that  are not known at\n   compile time.\n\n   @see safe_goal/1.",
    "prefix":"safe_call"
  },
  "sandbox:safe_goal/1": {
    "body": ["safe_goal(${1:Goal})$2\n$0" ],
    "description":"  safe_goal(:Goal) is det.\n\n   True if calling Goal provides  no   security  risc. This implies\n   that:\n\n     - The call-graph can be fully expanded. Full expansion *stops*\n     if a meta-goal is found for   which we cannot determine enough\n     details to know which predicate will be called.\n\n     - All predicates  referenced  from   the  fully  expanded  are\n     whitelisted by the predicate safe_primitive/1 and safe_meta/2.\n\n     - It is not allowed to make explicitly qualified calls into\n     modules to predicates that are not exported or declared\n     public.\n\n   @error  instantiation_error if the analysis encounters a term in\n           a callable position that is insufficiently instantiated\n           to determine the predicate called.\n   @error  permission_error(call, sandboxed, Goal) if Goal is in\n           the call-tree and not white-listed.",
    "prefix":"safe_goal"
  },
  "scan_arguments:scan_arguments/2": {
    "body": ["scan_arguments(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"scan_arguments('Param1','Param2')",
    "prefix":"scan_arguments"
  },
  "scan_arguments:scan_arguments/3": {
    "body": ["scan_arguments(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"scan_arguments('Param1','Param2','Param3')",
    "prefix":"scan_arguments"
  },
  "see/1": {
    "body":"see(${1:SrcDest})$2\n$0",
    "description":"see(+SrcDest).\nOpen SrcDest for reading and make it the current input (see set_input/1).  If SrcDest is a stream handle, just make this stream the  current input. See the introduction of section  4.17.3 for details.",
    "prefix":"see"
  },
  "seeing/1": {
    "body":"seeing(${1:SrcDest})$2\n$0",
    "description":"seeing(?SrcDest).\nSame as current_input/1,  except that user is returned if the current input is the  stream user_input to improve compatibility with traditional  Edinburgh I/O. See the introduction of section 4.17.3 for details.",
    "prefix":"seeing"
  },
  "seek/4": {
    "body":"seek(${1:Stream}, ${2:Offset}, ${3:Method}, ${4:NewLocation})$5\n$0",
    "description":"seek(+Stream, +Offset, +Method, -NewLocation).\nReposition the current point of the given Stream. Method  is one of bof, current or eof,  indicating positioning relative to the start, current point or end of  the underlying object. NewLocation is unified with the new  offset, relative to the start of the stream.  Positions are counted in `units'. A unit is 1 byte, except for text  files using 2-byte Unicode encoding (2 bytes) or wchar encoding  (sizeof(wchar_t)). The latter guarantees comfortable interaction with  wide-character text objects. Otherwise, the use of seek/4  on non-binary files (see open/4)  is of limited use, especially when using multi-byte text encodings (e.g. UTF-8)  or multi-byte newline files (e.g. DOS/Windows). On text files,  SWI-Prolog offers reliable backup to an old position using stream_property/2  and set_stream_position/2.  Skipping N character codes is achieved calling get_code/2 N  times or using copy_stream_data/3,  directing the output to a null stream (see open_null_stream/1).  If the seek modifies the current location, the line number and character  position in the line are set to 0. \n\nIf the stream cannot be repositioned, a permission_error  is raised. If applying the offset would result in a file position less  than zero, a domain_error is raised. Behaviour when seeking  to positions beyond the size of the underlying object depend on the  object and possibly the operating system. The predicate seek/4  is compatible with Quintus Prolog, though the error conditions and  signalling is ISO compliant. See also stream_property/2  and set_stream_position/2.\n\n",
    "prefix":"seek"
  },
  "seen/0": {
    "body":"seen$1\n$0",
    "description":"seen.\nClose the current input stream. The new input stream becomes user_input.",
    "prefix":"seen"
  },
  "select_dict/3": {
    "body":"select_dict(${1:Select}, ${2:From}, ${3:Rest})$4\n$0",
    "description":"[semidet]select_dict(+Select, +From, -Rest).\nTrue when the tags of Select and From have been  unified, all keys in Select appear in From and the  corresponding values have been unified. The key-value pairs of From  that do not appear in Select are used to form an anonymous  dict, which us unified with Rest. For example:  \n\n?- select_dict(P{x:0, y:Y}, point{x:0, y:1, z:2}, R).\nP = point,\nY = 1,\nR = _G1705{z:2}.\n\n  See also select_dict/2  to ignore Rest and >:<\/2  for a symmetric partial unification of two dicts.\n\n",
    "prefix":"select_dict"
  },
  "semweb/rdf11:lang_equal/2": {
    "body": ["lang_equal(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"lang_equal('Param1','Param2')",
    "prefix":"lang_equal"
  },
  "semweb/rdf11:lang_matches/2": {
    "body": ["lang_matches(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"lang_matches('Param1','Param2')",
    "prefix":"lang_matches"
  },
  "semweb/rdf11:rdf/3": {
    "body":"rdf(${1:S}, ${2:P}, ${3:O})$4\n$0",
    "description":"[nondet]rdf(?S, ?P, ?O).\n",
    "prefix":"rdf"
  },
  "semweb/rdf11:rdf/4": {
    "body":"rdf(${1:S}, ${2:P}, ${3:O}, ${4:G})$5\n$0",
    "description":"[nondet]rdf(?S, ?P, ?O, ?G).\nTrue if an RDF triple <S,P,O>  exists, optionally in the graph G. The object O is  either a resource (atom) or one of the terms listed below. The described  types apply for the case where O is unbound. If O  is instantiated it is converted according to the rules described with rdf_assert/3.  Triples consist of the following three terms: \n\n\n\nBlank nodes are encoded by atoms that start with `_:`.\nIRIs appear in two notations:  Full IRIs are encoded by atoms that do not start with `_:`.  Specifically, an IRI term is not required to follow the IRI standard  grammar.Abbreviated IRI notation that allows IRI prefix aliases that are  registered by rdf_register_prefix/[2,3] to be used. Their notation is Alias:Local,  where Alias and Local are atoms. Each abbreviated IRI is expanded by the  system to a full IRI.  \nLiterals appear in two notations:  String@Lang A language-tagged string, where String is a Prolog  string and Lang is an atom.Value^^Type A type qualified literal. For  unknown types, Value is a Prolog string. If type is known, the Prolog  representations from the table below are used. Datatype IRI Prolog term xsd:floatfloat xsd:doublefloat xsd:decimalfloat (1) xsd:integerinteger XSD integer sub-typesinteger xsd:booleantrue or false xsd:datedate(Y,M,D) xsd:dateTimedate_time(Y,M,D,HH,MM,SS)  (2,3) xsd:gDayinteger xsd:gMonthinteger xsd:gMonthDaymonth_day(M,D) xsd:gYearinteger xsd:gYearMonthyear_month(Y,M) xsd:timetime(HH,MM,SS) (2) \n\n  Notes:\n\n (1) The current implementation of xsd:decimal  values as floats is formally incorrect. Future versions of SWI-Prolog  may introduce decimal as a subtype of rational.  (2) SS fields denote the number of seconds. This  can either be an integer or a float.  (3) The date_time structure can have a 7th  field that denotes the timezone offset in seconds as an integer.  In addition, a ground object value is translated into a  properly typed RDF literal using rdf_canonical_literal/2. \n\nThere is a fine distinction in how duplicate statements are handled  in rdf/[3,4]: backtracking over rdf/3  will never return duplicate triples that appear in multiple graphs. rdf/4  will return such duplicate triples, because their graph term differs.\n\nS is the subject term. It is  either a blank node or IRI. P is the predicate term. It is  always an IRI. O is the object term. It is  either a literal, a blank node or IRI (except for true and false  that denote the values of datatype XSD boolean). G is the graph term. It is  always an IRI.   See also: - http://www.w3.org/TR/sparql11-query/#sparqlTriplePatternsTriple  pattern querying  - xsd_number_string/2 and xsd_time_string/3  are used to convert between lexical representations and Prolog terms.\n\n ",
    "prefix":"rdf"
  },
  "semweb/rdf11:rdf_active_transaction/1": {
    "body": ["rdf_active_transaction(${1:'Param1'})$2\n$0" ],
    "description":"rdf_active_transaction('Param1')",
    "prefix":"rdf_active_transaction"
  },
  "semweb/rdf11:rdf_alt/3": {
    "body":"rdf_alt(${1:Alt}, ${2:Default}, ${3:Others})$4\n$0",
    "description":"[nondet]rdf_alt(+Alt, ?Default, ?Others).\nTrue when Alt is an instance of rdf:Alt with  first member Default and remaining members Others.  Notice that this construct adds no machine-processable semantics but  is conventionally used to indicate to a human reader that the numerical  ordering of the container membership properties of Container is intended  to only be relevant in distinguishing between the first and all  non-first members. \n\nDefault denotes the default option to take when choosing  one of the alternatives container in Container. Others  denotes the non-default options that can be chosen from.\n\n",
    "prefix":"rdf_alt"
  },
  "semweb/rdf11:rdf_assert/3": {
    "body":"rdf_assert(${1:S}, ${2:P}, ${3:O})$4\n$0",
    "description":"[det]rdf_assert(+S, +P, +O).\n",
    "prefix":"rdf_assert"
  },
  "semweb/rdf11:rdf_assert/4": {
    "body":"rdf_assert(${1:S}, ${2:P}, ${3:O}, ${4:G})$5\n$0",
    "description":"[det]rdf_assert(+S, +P, +O, +G).\nAssert a new triple. If O is a literal, certain Prolog terms  are translated to typed RDF literals. These conversions are described  with rdf_canonical_literal/2.  If a type is provided using Value^^Type  syntax, additional conversions are performed. All types accept either an  atom or Prolog string holding a valid RDF lexical value for the type and  xsd:float and xsd:double accept a Prolog integer.\n\n",
    "prefix":"rdf_assert"
  },
  "semweb/rdf11:rdf_assert_alt/3": {
    "body":"rdf_assert_alt(${1:Alt}, ${2:Default}, ${3:Others})$4\n$0",
    "description":"[det]rdf_assert_alt(?Alt, +Default, +Others:list).\n",
    "prefix":"rdf_assert_alt"
  },
  "semweb/rdf11:rdf_assert_alt/4": {
    "body":"rdf_assert_alt(${1:Alt}, ${2:Default}, ${3:Others}, ${4:Graph})$5\n$0",
    "description":"[det]rdf_assert_alt(?Alt, +Default, +Others:list, +Graph).\nCreate an rdf:Alt with the given Default and Others. Default  and the members of Others must be valid object terms for rdf_assert/3.",
    "prefix":"rdf_assert_alt"
  },
  "semweb/rdf11:rdf_assert_bag/2": {
    "body":"rdf_assert_bag(${1:Bag}, ${2:Set})$3\n$0",
    "description":"[det]rdf_assert_bag(?Bag, +Set:list).\n",
    "prefix":"rdf_assert_bag"
  },
  "semweb/rdf11:rdf_assert_bag/3": {
    "body":"rdf_assert_bag(${1:Bag}, ${2:Set}, ${3:Graph})$4\n$0",
    "description":"[det]rdf_assert_bag(?Bag, +Set:list, +Graph).\nCreate an rdf:Bag from the given set of values. The members  of Set must be valid object terms for rdf_assert/3.",
    "prefix":"rdf_assert_bag"
  },
  "semweb/rdf11:rdf_assert_list/2": {
    "body":"rdf_assert_list(${1:PrologList}, ${2:RDFList})$3\n$0",
    "description":"[det]rdf_assert_list(+PrologList, ?RDFList).\n",
    "prefix":"rdf_assert_list"
  },
  "semweb/rdf11:rdf_assert_list/3": {
    "body":"rdf_assert_list(${1:PrologList}, ${2:RDFList}, ${3:Graph})$4\n$0",
    "description":"[det]rdf_assert_list(+PrologList, ?RDFList, +Graph).\nCreate an RDF list from the given Prolog List. PrologList  must be a proper Prolog list and all members of the list must be  acceptable as object for rdf_assert/3.  If RDFList is unbound and PrologList is not empty, rdf_create_bnode/1  is used to create RDFList.",
    "prefix":"rdf_assert_list"
  },
  "semweb/rdf11:rdf_assert_seq/2": {
    "body":"rdf_assert_seq(${1:Seq}, ${2:List})$3\n$0",
    "description":"[det]rdf_assert_seq(?Seq, +List).\n",
    "prefix":"rdf_assert_seq"
  },
  "semweb/rdf11:rdf_assert_seq/3": {
    "body":"rdf_assert_seq(${1:Seq}, ${2:List}, ${3:Graph})$4\n$0",
    "description":"[det]rdf_assert_seq(?Seq, +List, +Graph).\n",
    "prefix":"rdf_assert_seq"
  },
  "semweb/rdf11:rdf_atom_md5/3": {
    "body": ["rdf_atom_md5(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"rdf_atom_md5('Param1','Param2','Param3')",
    "prefix":"rdf_atom_md5"
  },
  "semweb/rdf11:rdf_bag/2": {
    "body":"rdf_bag(${1:Bag}, ${2:List})$3\n$0",
    "description":"[nondet]rdf_bag(+Bag, -List:list).\nTrue when Bag is an rdf:Bag and set is the set  values related through container membership properties to Bag.  Notice that this construct adds no machine-processable semantics but  is conventionally used to indicate to a human reader that the numerical  ordering of the container membership properties of Container is intended  to not be significant.\n\n",
    "prefix":"rdf_bag"
  },
  "semweb/rdf11:rdf_bnode/1": {
    "body":"rdf_bnode(${1:BNode})$2\n$0",
    "description":"[nondet]rdf_bnode(?BNode).\nTrue if BNode is a currently known blank node. The predicate  is semidet if BNode is ground.",
    "prefix":"rdf_bnode"
  },
  "semweb/rdf11:rdf_canonical_literal/2": {
    "body":"rdf_canonical_literal(${1:In}, ${2:Literal})$3\n$0",
    "description":"[det]rdf_canonical_literal(++In, -Literal).\nTransform a relaxed literal specification as allowed for rdf_assert/3 into its canonical  form. The following Prolog terms are translated: Prolog Term Datatype IRI floatxsd:double integerxsd:integer stringxsd:string true or false xsd:boolean date(Y,M,D) xsd:date date_time(Y,M,D,HH,MM,SS) xsd:dateTime date_time(Y,M,D,HH,MM,SS,TZ) xsd:dateTime month_day(M,D) xsd:gMonthDay year_month(Y,M) xsd:gYearMonth time(HH,MM,SS) xsd:time   For example: \n\n\n\n?- rdf_canonical_literal(42, X).\nX = 42^^'http://www.w3.org/2001/XMLSchema#integer'.\n\n ",
    "prefix":"rdf_canonical_literal"
  },
  "semweb/rdf11:rdf_compare/3": {
    "body":"rdf_compare(${1:Diff}, ${2:Left}, ${3:Right})$4\n$0",
    "description":"[det]rdf_compare(-Diff, +Left, +Right).\nTrue if the RDF terms Left and Right are ordered  according to the comparison operator Diff. The ordering is  defines as:  \n\nLiteral < BNode < IRI\nFor literals  Numeric < non-numericNumeric literals are ordered by value. If both are equal, floats are  ordered before integers.Other data types are ordered lexicographically.  \nBNodes and IRIs are ordered lexicographically.\n\n  Note that this ordering is a complete ordering of RDF terms that is  consistent with the partial ordering defined by SPARQL.\n\nDiff is one of <, =  or > ",
    "prefix":"rdf_compare"
  },
  "semweb/rdf11:rdf_create_bnode/1": {
    "body":"rdf_create_bnode(${1:BNode})$2\n$0",
    "description":"rdf_create_bnode(--BNode).\nCreate a new BNode. A blank node is an atom starting with _:. Blank nodes generated by this predicate are of the form _:genid followed by a unique integer.",
    "prefix":"rdf_create_bnode"
  },
  "semweb/rdf11:rdf_create_graph/1": {
    "body": ["rdf_create_graph(${1:'Param1'})$2\n$0" ],
    "description":"rdf_create_graph('Param1')",
    "prefix":"rdf_create_graph"
  },
  "semweb/rdf11:rdf_current_ns/2": {
    "body": ["rdf_current_ns(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_current_ns('Param1','Param2')",
    "prefix":"rdf_current_ns"
  },
  "semweb/rdf11:rdf_current_prefix/2": {
    "body": ["rdf_current_prefix(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_current_prefix('Param1','Param2')",
    "prefix":"rdf_current_prefix"
  },
  "semweb/rdf11:rdf_current_snapshot/1": {
    "body": ["rdf_current_snapshot(${1:'Param1'})$2\n$0" ],
    "description":"rdf_current_snapshot('Param1')",
    "prefix":"rdf_current_snapshot"
  },
  "semweb/rdf11:rdf_debug/1": {
    "body": ["rdf_debug(${1:'Param1'})$2\n$0" ],
    "description":"rdf_debug('Param1')",
    "prefix":"rdf_debug"
  },
  "semweb/rdf11:rdf_default_graph/1": {
    "body":"rdf_default_graph(${1:Graph})$2\n$0",
    "description":"[det]rdf_default_graph(-Graph).\n",
    "prefix":"rdf_default_graph"
  },
  "semweb/rdf11:rdf_default_graph/2": {
    "body":"rdf_default_graph(${1:Old}, ${2:New})$3\n$0",
    "description":"[det]rdf_default_graph(-Old, +New).\nQuery/set the notion of the default graph. The notion of the default  graph is local to a thread. Threads created inherit the default graph  from their creator. See set_prolog_flag/2.",
    "prefix":"rdf_default_graph"
  },
  "semweb/rdf11:rdf_delete_literal_map/2": {
    "body": ["rdf_delete_literal_map(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_delete_literal_map('Param1','Param2')",
    "prefix":"rdf_delete_literal_map"
  },
  "semweb/rdf11:rdf_delete_literal_map/3": {
    "body": [
      "rdf_delete_literal_map(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_delete_literal_map('Param1','Param2','Param3')",
    "prefix":"rdf_delete_literal_map"
  },
  "semweb/rdf11:rdf_delete_snapshot/1": {
    "body": ["rdf_delete_snapshot(${1:'Param1'})$2\n$0" ],
    "description":"rdf_delete_snapshot('Param1')",
    "prefix":"rdf_delete_snapshot"
  },
  "semweb/rdf11:rdf_destroy_literal_map/1": {
    "body": ["rdf_destroy_literal_map(${1:'Param1'})$2\n$0" ],
    "description":"rdf_destroy_literal_map('Param1')",
    "prefix":"rdf_destroy_literal_map"
  },
  "semweb/rdf11:rdf_equal/2": {
    "body": ["rdf_equal(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_equal('Param1','Param2')",
    "prefix":"rdf_equal"
  },
  "semweb/rdf11:rdf_estimate_complexity/4": {
    "body": [
      "rdf_estimate_complexity(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"rdf_estimate_complexity('Param1','Param2','Param3','Param4')",
    "prefix":"rdf_estimate_complexity"
  },
  "semweb/rdf11:rdf_find_literal_map/3": {
    "body": [
      "rdf_find_literal_map(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_find_literal_map('Param1','Param2','Param3')",
    "prefix":"rdf_find_literal_map"
  },
  "semweb/rdf11:rdf_gc/0": {"body": ["rdf_gc$1\n$0" ], "description":"rdf_gc", "prefix":"rdf_gc"},
  "semweb/rdf11:rdf_generation/1": {
    "body": ["rdf_generation(${1:'Param1'})$2\n$0" ],
    "description":"rdf_generation('Param1')",
    "prefix":"rdf_generation"
  },
  "semweb/rdf11:rdf_global_id/2": {
    "body": ["rdf_global_id(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_global_id('Param1','Param2')",
    "prefix":"rdf_global_id"
  },
  "semweb/rdf11:rdf_global_object/2": {
    "body": ["rdf_global_object(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_global_object('Param1','Param2')",
    "prefix":"rdf_global_object"
  },
  "semweb/rdf11:rdf_global_term/2": {
    "body": ["rdf_global_term(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_global_term('Param1','Param2')",
    "prefix":"rdf_global_term"
  },
  "semweb/rdf11:rdf_graph/1": {
    "body":"rdf_graph(${1:Graph})$2\n$0",
    "description":"[nondet]rdf_graph(?Graph).\nTrue when Graph is an existing graph.",
    "prefix":"rdf_graph"
  },
  "semweb/rdf11:rdf_graph_prefixes/2": {
    "body": ["rdf_graph_prefixes(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_graph_prefixes('Param1','Param2')",
    "prefix":"rdf_graph_prefixes"
  },
  "semweb/rdf11:rdf_graph_prefixes/3": {
    "body": [
      "rdf_graph_prefixes(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_graph_prefixes('Param1','Param2','Param3')",
    "prefix":"rdf_graph_prefixes"
  },
  "semweb/rdf11:rdf_graph_property/2": {
    "body": ["rdf_graph_property(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_graph_property('Param1','Param2')",
    "prefix":"rdf_graph_property"
  },
  "semweb/rdf11:rdf_has/3": {
    "body":"rdf_has(${1:S}, ${2:P}, ${3:O})$4\n$0",
    "description":"[nondet]rdf_has(?S, ?P, ?O).\n",
    "prefix":"rdf_has"
  },
  "semweb/rdf11:rdf_has/4": {
    "body":"rdf_has(${1:S}, ${2:P}, ${3:O}, ${4:RealP})$5\n$0",
    "description":"[nondet]rdf_has(?S, ?P, ?O, -RealP).\nSimilar to rdf/3 and rdf/4,  but P matches all predicates that are defined as an  rdfs:subPropertyOf of P. This predicate also recognises the  predicate properties inverse_of and symmetric. See rdf_set_predicate/2.",
    "prefix":"rdf_has"
  },
  "semweb/rdf11:rdf_insert_literal_map/3": {
    "body": [
      "rdf_insert_literal_map(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_insert_literal_map('Param1','Param2','Param3')",
    "prefix":"rdf_insert_literal_map"
  },
  "semweb/rdf11:rdf_insert_literal_map/4": {
    "body": [
      "rdf_insert_literal_map(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"rdf_insert_literal_map('Param1','Param2','Param3','Param4')",
    "prefix":"rdf_insert_literal_map"
  },
  "semweb/rdf11:rdf_iri/1": {
    "body":"rdf_iri(${1:IRI})$2\n$0",
    "description":"[nondet]rdf_iri(?IRI).\nTrue if IRI is a current IRI. The predicate is semidet  if IRI is ground.",
    "prefix":"rdf_iri"
  },
  "semweb/rdf11:rdf_is_bnode/1": {
    "body":"rdf_is_bnode(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_bnode(@Term).\nTrue if Term is an RDF blank node identifier.  A blank node is represented by an atom that starts with _:. \n\nSuccess of this goal does not imply that the blank node is present in  the database (see rdf_bnode/1  for that). \n\nFor backwards compatibility, atoms that are represented with an atom  that starts with __ are also considered to be a blank node.\n\n",
    "prefix":"rdf_is_bnode"
  },
  "semweb/rdf11:rdf_is_iri/1": {
    "body":"rdf_is_iri(${1:IRI})$2\n$0",
    "description":"[semidet]rdf_is_iri(@IRI).\nTrue if IRI is an RDF IRI term.  For performance reasons, this does not check for compliance to the  syntax defined in http://www.ietf.org/rfc/rfc3987.txtRFC 3987 . This  checks whether the term is (1) an atom and (2) not a blank node  identifier. \n\nSuccess of this goal does not imply that the IRI is  present in the database (see rdf_iri/1  for that).\n\n",
    "prefix":"rdf_is_iri"
  },
  "semweb/rdf11:rdf_is_literal/1": {
    "body":"rdf_is_literal(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_literal(@Term).\nTrue if Term is an RDF literal term.  An RDF literal term is of the form `String@LanguageTag or Value^^Datatype`. \n\nSuccess of this goal does not imply that the literal is well-formed  or that it is present in the database (see rdf_literal/1 for that).\n\n",
    "prefix":"rdf_is_literal"
  },
  "semweb/rdf11:rdf_is_name/1": {
    "body":"rdf_is_name(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_name(@Term).\nTrue if Term is an RDF Name, i.e., an IRI or literal.  Success of this goal does not imply that the name is well-formed or  that it is present in the database (see rdf_name/1) for that).\n\n",
    "prefix":"rdf_is_name"
  },
  "semweb/rdf11:rdf_is_object/1": {
    "body":"rdf_is_object(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_object(@Term).\nTrue if Term can appear in the object position of a triple.  Success of this goal does not imply that the object term in  well-formed or that it is present in the database (see rdf_object/1) for that). \n\nSince any RDF term can appear in the object position, this is  equaivalent to rdf_is_term/1.\n\n",
    "prefix":"rdf_is_object"
  },
  "semweb/rdf11:rdf_is_predicate/1": {
    "body":"rdf_is_predicate(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_predicate(@Term).\nTrue if Term can appear in the predicate position of a  triple.  Success of this goal does not imply that the predicate term is  present in the database (see rdf_predicate/1)  for that). \n\nSince only IRIs can appear in the predicate position, this is  equivalent to rdf_is_iri/1.\n\n",
    "prefix":"rdf_is_predicate"
  },
  "semweb/rdf11:rdf_is_subject/1": {
    "body":"rdf_is_subject(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_subject(@Term).\nTrue if Term can appear in the subject position of a triple.  Only blank nodes and IRIs can appear in the subject position. \n\nSuccess of this goal does not imply that the subject term is present  in the database (see rdf_subject/1)  for that). \n\nSince blank nodes are represented by atoms that start with `_:` and  an IRIs are atoms as well, this is equivalent to atom(Term).\n\n",
    "prefix":"rdf_is_subject"
  },
  "semweb/rdf11:rdf_is_term/1": {
    "body":"rdf_is_term(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_term(@Term).\nTrue if Term can be used as an RDF term, i.e., if Term  is either an IRI, a blank node or an RDF literal.  Success of this goal does not imply that the RDF term is present in  the database (see rdf_term/1) for  that).\n\n",
    "prefix":"rdf_is_term"
  },
  "semweb/rdf11:rdf_keys_in_literal_map/3": {
    "body": [
      "rdf_keys_in_literal_map(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_keys_in_literal_map('Param1','Param2','Param3')",
    "prefix":"rdf_keys_in_literal_map"
  },
  "semweb/rdf11:rdf_last/2": {
    "body":"rdf_last(${1:RDFList}, ${2:Last})$3\n$0",
    "description":"[det]rdf_last(+RDFList, -Last).\nTrue when Last is the last element of RDFList.  Note that if the last cell has multiple rdf:first triples, this  predicate becomes nondet.",
    "prefix":"rdf_last"
  },
  "semweb/rdf11:rdf_length/2": {
    "body":"rdf_length(${1:RDFList}, ${2:Length})$3\n$0",
    "description":"[nondet]rdf_length(+RDFList, -Length:nonneg).\nTrue when Length is the number of cells in RDFList.  Note that a list cell may have multiple rdf:rest triples, which makes  this predicate non-deterministic. This predicate does not check whether  the list cells have associated values (rdf:first). The list must end in  rdf:nil.",
    "prefix":"rdf_length"
  },
  "semweb/rdf11:rdf_lexical_form/2": {
    "body":"rdf_lexical_form(${1:Literal}, ${2:Lexical})$3\n$0",
    "description":"[det]rdf_lexical_form(++Literal, -Lexical:compound).\nTrue when Lexical is the lexical form for the literal Literal. Lexical is of one of the forms below. The ntriples  serialization is obtained by transforming String into a proper ntriples  string using double quotes and escaping where needed and turning Type  into a proper IRI reference.  \n\nString^^Type\nString@Lang\n\n",
    "prefix":"rdf_lexical_form"
  },
  "semweb/rdf11:rdf_list/1": {
    "body":"rdf_list(${1:RDFTerm})$2\n$0",
    "description":"[semidet]rdf_list(?RDFTerm).\nTrue if RDFTerm is a proper RDF list. This implies that every  node in the list has an rdf:first and rdf:rest  property and the list ends in rdf:nil.  If RDFTerm is unbound, RDFTerm is bound to each maximal  RDF list. An RDF list is maximal if there is no triple rdf(_, rdf:rest, RDFList).\n\n",
    "prefix":"rdf_list"
  },
  "semweb/rdf11:rdf_list/2": {
    "body":"rdf_list(${1:RDFList}, ${2:PrologList})$3\n$0",
    "description":"[det]rdf_list(+RDFList, -PrologList).\nTrue when PrologList represents the rdf:first objects for all  cells in RDFList. Note that this can be non-deterministic if  cells have multiple rdf:first or rdf:rest triples.",
    "prefix":"rdf_list"
  },
  "semweb/rdf11:rdf_literal/1": {
    "body":"rdf_literal(${1:Term})$2\n$0",
    "description":"[nondet]rdf_literal(?Term).\nTrue if Term is a known literal. If Term is  ground, it is pre-processed as the object argument of rdf_assert/3  and the predicate is semidet.",
    "prefix":"rdf_literal"
  },
  "semweb/rdf11:rdf_load/1": {
    "body": ["rdf_load(${1:'Param1'})$2\n$0" ],
    "description":"rdf_load('Param1')",
    "prefix":"rdf_load"
  },
  "semweb/rdf11:rdf_load/2": {
    "body": ["rdf_load(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_load('Param1','Param2')",
    "prefix":"rdf_load"
  },
  "semweb/rdf11:rdf_load_db/1": {
    "body": ["rdf_load_db(${1:'Param1'})$2\n$0" ],
    "description":"rdf_load_db('Param1')",
    "prefix":"rdf_load_db"
  },
  "semweb/rdf11:rdf_make/0": {
    "body": ["rdf_make$1\n$0" ],
    "description":"rdf_make",
    "prefix":"rdf_make"
  },
  "semweb/rdf11:rdf_match_label/3": {
    "body": [
      "rdf_match_label(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_match_label('Param1','Param2','Param3')",
    "prefix":"rdf_match_label"
  },
  "semweb/rdf11:rdf_md5/2": {
    "body": ["rdf_md5(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_md5('Param1','Param2')",
    "prefix":"rdf_md5"
  },
  "semweb/rdf11:rdf_member/2": {
    "body":"rdf_member(${1:Member}, ${2:RDFList})$3\n$0",
    "description":"[nondet]rdf_member(?Member, +RDFList).\nTrue when Member is a member of RDFList",
    "prefix":"rdf_member"
  },
  "semweb/rdf11:rdf_member_property/2": {
    "body": ["rdf_member_property(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_member_property('Param1','Param2')",
    "prefix":"rdf_member_property"
  },
  "semweb/rdf11:rdf_meta/1": {
    "body": ["rdf_meta(${1:'Param1'})$2\n$0" ],
    "description":"rdf_meta('Param1')",
    "prefix":"rdf_meta"
  },
  "semweb/rdf11:rdf_monitor/2": {
    "body": ["rdf_monitor(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_monitor('Param1','Param2')",
    "prefix":"rdf_monitor"
  },
  "semweb/rdf11:rdf_name/1": {
    "body":"rdf_name(${1:Name})$2\n$0",
    "description":"[nondet]rdf_name(?Name).\nTrue if Name is a current IRI or literal. The predicate is semidet if Name is ground.",
    "prefix":"rdf_name"
  },
  "semweb/rdf11:rdf_new_literal_map/1": {
    "body": ["rdf_new_literal_map(${1:'Param1'})$2\n$0" ],
    "description":"rdf_new_literal_map('Param1')",
    "prefix":"rdf_new_literal_map"
  },
  "semweb/rdf11:rdf_nextto/2": {
    "body": ["rdf_nextto(${1:X}, ${2:Y})$3\n$0" ],
    "description":" rdf_nextto(?X, ?Y) is nondet.\n rdf_nextto(?X, ?Y, ?RdfList) is nondet.\n\n       True if Y directly follows X in RdfList.",
    "prefix":"rdf_nextto"
  },
  "semweb/rdf11:rdf_nextto/3": {
    "body": ["rdf_nextto(${1:X}, ${2:Y}, ${3:RdfList})$4\n$0" ],
    "description":" rdf_nextto(?X, ?Y) is nondet.\n rdf_nextto(?X, ?Y, ?RdfList) is nondet.\n\n       True if Y directly follows X in RdfList.",
    "prefix":"rdf_nextto"
  },
  "semweb/rdf11:rdf_node/1": {
    "body":"rdf_node(${1:T})$2\n$0",
    "description":"[nondet]rdf_node(?T).\nTrue when T appears in the subject or object position of a  known triple, i.e., is a node in the RDF graph.",
    "prefix":"rdf_node"
  },
  "semweb/rdf11:rdf_nth0/3": {
    "body":"rdf_nth0(${1:Index}, ${2:RDFList}, ${3:X})$4\n$0",
    "description":"[nondet]rdf_nth0(?Index, +RDFList, ?X).\nTrue when X is the Index-th element (0-based) of RDFList.  This predicate is deterministic if Index is given and the  list has no multiple rdf:first or rdf:rest values.",
    "prefix":"rdf_nth0"
  },
  "semweb/rdf11:rdf_object/1": {
    "body":"rdf_object(${1:O})$2\n$0",
    "description":"[nondet]rdf_object(?O).\nTrue when O is a currently known object, i.e. it appeasr in  the object position of some visible triple. If Term is ground, it is  pre-processed as the object argument of rdf_assert/3  and the predicate is semidet.",
    "prefix":"rdf_object"
  },
  "semweb/rdf11:rdf_predicate/1": {
    "body":"rdf_predicate(${1:P})$2\n$0",
    "description":"[nondet]rdf_predicate(?P).\nTrue when P is a currently known predicate, i.e. it appears  in the predicate position of some visible triple. The predicate is semidet if P is ground.",
    "prefix":"rdf_predicate"
  },
  "semweb/rdf11:rdf_predicate_property/2": {
    "body": ["rdf_predicate_property(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_predicate_property('Param1','Param2')",
    "prefix":"rdf_predicate_property"
  },
  "semweb/rdf11:rdf_prefix/2": {
    "body": ["rdf_prefix(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_prefix('Param1','Param2')",
    "prefix":"rdf_prefix"
  },
  "semweb/rdf11:rdf_reachable/3": {
    "body":"rdf_reachable(${1:S}, ${2:P}, ${3:O})$4\n$0",
    "description":"[nondet]rdf_reachable(?S, +P, ?O).\n",
    "prefix":"rdf_reachable"
  },
  "semweb/rdf11:rdf_reachable/5": {
    "body":"rdf_reachable(${1:S}, ${2:P}, ${3:O}, ${4:MaxD}, ${5:D})$6\n$0",
    "description":"[nondet]rdf_reachable(?S, +P, ?O, +MaxD, -D).\nTrue when O can be reached from S using the  transitive closure of P. The predicate uses (the internals  of) rdf_has/3 and thus matches  both rdfs:subPropertyOf and the inverse_of and symmetric predicate properties. The version rdf_reachable/5  maximizes the steps considered and returns the number of steps taken.  If both S and O are given, these predicates are semidet.  The number of steps D is minimal because the implementation  uses breath first search.\n\n",
    "prefix":"rdf_reachable"
  },
  "semweb/rdf11:rdf_register_ns/2": {
    "body": ["rdf_register_ns(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_register_ns('Param1','Param2')",
    "prefix":"rdf_register_ns"
  },
  "semweb/rdf11:rdf_register_ns/3": {
    "body": [
      "rdf_register_ns(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_register_ns('Param1','Param2','Param3')",
    "prefix":"rdf_register_ns"
  },
  "semweb/rdf11:rdf_register_prefix/2": {
    "body": ["rdf_register_prefix(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_register_prefix('Param1','Param2')",
    "prefix":"rdf_register_prefix"
  },
  "semweb/rdf11:rdf_register_prefix/3": {
    "body": [
      "rdf_register_prefix(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_register_prefix('Param1','Param2','Param3')",
    "prefix":"rdf_register_prefix"
  },
  "semweb/rdf11:rdf_reset_db/0": {
    "body": ["rdf_reset_db$1\n$0" ],
    "description":"rdf_reset_db",
    "prefix":"rdf_reset_db"
  },
  "semweb/rdf11:rdf_reset_literal_map/1": {
    "body": ["rdf_reset_literal_map(${1:'Param1'})$2\n$0" ],
    "description":"rdf_reset_literal_map('Param1')",
    "prefix":"rdf_reset_literal_map"
  },
  "semweb/rdf11:rdf_resource/1": {
    "body": ["rdf_resource(${1:'Param1'})$2\n$0" ],
    "description":"rdf_resource('Param1')",
    "prefix":"rdf_resource"
  },
  "semweb/rdf11:rdf_retract_list/1": {
    "body":"rdf_retract_list(${1:RDFList})$2\n$0",
    "description":"[det]rdf_retract_list(+RDFList).\nRetract the rdf:first, rdf:rest and rdf:type=rdf:'List' triples from all  nodes reachable through rdf:rest. Note that other triples that exist on  the nodes are left untouched.",
    "prefix":"rdf_retract_list"
  },
  "semweb/rdf11:rdf_retractall/3": {
    "body":"rdf_retractall(${1:S}, ${2:P}, ${3:O})$4\n$0",
    "description":"[nondet]rdf_retractall(?S, ?P, ?O).\n",
    "prefix":"rdf_retractall"
  },
  "semweb/rdf11:rdf_retractall/4": {
    "body":"rdf_retractall(${1:S}, ${2:P}, ${3:O}, ${4:G})$5\n$0",
    "description":"[nondet]rdf_retractall(?S, ?P, ?O, ?G).\nRemove all matching triples from the database. Matching is performed  using the same rules as rdf/3. The  call does not instantiate any of its arguments.",
    "prefix":"rdf_retractall"
  },
  "semweb/rdf11:rdf_save/1": {
    "body": ["rdf_save(${1:'Param1'})$2\n$0" ],
    "description":"rdf_save('Param1')",
    "prefix":"rdf_save"
  },
  "semweb/rdf11:rdf_save/2": {
    "body": ["rdf_save(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_save('Param1','Param2')",
    "prefix":"rdf_save"
  },
  "semweb/rdf11:rdf_save_db/1": {
    "body": ["rdf_save_db(${1:'Param1'})$2\n$0" ],
    "description":"rdf_save_db('Param1')",
    "prefix":"rdf_save_db"
  },
  "semweb/rdf11:rdf_save_db/2": {
    "body": ["rdf_save_db(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_save_db('Param1','Param2')",
    "prefix":"rdf_save_db"
  },
  "semweb/rdf11:rdf_save_footer/1": {
    "body": ["rdf_save_footer(${1:'Param1'})$2\n$0" ],
    "description":"rdf_save_footer('Param1')",
    "prefix":"rdf_save_footer"
  },
  "semweb/rdf11:rdf_save_header/2": {
    "body": ["rdf_save_header(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_save_header('Param1','Param2')",
    "prefix":"rdf_save_header"
  },
  "semweb/rdf11:rdf_save_subject/3": {
    "body": [
      "rdf_save_subject(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_save_subject('Param1','Param2','Param3')",
    "prefix":"rdf_save_subject"
  },
  "semweb/rdf11:rdf_seq/2": {
    "body":"rdf_seq(${1:Seq}, ${2:List})$3\n$0",
    "description":"[nondet]rdf_seq(+Seq, -List:list).\nTrue when Seq is an instance of rdf:Seq and List  is a list of associated values, ordered according to the container  membership property used.  Notice that this construct adds no machine-processable semantics but  is conventionally used to indicate to a human reader that the numerical  ordering of the container membership properties of Container is intended  to be significant.\n\n",
    "prefix":"rdf_seq"
  },
  "semweb/rdf11:rdf_set/1": {
    "body": ["rdf_set(${1:'Param1'})$2\n$0" ],
    "description":"rdf_set('Param1')",
    "prefix":"rdf_set"
  },
  "semweb/rdf11:rdf_set_graph/2": {
    "body": ["rdf_set_graph(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_set_graph('Param1','Param2')",
    "prefix":"rdf_set_graph"
  },
  "semweb/rdf11:rdf_set_predicate/2": {
    "body": ["rdf_set_predicate(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_set_predicate('Param1','Param2')",
    "prefix":"rdf_set_predicate"
  },
  "semweb/rdf11:rdf_snapshot/1": {
    "body": ["rdf_snapshot(${1:'Param1'})$2\n$0" ],
    "description":"rdf_snapshot('Param1')",
    "prefix":"rdf_snapshot"
  },
  "semweb/rdf11:rdf_source/1": {
    "body": ["rdf_source(${1:'Param1'})$2\n$0" ],
    "description":"rdf_source('Param1')",
    "prefix":"rdf_source"
  },
  "semweb/rdf11:rdf_source/2": {
    "body": ["rdf_source(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_source('Param1','Param2')",
    "prefix":"rdf_source"
  },
  "semweb/rdf11:rdf_source_location/2": {
    "body": ["rdf_source_location(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_source_location('Param1','Param2')",
    "prefix":"rdf_source_location"
  },
  "semweb/rdf11:rdf_split_url/3": {
    "body": ["rdf_split_url(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"rdf_split_url('Param1','Param2','Param3')",
    "prefix":"rdf_split_url"
  },
  "semweb/rdf11:rdf_statistics/1": {
    "body": ["rdf_statistics(${1:'Param1'})$2\n$0" ],
    "description":"rdf_statistics('Param1')",
    "prefix":"rdf_statistics"
  },
  "semweb/rdf11:rdf_statistics_literal_map/2": {
    "body": ["rdf_statistics_literal_map(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_statistics_literal_map('Param1','Param2')",
    "prefix":"rdf_statistics_literal_map"
  },
  "semweb/rdf11:rdf_subject/1": {
    "body":"rdf_subject(${1:S})$2\n$0",
    "description":"[nondet]rdf_subject(?S).\nTrue when S is a currently known subject, i.e. it  appears in the subject position of some visible triple. The predicate is semidet if S is ground.",
    "prefix":"rdf_subject"
  },
  "semweb/rdf11:rdf_term/1": {
    "body":"rdf_term(${1:Term})$2\n$0",
    "description":"[nondet]rdf_term(?Term).\nTrue if Term appears in the RDF database. Term is  either an iri, literal or blank node and may appear in any position of  any triple. If Term is ground, it is pre-processed as the  object argument of rdf_assert/3  and the predicate is semidet.",
    "prefix":"rdf_term"
  },
  "semweb/rdf11:rdf_transaction/1": {
    "body": ["rdf_transaction(${1:'Param1'})$2\n$0" ],
    "description":"rdf_transaction('Param1')",
    "prefix":"rdf_transaction"
  },
  "semweb/rdf11:rdf_transaction/2": {
    "body": ["rdf_transaction(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_transaction('Param1','Param2')",
    "prefix":"rdf_transaction"
  },
  "semweb/rdf11:rdf_transaction/3": {
    "body": [
      "rdf_transaction(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_transaction('Param1','Param2','Param3')",
    "prefix":"rdf_transaction"
  },
  "semweb/rdf11:rdf_unload/1": {
    "body": ["rdf_unload(${1:'Param1'})$2\n$0" ],
    "description":"rdf_unload('Param1')",
    "prefix":"rdf_unload"
  },
  "semweb/rdf11:rdf_unload_graph/1": {
    "body": ["rdf_unload_graph(${1:'Param1'})$2\n$0" ],
    "description":"rdf_unload_graph('Param1')",
    "prefix":"rdf_unload_graph"
  },
  "semweb/rdf11:rdf_update/4": {
    "body": ["rdf_update(${1:S}, ${2:P}, ${3:O}, ${4:Action})$5\n$0" ],
    "description":"  rdf_update(+S, +P, +O, ++Action) is det.\n  rdf_update(+S, +P, +O, +G, ++Action) is det.\n\n   Replaces one of  the  three  fields   on  the  matching  triples\n   depending on Action:\n\n     * subject(Resource)\n     Changes the first field of the triple.\n     * predicate(Resource)\n     Changes the second field of the triple.\n     * object(Object)\n     Changes the last field of the triple to the given resource or\n     literal(Value).\n     * graph(Graph)\n     Moves the triple from its current named graph to Graph.\n\n   The argument matching  the  action  must   be  ground.  If  this\n   argument is equivalent to  the  current   value,  no  action  is\n   performed. Otherwise, the requested action   is performed on all\n   matching triples.  For example, all resources typed `rdfs:Class`\n   can be changed to `owl:Class` using\n\n     ```\n     ?- rdf_update(_, rdf:type, rdfs:'Class',\n                   object(owl:'Class')).\n     ```\n\n   @error instantiation_error if Action or the matching argument is\n          not ground.\n   @error domain_error(rdf_update_action, Action) if Action is not\n          one of the above terms.",
    "prefix":"rdf_update"
  },
  "semweb/rdf11:rdf_update/5": {
    "body": ["rdf_update(${1:S}, ${2:P}, ${3:O}, ${4:G}, ${5:Action})$6\n$0" ],
    "description":"  rdf_update(+S, +P, +O, ++Action) is det.\n  rdf_update(+S, +P, +O, +G, ++Action) is det.\n\n   Replaces one of  the  three  fields   on  the  matching  triples\n   depending on Action:\n\n     * subject(Resource)\n     Changes the first field of the triple.\n     * predicate(Resource)\n     Changes the second field of the triple.\n     * object(Object)\n     Changes the last field of the triple to the given resource or\n     literal(Value).\n     * graph(Graph)\n     Moves the triple from its current named graph to Graph.\n\n   The argument matching  the  action  must   be  ground.  If  this\n   argument is equivalent to  the  current   value,  no  action  is\n   performed. Otherwise, the requested action   is performed on all\n   matching triples.  For example, all resources typed `rdfs:Class`\n   can be changed to `owl:Class` using\n\n     ```\n     ?- rdf_update(_, rdf:type, rdfs:'Class',\n                   object(owl:'Class')).\n     ```\n\n   @error instantiation_error if Action or the matching argument is\n          not ground.\n   @error domain_error(rdf_update_action, Action) if Action is not\n          one of the above terms.",
    "prefix":"rdf_update"
  },
  "semweb/rdf11:rdf_update_duplicates/0": {
    "body": ["rdf_update_duplicates$1\n$0" ],
    "description":"rdf_update_duplicates",
    "prefix":"rdf_update_duplicates"
  },
  "semweb/rdf11:rdf_url_namespace/2": {
    "body": ["rdf_url_namespace(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdf_url_namespace('Param1','Param2')",
    "prefix":"rdf_url_namespace"
  },
  "semweb/rdf11:rdf_version/1": {
    "body": ["rdf_version(${1:'Param1'})$2\n$0" ],
    "description":"rdf_version('Param1')",
    "prefix":"rdf_version"
  },
  "semweb/rdf11:rdf_warm_indexes/0": {
    "body": ["rdf_warm_indexes$1\n$0" ],
    "description":"rdf_warm_indexes",
    "prefix":"rdf_warm_indexes"
  },
  "semweb/rdf11:rdf_warm_indexes/1": {
    "body": ["rdf_warm_indexes(${1:'Param1'})$2\n$0" ],
    "description":"rdf_warm_indexes('Param1')",
    "prefix":"rdf_warm_indexes"
  },
  "semweb/rdf11:rdf_where/1": {
    "body":"rdf_where(${1:Where})$2\n$0",
    "description":"[semidet]rdf_where(+Where).\nFormulate constraints on RDF terms, notably literals. These are intended  to be used as illustrated below. RDF constraints are pure: they may be  placed before, after or inside a graph pattern and, provided the code  contains no commit operations (!, ->), the  semantics of the goal remains the same. Preferably, constraints are  placed before the graph pattern as they often help the RDF  database to exploit its literal indexes. In the example below, the  database can choose between using the subject and/or predicate hash or  the ordered literal table.  \n\n    { Date >= \"2000-01-01\"^^xsd:dateTime },\n    rdf(S, P, Date)\n\n  The following constraints are currently defined: \n\n>() , >=(),==(),=<(),<(): The comparison operators are defined between numbers (of any recognised  type), typed literals of the same type and langStrings of the same  language.\n\nprefix(String, Pattern): substring(String, Pattern): word(String, Pattern): like(String, Pattern): icase(String, Pattern): Text matching operators that act on both typed literals and langStrings.\n\nlang_matches(Term, Pattern): Demands a full RDF term (Text@Lang) or a plain Lang term to  match the language pattern Pattern.\n\n  The predicates rdf_where/1  and {}/1 are identical. The rdf_where/1 variant is provided  to avoid ambiguity in applications where {}/1 is used for other  purposes. Note that it is also possible to write rdf11:{...}.\n\n",
    "prefix":"rdf_where"
  },
  "semweb/rdf11:rdfs_container/2": {
    "body":"rdfs_container(${1:Container}, ${2:List})$3\n$0",
    "description":"[nondet]rdfs_container(+Container, -List).\nTrue when List is the list of objects attached to Container  using a container membership property (rdf:_0, rdf:_1, ...). If multiple  objects are connected to the Container using the same  membership property, this predicate selects one value  non-deterministically.",
    "prefix":"rdfs_container"
  },
  "semweb/rdf11:rdfs_container_membership_property/1": {
    "body":"rdfs_container_membership_property(${1:Property})$2\n$0",
    "description":"[nondet]rdfs_container_membership_property(?Property).\nTrue when Property is a container membership property  (rdf:_1, rdf:_2, ...).",
    "prefix":"rdfs_container_membership_property"
  },
  "semweb/rdf11:rdfs_container_membership_property/2": {
    "body":"rdfs_container_membership_property(${1:Property}, ${2:Number})$3\n$0",
    "description":"[nondet]rdfs_container_membership_property(?Property, ?Number:nonneg).\nTrue when Property is the Nth container membership property.  Success of this goal does not imply that Property is  present in the database.\n\n",
    "prefix":"rdfs_container_membership_property"
  },
  "semweb/rdf11:rdfs_member/2": {
    "body":"rdfs_member(${1:Elem}, ${2:Container})$3\n$0",
    "description":"[nondet]rdfs_member(?Elem, ?Container).\nTrue if rdf(Container, P, Elem) is true and P is a  container membership property.",
    "prefix":"rdfs_member"
  },
  "semweb/rdf11:rdfs_nth0/3": {
    "body":"rdfs_nth0(${1:N}, ${2:Container}, ${3:Elem})$4\n$0",
    "description":"[nondet]rdfs_nth0(?N, ?Container, ?Elem).\nTrue if rdf(Container, P, Elem) is true and P is the N-th  (0-based) container membership property.",
    "prefix":"rdfs_nth0"
  },
  "semweb/rdf11_containers:rdf_alt/3": {
    "body": ["rdf_alt(${1:Alt}, ${2:Default}, ${3:Others})$4\n$0" ],
    "description":"  rdf_alt(+Alt, ?Default, ?Others) is nondet.\n\n   True when Alt is an instance of `rdf:Alt` with first member\n   Default and remaining members Others.\n\n   Notice that this construct adds no machine-processable semantics\n   but is conventionally used to indicate   to  a human reader that\n   the numerical ordering of the container membership properties of\n   Container is intended to  only   be  relevant  in distinguishing\n   between the first and all non-first members.\n\n   Default denotes the default option to  take when choosing one of\n   the alternatives container in  Container.   Others  denotes  the\n   non-default options that can be chosen from.",
    "prefix":"rdf_alt"
  },
  "semweb/rdf11_containers:rdf_assert_alt/3": {
    "body": ["rdf_assert_alt(${1:Alt}, ${2:Default}, ${3:Others})$4\n$0" ],
    "description":"  rdf_assert_alt(?Alt, +Default, +Others:list) is det.\n  rdf_assert_alt(?Alt, +Default, +Others:list, +Graph) is det.\n\n   Create an rdf:Alt with the given Default and Others. Default and\n   the  members  of  Others  must  be    valid   object  terms  for\n   rdf_assert/3.",
    "prefix":"rdf_assert_alt"
  },
  "semweb/rdf11_containers:rdf_assert_alt/4": {
    "body": [
      "rdf_assert_alt(${1:Alt}, ${2:Default}, ${3:Others}, ${4:Graph})$5\n$0"
    ],
    "description":"  rdf_assert_alt(?Alt, +Default, +Others:list) is det.\n  rdf_assert_alt(?Alt, +Default, +Others:list, +Graph) is det.\n\n   Create an rdf:Alt with the given Default and Others. Default and\n   the  members  of  Others  must  be    valid   object  terms  for\n   rdf_assert/3.",
    "prefix":"rdf_assert_alt"
  },
  "semweb/rdf11_containers:rdf_assert_bag/2": {
    "body": ["rdf_assert_bag(${1:Bag}, ${2:Set})$3\n$0" ],
    "description":"  rdf_assert_bag(?Bag, +Set:list) is det.\n  rdf_assert_bag(?Bag, +Set:list, +Graph) is det.\n\n   Create an rdf:Bag from the given set   of values. The members of\n   Set must be valid object terms for rdf_assert/3.",
    "prefix":"rdf_assert_bag"
  },
  "semweb/rdf11_containers:rdf_assert_bag/3": {
    "body": ["rdf_assert_bag(${1:Bag}, ${2:Set}, ${3:Graph})$4\n$0" ],
    "description":"  rdf_assert_bag(?Bag, +Set:list) is det.\n  rdf_assert_bag(?Bag, +Set:list, +Graph) is det.\n\n   Create an rdf:Bag from the given set   of values. The members of\n   Set must be valid object terms for rdf_assert/3.",
    "prefix":"rdf_assert_bag"
  },
  "semweb/rdf11_containers:rdf_assert_seq/2": {
    "body": ["rdf_assert_seq(${1:Seq}, ${2:List})$3\n$0" ],
    "description":"  rdf_assert_seq(?Seq, +List) is det.\n  rdf_assert_seq(?Seq, +List, +Graph) is det.",
    "prefix":"rdf_assert_seq"
  },
  "semweb/rdf11_containers:rdf_assert_seq/3": {
    "body": ["rdf_assert_seq(${1:Seq}, ${2:List}, ${3:Graph})$4\n$0" ],
    "description":"  rdf_assert_seq(?Seq, +List) is det.\n  rdf_assert_seq(?Seq, +List, +Graph) is det.",
    "prefix":"rdf_assert_seq"
  },
  "semweb/rdf11_containers:rdf_bag/2": {
    "body": ["rdf_bag(${1:Bag}, ${2:List})$3\n$0" ],
    "description":"  rdf_bag(+Bag, -List:list) is nondet.\n\n   True when Bag is an rdf:Bag and   set  is the set values related\n   through container membership properties to Bag.\n\n   Notice that this construct adds no machine-processable semantics\n   but is conventionally used to indicate   to  a human reader that\n   the numerical ordering of the container membership properties of\n   Container is intended to not be significant.",
    "prefix":"rdf_bag"
  },
  "semweb/rdf11_containers:rdf_seq/2": {
    "body": ["rdf_seq(${1:Seq}, ${2:List})$3\n$0" ],
    "description":"  rdf_seq(+Seq, -List:list) is nondet.\n\n   True when Seq is an instance of rdf:Seq   and  List is a list of\n   associated values, ordered according to the container membership\n   property used.\n\n   Notice that this construct adds no machine-processable semantics\n   but is conventionally used to indicate   to  a human reader that\n   the numerical ordering of the container membership properties of\n   Container is intended to be significant.",
    "prefix":"rdf_seq"
  },
  "semweb/rdf11_containers:rdfs_container/2": {
    "body": ["rdfs_container(${1:Container}, ${2:List})$3\n$0" ],
    "description":"  rdfs_container(+Container, -List) is nondet.\n\n   True when List is the  list   of  objects  attached to Container\n   using a container membership property  (rdf:_0, rdf:_1, ...). If\n   multiple objects are connected to the   Container using the same\n   membership  property,  this   predicate    selects   one   value\n   non-deterministically.",
    "prefix":"rdfs_container"
  },
  "semweb/rdf11_containers:rdfs_container_membership_property/1": {
    "body": ["rdfs_container_membership_property(${1:Property})$2\n$0" ],
    "description":"  rdfs_container_membership_property(?Property) is nondet.\n\n   True when Property is a   container membership property (rdf:_1,\n   rdf:_2, ...).",
    "prefix":"rdfs_container_membership_property"
  },
  "semweb/rdf11_containers:rdfs_container_membership_property/2": {
    "body": [
      "rdfs_container_membership_property(${1:Property}, ${2:Number})$3\n$0"
    ],
    "description":"  rdfs_container_membership_property(?Property, ?Number:nonneg) is nondet.\n\n   True when Property is the Nth container membership property.\n\n   Success of this goal does not imply that Property is present\n   in the database.",
    "prefix":"rdfs_container_membership_property"
  },
  "semweb/rdf11_containers:rdfs_member/2": {
    "body": ["rdfs_member(${1:Elem}, ${2:Container})$3\n$0" ],
    "description":"  rdfs_member(?Elem, ?Container) is nondet.\n\n   True if rdf(Container, P, Elem) is true   and P is a container\n   membership property.",
    "prefix":"rdfs_member"
  },
  "semweb/rdf11_containers:rdfs_nth0/3": {
    "body": ["rdfs_nth0(${1:N}, ${2:Container}, ${3:Elem})$4\n$0" ],
    "description":"  rdfs_nth0(?N, ?Container, ?Elem) is nondet.\n\n   True if rdf(Container, P, Elem)  is  true   and  P  is the N-th\n   (0-based) container membership property.",
    "prefix":"rdfs_nth0"
  },
  "semweb/rdf_cache:rdf_cache_file/3": {
    "body":"rdf_cache_file(${1:URL}, ${2:ReadWrite}, ${3:File})$4\n$0",
    "description":"[semidet]rdf_cache_file(+URL, +ReadWrite, -File).\nFile is the cache file for URL. If ReadWrite  is read, it returns the name of an existing file. If write  it returns where a new cache file can be overwritten or created.",
    "prefix":"rdf_cache_file"
  },
  "semweb/rdf_cache:rdf_set_cache_options/1": {
    "body":"rdf_set_cache_options(${1:Options})$2\n$0",
    "description":"rdf_set_cache_options(+Options).\nChange the cache policy. Provided options are:  \n\nenabled(Boolean) If true, caching is  enabled.\nlocal_directory(Name). Plain name of local directory.  Default .cache (_cache on Windows).\ncreate_local_directory(Bool) If true, try  to create local cache directories\nglobal_directory(Dir) Writeable directory for storing  cached parsed files.\ncreate_global_directory(Bool) If true, try  to create the global cache directory.\n\n",
    "prefix":"rdf_set_cache_options"
  },
  "semweb/rdf_compare:rdf_equal_graphs/3": {
    "body":"rdf_equal_graphs(${1:GraphA}, ${2:GraphB}, ${3:Substition})$4\n$0",
    "description":"[semidet]rdf_equal_graphs(+GraphA, +GraphB, -Substition).\nTrue if GraphA and GraphB are the same under Substition. Substition is a list of BNodeA = BNodeB, where BNodeA is a  blank node that appears in GraphA and BNodeB is a blank node  that appears in GraphB. GraphA is a list of rdf(S,P,O)  terms GraphB is a list of rdf(S,P,O)  terms Substition is a list if NodeA =  NodeB terms.   To be done: The current implementation is rather naive. After dealing with the  subgraphs that contain no bnodes, it performs a fully non-deterministic  substitution.\n\n ",
    "prefix":"rdf_equal_graphs"
  },
  "semweb/rdf_compare:sparql_read_json_result/2": {
    "body":"sparql_read_json_result(${1:Input}, ${2:Result})$3\n$0",
    "description":"[det]sparql_read_json_result(+Input, -Result).\nThe returned Result term is of the format:  select(VarNames, Rows): Where VarNames is a term v(Name, ...) and Rows  is a list of row(....) containing the column values in the  same order as the variable names.\n\nask(Bool): Where Bool is either true or false\n\n  See also: http://www.w3.org/TR/rdf-sparql-json-res/\n\n ",
    "prefix":"sparql_read_json_result"
  },
  "semweb/rdf_db:lang_equal/2": {
    "body":"lang_equal(${1:Lang1}, ${2:Lang2})$3\n$0",
    "description":"[semidet]lang_equal(+Lang1, +Lang2).\nTrue if two RFC language specifiers denote the same language  See also: lang_matches/2.\n\n ",
    "prefix":"lang_equal"
  },
  "semweb/rdf_db:lang_matches/2": {
    "body":"lang_matches(${1:Lang}, ${2:Pattern})$3\n$0",
    "description":"[semidet]lang_matches(+Lang, +Pattern).\nTrue if Lang matches Pattern. This implements XML  language matching conform RFC 4647. Both Lang and Pattern  are dash-separated strings of identifiers or (for Pattern)  the wildcart *. Identifiers are matched case-insensitive and a * matches  any number of identifiers. A short pattern is the same as *.",
    "prefix":"lang_matches"
  },
  "semweb/rdf_db:rdf/3": {
    "body":"rdf(${1:Subject}, ${2:Predicate}, ${3:Object})$4\n$0",
    "description":"[nondet]rdf(?Subject, ?Predicate, ?Object).\nElementary query for triples. Subject and Predicate  are atoms representing the fully qualified URL of the resource. Object  is either an atom representing a resource or literal(Value)  if the object is a literal value. If a value of the form  NameSpaceID:LocalName is provided it is expanded to a ground atom using expand_goal/2.  This implies you can use this construct in compiled code without paying  a performance penalty. Literal values take one of the following forms:  Atom: If the value is a simple atom it is the textual representation of a  string literal without explicit type or language qualifier.\n\nlang(LangID, Atom): Atom represents the text of a string literal qualified with  the given language.\n\ntype(TypeID, Value): Used for attributes qualified using the rdf:datatype TypeID. The Value is either the textual  representation or a natural Prolog representation. See the option  convert_typed_literal(:Convertor) of the parser. The storage layer  provides efficient handling of atoms, integers (64-bit) and floats  (native C-doubles). All other data is represented as a Prolog record.\n\n  For literal querying purposes, Object can be of the form literal(+Query, -Value), where Query is one of the terms  below. If the Query takes a literal argument and the value has a numeric  type numerical comparison is performed. \n\nplain(+Text): Perform exact match and demand the language or type qualifiers to match.  This query is fully indexed.\n\nicase(+Text): Perform a full but case-insensitive match. This query is fully indexed.\n\nexact(+Text): Same as icase(Text). Backward compatibility.\n\nsubstring(+Text): Match any literal that contains Text as a case-insensitive  substring. The query is not indexed on Object.\n\nword(+Text): Match any literal that contains Text delimited by a non  alpha-numeric character, the start or end of the string. The query is  not indexed on Object.\n\nprefix(+Text): Match any literal that starts with Text. This call is  intended for completion. The query is indexed using the skip list of  literals.\n\nge(+Literal): Match any literal that is equal or larger then Literal in the  ordered set of literals.\n\ngt(+Literal): Match any literal that is larger then Literal in the ordered  set of literals.\n\neq(+Literal): Match any literal that is equal to Literal in the ordered set  of literals.\n\nle(+Literal): Match any literal that is equal or smaller then Literal in  the ordered set of literals.\n\nlt(+Literal): Match any literal that is smaller then Literal in the ordered  set of literals.\n\nbetween(+Literal1, +Literal2): Match any literal that is between Literal1 and Literal2  in the ordered set of literals. This may include both Literal1  and Literal2.\n\nlike(+Pattern): Match any literal that matches Pattern case insensitively,  where the `*' character in Pattern matches zero or more  characters.\n\n  Backtracking never returns duplicate triples. Duplicates can be  retrieved using rdf/4. The predicate rdf/3  raises a type-error if called with improper arguments. If rdf/3  is called with a term literal(_) as Subject or Predicate  object it fails silently. This allows for graph matching goals like rdf(S,P,O),rdf(O,P2,O2) to proceed without  errors.\n\n",
    "prefix":"rdf"
  },
  "semweb/rdf_db:rdf/4": {
    "body":"rdf(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:Source})$5\n$0",
    "description":"[nondet]rdf(?Subject, ?Predicate, ?Object, ?Source).\nAs rdf/3 but in addition query the  graph to which the triple belongs. Unlike rdf/3,  this predicate does not remove duplicates from the result set. Source is a term Graph:Line. If Source  is instatiated, passing an atom is the same as passing Atom:_. ",
    "prefix":"rdf"
  },
  "semweb/rdf_db:rdf_active_transaction/1": {
    "body":"rdf_active_transaction(${1:Id})$2\n$0",
    "description":"[nondet]rdf_active_transaction(?Id).\nTrue if Id is the identifier of a transaction in the context  of which this call is executed. If Id is not instantiated,  backtracking yields transaction identifiers starting with the innermost  nested transaction. Transaction identifier terms are not copied, need  not be ground and can be instantiated during the transaction.",
    "prefix":"rdf_active_transaction"
  },
  "semweb/rdf_db:rdf_assert/3": {
    "body":"rdf_assert(${1:Subject}, ${2:Predicate}, ${3:Object})$4\n$0",
    "description":"[det]rdf_assert(+Subject, +Predicate, +Object).\nAssert a new triple into the database. This is equivalent to rdf_assert/4 using Graph user. Subject  and Predicate are resources. Object is either a  resource or a term literal(Value). See rdf/3  for an explanation of Value for typed and language qualified literals.  All arguments are subject to name-space expansion. Complete duplicates  (including the same graph and `line' and with a compatible `lifespan')  are not added to the database.",
    "prefix":"rdf_assert"
  },
  "semweb/rdf_db:rdf_assert/4": {
    "body":"rdf_assert(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:Graph})$5\n$0",
    "description":"[det]rdf_assert(+Subject, +Predicate, +Object, +Graph).\nAs rdf_assert/3, adding the  predicate to the indicated named graph. Graph is either the name of a  graph (an atom) or a term Graph:Line, where Line is an integer that denotes a line  number. ",
    "prefix":"rdf_assert"
  },
  "semweb/rdf_db:rdf_atom_md5/3": {
    "body": ["rdf_atom_md5(${1:Text}, ${2:Times}, ${3:MD5})$4\n$0" ],
    "description":"  rdf_atom_md5(+Text, +Times, -MD5) is det.\n\n   Computes the MD5 hash from Text,  which   is  an atom, string or\n   list of character codes. Times is an integer >= 1. When > 0, the\n   MD5 algorithm is repeated Times  times   on  the generated hash.\n   This can be used for  password   encryption  algorithms  to make\n   generate-and-test loops slow.\n\n   @deprecated. New code should  use   the  library(crypt)  library\n   provided  by  the  clib  package  for  password  encryption  and\n   library(md5) to compute MD5 hashes.",
    "prefix":"rdf_atom_md5"
  },
  "semweb/rdf_db:rdf_bnode/1": {
    "body":"rdf_bnode(${1:Id})$2\n$0",
    "description":"rdf_bnode(-Id).\nGenerate a unique anonymous identifier for a subject.",
    "prefix":"rdf_bnode"
  },
  "semweb/rdf_db:rdf_compare/3": {
    "body": ["rdf_compare(${1:Dif}, ${2:Object1}, ${3:Object2})$4\n$0" ],
    "description":"  rdf_compare(-Dif, +Object1, +Object2) is det.\n\n   Compare  two  object  terms.  Where  SPARQL  defines  a  partial\n   ordering, we define a complete ordering   of terms. The ordering\n   is defines as:\n\n     - Blank nodes < IRIs < Literals\n     - Numeric literals < other literals\n     - Numeric literals are compared by value and then by type,\n       where Integer < Decimal < Double\n     - Other literals are compare lexically, case insensitive.\n       If equal, uppercase preceeds lowercase.  If still equal,\n       the types are compared lexically.",
    "prefix":"rdf_compare"
  },
  "semweb/rdf_db:rdf_create_graph/1": {
    "body":"rdf_create_graph(${1:Graph})$2\n$0",
    "description":"[det]rdf_create_graph(+Graph).\nCreate an RDF graph without triples. Succeeds silently if the graph  already exists.",
    "prefix":"rdf_create_graph"
  },
  "semweb/rdf_db:rdf_current_literal/1": {
    "body":"rdf_current_literal(${1:Literal})$2\n$0",
    "description":"[nondet]rdf_current_literal(-Literal).\nTrue when Literal is a currently known literal. Enumerates  each unique literal exactly once. Note that it is possible that the  literal only appears in already deleted triples. Deleted triples may be  locked due to active queries, transactions or snapshots or may not yet  be reclaimed by the garbage collector.",
    "prefix":"rdf_current_literal"
  },
  "semweb/rdf_db:rdf_current_ns/2": {
    "body":"rdf_current_ns(${1:Prefix}, ${2:URI})$3\n$0",
    "description":"[nondet]rdf_current_ns(:Prefix, ?URI).\n deprecated: . Use rdf_current_prefix/2.\n\n ",
    "prefix":"rdf_current_ns"
  },
  "semweb/rdf_db:rdf_current_predicate/1": {
    "body":"rdf_current_predicate(${1:Predicate})$2\n$0",
    "description":"[nondet]rdf_current_predicate(?Predicate).\nTrue when Predicate is a currently known predicate.  Predicates are created if a triples is created that uses this predicate  or a property of the predicate is set using rdf_set_predicate/2.  The predicate may (no longer) have triples associated with it.  Note that resources that have rdf:type rdf:Property  are not automatically included in the result-set of this predicate,  while all resources that appear as the second argument of a  triple are included. \n\nSee also: rdf_predicate_property/2.\n\n ",
    "prefix":"rdf_current_predicate"
  },
  "semweb/rdf_db:rdf_current_prefix/2": {
    "body":"rdf_current_prefix(${1:Alias}, ${2:URI})$3\n$0",
    "description":"[nondet]rdf_current_prefix(:Alias, ?URI).\nQuery predefined prefixes and prefixes defined with rdf_register_prefix/2  and local prefixes defined with rdf_prefix/2. If Alias is  unbound and one URI is the prefix of another, the longest is  returned first. This allows turning a resource into a prefix/local  couple using the simple enumeration below. See rdf_global_id/2.  \n\nrdf_current_prefix(Prefix, Expansion),\natom_concat(Expansion, Local, URI),\n\n ",
    "prefix":"rdf_current_prefix"
  },
  "semweb/rdf_db:rdf_current_snapshot/1": {
    "body":"rdf_current_snapshot(${1:Term})$2\n$0",
    "description":"[nondet]rdf_current_snapshot(?Term).\nTrue when Term is a currently known snapshot.  bug: Enumeration of snapshots is slow.\n\n ",
    "prefix":"rdf_current_snapshot"
  },
  "semweb/rdf_db:rdf_debug/1": {
    "body": ["rdf_debug(${1:Level})$2\n$0" ],
    "description":"  rdf_debug(+Level) is det.\n\n   Set debugging to Level.  Level is an integer 0..9.  Default is\n   0 no debugging.",
    "prefix":"rdf_debug"
  },
  "semweb/rdf_db:rdf_delete_literal_map/2": {
    "body": ["rdf_delete_literal_map(${1:Map}, ${2:Key})$3\n$0" ],
    "description":"  rdf_delete_literal_map(+Map, +Key) is det.\n\n   Delete Key and all associated values from the map.",
    "prefix":"rdf_delete_literal_map"
  },
  "semweb/rdf_db:rdf_delete_literal_map/3": {
    "body": ["rdf_delete_literal_map(${1:Map}, ${2:Key}, ${3:Value})$4\n$0" ],
    "description":"  rdf_delete_literal_map(+Map, +Key, +Value) is det.\n\n   Delete the association between Key and Value from the map.",
    "prefix":"rdf_delete_literal_map"
  },
  "semweb/rdf_db:rdf_delete_snapshot/1": {
    "body":"rdf_delete_snapshot(${1:Snapshot})$2\n$0",
    "description":"[det]rdf_delete_snapshot(+Snapshot).\nDelete a snapshot as obtained from rdf_snapshot/1.  After this call, resources used for maintaining the snapshot become  subject to garbage collection.",
    "prefix":"rdf_delete_snapshot"
  },
  "semweb/rdf_db:rdf_destroy_literal_map/1": {
    "body": ["rdf_destroy_literal_map(${1:Map})$2\n$0" ],
    "description":"  rdf_destroy_literal_map(+Map) is det.\n\n   Destroy a literal map. After this call,   further use of the Map\n   handle is illegal. Additional synchronisation  is needed if maps\n   that are shared between threads are   destroyed to guarantee the\n   handle    is    no    longer    used.    In    some    scenarios\n   rdf_reset_literal_map/1 provides a safe alternative.",
    "prefix":"rdf_destroy_literal_map"
  },
  "semweb/rdf_db:rdf_equal/2": {
    "body":"rdf_equal(${1:Resource1}, ${2:Resource2})$3\n$0",
    "description":"rdf_equal(?Resource1, ?Resource2).\nSimple equality test to exploit goal-expansion",
    "prefix":"rdf_equal"
  },
  "semweb/rdf_db:rdf_estimate_complexity/4": {
    "body":"rdf_estimate_complexity(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:Complexity})$5\n$0",
    "description":"rdf_estimate_complexity(?Subject, ?Predicate, ?Object, -Complexity).\nReturn the number of alternatives as indicated by the database internal  hashed indexing. This is a rough measure for the number of alternatives  we can expect for an rdf_has/3  call using the given three arguments. When called with three variables,  the total number of triples is returned. This estimate is used in query  optimisation. See also rdf_predicate_property/2  and rdf_statistics/1 for  additional information to help optimizers.",
    "prefix":"rdf_estimate_complexity"
  },
  "semweb/rdf_db:rdf_find_literal_map/3": {
    "body": [
      "rdf_find_literal_map(${1:Map}, ${2:KeyList}, ${3:ValueList})$4\n$0"
    ],
    "description":"  rdf_find_literal_map(+Map, +KeyList, -ValueList) is det.\n\n   Unify ValueList with an ordered set  of values associated to all\n   keys from KeyList. Each key in  KeyList   is  either an atom, an\n   integer or a term not(Key).  If   not-terms  are provided, there\n   must be at least one positive keywords. The negations are tested\n   after establishing the positive matches.",
    "prefix":"rdf_find_literal_map"
  },
  "semweb/rdf_db:rdf_gc/0": {
    "body": ["rdf_gc$1\n$0" ],
    "description":"  rdf_gc is det.\n\n   Run the RDF-DB garbage collector until   no  garbage is left and\n   all  tables  are  fully  optimized.  Under  normal  operation  a\n   seperate thread with  identifier   =__rdf_GC=  performs  garbage\n   collection as long as it is considered `useful'.\n\n   Using rdf_gc/0 should only be  needed   to  ensure a fully clean\n   database for analysis purposes such as leak detection.",
    "prefix":"rdf_gc"
  },
  "semweb/rdf_db:rdf_generation/1": {
    "body":"rdf_generation(${1:Generation})$2\n$0",
    "description":"[det]rdf_generation(-Generation).\nTrue when Generation is the current generation of the  database. Each modification to the database increments the generation.  It can be used to check the validity of cached results deduced from the  database. Committing a non-empty transaction increments the generation  by one.  When inside a transaction, Generation is unified to a term TransactionStartGen + InsideTransactionGen. E.g., 4+3  means that the transaction was started at generation 4 of the global  database and we have created 3 new generations inside the transaction.  Note that this choice of representation allows for comparing generations  using Prolog arithmetic. Comparing a generation in one transaction with  a generation in another transaction is meaningless.\n\n",
    "prefix":"rdf_generation"
  },
  "semweb/rdf_db:rdf_global_id/2": {
    "body":"rdf_global_id(${1:IRISpec}, ${2:IRI})$3\n$0",
    "description":"[semidet]rdf_global_id(?IRISpec, :IRI).\nConvert between Prefix:Local and full IRI (an atom). If IRISpec  is an atom, it is simply unified with IRI. This predicate  fails silently if IRI is an RDF literal.  Note that this predicate is a meta-predicate on its output argument.  This is necessary to get the module context while the first argument may  be of the form (:)/2. The above mode description is correct, but should  be interpreted as (?,?). \n\nErrors: existence_error(rdf_prefix, Prefix)\n\nSee also: - rdf_equal/2 provides a compile  time alternative  - The rdf_meta/1 directive asks for  compile time expansion of arguments.\n\nbug: Error handling is incomplete. In its current implementation the same  code is used for compile-time expansion and to facilitate runtime  conversion and checking. These use cases have different requirements.\n\n ",
    "prefix":"rdf_global_id"
  },
  "semweb/rdf_db:rdf_global_object/2": {
    "body":"rdf_global_object(${1:Object}, ${2:GlobalObject})$3\n$0",
    "description":"[semidet]rdf_global_object(-Object, :GlobalObject).\nSame as rdf_global_id/2, but  intended for dealing with the object part of a triple, in particular the  type for typed literals. Note that the predicate is a meta-predicate on  the output argument. This is necessary to get the module context while  the first argument may be of the form (:)/2.  Errors: existence_error(rdf_prefix, Prefix)\n\n ",
    "prefix":"rdf_global_object"
  },
  "semweb/rdf_db:rdf_global_term/2": {
    "body":"rdf_global_term(${1:TermIn}, ${2:GlobalTerm})$3\n$0",
    "description":"[det]rdf_global_term(+TermIn, :GlobalTerm).\nDoes rdf_global_id/2 on all  terms NS:Local by recursively analysing the term. Note that the  predicate is a meta-predicate on the output argument. This is necessary  to get the module context while the first argument may be of the form  (:)/2.  Terms of the form Prefix:Local that appear in TermIn for  which Prefix is not defined are not replaced. Unlike rdf_global_id/2  and rdf_global_object/2,  no error is raised.\n\n",
    "prefix":"rdf_global_term"
  },
  "semweb/rdf_db:rdf_graph/1": {
    "body":"rdf_graph(${1:Graph})$2\n$0",
    "description":"[nondet]rdf_graph(?Graph).\nTrue when Graph is an existing graph.",
    "prefix":"rdf_graph"
  },
  "semweb/rdf_db:rdf_graph_prefixes/2": {
    "body": ["rdf_graph_prefixes(${1:Graph}, ${2:List})$3\n$0" ],
    "description":"  rdf_graph_prefixes(?Graph, -List:ord_set) is det.\n  rdf_graph_prefixes(?Graph, -List:ord_set, :Options) is det.\n\n   List is a sorted list of  prefixes (namepaces) in Graph. Options\n   defined are:\n\n       * filter(:Filter)\n       optional Filter argument is used to filter the results. It\n       is called with 3 additional arguments:\n\n           ==\n           call(Filter, Where, Prefix, URI)\n           ==\n\n       The Where argument gives the location of the prefix ans is\n       one of =subject=, =predicate=, =object= or =type=. The\n       Prefix argument is the potentionally new prefix and URI is\n       the full URI that is being processed.\n\n       * expand(:Goal)\n       Hook to generate the graph.  Called using\n\n           ==\n           call(Goal,S,P,O,Graph)\n           ==\n\n       * min_count(+Count)\n       Only include prefixes that appear at least N times.  Default\n       is 1. Declared prefixes are always returned if found at\n       least one time.",
    "prefix":"rdf_graph_prefixes"
  },
  "semweb/rdf_db:rdf_graph_prefixes/3": {
    "body": ["rdf_graph_prefixes(${1:Graph}, ${2:List}, ${3:Options})$4\n$0" ],
    "description":"  rdf_graph_prefixes(?Graph, -List:ord_set) is det.\n  rdf_graph_prefixes(?Graph, -List:ord_set, :Options) is det.\n\n   List is a sorted list of  prefixes (namepaces) in Graph. Options\n   defined are:\n\n       * filter(:Filter)\n       optional Filter argument is used to filter the results. It\n       is called with 3 additional arguments:\n\n           ==\n           call(Filter, Where, Prefix, URI)\n           ==\n\n       The Where argument gives the location of the prefix ans is\n       one of =subject=, =predicate=, =object= or =type=. The\n       Prefix argument is the potentionally new prefix and URI is\n       the full URI that is being processed.\n\n       * expand(:Goal)\n       Hook to generate the graph.  Called using\n\n           ==\n           call(Goal,S,P,O,Graph)\n           ==\n\n       * min_count(+Count)\n       Only include prefixes that appear at least N times.  Default\n       is 1. Declared prefixes are always returned if found at\n       least one time.",
    "prefix":"rdf_graph_prefixes"
  },
  "semweb/rdf_db:rdf_graph_property/2": {
    "body":"rdf_graph_property(${1:Graph}, ${2:Property})$3\n$0",
    "description":"[nondet]rdf_graph_property(?Graph, ?Property).\nTrue when Property is a property of Graph. Defined  properties are:  hash(Hash): Hash is the (MD5-)hash for the content of Graph.\n\nmodified(Boolean): True if the graph is modified since it was loaded or rdf_set_graph/2 was called  with modified(false).\n\nsource(Source): The graph is loaded from the Source (a URL)\n\nsource_last_modified(?Time): Time is the last-modified timestamp of Source at the moment  that the graph was loaded from Source.\n\ntriples(Count): True when Count is the number of triples in Graph.\n\n  Additional graph properties can be added by defining rules for the  multifile predicate property_of_graph/2.  Currently, the following extensions are defined: \n\n\n\nlibrary(semweb/rdf_persistency)  persistent(Boolean)Boolean is true if the graph is persistent. \n\n",
    "prefix":"rdf_graph_property"
  },
  "semweb/rdf_db:rdf_has/3": {
    "body":"rdf_has(${1:Subject}, ${2:Predicate}, ${3:Object})$4\n$0",
    "description":"[nondet]rdf_has(?Subject, +Predicate, ?Object).\nSucceeds if the triple rdf(Subject, Predicate, Object) is  true exploiting the rdfs:subPropertyOf predicate as well as inverse  predicates declared using rdf_set_predicate/2  with the inverse_of property.",
    "prefix":"rdf_has"
  },
  "semweb/rdf_db:rdf_has/4": {
    "body":"rdf_has(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:RealPredicate})$5\n$0",
    "description":"[nondet]rdf_has(?Subject, +Predicate, ?Object, -RealPredicate).\nSame as rdf_has/3, but RealPredicate  is unified to the actual predicate that makes this relation true. RealPredicate  must be Predicate or an rdfs:subPropertyOf Predicate. If  an inverse match is found, RealPredicate is the term inverse_of(Pred).",
    "prefix":"rdf_has"
  },
  "semweb/rdf_db:rdf_insert_literal_map/3": {
    "body": ["rdf_insert_literal_map(${1:Map}, ${2:Key}, ${3:Value})$4\n$0" ],
    "description":"  rdf_insert_literal_map(+Map, +Key, +Value) is det.\n\n   Add a relation between  Key  and  Value   to  the  map.  If this\n   relation already exists no action is performed.",
    "prefix":"rdf_insert_literal_map"
  },
  "semweb/rdf_db:rdf_insert_literal_map/4": {
    "body": [
      "rdf_insert_literal_map(${1:Map}, ${2:Key}, ${3:Value}, ${4:KeyCount})$5\n$0"
    ],
    "description":"  rdf_insert_literal_map(+Map, +Key, +Value, -KeyCount) is det.\n\n   As rdf_insert_literal_map/3. In addition, if Key is a new key in\n   Map, unify KeyCount with the number of  keys in Map. This serves\n   two purposes. Derived maps, such as  the stem and metaphone maps\n   need to know about new  keys   and  it avoids additional foreign\n   calls for doing the progress in rdf_litindex.pl.",
    "prefix":"rdf_insert_literal_map"
  },
  "semweb/rdf_db:rdf_is_bnode/1": {
    "body":"rdf_is_bnode(${1:Id})$2\n$0",
    "description":"rdf_is_bnode(+Id).\nTests if a resource is a blank node (i.e. is an anonymous resource). A  blank node is represented as an atom that starts with _:.  For backward compatibility reason, __ is also considered to  be a blank node.  See also: rdf_bnode/1.\n\n ",
    "prefix":"rdf_is_bnode"
  },
  "semweb/rdf_db:rdf_is_literal/1": {
    "body":"rdf_is_literal(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_literal(@Term).\nTrue if Term is an RDF literal object. Currently only checks  for groundness and the literal functor.",
    "prefix":"rdf_is_literal"
  },
  "semweb/rdf_db:rdf_is_resource/1": {
    "body":"rdf_is_resource(${1:Term})$2\n$0",
    "description":"[semidet]rdf_is_resource(@Term).\nTrue if Term is an RDF resource. Note that this is merely a  type-test; it does not mean this resource is involved in any triple.  Blank nodes are also considered resources.  See also: rdf_is_bnode/1\n\n ",
    "prefix":"rdf_is_resource"
  },
  "semweb/rdf_db:rdf_keys_in_literal_map/3": {
    "body": ["rdf_keys_in_literal_map(${1:Map}, ${2:Spec}, ${3:Answer})$4\n$0" ],
    "description":"  rdf_keys_in_literal_map(+Map, +Spec, -Answer) is det.\n\n   Realises various queries on the key-set:\n\n     * all\n\n     Unify Answer with an ordered list of all keys.\n     * key(+Key)\n\n     Succeeds if Key is a key in the map and unify Answer with the\n     number of values associated with the key. This provides a fast\n     test of existence without fetching the possibly large\n     associated value set as with rdf_find_literal_map/3.\n\n     * prefix(+Prefix)\n     Unify Answer with an ordered set of all keys that have the\n     given prefix. See section 3.1 for details on prefix matching.\n     Prefix must be an atom. This call is intended for\n     auto-completion in user interfaces.\n\n     * ge(+Min)\n     Unify Answer with all keys that are larger or equal to the\n     integer Min.\n\n     * le(+Max)\n     Unify Answer with all keys that are smaller or equal to the integer\n     Max.\n\n     * between(+Min, +Max) Unify\n     Answer with all keys between Min and Max (including).",
    "prefix":"rdf_keys_in_literal_map"
  },
  "semweb/rdf_db:rdf_literal_value/2": {
    "body": ["rdf_literal_value(${1:Literal}, ${2:Value})$3\n$0" ],
    "description":"  rdf_literal_value(+Literal, -Value) is semidet.\n\n   True when value is  the   appropriate  Prolog  representation of\n   Literal in the RDF _|value space|_.  Current mapping:\n\n     | Plain literals              | Atom                    |\n     | Language tagged literal     | Atom holding plain text |\n     | xsd:string                  | Atom                    |\n     | rdf:XMLLiteral              | XML DOM Tree            |\n     | Numeric XSD type            | Number                  |\n\n   @tbd    Well, this is the long-term idea.\n   @tbd    Add mode (-,+)",
    "prefix":"rdf_literal_value"
  },
  "semweb/rdf_db:rdf_load/1": {
    "body":"rdf_load(${1:FileOrList})$2\n$0",
    "description":"[det]rdf_load(+FileOrList).\nSame as rdf_load(FileOrList, []). See rdf_load/2.",
    "prefix":"rdf_load"
  },
  "semweb/rdf_db:rdf_load/2": {
    "body":"rdf_load(${1:FileOrList}, ${2:Options})$3\n$0",
    "description":"[det]rdf_load(+FileOrList, :Options).\nLoad RDF data. Options provides additional processing  options. Defined options are:  blank_nodes(+ShareMode): How to handle equivalent blank nodes. If share (default),  equivalent blank nodes are shared in the same resource.\n\nbase_uri(+URI): URI that is used for rdf:about=\"\" and other RDF constructs  that are relative to the base uri. Default is the source URL.\n\nconcurrent(+Jobs): If FileOrList is a list of files, process the input files  using Jobs threads concurrently. Default is the mininum of  the number of cores and the number of inputs. Higher values can be  useful when loading inputs from (slow) network connections. Using 1  (one) does not use separate worker threads.\n\nformat(+Format): Specify the source format explicitly. Normally this is deduced from the  filename extension or the mime-type. The core library understands the  formats xml (RDF/XML) and triples (internal quick load and cache  format). Plugins, such as library(semweb/turtle) extend the  set of recognised extensions.\n\ngraph(?Graph): Named graph in which to load the data. It is not allowed to load  two sources into the same named graph. If Graph is unbound,  it is unified to the graph into which the data is loaded. The default  graph is a =file://= URL when loading a file or, if the specification is  a URL, its normalized version without the optional #fragment.\n\nif(Condition): When to load the file. One of true, changed  (default) or not_loaded.\n\nmodified(-Modified): Unify Modified with one of not_modified, cached(File), last_modified(Stamp) or unknown.\n\ncache(Bool): If false, do not use or create a cache file.\n\nregister_namespaces(Bool): If true (default false), register xmlns  namespace declarations or Turtle @prefix prefixes using rdf_register_prefix/3  if there is no conflict.\n\nsilent(+Bool): If true, the message reporting completion is printed using  level silent. Otherwise the level is informational.  See also print_message/2.\n\n  Other options are forwarded to process_rdf/3.  By default, rdf_load/2 only loads RDF/XML  from files. It can be extended to load data from other formats and  locations using plugins. The full set of plugins relevant to support  different formats and locations is below: \n\n\n\n:- use_module(library(semweb/turtle)).        % Turtle and TRiG\n:- use_module(library(semweb/rdf_ntriples)).\n:- use_module(library(semweb/rdf_zlib_plugin)).\n:- use_module(library(semweb/rdf_http_plugin)).\n:- use_module(library(http/http_ssl_plugin)).\n\n  See also: rdf_db:rdf_open_hook/3, library(semweb/rdf_persistency)  and library(semweb/rdf_cache)\n\n ",
    "prefix":"rdf_load"
  },
  "semweb/rdf_db:rdf_load_db/1": {
    "body":"rdf_load_db(${1:File})$2\n$0",
    "description":"[det]rdf_load_db(+File).\nLoad triples from a file created using rdf_save_db/2.",
    "prefix":"rdf_load_db"
  },
  "semweb/rdf_db:rdf_make/0": {
    "body":"rdf_make$1\n$0",
    "description":"rdf_make.\nReload all loaded files that have been modified since the last time they  were loaded.",
    "prefix":"rdf_make"
  },
  "semweb/rdf_db:rdf_match_label/3": {
    "body":"rdf_match_label(${1:How}, ${2:Pattern}, ${3:Label})$4\n$0",
    "description":"[semidet]rdf_match_label(+How, +Pattern, +Label).\nTrue if Label matches Pattern according to How. How  is one of icase, substring, word, prefix  or like. For backward compatibility, exact is  a synonym for icase.",
    "prefix":"rdf_match_label"
  },
  "semweb/rdf_db:rdf_md5/2": {
    "body": ["rdf_md5(${1:Graph}, ${2:MD5})$3\n$0" ],
    "description":"  rdf_md5(+Graph, -MD5) is det.\n\n   True when MD5 is the MD5 hash for  all triples in graph. The MD5\n   digest itself is represented as an   atom holding a 32-character\n   hexadecimal   string.   The   library   maintains   the   digest\n   incrementally on rdf_load/[1,2], rdf_load_db/1, rdf_assert/[3,4]\n   and  rdf_retractall/[3,4].  Checking  whether   the  digest  has\n   changed since the last rdf_load/[1,2]  call provides a practical\n   means for checking whether the file needs to be saved.\n\n   @deprecated New code should use rdf_graph_property(Graph,\n   hash(Hash)).",
    "prefix":"rdf_md5"
  },
  "semweb/rdf_db:rdf_member_property/2": {
    "body": ["rdf_member_property(${1:Prop}, ${2:Index})$3\n$0" ],
    "description":"  rdf_member_property(?Prop, ?Index)\n\n   Deal with the rdf:_1, ... properties.",
    "prefix":"rdf_member_property"
  },
  "semweb/rdf_db:rdf_meta/1": {
    "body": ["rdf_meta(${1:Heads})$2\n$0" ],
    "description":"  rdf_meta(+Heads)\n\n   This  directive  defines  the  argument    types  of  the  named\n   predicates, which will force compile   time  namespace expansion\n   for these predicates. Heads is a coma-separated list of callable\n   terms. Defined argument properties are:\n\n     $ : :\n     Argument is a goal. The goal is processed using expand_goal/2,\n     recursively applying goal transformation on the argument.\n\n     $ + :\n     The argument is instantiated at entry. Nothing is changed.\n\n     $ - :\n     The argument is not instantiated at entry. Nothing is changed.\n\n     $ ? :\n     The argument is unbound or instantiated at entry. Nothing is\n     changed.\n\n     $ @ :\n     The argument is not changed.\n\n     $ r :\n     The argument must be a resource. If it is a term\n     _prefix_:_local_ it is translated.\n\n     $ o :\n     The argument is an object or resource. See\n     rdf_global_object/2.\n\n     $ t :\n     The argument is a term that must be translated. Expansion will\n     translate all occurences of _prefix_:_local_ appearing\n     anywhere in the term. See rdf_global_term/2.\n\n   As it is subject to term_expansion/2, the rdf_meta/1 declaration\n   can only be used as a directive. The directive must be processed\n   before the definition of  the  predicates   as  well  as  before\n   compiling code that  uses  the   rdf  meta-predicates.  The atom\n   =rdf_meta=  is  declared   as   an    operator   exported   from\n   library(semweb/rdf_db). Files using rdf_meta/1  must explicitely\n   load this library.\n\n   Beginning with SWI-Prolog 7.3.17, the   low-level  RDF interface\n   (rdf/3,  rdf_assert/3,  etc.)  perform    runtime  expansion  of\n   `Prefix:Local` terms. This eliminates the   need  for rdf_meta/1\n   for  simple  cases.  However,  runtime   expansion  comes  at  a\n   significant overhead and having two  representations for IRIs (a\n   plain atom and  a  term   `Prefix:Local`)  implies  that  simple\n   operations such as comparison of IRIs   no  longer map to native\n   Prolog operations such as `IRI1 == IRI2`.",
    "prefix":"rdf_meta"
  },
  "semweb/rdf_db:rdf_monitor/2": {
    "body":"rdf_monitor(${1:Goal}, ${2:Mask})$3\n$0",
    "description":"rdf_monitor(:Goal, +Mask).\nGoal is called for modifications of the database. It is  called with a single argument that describes the modification. Defined  events are:  assert(+S, +P, +O, +DB): A triple has been asserted.\n\nretract(+S, +P, +O, +DB): A triple has been deleted.\n\nupdate(+S, +P, +O, +DB, +Action): A triple has been updated.\n\nnew_literal(+Literal): A new literal has been created. Literal is the argument of literal(Arg) of the triple's object. This event is  introduced in version 2.5.0 of this library.\n\nold_literal(+Literal): The literal Literal is no longer used by any triple.\n\ntransaction(+BeginOrEnd, +Id): Mark begin or end of the commit of a transaction started by rdf_transaction/2. BeginOrEnd  is begin(Nesting) or end(Nesting). Nesting expresses the nesting  level of transactions, starting at `0' for a toplevel transaction. Id  is the second argument of rdf_transaction/2.  The following transaction Ids are pre-defined by the library:  parse(Id)A file is loaded using rdf_load/2. Id  is one of file(Path) or stream(Stream).unload(DB)All triples with source DB are being unloaded using rdf_unload/1.resetIssued by rdf_reset_db/0. \n\nload(+BeginOrEnd, +Spec): Mark begin or end of rdf_load_db/1  or load through rdf_load/2  from a cached file. Spec is currently defined as file(Path).\n\nrehash(+BeginOrEnd): Marks begin/end of a re-hash due to required re-indexing or garbage  collection.\n\n  Mask is a list of events this monitor is interested in.  Default (empty list) is to report all events. Otherwise each element is  of the form +Event or -Event to include or exclude monitoring for  certain events. The event-names are the functor names of the events  described above. The special name all refers to all events  and assert(load) to assert events originating from rdf_load_db/1.  As loading triples using rdf_load_db/1  is very fast, monitoring this at the triple level may seriously harm  performance. \n\nThis predicate is intended to maintain derived data, such as a  journal, information for undo, additional indexing in literals,  etc. There is no way to remove registered monitors. If this is required  one should register a monitor that maintains a dynamic list of  subscribers like the XPCE broadcast library. A second subscription of  the same hook predicate only re-assignes the mask. \n\nThe monitor hooks are called in the order of registration and in the  same thread that issued the database manipulation. To process all  changes in one thread they should be send to a thread message queue. For  all updating events, the monitor is called while the calling thread has  a write lock on the RDF store. This implies that these events are  processed strickly synchronous, even if modifications originate from  multiple threads. In particular, the transaction begin,  ... updates ... end sequence is never interleaved with  other events. Same for load and parse.\n\n",
    "prefix":"rdf_monitor"
  },
  "semweb/rdf_db:rdf_new_literal_map/1": {
    "body": ["rdf_new_literal_map(${1:Map})$2\n$0" ],
    "description":"  rdf_new_literal_map(-Map) is det.\n\n   Create a new literal map, returning an opaque handle.",
    "prefix":"rdf_new_literal_map"
  },
  "semweb/rdf_db:rdf_node/1": {
    "body": ["rdf_node(${1:Id})$2\n$0" ],
    "description":"  rdf_node(-Id)\n\n   Generate a unique blank node identifier for a subject.\n\n   @deprecated     New code should use rdf_bnode/1.",
    "prefix":"rdf_node"
  },
  "semweb/rdf_db:rdf_predicate_property/2": {
    "body":"rdf_predicate_property(${1:Predicate}, ${2:Property})$3\n$0",
    "description":"rdf_predicate_property(?Predicate, ?Property).\nQuery properties of a defined predicate. Currently defined properties  are given below.  symmetric(Bool): True if the predicate is defined to be symetric. I.e., {A} P {B} implies {B} P {A}. Setting symmetric is equivalent to inverse_of(Self).\n\ninverse_of(Inverse): True if this predicate is the inverse of Inverse. This  property is used by rdf_has/3, rdf_has/4, rdf_reachable/3  and rdf_reachable/5.\n\ntransitive(Bool): True if this predicate is transitive. This predicate is currently not  used. It might be used to make rdf_has/3  imply rdf_reachable/3 for  transitive predicates.\n\ntriples(Triples): Unify Triples with the number of existing triples using this  predicate as second argument. Reporting the number of triples is  intended to support query optimization.\n\nrdf_subject_branch_factor(-Float): Unify Float with the average number of triples associated  with each unique value for the subject-side of this relation. If there  are no triples the value 0.0 is returned. This value is cached with the  predicate and recomputed only after substantial changes to the triple  set associated to this relation. This property is intended for path  optimalisation when solving conjunctions of rdf/3  goals.\n\nrdf_object_branch_factor(-Float): Unify Float with the average number of triples associated  with each unique value for the object-side of this relation. In addition  to the comments with the subject_branch_factor property, uniqueness of  the object value is computed from the hash key rather than the actual  values.\n\nrdfs_subject_branch_factor(-Float): Same as rdf_subject_branch_factor, but also considering  triples of `subPropertyOf' this relation. See also rdf_has/3.\n\nrdfs_object_branch_factor(-Float): Same as rdf_object_branch_factor, but also considering  triples of `subPropertyOf' this relation. See also rdf_has/3.\n\n  See also: rdf_set_predicate/2.\n\n ",
    "prefix":"rdf_predicate_property"
  },
  "semweb/rdf_db:rdf_prefix/2": {
    "body": ["rdf_prefix(${1:Alias}, ${2:URI})$3\n$0" ],
    "description":"  rdf_prefix(:Alias, +URI) is det.\n\n   Register a _local_ prefix.  This   declaration  takes precedence\n   over globally defined prefixes   using  rdf_register_prefix/2,3.\n   Module local prefixes are notably required   to deal with SWISH,\n   where users need to  be  able   to  have  independent  namespace\n   declarations.",
    "prefix":"rdf_prefix"
  },
  "semweb/rdf_db:rdf_reachable/3": {
    "body":"rdf_reachable(${1:Subject}, ${2:Predicate}, ${3:Object})$4\n$0",
    "description":"[nondet]rdf_reachable(?Subject, +Predicate, ?Object).\nIs true if Object can be reached from Subject  following the transitive predicate Predicate or a  sub-property thereof, while repecting the symetric(true) or inverse_of(P2)  properties.  If used with either Subject or Object unbound,  it first returns the origin, followed by the reachable nodes in  breath-first search-order. The implementation internally looks one  solution ahead and succeeds deterministically on the last solution. This  predicate never generates the same node twice and is robust against  cycles in the transitive relation. \n\nWith all arguments instantiated, it succeeds deterministically if a  path can be found from Subject to Object.  Searching starts at Subject, assuming the branching factor is  normally lower. A call with both Subject and Object  unbound raises an instantiation error. The following example generates  all subclasses of rdfs:Resource: \n\n\n\n?- rdf_reachable(X, rdfs:subClassOf, rdfs:'Resource').\nX = 'http://www.w3.org/2000/01/rdf-schema#Resource' ;\nX = 'http://www.w3.org/2000/01/rdf-schema#Class' ;\nX = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#Property' ;\n...\n\n ",
    "prefix":"rdf_reachable"
  },
  "semweb/rdf_db:rdf_reachable/5": {
    "body":"rdf_reachable(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:MaxD}, ${5:D})$6\n$0",
    "description":"[nondet]rdf_reachable(?Subject, +Predicate, ?Object, +MaxD, -D).\nSame as rdf_reachable/3, but  in addition, MaxD limits the number of edges expanded and D  is unified with the `distance' between Subject and Object. Distance 0 means Subject  and Object are the same resource. MaxD can be the  constant infinite to impose no distance-limit.",
    "prefix":"rdf_reachable"
  },
  "semweb/rdf_db:rdf_register_ns/2": {
    "body": ["rdf_register_ns(${1:Prefix}, ${2:URI})$3\n$0" ],
    "description":"  rdf_register_ns(:Prefix, ?URI) is det.\n  rdf_register_ns(:Prefix, ?URI, +Options) is det.\n\n   Register an RDF prefix.\n\n   @deprecated. Use rdf_register_prefix/2 or rdf_register_prefix/3.",
    "prefix":"rdf_register_ns"
  },
  "semweb/rdf_db:rdf_register_ns/3": {
    "body": ["rdf_register_ns(${1:Prefix}, ${2:URI}, ${3:Options})$4\n$0" ],
    "description":"  rdf_register_ns(:Prefix, ?URI) is det.\n  rdf_register_ns(:Prefix, ?URI, +Options) is det.\n\n   Register an RDF prefix.\n\n   @deprecated. Use rdf_register_prefix/2 or rdf_register_prefix/3.",
    "prefix":"rdf_register_ns"
  },
  "semweb/rdf_db:rdf_register_prefix/2": {
    "body":"rdf_register_prefix(${1:Prefix}, ${2:URI})$3\n$0",
    "description":"[det]rdf_register_prefix(+Prefix, +URI).\n",
    "prefix":"rdf_register_prefix"
  },
  "semweb/rdf_db:rdf_register_prefix/3": {
    "body":"rdf_register_prefix(${1:Prefix}, ${2:URI}, ${3:Options})$4\n$0",
    "description":"[det]rdf_register_prefix(+Prefix, +URI, +Options).\nRegister Prefix as an abbreviation for URI. Options:  force(Boolean): If true, Replace existing namespace alias. Please note that  replacing a namespace is dangerous as namespaces affect preprocessing.  Make sure all code that depends on a namespace is compiled after  changing the registration.\n\nkeep(Boolean): If true and Alias is already defined, keep the original  binding for Prefix and succeed silently.\n\n  Without options, an attempt to redefine an alias raises a permission  error. \n\nPredefined prefixes are:\n\nAlias IRI prefix dchttp://purl.org/dc/elements/1.1/ dctermshttp://purl.org/dc/terms/ eorhttp://dublincore.org/2000/03/13/eor# foafhttp://xmlns.com/foaf/0.1/ owlhttp://www.w3.org/2002/07/owl# rdfhttp://www.w3.org/1999/02/22-rdf-syntax-ns# rdfshttp://www.w3.org/2000/01/rdf-schema# serqlhttp://www.openrdf.org/schema/serql# skoshttp://www.w3.org/2004/02/skos/core# voidhttp://rdfs.org/ns/void# xsdhttp://www.w3.org/2001/XMLSchema# ",
    "prefix":"rdf_register_prefix"
  },
  "semweb/rdf_db:rdf_reset_db/0": {
    "body":"rdf_reset_db$1\n$0",
    "description":"rdf_reset_db.\nRemove all triples from the RDF database and reset all its statistics.  bug: This predicate checks for active queries, but this check is not properly  synchronized and therefore the use of this predicate is unsafe in  multi-threaded contexts. It is mainly used to run functionality tests  that need to start with an empty database.\n\n ",
    "prefix":"rdf_reset_db"
  },
  "semweb/rdf_db:rdf_reset_literal_map/1": {
    "body": ["rdf_reset_literal_map(${1:Map})$2\n$0" ],
    "description":"  rdf_reset_literal_map(+Map) is det.\n\n   Delete all content from the literal map.",
    "prefix":"rdf_reset_literal_map"
  },
  "semweb/rdf_db:rdf_resource/1": {
    "body":"rdf_resource(${1:Resource})$2\n$0",
    "description":"[nondet]rdf_resource(?Resource).\nTrue when Resource is a resource used as a subject or object  in a triple.  This predicate is primarily intended as a way to process all  resources without processing resources twice. The user must be aware  that some of the returned resources may not appear in any visible triple.\n\n",
    "prefix":"rdf_resource"
  },
  "semweb/rdf_db:rdf_retractall/3": {
    "body":"rdf_retractall(${1:Subject}, ${2:Predicate}, ${3:Object})$4\n$0",
    "description":"[det]rdf_retractall(?Subject, ?Predicate, ?Object).\nRemove all matching triples from the database. As rdf_retractall/4 using an  unbound graph.",
    "prefix":"rdf_retractall"
  },
  "semweb/rdf_db:rdf_retractall/4": {
    "body":"rdf_retractall(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:Graph})$5\n$0",
    "description":"[det]rdf_retractall(?Subject, ?Predicate, ?Object, ?Graph).\nAs rdf_retractall/3, also  matching Graph. This is particulary useful to remove all  triples coming from a loaded file. See also rdf_unload/1.",
    "prefix":"rdf_retractall"
  },
  "semweb/rdf_db:rdf_save/1": {
    "body":"rdf_save(${1:Out})$2\n$0",
    "description":"[det]rdf_save(+Out).\nSame as rdf_save(Out, []). See rdf_save/2  for details.",
    "prefix":"rdf_save"
  },
  "semweb/rdf_db:rdf_save/2": {
    "body":"rdf_save(${1:Out}, ${2:Options})$3\n$0",
    "description":"[det]rdf_save(+Out, :Options).\nWrite RDF data as RDF/XML. Options is a list of one or more  of the following options:  graph(+Graph): Save only triples associated to the given named Graph.\n\nanon(Bool): If false (default true) do not save blank nodes that do not appear  (indirectly) as object of a named resource.\n\nbase_uri(URI): BaseURI used. If present, all URIs that can be represented relative to  this base are written using their shorthand. See also write_xml_base  option\n\nconvert_typed_literal(:Convertor): Call Convertor(-Type, -Content, +RDFObject), providing the  opposite for the convert_typed_literal option of the RDF parser.\n\ndocument_language(+Lang): Initial xml:lang saved with rdf:RDF element\n\nencoding(Encoding): Encoding for the output. Either utf8 or iso_latin_1\n\ninline(+Bool): If true (default false), inline resources when  encountered for the first time. Normally, only bnodes are handled this  way.\n\nnamespaces(+List): Explicitely specify saved namespace declarations. See rdf_save_header/2 option  namespaces for details.\n\nsorted(+Boolean): If true (default false), emit subjects sorted  on the full URI. Useful to make file comparison easier.\n\nwrite_xml_base(Bool): If false, do not include the xml:base  declaration that is written normally when using the base_uri option.\n\nxml_attributes(+Bool): If false (default true), never use xml  attributes to save plain literal attributes, i.e., always used an XML  element as in <name>Joe<\/name>.\n\n  Out Location to save the data.  This can also be a file-url (file://path) or a stream  wrapped in a term stream(Out).   See also: rdf_save_db/1\n\n ",
    "prefix":"rdf_save"
  },
  "semweb/rdf_db:rdf_save_db/1": {
    "body":"rdf_save_db(${1:File})$2\n$0",
    "description":"[det]rdf_save_db(+File).\n",
    "prefix":"rdf_save_db"
  },
  "semweb/rdf_db:rdf_save_db/2": {
    "body":"rdf_save_db(${1:File}, ${2:Graph})$3\n$0",
    "description":"[det]rdf_save_db(+File, +Graph).\nSave triples into File in a quick-to-load binary format. If Graph  is supplied only triples flagged to originate from that database are  added. Files created this way can be loaded using rdf_load_db/1.",
    "prefix":"rdf_save_db"
  },
  "semweb/rdf_db:rdf_save_footer/1": {
    "body":"rdf_save_footer(${1:Out})$2\n$0",
    "description":"[det]rdf_save_footer(Out:stream).\nFinish XML generation and write the document footer.  See also: rdf_save_header/2, rdf_save_subject/3.\n\n ",
    "prefix":"rdf_save_footer"
  },
  "semweb/rdf_db:rdf_save_header/2": {
    "body":"rdf_save_header(${1:Fd}, ${2:Options})$3\n$0",
    "description":"rdf_save_header(+Fd, +Options).\nSave XML document header, doctype and open the RDF environment. This  predicate also sets up the namespace notation.  Save an RDF header, with the XML header, DOCTYPE, ENTITY and opening  the rdf:RDF element with appropriate namespace declarations. It uses the  primitives from section 3.5 to generate the required namespaces and  desired short-name. Options is one of: \n\ngraph(+URI): Only search for namespaces used in triples that belong to the given  named graph.\n\nnamespaces(+List): Where List is a list of namespace abbreviations. With this  option, the expensive search for all namespaces that may be used by your  data is omitted. The namespaces rdf and rdfs  are added to the provided List. If a namespace is not  declared, the resource is emitted in non-abreviated form.\n\n ",
    "prefix":"rdf_save_header"
  },
  "semweb/rdf_db:rdf_save_subject/3": {
    "body":"rdf_save_subject(${1:Out}, ${2:Subject}, ${3:Options})$4\n$0",
    "description":"[det]rdf_save_subject(+Out, +Subject:resource, +Options).\nSave the triples associated to Subject to Out. Options:  graph(+Graph): Only save properties from Graph.\n\nbase_uri(+URI): convert_typed_literal(:Goal): document_language(+XMLLang): \n\n  See also: rdf_save/2 for a description of  these options.\n\n ",
    "prefix":"rdf_save_subject"
  },
  "semweb/rdf_db:rdf_set/1": {
    "body":"rdf_set(${1:Term})$2\n$0",
    "description":"[det]rdf_set(+Term).\nSet properties of the RDF store. Currently defines:  hash(+Hash, +Parameter, +Value): Set properties for a triple index. Hash is one of s, p, sp, o, po, spo, g, sg  or pg. Parameter is one of:  sizeValue defines the number of entries in the hash-table. Value is rounded down to a power of 2. After setting  the size explicitly, auto-sizing for this table is disabled. Setting the  size smaller than the current size results in a permission_error  exception.average_chain_lenSet maximum average collision number for the hash.optimize_thresholdRelated to resizing hash-tables. If 0, all triples are moved to the new  size by the garbage collector. If more then zero, those of the last Value  resize steps remain at their current location. Leaving cells at their  current location reduces memory fragmentation and slows down access. \n\n ",
    "prefix":"rdf_set"
  },
  "semweb/rdf_db:rdf_set_graph/2": {
    "body":"rdf_set_graph(${1:Graph}, ${2:Property})$3\n$0",
    "description":"[det]rdf_set_graph(+Graph, +Property).\nSet properties of Graph. Defined properties are:  modified(false): Set the modified state of Graph to false.\n\n ",
    "prefix":"rdf_set_graph"
  },
  "semweb/rdf_db:rdf_set_predicate/2": {
    "body":"rdf_set_predicate(${1:Predicate}, ${2:Property})$3\n$0",
    "description":"[det]rdf_set_predicate(+Predicate, +Property).\nDefine a property of the predicate. This predicate currently supports  the following properties:  symmetric(+Boolean): Set/unset the predicate as being symmetric. Using symmetric(true) is the same as inverse_of(Predicate),  i.e., creating a predicate that is the inverse of itself.\n\ntransitive(+Boolean): Sets the transitive property.\n\ninverse_of(+Predicate2): Define Predicate as the inverse of Predicate2. An  inverse relation is deleted using inverse_of([]).\n\n  The transitive property is currently not used. The symmetric  and inverse_of properties are considered by rdf_has/3,4  and rdf_reachable/3. \n\nTo be done: Maintain these properties based on OWL triples.\n\n ",
    "prefix":"rdf_set_predicate"
  },
  "semweb/rdf_db:rdf_snapshot/1": {
    "body":"rdf_snapshot(${1:Snapshot})$2\n$0",
    "description":"[det]rdf_snapshot(-Snapshot).\nTake a snapshot of the current state of the RDF store. Later, goals may  be executed in the context of the database at this moment using rdf_transaction/3  with the snapshot option. A snapshot created outside a  transaction exists until it is deleted. Snapshots taken inside a  transaction can only be used inside this transaction.",
    "prefix":"rdf_snapshot"
  },
  "semweb/rdf_db:rdf_source/1": {
    "body": ["rdf_source(${1:Source})$2\n$0" ],
    "description":"  rdf_source(?Source)\n\n   True if Source is a loaded source.\n\n   @deprecated     Use rdf_graph/1 or rdf_source/2.",
    "prefix":"rdf_source"
  },
  "semweb/rdf_db:rdf_source/2": {
    "body": ["rdf_source(${1:Graph}, ${2:SourceURL})$3\n$0" ],
    "description":"  rdf_source(?Graph, ?SourceURL) is nondet.\n\n   True if named Graph is loaded from SourceURL.\n\n   @deprecated Use rdf_graph_property(Graph, source(SourceURL)).",
    "prefix":"rdf_source"
  },
  "semweb/rdf_db:rdf_source_location/2": {
    "body":"rdf_source_location(${1:Subject}, ${2:Location})$3\n$0",
    "description":"[nondet]rdf_source_location(+Subject, -Location).\nTrue when triples for Subject are loaded from Location. Location is a term File:Line. ",
    "prefix":"rdf_source_location"
  },
  "semweb/rdf_db:rdf_split_url/3": {
    "body": ["rdf_split_url(${1:Prefix}, ${2:Local}, ${3:URL})$4\n$0" ],
    "description":"  rdf_split_url(+Prefix, +Local, -URL) is det.\n  rdf_split_url(-Prefix, -Local, +URL) is det.\n\n   Split/join a URL.  This functionality is moved to library(sgml).\n\n   @deprecated Use iri_xml_namespace/3. Note that the argument\n   order is iri_xml_namespace(+IRI, -Namespace, -Localname).",
    "prefix":"rdf_split_url"
  },
  "semweb/rdf_db:rdf_statistics/1": {
    "body":"rdf_statistics(${1:KeyValue})$2\n$0",
    "description":"[nondet]rdf_statistics(?KeyValue).\nObtain statistics on the RDF database. Defined statistics are:  graphs(-Count): Number of named graphs\n\ntriples(-Count): Total number of triples in the database. This is the number of asserted  triples minus the number of retracted ones. The number of visible  triples in a particular context may be different due to visibility rules  defined by the logical update view and transaction isolation.\n\nresources(-Count): Number of resources that appear as subject or object in a triple. See rdf_resource/1.\n\nproperties(-Count): Number of current predicates. See rdf_current_predicate/1.\n\nliterals(-Count): Number of current literals. See rdf_current_literal/1.\n\ngc(GCCount, ReclaimedTriples,  ReindexedTriples, Time): Information about the garbage collector.\n\nsearched_nodes(-Count): Number of nodes expanded by rdf_reachable/3  and rdf_reachable/5.\n\nlookup(rdf(S,P,O,G), Count): Number of queries for this particular instantiation pattern. Each of S,P,O,G  is either + or -.\n\nhash_quality(rdf(S,P,O,G), Buckets, Quality,  PendingResize): Statistics on the index for this pattern. Indices are created lazily on  the first relevant query.\n\ntriples_by_graph(Graph, Count): This statistics is produced for each named graph. See triples for the interpretation of this value.\n\n ",
    "prefix":"rdf_statistics"
  },
  "semweb/rdf_db:rdf_statistics_literal_map/2": {
    "body": ["rdf_statistics_literal_map(${1:Map}, ${2:KeyValue})$3\n$0" ],
    "description":"  rdf_statistics_literal_map(+Map, -KeyValue)\n\n   Query some statistics of the map. Provides KeyValue are:\n\n     * size(-Keys, -Relations)\n     Unify Keys with the total key-count of the index and Relation\n     with the total Key-Value count.",
    "prefix":"rdf_statistics_literal_map"
  },
  "semweb/rdf_db:rdf_subject/1": {
    "body":"rdf_subject(${1:Resource})$2\n$0",
    "description":"[nondet]rdf_subject(?Resource).\nTrue if Resource appears as a subject. This query respects  the visibility rules implied by the logical update view.  See also: rdf_resource/1.\n\n ",
    "prefix":"rdf_subject"
  },
  "semweb/rdf_db:rdf_transaction/1": {
    "body":"rdf_transaction(${1:Goal})$2\n$0",
    "description":"[semidet]rdf_transaction(:Goal).\nSame as rdf_transaction(Goal, user, []). See rdf_transaction/3.",
    "prefix":"rdf_transaction"
  },
  "semweb/rdf_db:rdf_transaction/2": {
    "body":"rdf_transaction(${1:Goal}, ${2:Id})$3\n$0",
    "description":"[semidet]rdf_transaction(:Goal, +Id).\nSame as rdf_transaction(Goal, Id, []). See rdf_transaction/3.",
    "prefix":"rdf_transaction"
  },
  "semweb/rdf_db:rdf_transaction/3": {
    "body":"rdf_transaction(${1:Goal}, ${2:Id}, ${3:Options})$4\n$0",
    "description":"[semidet]rdf_transaction(:Goal, +Id, +Options).\nRun Goal in an RDF transaction. Compared to the ACID model,  RDF transactions have the following properties:  \n\nModifications inside the transactions become all atomically visible  to the outside world if Goal succeeds or remain invisible if Goal  fails or throws an exception. I.e., the atomicy property is fully  supported.\nConsistency is not guaranteed. Later versions may implement  consistency constraints that will be checked serialized just before the  actual commit of a transaction.\nConcurrently executing transactions do not infuence each other.  I.e., the isolation property is fully supported.\nDurability can be activated by loading library(semweb/rdf_persistency).\n\n  Processed options are: \n\nsnapshot(+Snapshot): Execute Goal using the state of the RDF store as stored in Snapshot. See rdf_snapshot/1. Snapshot  can also be the atom true, which implies that an anonymous  snapshot is created at the current state of the store. Modifications due  to executing Goal are only visible to Goal.\n\n ",
    "prefix":"rdf_transaction"
  },
  "semweb/rdf_db:rdf_unload/1": {
    "body":"rdf_unload(${1:Source})$2\n$0",
    "description":"[det]rdf_unload(+Source).\nIdentify the graph loaded from Source and use rdf_unload_graph/1  to erase this graph.  deprecated: For compatibility, this predicate also accepts a graph name instead of a  source specification. Please update your code to use rdf_unload_graph/1.\n\n ",
    "prefix":"rdf_unload"
  },
  "semweb/rdf_db:rdf_unload_graph/1": {
    "body":"rdf_unload_graph(${1:Graph})$2\n$0",
    "description":"[det]rdf_unload_graph(+Graph).\nRemove Graph from the RDF store. Succeeds silently if the  named graph does not exist.",
    "prefix":"rdf_unload_graph"
  },
  "semweb/rdf_db:rdf_update/4": {
    "body":"rdf_update(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:Action})$5\n$0",
    "description":"[det]rdf_update(+Subject, +Predicate, +Object, +Action).\nReplaces one of the three fields on the matching triples depending on Action:  subject(Resource): Changes the first field of the triple.\n\npredicate(Resource): Changes the second field of the triple.\n\nobject(Object): Changes the last field of the triple to the given resource or literal(Value).\n\ngraph(Graph): Moves the triple from its current named graph to Graph.\n\n ",
    "prefix":"rdf_update"
  },
  "semweb/rdf_db:rdf_update/5": {
    "body":"rdf_update(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:Graph}, ${5:Action})$6\n$0",
    "description":"[det]rdf_update(+Subject, +Predicate, +Object, +Graph, +Action).\nAs rdf_update/4 but allows for  specifying the graph.",
    "prefix":"rdf_update"
  },
  "semweb/rdf_db:rdf_update_duplicates/0": {
    "body": ["rdf_update_duplicates$1\n$0" ],
    "description":"  rdf_update_duplicates is det.\n\n   Update the duplicate administration. If   this  adminstration is\n   up-to-date, each triples that _may_ have a duplicate is flagged.\n   The predicate rdf/3 uses this administration to speedup checking\n   for duplicate answers.\n\n   This predicate is normally  executed   from  a background thread\n   named =__rdf_duplicate_detecter= which is created   when a query\n   discovers that checking for duplicates becomes too expensive.",
    "prefix":"rdf_update_duplicates"
  },
  "semweb/rdf_db:rdf_url_namespace/2": {
    "body": ["rdf_url_namespace(${1:URL}, ${2:Namespace})$3\n$0" ],
    "description":"  rdf_url_namespace(+URL, -Namespace)\n\n   Namespace is the namespace of URL.\n\n   @deprecated Use iri_xml_namespace/2",
    "prefix":"rdf_url_namespace"
  },
  "semweb/rdf_db:rdf_version/1": {
    "body":"rdf_version(${1:Version})$2\n$0",
    "description":"[det]rdf_version(-Version).\nTrue when Version is the numerical version-id of this  library. The version is computed as  \n\nMajor*10000 + Minor*100 + Patch.\n\n  \n\n",
    "prefix":"rdf_version"
  },
  "semweb/rdf_db:rdf_warm_indexes/0": {
    "body": ["rdf_warm_indexes$1\n$0" ],
    "description":"  rdf_warm_indexes\n\n   Warm all indexes.  See rdf_warm_indexes/1.",
    "prefix":"rdf_warm_indexes"
  },
  "semweb/rdf_db:rdf_warm_indexes/1": {
    "body": ["rdf_warm_indexes(${1:Indexes})$2\n$0" ],
    "description":"  rdf_warm_indexes(+Indexes) is det.\n\n   Create the named indexes.  Normally,   the  RDF database creates\n   indexes on lazily the first time they are needed. This predicate\n   serves two purposes: it provides an   explicit  way to make sure\n   that the required indexes  are   present  and  creating multiple\n   indexes at the same time is more efficient.",
    "prefix":"rdf_warm_indexes"
  },
  "semweb/rdf_db:rdfs_nth0/3": {
    "body":"rdfs_nth0(${1:N}, ${2:Container}, ${3:Elem})$4\n$0",
    "description":"[nondet]rdfs_nth0(?N, ?Container, ?Elem).\nTrue if rdf(Container, P, Elem) is true and P is the N-th  (0-based) container membership property.",
    "prefix":"rdfs_nth0"
  },
  "semweb/rdf_edit:rdfe_assert/3": {
    "body": ["rdfe_assert(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"rdfe_assert('Param1','Param2','Param3')",
    "prefix":"rdfe_assert"
  },
  "semweb/rdf_edit:rdfe_assert/4": {
    "body": [
      "rdfe_assert(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"rdfe_assert('Param1','Param2','Param3','Param4')",
    "prefix":"rdfe_assert"
  },
  "semweb/rdf_edit:rdfe_can_redo/1": {
    "body": ["rdfe_can_redo(${1:TID})$2\n$0" ],
    "description":"  rdfe_can_redo(-TID) is semidet.\n  rdfe_can_undo(-TID) is semidet.\n\n   Check if we can undo and if so return the id of the transaction\n   that will be un/re-done.  A subsequent call to rdfe_transaction_name\n   can be used to give a hint in the UI.",
    "prefix":"rdfe_can_redo"
  },
  "semweb/rdf_edit:rdfe_can_undo/1": {
    "body": ["rdfe_can_undo(${1:TID})$2\n$0" ],
    "description":"  rdfe_can_redo(-TID) is semidet.\n  rdfe_can_undo(-TID) is semidet.\n\n   Check if we can undo and if so return the id of the transaction\n   that will be un/re-done.  A subsequent call to rdfe_transaction_name\n   can be used to give a hint in the UI.",
    "prefix":"rdfe_can_undo"
  },
  "semweb/rdf_edit:rdfe_clear_modified/1": {
    "body": ["rdfe_clear_modified(${1:Graph})$2\n$0" ],
    "description":"  rdfe_clear_modified(+Graph) is det.\n\n   Consider the current state of Graph as _unmodified_.",
    "prefix":"rdfe_clear_modified"
  },
  "semweb/rdf_edit:rdfe_close_journal/0": {
    "body": ["rdfe_close_journal$1\n$0" ],
    "description":"  rdfe_close_journal\n\n   Close  the  journal.  Automatically  called    from  at  program\n   termination from at_halt/1.",
    "prefix":"rdfe_close_journal"
  },
  "semweb/rdf_edit:rdfe_current_journal/1": {
    "body": ["rdfe_current_journal(${1:Path})$2\n$0" ],
    "description":"  rdfe_current_journal(-Path)\n\n   Query the currently open journal",
    "prefix":"rdfe_current_journal"
  },
  "semweb/rdf_edit:rdfe_delete/1": {
    "body": ["rdfe_delete(${1:Subject})$2\n$0" ],
    "description":"  rdfe_delete(+Subject)\n\n   Delete a subject and all we know about it. This is a bit tricky.\n   If we are involved in transitive relations, should we re-joint\n   these in this module?",
    "prefix":"rdfe_delete"
  },
  "semweb/rdf_edit:rdfe_get_file_property/2": {
    "body": ["rdfe_get_file_property(${1:FileOrURL}, ${2:Option})$3\n$0" ],
    "description":"  rdfe_get_file_property(+FileOrURL, ?Option).\n  rdfe_get_file_property(-URL, ?Option).\n\n   Fetch file properties set with rdfe_set_file_property/2.",
    "prefix":"rdfe_get_file_property"
  },
  "semweb/rdf_edit:rdfe_is_modified/1": {
    "body": ["rdfe_is_modified(${1:Source})$2\n$0" ],
    "description":"  rdfe_is_modified(?Source)\n\n   True if facts have been added, deleted or updated that have\n   Source as `payload'.",
    "prefix":"rdfe_is_modified"
  },
  "semweb/rdf_edit:rdfe_load/1": {
    "body": ["rdfe_load(${1:File})$2\n$0" ],
    "description":"  rdfe_load(+File) is det.\n  rdfe_load(+File, +Options) is det.\n\n   Load an RDF file and record this action including version information\n   to facilitate reliable reload.",
    "prefix":"rdfe_load"
  },
  "semweb/rdf_edit:rdfe_load/2": {
    "body": ["rdfe_load(${1:File}, ${2:Options})$3\n$0" ],
    "description":"  rdfe_load(+File) is det.\n  rdfe_load(+File, +Options) is det.\n\n   Load an RDF file and record this action including version information\n   to facilitate reliable reload.",
    "prefix":"rdfe_load"
  },
  "semweb/rdf_edit:rdfe_open_journal/2": {
    "body": ["rdfe_open_journal(${1:File}, ${2:Mode})$3\n$0" ],
    "description":"  rdfe_open_journal(+File, +Mode) is det.\n\n   Open a journal writing to File in Mode.  Mode is one of\n\n           * read\n           Open and replay the journal\n\n           * write\n           Delete current journal and create a fresh one\n\n           * append\n           Read and replay the existing journal and append new\n           modifications to the File.",
    "prefix":"rdfe_open_journal"
  },
  "semweb/rdf_edit:rdfe_redo/0": {
    "body": ["rdfe_redo$1\n$0" ],
    "description":"  rdfe_redo\n\n   Start a redo-session",
    "prefix":"rdfe_redo"
  },
  "semweb/rdf_edit:rdfe_register_ns/2": {
    "body": ["rdfe_register_ns(${1:Id}, ${2:URI})$3\n$0" ],
    "description":"  rdfe_register_ns(Id, URI)\n\n   Encapsulation of rdf_register_ns(Id, URI)",
    "prefix":"rdfe_register_ns"
  },
  "semweb/rdf_edit:rdfe_replay_journal/1": {
    "body": ["rdfe_replay_journal(${1:File})$2\n$0" ],
    "description":"  rdfe_replay_journal(+File)\n\n   Replay a journal file. For now  this   is  our cheap way to deal\n   with save/load. Future versions may be  more clever when dealing\n   with the version information stored in the journal.",
    "prefix":"rdfe_replay_journal"
  },
  "semweb/rdf_edit:rdfe_reset/0": {
    "body": ["rdfe_reset$1\n$0" ],
    "description":"  rdfe_reset\n\n   Clear database, undo, namespaces and journalling info.",
    "prefix":"rdfe_reset"
  },
  "semweb/rdf_edit:rdfe_retractall/3": {
    "body": [
      "rdfe_retractall(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdfe_retractall('Param1','Param2','Param3')",
    "prefix":"rdfe_retractall"
  },
  "semweb/rdf_edit:rdfe_retractall/4": {
    "body": [
      "rdfe_retractall(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"rdfe_retractall('Param1','Param2','Param3','Param4')",
    "prefix":"rdfe_retractall"
  },
  "semweb/rdf_edit:rdfe_set_file_property/2": {
    "body": ["rdfe_set_file_property(${1:File}, ${2:Options})$3\n$0" ],
    "description":"  rdfe_set_file_property(+File, +Options)\n\n   Set properties on the file.  Options is one of\n\n           * access(ro/rw)\n           * default(all/fallback)",
    "prefix":"rdfe_set_file_property"
  },
  "semweb/rdf_edit:rdfe_set_transaction_name/1": {
    "body": ["rdfe_set_transaction_name(${1:Name})$2\n$0" ],
    "description":"  rdfe_set_transaction_name(+Name)\n\n   Set name of the current transaction",
    "prefix":"rdfe_set_transaction_name"
  },
  "semweb/rdf_edit:rdfe_set_watermark/1": {
    "body": ["rdfe_set_watermark(${1:Name})$2\n$0" ],
    "description":"  rdfe_set_watermark(Name)\n\n   Create a watermark for undo and replay journal upto this point.\n   The rest of the logic needs to be written later.",
    "prefix":"rdfe_set_watermark"
  },
  "semweb/rdf_edit:rdfe_snapshot_file/1": {
    "body": ["rdfe_snapshot_file(${1:File})$2\n$0" ],
    "description":"  rdfe_snapshot_file(-File)\n\n   Enumerate the MD5 snapshot files required to restore the current\n   journal file. Using this  call  we   can  write  a  routine that\n   packages the journal file with all required snapshots to restore\n   the journal on another computer.",
    "prefix":"rdfe_snapshot_file"
  },
  "semweb/rdf_edit:rdfe_transaction/1": {
    "body": ["rdfe_transaction(${1:Goal})$2\n$0" ],
    "description":"  rdfe_transaction(:Goal)\n\n   Run Goal, recording all modifications   as a single transaction.\n   If  Goal  raises  an  exception  or    fails,  all  changes  are\n   rolled-back.",
    "prefix":"rdfe_transaction"
  },
  "semweb/rdf_edit:rdfe_transaction/2": {
    "body": ["rdfe_transaction(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdfe_transaction('Param1','Param2')",
    "prefix":"rdfe_transaction"
  },
  "semweb/rdf_edit:rdfe_transaction_member/2": {
    "body": ["rdfe_transaction_member(${1:TID}, ${2:Action})$3\n$0" ],
    "description":"  rdfe_transaction_member(+TID, -Action)\n\n   Query actions inside a transaction to allow for quick update\n   of visualisers.",
    "prefix":"rdfe_transaction_member"
  },
  "semweb/rdf_edit:rdfe_transaction_name/2": {
    "body": ["rdfe_transaction_name(${1:TID}, ${2:Name})$3\n$0" ],
    "description":"  rdfe_transaction_name(+TID, -Name)\n\n   Return name if the transaction is named.",
    "prefix":"rdfe_transaction_name"
  },
  "semweb/rdf_edit:rdfe_undo/0": {
    "body": ["rdfe_undo$1\n$0" ],
    "description":"  rdfe_undo\n\n   Undo a (toplevel) transaction. More calls do further undo. The\n   `Undone' actions are re-added to the undo log, so the user can\n   redo them.  Fails if there are no more undo/redo transactions.",
    "prefix":"rdfe_undo"
  },
  "semweb/rdf_edit:rdfe_unregister_ns/2": {
    "body": ["rdfe_unregister_ns(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"rdfe_unregister_ns('Param1','Param2')",
    "prefix":"rdfe_unregister_ns"
  },
  "semweb/rdf_edit:rdfe_update/4": {
    "body": [
      "rdfe_update(${1:Subject}, ${2:Predicate}, ${3:Object}, ${4:Action})$5\n$0"
    ],
    "description":"  rdfe_update(+Subject, +Predicate, +Object, +Action)\n\n   Update an existing triple.  Possible actions are:\n\n          subject(+Subject)\n          predicate(+Predicate)\n          object(+Object)\n          source(+Source)",
    "prefix":"rdfe_update"
  },
  "semweb/rdf_edit:rdfe_update/5": {
    "body": [
      "rdfe_update(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'}, ${5:'Param5'})$6\n$0"
    ],
    "description":"rdfe_update('Param1','Param2','Param3','Param4','Param5')",
    "prefix":"rdfe_update"
  },
  "semweb/rdf_library:rdf_attach_library/1": {
    "body": ["rdf_attach_library(${1:Source})$2\n$0" ],
    "description":"  rdf_attach_library(+Source)\n\n   Attach manifest from Source.  Source is one of\n\n           * URL\n           Load single manifest from this URL\n           * File\n           Load single manifest from this file\n           * Directory\n           Scan all subdirectories and load all =|Manifest.ttl|= or\n           =|Manifest.rdf|= found.  If Directory is a path-alias\n           (e.g., ontology(.)), _all_ referenced directories are\n           scanned for manifest files.\n\n   Encountered namespaces are registered   using rdf_register_ns/2.\n   Encountered ontologies are added to the index. If a manifest was\n   already loaded it will be reloaded  if the modification time has\n   changed.",
    "prefix":"rdf_attach_library"
  },
  "semweb/rdf_library:rdf_current_manifest/1": {
    "body": ["rdf_current_manifest(${1:URL})$2\n$0" ],
    "description":"  rdf_current_manifest(-URL) is nondet.\n\n   True if URL is the URL of a currently loaded manifest file.",
    "prefix":"rdf_current_manifest"
  },
  "semweb/rdf_library:rdf_library_index/2": {
    "body": ["rdf_library_index(${1:Id}, ${2:Facet})$3\n$0" ],
    "description":"  rdf_library_index(?Id, ?Facet) is nondet.\n\n   Query the content of the library.  Defined facets are:\n\n           * source(URL)\n           Location from which to load the ontology\n\n           * title(Atom)\n           Title used for the ontology\n\n           * comment(Atom)\n           Additional comments for the ontology\n\n           * version(Atom)\n           Version information on the ontology\n\n           * imports(Type, URL)\n           URLs needed by this ontology. May succeed multiple\n           times.  Type is one of =ontology=, =schema= or =instances=.\n\n           * base_uri(BaseURI)\n           Base URI to use when loading documents. If BaseURI\n           ends in =|/|=, the actual filename is attached.\n\n           * claimed_source(Source)\n           URL from which we claim to have loaded the RDF. If\n           Source ends in =|/|=, the actual filename is\n           attached.\n\n           * blank_nodes(Share)\n           Defines how equivalent blank nodes are handled, where\n           Share is one of =share= or =noshare=.  Default is to\n           share.\n\n           * format(Format)\n           Format of the resource.  Can be used to overrule\n           if the format as derived from the HTTP content type\n           is wrong.\n\n           * provides_ns(URL)\n           Ontology provides definitions in the namespace URL.\n           The formal definition of this is troublesome, but in\n           practice it means the ontology has triples whose\n           subjects are in the given namespace.\n\n           * uses_ns(URL)\n           The ontology depends on the given namespace.  Normally\n           means it contains triples that have predicates or\n           objects in the given namespace.\n\n           * manifest(URL)\n           URL of the manifest in which this ontology is defined.\n\n           * virtual\n           Entry is virtual (cannot be loaded)",
    "prefix":"rdf_library_index"
  },
  "semweb/rdf_library:rdf_library_source/2": {
    "body": ["rdf_library_source(${1:Id}, ${2:Source})$3\n$0" ],
    "description":"  rdf_library_source(+Id, -Source) is nondet.\n\n   True of Source is the URL that is  part of the given library Id.\n   This predicate finds all indirect   dependencies.  It does _not_\n   check whether the source exists or is valid.\n\n   @see uri_file_name/2 for converting file:// URLs to a filename.",
    "prefix":"rdf_library_source"
  },
  "semweb/rdf_library:rdf_list_library/0": {
    "body": ["rdf_list_library$1\n$0" ],
    "description":"  rdf_list_library\n\n   Prints known RDF library identifiers to current output.",
    "prefix":"rdf_list_library"
  },
  "semweb/rdf_library:rdf_list_library/1": {
    "body": ["rdf_list_library(${1:Id})$2\n$0" ],
    "description":"  rdf_list_library(+Id) is det.\n  rdf_list_library(+Id, +Options) is det.\n\n   Print library dependency tree to the terminal.  Options include\n   options for rdf_load_library/2 and\n\n           * show_source(+Boolean)\n           If =true= (default), show location we are loading\n\n           * show_graph(+Boolean)\n           If =true= (default =false=), show name of graph\n\n           * show_virtual(+Boolean)\n           If =false= (default =true=), do not show virtual\n           repositories.\n\n           * indent(Atom)\n           Atom repeated for indentation levels",
    "prefix":"rdf_list_library"
  },
  "semweb/rdf_library:rdf_list_library/2": {
    "body": ["rdf_list_library(${1:Id}, ${2:Options})$3\n$0" ],
    "description":"  rdf_list_library(+Id) is det.\n  rdf_list_library(+Id, +Options) is det.\n\n   Print library dependency tree to the terminal.  Options include\n   options for rdf_load_library/2 and\n\n           * show_source(+Boolean)\n           If =true= (default), show location we are loading\n\n           * show_graph(+Boolean)\n           If =true= (default =false=), show name of graph\n\n           * show_virtual(+Boolean)\n           If =false= (default =true=), do not show virtual\n           repositories.\n\n           * indent(Atom)\n           Atom repeated for indentation levels",
    "prefix":"rdf_list_library"
  },
  "semweb/rdf_library:rdf_load_library/1": {
    "body": ["rdf_load_library(${1:Id})$2\n$0" ],
    "description":"  rdf_load_library(+Id) is det.\n  rdf_load_library(+Id, +Options) is det.\n\n   Load ontologies from the  library.  A   library  must  first  be\n   attached using rdf_attach_library/1.  Defined Options are:\n\n           * import(Bool)\n           If =true= (default), also load ontologies that are\n           explicitely imported.\n\n           * base_uri(URI)\n           BaseURI used for loading RDF.  Local definitions in\n           ontologies overrule this option.\n\n           * claimed_source(URL)\n           URL from which we claim to have loaded the data.\n\n           * not_found(+Level)\n           The system does a pre-check for the existence of\n           all references RDF databases.  If Level is =error=\n           it reports missing databases as an error and fails.\n           If =warning= it prints them, but continues.  If\n           =silent=, no checks are preformed.  Default is =error=.\n\n           * concurrent(Threads)\n           Perform the load concurrently using N threads.  If not\n           specified, the number is determined by\n           guess_concurrency/2.\n\n           * load(+Bool)\n           If =false=, to all the preparation, but do not execute\n           the actual loading.  See also rdf_list_library/2.",
    "prefix":"rdf_load_library"
  },
  "semweb/rdf_library:rdf_load_library/2": {
    "body": ["rdf_load_library(${1:Id}, ${2:Options})$3\n$0" ],
    "description":"  rdf_load_library(+Id) is det.\n  rdf_load_library(+Id, +Options) is det.\n\n   Load ontologies from the  library.  A   library  must  first  be\n   attached using rdf_attach_library/1.  Defined Options are:\n\n           * import(Bool)\n           If =true= (default), also load ontologies that are\n           explicitely imported.\n\n           * base_uri(URI)\n           BaseURI used for loading RDF.  Local definitions in\n           ontologies overrule this option.\n\n           * claimed_source(URL)\n           URL from which we claim to have loaded the data.\n\n           * not_found(+Level)\n           The system does a pre-check for the existence of\n           all references RDF databases.  If Level is =error=\n           it reports missing databases as an error and fails.\n           If =warning= it prints them, but continues.  If\n           =silent=, no checks are preformed.  Default is =error=.\n\n           * concurrent(Threads)\n           Perform the load concurrently using N threads.  If not\n           specified, the number is determined by\n           guess_concurrency/2.\n\n           * load(+Bool)\n           If =false=, to all the preparation, but do not execute\n           the actual loading.  See also rdf_list_library/2.",
    "prefix":"rdf_load_library"
  },
  "semweb/rdf_litindex:rdf_cache_file/3": {
    "body":"rdf_cache_file(${1:URL}, ${2:ReadWrite}, ${3:File})$4\n$0",
    "description":"[semidet]rdf_cache_file(+URL, +ReadWrite, -File).\nFile is the cache file for URL. If ReadWrite  is read, it returns the name of an existing file. If write  it returns where a new cache file can be overwritten or created.",
    "prefix":"rdf_cache_file"
  },
  "semweb/rdf_litindex:rdf_delete_literal_index/1": {
    "body": ["rdf_delete_literal_index(${1:Type})$2\n$0" ],
    "description":"  rdf_delete_literal_index(+Type)\n\n   Fully delete a literal index",
    "prefix":"rdf_delete_literal_index"
  },
  "semweb/rdf_litindex:rdf_delete_literal_map/2": {
    "body":"rdf_delete_literal_map(${1:Map}, ${2:Key})$3\n$0",
    "description":"rdf_delete_literal_map(+Map, +Key).\nDelete Key and all associated values from the map. Succeeds  always.",
    "prefix":"rdf_delete_literal_map"
  },
  "semweb/rdf_litindex:rdf_delete_literal_map/3": {
    "body":"rdf_delete_literal_map(${1:Map}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"rdf_delete_literal_map(+Map, +Key, +Value).\nDelete the association between Key and Value from  the map. Succeeds always.",
    "prefix":"rdf_delete_literal_map"
  },
  "semweb/rdf_litindex:rdf_destroy_literal_map/1": {
    "body":"rdf_destroy_literal_map(${1:Map})$2\n$0",
    "description":"rdf_destroy_literal_map(+Map).\nDestroy a literal map. After this call, further use of the Map  handle is illegal. Additional synchronisation is needed if maps that are  shared between threads are destroyed to guarantee the handle is no  longer used. In some scenarios rdf_reset_literal_map/1  provides a safe alternative.",
    "prefix":"rdf_destroy_literal_map"
  },
  "semweb/rdf_litindex:rdf_find_literal/2": {
    "body": ["rdf_find_literal(${1:Spec}, ${2:Literal})$3\n$0" ],
    "description":"  rdf_find_literal(+Spec, -Literal) is nondet.\n  rdf_find_literals(+Spec, -Literals) is det.\n\n   Find literals in the RDF database matching Spec.  Spec is defined\n   as:\n\n   ==\n   Spec ::= and(Spec,Spec)\n   Spec ::= or(Spec,Spec)\n   Spec ::= not(Spec)\n   Spec ::= sounds(Like)\n   Spec ::= stem(Like)             % same as stem(Like, en)\n   Spec ::= stem(Like, Lang)\n   Spec ::= prefix(Prefix)\n   Spec ::= between(Low, High)     % Numerical between\n   Spec ::= ge(High)               % Numerical greater-equal\n   Spec ::= le(Low)                % Numerical less-equal\n   Spec ::= Token\n   ==\n\n   sounds(Like) and stem(Like) both map to  a disjunction. First we\n   compile the spec to normal form:   a disjunction of conjunctions\n   on elementary tokens. Then we execute   all the conjunctions and\n   generate the union using ordered-set algorithms.\n\n   Stopgaps are ignored. If the final result is only a stopgap, the\n   predicate fails.\n\n   @tbd Exploit ordering of numbers and allow for > N, < N, etc.",
    "prefix":"rdf_find_literal"
  },
  "semweb/rdf_litindex:rdf_find_literal_map/3": {
    "body":"rdf_find_literal_map(${1:Map}, ${2:KeyList}, ${3:ValueList})$4\n$0",
    "description":"[det]rdf_find_literal_map(+Map, +KeyList, -ValueList).\nUnify ValueList with an ordered set of values associated to  all keys from KeyList. Each key in KeyList is  either an atom, an integer or a term not(Key). If not-terms  are provided, there must be at least one positive keywords. The  negations are tested after establishing the positive matches.",
    "prefix":"rdf_find_literal_map"
  },
  "semweb/rdf_litindex:rdf_find_literals/2": {
    "body":"rdf_find_literals(${1:Spec}, ${2:ListOfLiterals})$3\n$0",
    "description":"rdf_find_literals(+Spec, -ListOfLiterals).\nFind literals (without type or language specification) that satisfy Spec. The required indices are created as needed and kept  up-to-date using hooks registered with rdf_monitor/2.  Numerical indexing is currently limited to integers in the range 2^30  (2^62 on 64-bit platforms). Spec is defined  as:  and(Spec1, Spec2): Intersection of both specifications.\n\nor(Spec1, Spec2): Union of both specifications.\n\nnot(Spec): Negation of Spec. After translation of the full specification  to Disjunctive Normal Form (DNF), negations are only allowed  inside a conjunction with at least one positive literal.\n\ncase(Word): Matches all literals containing the word Word, doing the  match case insensitive and after removing diacritics.\n\nstem(Like): Matches all literals containing at least one word that has the same stem  as Like using the Porter stem algorithm. See NLP package for  details.\n\nsounds(Like): Matches all literals containing at least one word that `sounds like' Like using the double metaphone algorithm. See NLP package  for details.\n\nprefix(Prefix): Matches all literals containing at least one word that starts with  Prefix, discarding diacritics and case.\n\nbetween(Low, High): Matches all literals containing an integer token in the range Low..High, including the boundaries.\n\nge(Low): Matches all literals containing an integer token with value Low or higher.\n\nle(High): Matches all literals containing an integer token with value High or lower.\n\nToken: Matches all literals containing the given token. See tokenize_atom/2  of the NLP package for details.\n\n ",
    "prefix":"rdf_find_literals"
  },
  "semweb/rdf_litindex:rdf_insert_literal_map/3": {
    "body":"rdf_insert_literal_map(${1:Map}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"rdf_insert_literal_map(+Map, +Key, +Value).\nAdd a relation between Key and Value to the map.  If this relation already exists no action is performed.",
    "prefix":"rdf_insert_literal_map"
  },
  "semweb/rdf_litindex:rdf_insert_literal_map/4": {
    "body":"rdf_insert_literal_map(${1:Map}, ${2:Key}, ${3:Value}, ${4:KeyCount})$5\n$0",
    "description":"rdf_insert_literal_map(+Map, +Key, +Value, -KeyCount).\nAs rdf_insert_literal_map/3.  In addition, if Key is a new key in Map, unify KeyCount with the number of keys in Map.  This serves two purposes. Derived maps, such as the stem and metaphone  maps need to know about new keys and it avoids additional foreign calls  for doing the progress in rdf_litindex.pl.",
    "prefix":"rdf_insert_literal_map"
  },
  "semweb/rdf_litindex:rdf_keys_in_literal_map/3": {
    "body":"rdf_keys_in_literal_map(${1:Map}, ${2:Spec}, ${3:Answer})$4\n$0",
    "description":"rdf_keys_in_literal_map(+Map, +Spec, -Answer).\nRealises various queries on the key-set:  all: Unify Answer with an ordered list of all keys.\n\nkey(+Key): Succeeds if Key is a key in the map and unify Answer  with the number of values associated with the key. This provides a fast  test of existence without fetching the possibly large associated value  set as with rdf_find_literal_map/3.\n\nprefix(+Prefix): Unify Answer with an ordered set of all keys that have the  given prefix. Prefix must be an atom. This call is intended  for auto-completion in user interfaces.\n\nge(+Min): Unify Answer with all keys that are larger or equal to the  integer Min.\n\nle(+Max): Unify Answer with all keys that are smaller or equal to the  integer Max.\n\nbetween(+Min, +Max): Unify Answer with all keys between Min and Max  (including).\n\n ",
    "prefix":"rdf_keys_in_literal_map"
  },
  "semweb/rdf_litindex:rdf_literal_index/2": {
    "body": ["rdf_literal_index(${1:Type}, ${2:Index})$3\n$0" ],
    "description":"  rdf_literal_index(+Type, -Index) is det.\n\n   True when Index is a literal map   containing the index of Type.\n   Type is one of:\n\n     - token\n     Tokens are basically words of literal values. See\n     rdf_tokenize_literal/2.  The `token` map maps tokens to full\n     literal texts.\n     - stem\n     Index of stemmed tokens.  If the language is available, the\n     tokens are stemmed using the matching _snowball_ stemmer.\n     The `stem` map maps stemmed to full tokens.\n     - metaphone\n     Phonetic index of tokens.  The `metaphone` map maps phonetic\n     keys to tokens.",
    "prefix":"rdf_literal_index"
  },
  "semweb/rdf_litindex:rdf_new_literal_map/1": {
    "body":"rdf_new_literal_map(${1:Map})$2\n$0",
    "description":"rdf_new_literal_map(-Map).\nCreate a new literal map, returning an opaque handle.",
    "prefix":"rdf_new_literal_map"
  },
  "semweb/rdf_litindex:rdf_reset_literal_map/1": {
    "body":"rdf_reset_literal_map(${1:Map})$2\n$0",
    "description":"rdf_reset_literal_map(+Map).\nDelete all content from the literal map.",
    "prefix":"rdf_reset_literal_map"
  },
  "semweb/rdf_litindex:rdf_set_literal_index_option/1": {
    "body": ["rdf_set_literal_index_option(${1:Options})$2\n$0" ],
    "description":"  rdf_set_literal_index_option(+Options:list)\n\n   Set options for the literal package.  Currently defined options\n\n           * verbose(Bool)\n           If =true=, print progress messages while building the\n           index tables.\n\n           * index_threads(+Count)\n           Number of threads to use for initial indexing of\n           literals\n\n           * index(+How)\n           How to deal with indexing new literals.  How is one of\n           =self= (execute in the same thread), thread(N) (execute\n           in N concurrent threads) or =default= (depends on number\n           of cores).\n\n           * stopgap_threshold(+Count)\n           Add a token to the dynamic stopgap set if it appears in\n           more than Count literals.  The default is 50,000.",
    "prefix":"rdf_set_literal_index_option"
  },
  "semweb/rdf_litindex:rdf_statistics_literal_map/2": {
    "body":"rdf_statistics_literal_map(${1:Map}, ${2:Key(})$3\n$0",
    "description":"rdf_statistics_literal_map(+Map, +Key(-Arg...)).\nQuery some statistics of the map. Provides keys are:  size(-Keys, -Relations): Unify Keys with the total key-count of the index and Relation with the total Key-Value  count.\n\n ",
    "prefix":"rdf_statistics_literal_map"
  },
  "semweb/rdf_litindex:rdf_stopgap_token/1": {
    "body": ["rdf_stopgap_token(${1:Token})$2\n$0" ],
    "description":"  rdf_stopgap_token(-Token) is nondet.\n\n   True when Token is a stopgap  token. Currently, this implies one\n   of:\n\n     - exclude_from_index(token, Token) is true\n     - default_stopgap(Token) is true\n     - Token is an atom of length 1\n     - Token was added to the dynamic stopgap token set because\n       it appeared in more than _stopgap_threshold_ literals.",
    "prefix":"rdf_stopgap_token"
  },
  "semweb/rdf_litindex:rdf_token_expansions/2": {
    "body":"rdf_token_expansions(${1:Spec}, ${2:Expansions})$3\n$0",
    "description":"rdf_token_expansions(+Spec, -Expansions).\nUses the same database as rdf_find_literals/2  to find possible expansions of Spec, i.e. which words `sound  like', `have prefix', etc. Spec is a compound expression as  in rdf_find_literals/2. Expansions is unified to a list of terms sounds(Like,  Words), stem(Like, Words) or prefix(Prefix,  Words). On compound expressions, only combinations that provide  literals are returned. Below is an example after loading the ULAN2Unified  List of Artist Names from the Getty Foundation. database  and showing all words that sounds like `rembrandt' and appear together  in a literal with the word `Rijn'. Finding this result from the 228,710  literals contained in ULAN requires 0.54 milliseconds (AMD 1600+).  \n\n?- rdf_token_expansions(and('Rijn', sounds(rembrandt)), L).\n\nL = [sounds(rembrandt, ['Rambrandt', 'Reimbrant', 'Rembradt',\n                        'Rembrand', 'Rembrandt', 'Rembrandtsz',\n                        'Rembrant', 'Rembrants', 'Rijmbrand'])]\n\n  Here is another example, illustrating handling of diacritics:\n\n \n\n?- rdf_token_expansions(case(cafe), L).\n\nL = [case(cafe, [cafe, caf\\'e])]\n\n ",
    "prefix":"rdf_token_expansions"
  },
  "semweb/rdf_litindex:rdf_tokenize_literal/2": {
    "body":"rdf_tokenize_literal(${1:Literal}, ${2:Tokens})$3\n$0",
    "description":"rdf_tokenize_literal(+Literal, -Tokens).\nTokenize a literal, returning a list of atoms and integers in the range -1073741824 ... 1073741823. As tokenization is in general  domain and task-dependent this predicate first calls the hook rdf_litindex:tokenization(Literal, -Tokens). On failure it  calls tokenize_atom/2  from the NLP package and deletes the following: atoms of length 1,  floats, integers that are out of range and the english words and, an, or, of, on, in, this and the.  Deletion first calls the hook rdf_litindex:exclude_from_index(token,  X). This hook is called as follows:  \n\nno_index_token(X) :-\n        exclude_from_index(token, X), !.\nno_index_token(X) :-\n        ...\n\n  \n\n",
    "prefix":"rdf_tokenize_literal"
  },
  "semweb/rdf_ntriples:rdf_process_ntriples/3": {
    "body":"rdf_process_ntriples(${1:Input}, ${2:CallBack}, ${3:Options})$4\n$0",
    "description":"rdf_process_ntriples(+Input, :CallBack, +Options).\nCall-back interface, compatible with the other triple readers. In  addition to the options from rdf_read_ntriples/3,  this processes the option graph(Graph). CallBack is called as call(CallBack, Triples, Graph),  where Triples is a list holding a single rdf(S,P,O) triple.  Graph is passed from the graph option and unbound if this  option is omitted. ",
    "prefix":"rdf_process_ntriples"
  },
  "semweb/rdf_ntriples:rdf_read_nquads/3": {
    "body":"rdf_read_nquads(${1:Input}, ${2:Quads}, ${3:Options})$4\n$0",
    "description":"[det]rdf_read_nquads(+Input, -Quads, +Options).\nTrue when Triples/Quads is a list of triples/quads  from Input. Options:  anon_prefix(+AtomOrNode): Prefix nodeIDs with this atom. If AtomOrNode is the term node(_), bnodes are returned as node(Id).\n\nbase_uri(+Atom): Defines the default anon_prefix as _:<baseuri>_\n\non_error(Action): One of warning (default) or error\n\nerror_count(-Count): If on_error is warning, unify Count  with th number of errors.\n\ngraph(+Graph): For rdf_read_nquads/3,  this defines the graph associated to triples loaded from the  input. For rdf_read_ntriples/3  this opion is ignored.\n\n  Triples is a list of rdf(Subject, Predicate, Object) Quads is a list of rdf(Subject, Predicate, Object, Graph) ",
    "prefix":"rdf_read_nquads"
  },
  "semweb/rdf_ntriples:rdf_read_ntriples/3": {
    "body":"rdf_read_ntriples(${1:Input}, ${2:Triples}, ${3:Options})$4\n$0",
    "description":"[det]rdf_read_ntriples(+Input, -Triples, +Options).\n",
    "prefix":"rdf_read_ntriples"
  },
  "semweb/rdf_ntriples:rdf_save_turtle/2": {
    "body":"rdf_save_turtle(${1:Out}, ${2:Options})$3\n$0",
    "description":"[det]rdf_save_turtle(+Out, :Options).\nSave an RDF graph as Turtle. Options processed are:  a(+Boolean): If true (default), use a for the predicate rdf:type.  Otherwise use the full resource.\n\nalign_prefixes(+Boolean): Nicely align the @prefix declarations\n\nbase(+Base): Save relative to the given Base\n\ncanonize_numbers(+Boolean): If true (default false), emit numeric  datatypes using Prolog's write to achieve canonical output.\n\ncomment(+Boolean): It true (default), write some informative comments between  the output segments\n\nencoding(+Encoding): Encoding used for the output stream. Default is UTF-8.\n\nexpand(:Goal): Query an alternative graph-representation. See below.\n\nindent(+Column): Indentation for ; -lists. `0' does not indent, but writes on the same  line. Default is 8.\n\ngraph(+Graph): Save only the named graph\n\ngroup(+Boolean): If true (default), using P-O and O-grouping.\n\ninline_bnodes(+Boolean): if true (default), inline bnodes that are used once.\n\nabbreviate_literals(+Boolean): if true (default), omit the type if allowed by turtle.\n\nonly_known_prefixes(+Boolean): Only use prefix notation for known prefixes. Without, some documents  produce huge amounts of prefixes.\n\nprefixes(+List): If provided, uses exactly these prefixes. List is a list of  prefix specifications, where each specification is either a term Prefix-URI  or a prefix that is known to rdf_current_prefix/2.\n\nsilent(+Boolean): If true (default false), do not print the  final informational message.\n\nsingle_line_bnodes(+Bool): If true (default false), write [...] and (...)  on a single line.\n\nsubject_white_lines(+Count): Extra white lines to insert between statements about a different  subject. Default is 1.\n\ntab_distance(+Tab): Distance between tab-stops. `0' forces the library to use only spaces  for layout. Default is 8.\n\nuser_prefixes(+Boolean): If true (default), use prefixes from rdf_current_prefix/2.\n\n  The option expand allows for serializing alternative  graph representations. It is called through call/5,  where the first argument is the expand-option, followed by S,P,O,G. G is  the graph-option (which is by default a variable). This notably allows  for writing RDF graphs represented as rdf(S,P,O) using the  following code fragment: \n\n\n\ntriple_in(RDF, S,P,O,_G) :-\n    member(rdf(S,P,O), RDF).\n\n    ...,\n    rdf_save_turtle(Out, [ expand(triple_in(RDF)) ]),\n\n  Out is one of stream(Stream),  a stream handle, a file-URL or an atom that denotes a filename. ",
    "prefix":"rdf_save_turtle"
  },
  "semweb/rdf_ntriples:read_nquad/2": {
    "body":"read_nquad(${1:Stream}, ${2:Quad})$3\n$0",
    "description":"[det]read_nquad(+Stream, -Quad).\nRead the next quad from Stream as Quad. Stream  must have a byte-oriented encoding and must contain pure ASCII text. Quad is a term quad(Subject,Predicate,Object,Graph).  Arguments follow the normal conventions of the RDF libraries. NodeID  elements are mapped to node(Id). If end-of-file is reached, Quad  is unified with end_of_file.   Errors: syntax_error(Message) on syntax errors\n\n ",
    "prefix":"read_nquad"
  },
  "semweb/rdf_ntriples:read_ntriple/2": {
    "body":"read_ntriple(${1:Stream}, ${2:Triple})$3\n$0",
    "description":"[det]read_ntriple(+Stream, -Triple).\nRead the next triple from Stream as Triple. Stream  must have a byte-oriented encoding and must contain pure ASCII text. Triple is a term triple(Subject,Predicate,Object).  Arguments follow the normal conventions of the RDF libraries. NodeID  elements are mapped to node(Id). If end-of-file is reached, Triple  is unified with end_of_file.   Errors: syntax_error(Message) on syntax errors\n\n ",
    "prefix":"read_ntriple"
  },
  "semweb/rdf_ntriples:read_ntuple/2": {
    "body":"read_ntuple(${1:Stream}, ${2:Tuple})$3\n$0",
    "description":"[det]read_ntuple(+Stream, -Tuple).\nRead the next triple or quad from Stream as Tuple. Tuple  is one of the terms below. See read_ntriple/2  and read_nquad/2 for details.  \n\ntriple(Subject,Predicate,Object)\nquad(Subject,Predicate,Object,Graph).\n\n",
    "prefix":"read_ntuple"
  },
  "semweb/rdf_persistency:rdf_attach_db/2": {
    "body":"rdf_attach_db(${1:Directory}, ${2:Options})$3\n$0",
    "description":"rdf_attach_db(+Directory, +Options).\nAttach Directory as the persistent database. If Directory  does not exist it is created. Otherwise all sources defined in the  directory are loaded into the RDF database. Loading a source means  loading the base state (if any) and replaying the journal (if any). The  current implementation does not synchronise triples that are in the  store before attaching a database. They are not removed from the  database, nor added to the presistent store. Different merging options  may be supported through the Options argument later.  Currently defined options are:  concurrency(+PosInt): Number of threads used to reload databased and journals from the files  in Directory. Default is the number of physical CPUs  determined by the Prolog flag cpu_count or 1 (one) on  systems where this number is unknown. See also concurrent/3.\n\nmax_open_journals(+PosInt): The library maintains a pool of open journal files. This option  specifies the size of this pool. The default is 10. Raising the option  can make sense if many writes occur on many different named graphs. The  value can be lowered for scenarios where write operations are very  infrequent.\n\nsilent(Boolean): If true, supress loading messages from rdf_attach_db/2.\n\nlog_nested_transactions(Boolean): If true, nested log transactions are added to the  journal information. By default (false), no log-term is  added for nested transactions.\n\n  The database is locked against concurrent access using a file lock in Directory. An attempt to attach to a  locked database raises a permission_error exception. The  error context contains a term rdf_locked(Args), where args  is a list containing time(Stamp) and pid(PID).  The error can be caught by the application. Otherwise it prints: \n\n\n\nERROR: No permission to lock rdf_db `/home/jan/src/pl/packages/semweb/DB'\nERROR: locked at Wed Jun 27 15:37:35 2007 by process id 1748\n\n ",
    "prefix":"rdf_attach_db"
  },
  "semweb/rdf_persistency:rdf_current_db/1": {
    "body":"rdf_current_db(${1:Directory})$2\n$0",
    "description":"rdf_current_db(-Directory).\nUnify Directory with the current database directory. Fails if  no persistent database is attached.",
    "prefix":"rdf_current_db"
  },
  "semweb/rdf_persistency:rdf_db_to_file/2": {
    "body":"rdf_db_to_file(${1:DB}, ${2:FileBase})$3\n$0",
    "description":"rdf_db_to_file(?DB, ?FileBase).\nConvert between DB (see rdf_source/1)  and file base-file used for storing information on this database. The  full file is located in the directory described by rdf_current_db/1  and has the extension .trp for the base state and .jrn for the  journal.",
    "prefix":"rdf_db_to_file"
  },
  "semweb/rdf_persistency:rdf_detach_db/0": {
    "body":"rdf_detach_db$1\n$0",
    "description":"rdf_detach_db.\nDetaches the persistent store. No triples are removed from the RDF  triple store.",
    "prefix":"rdf_detach_db"
  },
  "semweb/rdf_persistency:rdf_flush_journals/1": {
    "body":"rdf_flush_journals(${1:Options})$2\n$0",
    "description":"rdf_flush_journals(+Options).\nFlush dirty journals. With the option min_size(KB) only  journals larger than KB Kbytes are merged with the base  state. Flushing a journal takes the following steps, ensuring a stable  state can be recovered at any moment. Save the current database in a new file using the extension .new.\nOn success, delete the journal\nOn success, atomically move the .new file over the base  state.\n\n  Note that journals are not merged automatically for two  reasons. First of all, some applications may decide never to merge as  the journal contains a complete changelog of the database.  Second, merging large databases can be slow and the application may wish  to schedule such actions at quiet times or scheduled maintenance  periods.\n\n",
    "prefix":"rdf_flush_journals"
  },
  "semweb/rdf_persistency:rdf_journal_file/2": {
    "body":"rdf_journal_file(${1:DB}, ${2:JournalFile})$3\n$0",
    "description":"rdf_journal_file(?DB, ?JournalFile).\nTrue if File is the absolute file name of an existing named graph DB. A journal file contains a sequence of Prolog terms of the  following format.4Future versions  of this library may use an XML based language neutral format.  start(Attributes): Journal has been opened. Currently Attributes contains a term time(Stamp).\n\nend(Attributes): Journal was closed. Currently Attributes contains a term time(Stamp).\n\nassert(Subject, Predicate, Object): A triple {Subject, Predicate, Object} was added to the database.\n\nassert(Subject, Predicate, Object, Line): A triple {Subject, Predicate, Object} was added to the database with  given Line context.\n\nretract(Subject, Predicate, Object): A triple {Subject, Predicate, Object} was deleted from the database.  Note that an rdf_retractall/3  call can retract multiple triples. Each of them have a record in the  journal. This allows for `undo'.\n\nretract(Subject, Predicate, Object, Line): Same as above, for a triple with associated line info.\n\nupdate(Subject, Predicate, Object, Action): See rdf_update/4.\n\nbegin(Id, Nest, Time, Message): Added before the changes in each database affected by a transaction with  transaction identifier log(Message). Id is an  integer counting the logged transactions to this database. Numbers are  increasing and designed for binary search within the journal file. Nest is the nesting level, where `0' is a toplevel  transaction. Time is a time-stamp, currently using float notation with two  fractional digits. Message is the term provided by the user  as argument of the log(Message) transaction.\n\nend(Id, Nest, Others): Added after the changes in each database affected by a transaction with  transaction identifier log(Message). Id and Nest  match the begin-term. Others gives a list of other databases  affected by this transaction and the Id of these records. The  terms in this list have the format DB:Id.\n\n ",
    "prefix":"rdf_journal_file"
  },
  "semweb/rdf_persistency:rdf_persistency/2": {
    "body":"rdf_persistency(${1:DB}, ${2:Bool})$3\n$0",
    "description":"rdf_persistency(+DB, +Bool).\nChange presistency of named database (4th argument of rdf/4).  By default all databases are presistent. Using false, the  journal and snapshot for the database are deleted and further changes to  triples associated with DB are not recorded. If Bool  is true a snapshot is created for the current state and  further modifications are monitored. Switching persistency does not  affect the triples in the in-memory RDF database.",
    "prefix":"rdf_persistency"
  },
  "semweb/rdf_persistency:rdf_persistency_property/1": {
    "body": ["rdf_persistency_property(${1:Property})$2\n$0" ],
    "description":"  rdf_persistency_property(?Property) is nondet.\n\n   True if Property  is  a  property   of  the  current  persistent\n   database. Currently makes to options   passed to rdf_attach_db/2\n   available.  Notable  rdf_persistency_property(access(read_only))\n   is true if the database  is   mounted  in  read-only mode. Other\n   properties:\n\n     - directory(Dir)\n     Directory in which the database resides.",
    "prefix":"rdf_persistency_property"
  },
  "semweb/rdf_persistency:rdf_snapshot_file/2": {
    "body": ["rdf_snapshot_file(${1:Graph}, ${2:File})$3\n$0" ],
    "description":"  rdf_snapshot_file(+Graph, -File) is semidet.\n  rdf_snapshot_file(-Graph, -File) is nondet.\n\n   True if File the name of the existing snapshot file for Graph.",
    "prefix":"rdf_snapshot_file"
  },
  "semweb/rdf_persistency:rdf_statistics_literal_map/2": {
    "body":"rdf_statistics_literal_map(${1:Map}, ${2:Key(})$3\n$0",
    "description":"rdf_statistics_literal_map(+Map, +Key(-Arg...)).\nQuery some statistics of the map. Provides keys are:  size(-Keys, -Relations): Unify Keys with the total key-count of the index and Relation with the total Key-Value  count.\n\n ",
    "prefix":"rdf_statistics_literal_map"
  },
  "semweb/rdf_portray:rdf_equal_graphs/3": {
    "body":"rdf_equal_graphs(${1:GraphA}, ${2:GraphB}, ${3:Substition})$4\n$0",
    "description":"[semidet]rdf_equal_graphs(+GraphA, +GraphB, -Substition).\nTrue if GraphA and GraphB are the same under Substition. Substition is a list of BNodeA = BNodeB, where BNodeA is a  blank node that appears in GraphA and BNodeB is a blank node  that appears in GraphB. GraphA is a list of rdf(S,P,O)  terms GraphB is a list of rdf(S,P,O)  terms Substition is a list if NodeA =  NodeB terms.   To be done: The current implementation is rather naive. After dealing with the  subgraphs that contain no bnodes, it performs a fully non-deterministic  substitution.\n\n ",
    "prefix":"rdf_equal_graphs"
  },
  "semweb/rdf_portray:rdf_portray_as/1": {
    "body":"rdf_portray_as(${1:Style})$2\n$0",
    "description":"[det]rdf_portray_as(+Style).\nSet the style used to portray resources. Style is one of:  prefix:id: Write as NS:ID, compatible with what can be handed to the rdf  predicates. This is the default.\n\nwriteq: Use quoted write of the full resource.\n\nprefix:label: Write namespace followed by the label. This format cannot be handed to rdf/3  and friends, but can be useful if resource-names are meaningless  identifiers.\n\nprefix:id=label: This combines prefix:id with prefix:label, providing both human readable  output and output that can be pasted into the commandline.\n\n ",
    "prefix":"rdf_portray_as"
  },
  "semweb/rdf_portray:rdf_portray_lang/1": {
    "body":"rdf_portray_lang(${1:Lang})$2\n$0",
    "description":"[det]rdf_portray_lang(+Lang).\nIf Lang is a list, set the list or preferred languages. If it  is a single atom, push this language as the most preferred language.",
    "prefix":"rdf_portray_lang"
  },
  "semweb/rdf_turtle:rdf_load_turtle/3": {
    "body": [
      "rdf_load_turtle(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_load_turtle('Param1','Param2','Param3')",
    "prefix":"rdf_load_turtle"
  },
  "semweb/rdf_turtle:rdf_process_turtle/3": {
    "body": [
      "rdf_process_turtle(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_process_turtle('Param1','Param2','Param3')",
    "prefix":"rdf_process_turtle"
  },
  "semweb/rdf_turtle:rdf_read_turtle/3": {
    "body": [
      "rdf_read_turtle(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"rdf_read_turtle('Param1','Param2','Param3')",
    "prefix":"rdf_read_turtle"
  },
  "semweb/rdf_turtle_write:rdf_save_canonical_trig/2": {
    "body": ["rdf_save_canonical_trig(${1:Spec}, ${2:Options})$3\n$0" ],
    "description":"  rdf_save_canonical_trig(+Spec, :Options) is det.\n\n   Save     triples     in     a      canonical     format.     See\n   rdf_save_canonical_turtle/2 foir details.",
    "prefix":"rdf_save_canonical_trig"
  },
  "semweb/rdf_turtle_write:rdf_save_canonical_turtle/2": {
    "body": ["rdf_save_canonical_turtle(${1:Spec}, ${2:Options})$3\n$0" ],
    "description":"  rdf_save_canonical_turtle(+Spec, :Options) is det.\n\n   Save triples in  a  canonical  format.   This  is  the  same  as\n   rdf_save_turtle/2, but using different defaults. In particular:\n\n       * encoding(utf8),\n       * indent(0),\n       * tab_distance(0),\n       * subject_white_lines(1),\n       * align_prefixes(false),\n       * user_prefixes(false)\n       * comment(false),\n       * group(false),\n       * single_line_bnodes(true)\n\n   @tbd Work in progress. Notably blank-node handling is\n   incomplete.",
    "prefix":"rdf_save_canonical_turtle"
  },
  "semweb/rdf_turtle_write:rdf_save_ntriples/2": {
    "body": ["rdf_save_ntriples(${1:Spec}, ${2:Options})$3\n$0" ],
    "description":"  rdf_save_ntriples(+Spec, :Options) is det.\n\n   Save RDF using ntriples format. The  ntriples format is a subset\n   of Turtle, writing each triple fully qualified on its own line.",
    "prefix":"rdf_save_ntriples"
  },
  "semweb/rdf_turtle_write:rdf_save_trig/2": {
    "body": ["rdf_save_trig(${1:Spec}, ${2:Options})$3\n$0" ],
    "description":"  rdf_save_trig(+Spec, :Options) is det.\n\n   Save multiple RDF graphs into a TriG  file. Options are the same\n   as   for   rdf_save_turtle/2.   rdf_save_trig/2    ignores   the\n   graph(+Graph)  option  and  instead   processes  one  additional\n   option:\n\n     - graphs(+ListOfGraphs)\n     List of graphs to save. When omitted, all graphs in the RDF\n     store are stored in the TriG file.",
    "prefix":"rdf_save_trig"
  },
  "semweb/rdf_turtle_write:rdf_save_turtle/2": {
    "body": ["rdf_save_turtle(${1:Out}, ${2:Options})$3\n$0" ],
    "description":"  rdf_save_turtle(+Out, :Options) is det.\n\n   Save an RDF graph as Turtle.  Options processed are:\n\n       * a(+Boolean)\n       If =true= (default), use =a= for the predicate =rdf:type=.\n       Otherwise use the full resource.\n       * align_prefixes(+Boolean)\n       Nicely align the @prefix declarations\n       * base(+Base)\n       Save relative to the given Base\n       * canonize_numbers(+Boolean)\n       If =true= (default =false=), emit numeric datatypes using\n       Prolog's write to achieve canonical output.\n       * comment(+Boolean)\n       It =true= (default), write some informative comments\n       between the output segments\n       * encoding(+Encoding)\n       Encoding used for the output stream.  Default is UTF-8.\n       * expand(:Goal)\n       Query an alternative graph-representation.  See below.\n       * indent(+Column)\n       Indentation for ; -lists.  `0' does not indent, but\n       writes on the same line.  Default is 8.\n       * graph(+Graph)\n       Save only the named graph\n       * group(+Boolean)\n       If =true= (default), using P-O and O-grouping.\n       * inline_bnodes(+Boolean)\n       if =true= (default), inline bnodes that are used once.\n       * abbreviate_literals(+Boolean)\n       if =true= (default), omit the type if allowed by turtle.\n       * only_known_prefixes(+Boolean)\n       Only use prefix notation for known prefixes.  Without, some\n       documents produce _huge_ amounts of prefixes.\n       * prefixes(+List)\n       If provided, uses exactly these prefixes.  List is a list\n       of prefix specifications, where each specification is either\n       a term _Prefix_-_URI_ or a prefix that is known to\n       rdf_current_prefix/2.\n       * silent(+Boolean)\n       If =true= (default =false=), do not print the final\n       informational message.\n       * single_line_bnodes(+Bool)\n       If =true= (default =false=), write [...] and (...) on a\n       single line.\n       * subject_white_lines(+Count)\n       Extra white lines to insert between statements about a\n       different subject.  Default is 1.\n       * tab_distance(+Tab)\n       Distance between tab-stops.  `0' forces the library to\n       use only spaces for layout.  Default is 8.\n       * user_prefixes(+Boolean)\n       If =true= (default), use prefixes from rdf_current_prefix/2.\n\n   The option =expand= allows  for   serializing  alternative graph\n   representations. It is called through   call/5,  where the first\n   argument is the expand-option, followed  by   S,P,O,G.  G is the\n   graph-option (which is by  default   a  variable).  This notably\n   allows for writing RDF graphs   represented  as rdf(S,P,O) using\n   the following code fragment:\n\n       ==\n       triple_in(RDF, S,P,O,_G) :-\n           member(rdf(S,P,O), RDF).\n\n           ...,\n           rdf_save_turtle(Out, [ expand(triple_in(RDF)) ]),\n       ==\n\n   @param  Out is one of stream(Stream), a stream handle, a file-URL\n           or an atom that denotes a filename.",
    "prefix":"rdf_save_turtle"
  },
  "semweb/rdfa:read_rdfa/3": {
    "body":"read_rdfa(${1:Input}, ${2:Triples}, ${3:Options})$4\n$0",
    "description":"[det]read_rdfa(+Input, -Triples, +Options).\nTrue when Triples is a list of rdf(S,P,O)  triples extracted from Input. Input is either a stream, a file name, a  URL referencing a file name or a URL that is valid for http_open/3. Options  are passed to open/4, http_open/3  and xml_rdfa/3. If no base is  provided in Options, a base is deduced from Input.",
    "prefix":"read_rdfa"
  },
  "semweb/rdfa:xml_rdfa/3": {
    "body":"xml_rdfa(${1:DOM}, ${2:RDF}, ${3:Options})$4\n$0",
    "description":"xml_rdfa(+DOM, -RDF, +Options).\nTrue when RDF is a list of rdf(S,P,O) terms  extracted from DOM according to the RDFa specification. Options  processed:  base(+BaseURI): URI to use for ''. Normally set to the document URI.\n\nanon_prefix(+AnnonPrefix): Prefix for blank nodes.\n\nlang(+Lang): Default for lang\n\nvocab(+Vocab): Default for vocab\n\nmarkup(+Markup): Markup language processed (xhtml, xml, ...)\n\n ",
    "prefix":"xml_rdfa"
  },
  "semweb/rdfs:rdf_attach_library/1": {
    "body":"rdf_attach_library(${1:FileOrDirectory})$2\n$0",
    "description":"rdf_attach_library(+FileOrDirectory).\nLoad meta-data on RDF repositories from FileOrDirectory. If  the argument is a directory, this directory is processed recursively and  each for each directory, a file named void.ttl, Manifest.ttl or Manifest.rdf is loaded (in  this order of preference).  Declared namespaces are added to the rdf-db namespace list.  Encountered ontologies are added to a private database of rdf_list_library.pl. Each ontology is given an identifier, derived from the basename of the URL without the  extension. This, using the declaration below, the identifier of the  declared ontology is wn-basic. \n\n\n\n<wn-basic>\n        a void:Dataset ;\n        dcterms:title \"Basic WordNet\" ;\n        ...\n\n ",
    "prefix":"rdf_attach_library"
  },
  "semweb/rdfs:rdf_list_library/0": {
    "body":"rdf_list_library$1\n$0",
    "description":"rdf_list_library.\nList the available resources in the library. Currently only lists  resources that have a dcterms:title property. See section  9.2 for an example.",
    "prefix":"rdf_list_library"
  },
  "semweb/rdfs:rdf_list_library/1": {
    "body":"rdf_list_library(${1:Id})$2\n$0",
    "description":"rdf_list_library(+Id).\nSame as rdf_list_library(Id,[]).",
    "prefix":"rdf_list_library"
  },
  "semweb/rdfs:rdf_list_library/2": {
    "body":"rdf_list_library(${1:Id}, ${2:Options})$3\n$0",
    "description":"rdf_list_library(+Id, +Options).\nLists the resources that will be loaded if Id is handed to rdf_load_library/2.  See rdf_attach_library/1  for how ontology identifiers are generated. In addition it checks the  existence of each resource to help debugging library dependencies.  Before doing its work, rdf_list_library/2  reloads manifests that have changed since they were loaded the last  time. For HTTP resources it uses the HEAD method to verify existence and  last modification time of resources.",
    "prefix":"rdf_list_library"
  },
  "semweb/rdfs:rdf_load_library/2": {
    "body":"rdf_load_library(${1:Id}, ${2:Options})$3\n$0",
    "description":"rdf_load_library(+Id, +Options).\nLoad the given library. First rdf_load_library/2  will establish what resources need to be loaded and whether all  resources exist. Than it will load the resources.",
    "prefix":"rdf_load_library"
  },
  "semweb/rdfs:rdfs_assert_list/2": {
    "body":"rdfs_assert_list(${1:List}, ${2:Resource})$3\n$0",
    "description":"rdfs_assert_list(+List, -Resource).\nEquivalent to rdfs_assert_list/3  using DB = user.",
    "prefix":"rdfs_assert_list"
  },
  "semweb/rdfs:rdfs_assert_list/3": {
    "body":"rdfs_assert_list(${1:List}, ${2:Resource}, ${3:DB})$4\n$0",
    "description":"rdfs_assert_list(+List, -Resource, +DB).\nIf List is a list of resources, create an RDF list Resource  that reflects these resources. Resource and the sublist  resources are generated with rdf_bnode/1.  The new triples are associated with the database DB.",
    "prefix":"rdfs_assert_list"
  },
  "semweb/rdfs:rdfs_class_property/2": {
    "body":"rdfs_class_property(${1:Class}, ${2:Property})$3\n$0",
    "description":"rdfs_class_property(+Class, ?Property).\nTrue if the domain of Property includes Class.  Used to generate all properties that apply to a class.",
    "prefix":"rdfs_class_property"
  },
  "semweb/rdfs:rdfs_find/5": {
    "body": [
      "rdfs_find(${1:String}, ${2:Domain}, ${3:Properties}, ${4:Method}, ${5:Subject})$6\n$0"
    ],
    "description":"  rdfs_find(+String, +Domain, ?Properties, +Method, -Subject)\n\n   Search all classes below Domain for a literal property with\n   that matches String.  Method is one of\n\n           * substring\n           * word\n           * prefix\n           * exact\n\n   domain is defined by owl_satisfy from owl.pl\n\n   Note that the rdfs:label field is handled by rdfs_label/2,\n   making the URI-ref fragment name the last resort to determine\n   the label.",
    "prefix":"rdfs_find"
  },
  "semweb/rdfs:rdfs_individual_of/2": {
    "body":"rdfs_individual_of(${1:Resource}, ${2:Class})$3\n$0",
    "description":"rdfs_individual_of(?Resource, ?Class).\nTrue if Resource is an indivisual of Class. This  implies Resource has an rdf:type property that refers to Class or a sub-class thereof. Can be used to test, generate  classes Resource belongs to or generate individuals described  by Class.",
    "prefix":"rdfs_individual_of"
  },
  "semweb/rdfs:rdfs_label/2": {
    "body": ["rdfs_label(${1:Resource}, ${2:Label})$3\n$0" ],
    "description":"  rdfs_label(+Resource, -Label).\n  rdfs_label(-Resource, +Label).\n\n   Convert between class and label.  If the label is generated from\n   the resource the it uses both rdfs:label and its sub-properties,\n   but labels registered with rdfs:label are returned first.",
    "prefix":"rdfs_label"
  },
  "semweb/rdfs:rdfs_label/3": {
    "body": ["rdfs_label(${1:Resource}, ${2:Lang}, ${3:Label})$4\n$0" ],
    "description":"  rdfs_label(+Resource, ?Lang, -Label) is multi.\n  rdfs_label(+Resource, ?Lang, +Label) is semidet.\n  rdfs_label(-Resource, ?Lang, ?Label) is nondet.\n\n   Resource  has  Label  in  Lang.  If  Resource  is  nonvar  calls\n   take_label/3 which is guaranteed to succeed label.",
    "prefix":"rdfs_label"
  },
  "semweb/rdfs:rdfs_list_to_prolog_list/2": {
    "body":"rdfs_list_to_prolog_list(${1:Set}, ${2:List})$3\n$0",
    "description":"rdfs_list_to_prolog_list(+Set, -List).\nConvert Set, which must be an individual of rdf:List  into a Prolog list of objects.",
    "prefix":"rdfs_list_to_prolog_list"
  },
  "semweb/rdfs:rdfs_member/2": {
    "body":"rdfs_member(${1:Resource}, ${2:Set})$3\n$0",
    "description":"rdfs_member(?Resource, +Set).\nTest or generate the members of Set. Set is either  an individual of rdf:List or rdfs:Container.",
    "prefix":"rdfs_member"
  },
  "semweb/rdfs:rdfs_ns_label/2": {
    "body": ["rdfs_ns_label(${1:Resource}, ${2:Label})$3\n$0" ],
    "description":"  rdfs_ns_label(+Resource, -Label) is multi.\n  rdfs_ns_label(+Resource, ?Lang, -Label) is multi.\n\n   Present label with  namespace  indication.   This  predicate  is\n   intended  to  provide  meaningful  short   names  applicable  to\n   ontology maintainers.  Note that this predicate is non-deterministic\n   if the resource has multiple rdfs:label properties",
    "prefix":"rdfs_ns_label"
  },
  "semweb/rdfs:rdfs_ns_label/3": {
    "body": ["rdfs_ns_label(${1:Resource}, ${2:Lang}, ${3:Label})$4\n$0" ],
    "description":"  rdfs_ns_label(+Resource, -Label) is multi.\n  rdfs_ns_label(+Resource, ?Lang, -Label) is multi.\n\n   Present label with  namespace  indication.   This  predicate  is\n   intended  to  provide  meaningful  short   names  applicable  to\n   ontology maintainers.  Note that this predicate is non-deterministic\n   if the resource has multiple rdfs:label properties",
    "prefix":"rdfs_ns_label"
  },
  "semweb/rdfs:rdfs_subclass_of/2": {
    "body":"rdfs_subclass_of(${1:SubClass}, ${2:Class})$3\n$0",
    "description":"rdfs_subclass_of(?SubClass, ?Class).\nTrue if SubClass is equal to Class or Class  can be reached from SubClass following the rdfs:subClassOf relation. It can be used to test as well as  generate sub-classes or super-classes.bugThe  current implementation cannot deal with cycles.",
    "prefix":"rdfs_subclass_of"
  },
  "semweb/rdfs:rdfs_subproperty_of/2": {
    "body":"rdfs_subproperty_of(${1:SubProperty}, ${2:Property})$3\n$0",
    "description":"rdfs_subproperty_of(?SubProperty, ?Property).\nTrue if SubProperty is equal to Property or Property  can be reached from SubProperty following the rdfs:subPropertyOf relation. It can be used to test as well  as generate sub-properties or super-properties. Note that the commonly  used semantics of this predicate is wired into rdf_has/[3,4].bugThe  current implementation cannot deal with cycles.bugThe  current implementation cannot deal with predicates that are an rdfs:subPropertyOf  of rdfs:subPropertyOf, such as owl:samePropertyAs.",
    "prefix":"rdfs_subproperty_of"
  },
  "semweb/sparql_client:rdf_load_library/2": {
    "body":"rdf_load_library(${1:Id}, ${2:Options})$3\n$0",
    "description":"rdf_load_library(+Id, +Options).\nLoad the given library. First rdf_load_library/2  will establish what resources need to be loaded and whether all  resources exist. Than it will load the resources.",
    "prefix":"rdf_load_library"
  },
  "semweb/sparql_client:sparql_query/3": {
    "body":"sparql_query(${1:Query}, ${2:Result}, ${3:Options})$4\n$0",
    "description":"[nondet]sparql_query(+Query, -Result, +Options).\nExecute a SPARQL query on an HTTP SPARQL endpoint. Query is  an atom that denotes the query. Result is unified to a term rdf(S,P,O) for CONSTRUCT and DESCRIBE  queries, row(...) for SELECT queries and true or false  for ASK queries. Options are  host(+Host): port(+Port): path(+Path): The above three options set the location of the server.\n\nsearch(+ListOfParams): Provide additional query parameters, such as the graph.\n\nvariable_names(-ListOfNames): Unifies ListOfNames with a list of atoms that describe the  names of the variables in a SELECT query.\n\n  Remaining options are passed to http_open/3.  The defaults for Host, Port and Path can be set using sparql_set_server/1.  The initial default for port is 80 and path is /sparql/. \n\nFor example, the ClioPatria server understands the parameter entailment. The code below queries for all triples using  _rdfs_entailment. \n\n\n\n?- sparql_query('select * where { ?s ?p ?o }',\n                Row,\n                [ search([entailment=rdfs])\n                ]).\n\n ",
    "prefix":"sparql_query"
  },
  "semweb/sparql_client:sparql_read_json_result/2": {
    "body":"sparql_read_json_result(${1:Input}, ${2:Result})$3\n$0",
    "description":"[det]sparql_read_json_result(+Input, -Result).\nThe returned Result term is of the format:  select(VarNames, Rows): Where VarNames is a term v(Name, ...) and Rows  is a list of row(....) containing the column values in the  same order as the variable names.\n\nask(Bool): Where Bool is either true or false\n\n  See also: http://www.w3.org/TR/rdf-sparql-json-res/\n\n ",
    "prefix":"sparql_read_json_result"
  },
  "semweb/sparql_client:sparql_read_xml_result/2": {
    "body":"sparql_read_xml_result(${1:Input}, ${2:Result})$3\n$0",
    "description":"sparql_read_xml_result(+Input, -Result).\nSpecs from http://www.w3.org/TR/rdf-sparql-XMLres/.  The returned Result term is of the format:  select(VarNames, Rows): Where VarNames is a term v(Name, ...) and Rows  is a list of row(....) containing the column values in the  same order as the variable names.\n\nask(Bool): Where Bool is either true or false\n\n ",
    "prefix":"sparql_read_xml_result"
  },
  "semweb/sparql_client:sparql_set_server/1": {
    "body":"sparql_set_server(${1:OptionOrList})$2\n$0",
    "description":"sparql_set_server(+OptionOrList).\nSet sparql server default options. Provided defaults are: host, port and  repository. For example:  \n\n    sparql_set_server([ host(localhost),\n                        port(8080)\n                        path(world)\n                      ])\n\n  The default for port is 80 and path is /sparql/.\n\n",
    "prefix":"sparql_set_server"
  },
  "semweb/turtle:rdf_db_to_file/2": {
    "body":"rdf_db_to_file(${1:DB}, ${2:FileBase})$3\n$0",
    "description":"rdf_db_to_file(?DB, ?FileBase).\nConvert between DB (see rdf_source/1)  and file base-file used for storing information on this database. The  full file is located in the directory described by rdf_current_db/1  and has the extension .trp for the base state and .jrn for the  journal.",
    "prefix":"rdf_db_to_file"
  },
  "semweb/turtle:rdf_load_turtle/3": {
    "body":"rdf_load_turtle(${1:Input}, ${2:Triples}, ${3:Options})$4\n$0",
    "description":"rdf_load_turtle(+Input, -Triples, +Options).\n deprecated: Use rdf_read_turtle/3\n\n ",
    "prefix":"rdf_load_turtle"
  },
  "semweb/turtle:rdf_process_turtle/3": {
    "body":"rdf_process_turtle(${1:Input}, ${2:OnObject}, ${3:Options})$4\n$0",
    "description":"[det]rdf_process_turtle(+Input, :OnObject, +Options).\nStreaming Turtle parser. The predicate rdf_process_turtle/3  processes Turtle data from Input, calling OnObject  with a list of triples for every Turtle statement found in Input. OnObject  is called as below, where ListOfTriples is a list of rdf(S,P,O) terms for a normal Turtle file or rdf(S,P,O,G)  terms if the GRAPH keyword is used to associate a set of  triples in the document with a particular graph. The Graph  argument provides the default graph for storing the triples and Line  is the line number where the statement started.  \n\ncall(OnObject, ListOfTriples, Graph:Line)\n\n  This predicate supports the same Options as rdf_load_turtle/3. \n\nErrors encountered are sent to print_message/2,  after which the parser tries to recover and parse the remainder of the  data. \n\nSee also: This predicate is normally used by load_rdf/2  for processing RDF data.\n\n ",
    "prefix":"rdf_process_turtle"
  },
  "semweb/turtle:rdf_read_turtle/3": {
    "body":"rdf_read_turtle(${1:Input}, ${2:Triples}, ${3:Options})$4\n$0",
    "description":"rdf_read_turtle(+Input, -Triples, +Options).\nRead a stream or file into a set of triples or quadruples (if faced with  TRiG input) of the format  \n\nrdf(Subject, Predicate, Object [, Graph])\n\n  The representation is consistent with the SWI-Prolog RDF/XML and  ntriples parsers. Provided options are: \n\nbase_uri(+BaseURI): Initial base URI. Defaults to file://<file>  for loading files.\n\nanon_prefix(+Prefix): Blank nodes are generated as <Prefix>1, <Prefix>2,  etc. If Prefix is not an atom blank nodes are generated as node(1), node(2), ...\n\nformat(+Format): One of auto (default), turtle or trig.  The auto mode switches to TRiG format of there is a { before the first triple. Finally, of the format is  explicitly stated as turtle and the file appears to be a  TRiG file, a warning is printed and the data is loaded while ignoring  the graphs.\n\nresources(URIorIRI): Officially, Turtle resources are IRIs. Quite a few applications however  send URIs. By default we do URI->IRI mapping because  this rarely causes errors. To force strictly conforming mode, pass iri.\n\nprefixes(-Pairs): Return encountered prefix declarations as a list of Alias-URI\n\nnamespaces(-Pairs): Same as prefixes(Pairs). Compatibility to rdf_load/2.\n\nbase_used(-Base): Base URI used for processing the data. Unified to [] if there is no base-uri.\n\non_error(+ErrorMode): In warning (default), print the error and continue parsing  the remainder of the file. If error, abort with an  exception on the first error encountered.\n\nerror_count(-Count): If on_error(warning) is active, this option cane be used to  retrieve the number of generated errors.\n\n  Input is one of stream(Stream), atom(Atom),  a http, https or file url or a filename specification  as accepted by absolute_file_name/3. ",
    "prefix":"rdf_read_turtle"
  },
  "semweb/turtle:rdf_save_canonical_trig/2": {
    "body":"rdf_save_canonical_trig(${1:Spec}, ${2:Options})$3\n$0",
    "description":"[det]rdf_save_canonical_trig(+Spec, :Options).\nSave triples in a canonical format. See rdf_save_canonical_turtle/2  foir details.",
    "prefix":"rdf_save_canonical_trig"
  },
  "semweb/turtle:rdf_save_canonical_turtle/2": {
    "body":"rdf_save_canonical_turtle(${1:Spec}, ${2:Options})$3\n$0",
    "description":"[det]rdf_save_canonical_turtle(+Spec, :Options).\nSave triples in a canonical format. This is the same as rdf_save_turtle/2, but  using different defaults. In particular:  \n\nencoding(utf8),\nindent(0),\ntab_distance(0),\nsubject_white_lines(1),\nalign_prefixes(false),\nuser_prefixes(false)\ncomment(false),\ngroup(false),\nsingle_line_bnodes(true)\n\n  To be done: Work in progress. Notably blank-node handling is incomplete.\n\n ",
    "prefix":"rdf_save_canonical_turtle"
  },
  "semweb/turtle:rdf_save_ntriples/2": {
    "body":"rdf_save_ntriples(${1:Spec}, ${2:Options})$3\n$0",
    "description":"[det]rdf_save_ntriples(+Spec, :Options).\nSave RDF using ntriples format. The ntriples format is a subset of  Turtle, writing each triple fully qualified on its own line.",
    "prefix":"rdf_save_ntriples"
  },
  "semweb/turtle:rdf_save_trig/2": {
    "body":"rdf_save_trig(${1:Spec}, ${2:Options})$3\n$0",
    "description":"[det]rdf_save_trig(+Spec, :Options).\nSave multiple RDF graphs into a TriG file. Options are the  same as for rdf_save_turtle/2. rdf_save_trig/2  ignores the graph(+Graph) option and instead processes one additional  option:  graphs(+ListOfGraphs): List of graphs to save. When omitted, all graphs in the RDF store are  stored in the TriG file.\n\n ",
    "prefix":"rdf_save_trig"
  },
  "semweb/turtle:rdf_save_turtle/2": {
    "body":"rdf_save_turtle(${1:Out}, ${2:Options})$3\n$0",
    "description":"[det]rdf_save_turtle(+Out, :Options).\nSave an RDF graph as Turtle. Options processed are:  a(+Boolean): If true (default), use a for the predicate rdf:type.  Otherwise use the full resource.\n\nalign_prefixes(+Boolean): Nicely align the @prefix declarations\n\nbase(+Base): Save relative to the given Base\n\ncanonize_numbers(+Boolean): If true (default false), emit numeric  datatypes using Prolog's write to achieve canonical output.\n\ncomment(+Boolean): It true (default), write some informative comments between  the output segments\n\nencoding(+Encoding): Encoding used for the output stream. Default is UTF-8.\n\nexpand(:Goal): Query an alternative graph-representation. See below.\n\nindent(+Column): Indentation for ; -lists. `0' does not indent, but writes on the same  line. Default is 8.\n\ngraph(+Graph): Save only the named graph\n\ngroup(+Boolean): If true (default), using P-O and O-grouping.\n\ninline_bnodes(+Boolean): if true (default), inline bnodes that are used once.\n\nabbreviate_literals(+Boolean): if true (default), omit the type if allowed by turtle.\n\nonly_known_prefixes(+Boolean): Only use prefix notation for known prefixes. Without, some documents  produce huge amounts of prefixes.\n\nprefixes(+List): If provided, uses exactly these prefixes. List is a list of  prefix specifications, where each specification is either a term Prefix-URI  or a prefix that is known to rdf_current_prefix/2.\n\nsilent(+Boolean): If true (default false), do not print the  final informational message.\n\nsingle_line_bnodes(+Bool): If true (default false), write [...] and (...)  on a single line.\n\nsubject_white_lines(+Count): Extra white lines to insert between statements about a different  subject. Default is 1.\n\ntab_distance(+Tab): Distance between tab-stops. `0' forces the library to use only spaces  for layout. Default is 8.\n\nuser_prefixes(+Boolean): If true (default), use prefixes from rdf_current_prefix/2.\n\n  The option expand allows for serializing alternative  graph representations. It is called through call/5,  where the first argument is the expand-option, followed by S,P,O,G. G is  the graph-option (which is by default a variable). This notably allows  for writing RDF graphs represented as rdf(S,P,O) using the  following code fragment: \n\n\n\ntriple_in(RDF, S,P,O,_G) :-\n    member(rdf(S,P,O), RDF).\n\n    ...,\n    rdf_save_turtle(Out, [ expand(triple_in(RDF)) ]),\n\n  Out is one of stream(Stream),  a stream handle, a file-URL or an atom that denotes a filename. ",
    "prefix":"rdf_save_turtle"
  },
  "set_end_of_stream/1": {
    "body":"set_end_of_stream(${1:Stream})$2\n$0",
    "description":"set_end_of_stream(+Stream).\nSet the size of the file opened as Stream to the current file  position. This is typically used in combination with the open-mode update.",
    "prefix":"set_end_of_stream"
  },
  "set_flag/2": {
    "body":"set_flag(${1:Key}, ${2:Value})$3\n$0",
    "description":"set_flag(+Key, Value).\nSet flag Key to Value. Value must be an atom,  small (64-bit) integer or float.",
    "prefix":"set_flag"
  },
  "set_input/1": {
    "body":"set_input(${1:Stream})$2\n$0",
    "description":"[ISO]set_input(+Stream).\nSet the current input stream to become Stream. Thus, open(file,  read, Stream), set_input(Stream) is equivalent to see(file).",
    "prefix":"set_input"
  },
  "set_locale/1": {
    "body":"set_locale(${1:Locale})$2\n$0",
    "description":"set_locale(+Locale).\nSet the default locale for the current thread, as well as the locale for  the standard streams (user_input, user_output, user_error, current_output and current_input.  This locale is used for new streams, unless overruled using the locale(Locale) option of open/4  or set_stream/2.",
    "prefix":"set_locale"
  },
  "set_module/1": {
    "body":"set_module(${1:Property})$2\n$0",
    "description":"set_module(:Property).\nModify properties of the module. Currently, the following properties may  be modified:  base(+Base): Set the default import module of the current module to Module.  Typically, Module is one of user or system.  See section 6.9.\n\nclass(+Class): Set the class of the module. See module_property/2.\n\nprogram_space(+Bytes): Maximum amount of memory used to store the predicates defined inside the  module. Raises a permission error if the current usage is above the  requested limit. Setting the limit to 0 (zero) removes the limit. An  attempt to assert clauses that causes the limit to be exceeded causes a resource_error(program_space) exception. See assertz/1  and module_property/2.\n\n ",
    "prefix":"set_module"
  },
  "set_output/1": {
    "body":"set_output(${1:Stream})$2\n$0",
    "description":"[ISO]set_output(+Stream).\nSet the current output stream to become Stream. See also with_output_to/2.",
    "prefix":"set_output"
  },
  "set_prolog_IO/3": {
    "body":"set_prolog_IO(${1:In}, ${2:Out}, ${3:Error})$4\n$0",
    "description":"set_prolog_IO(+In, +Out, +Error).\nPrepare the given streams for interactive behaviour normally associated  to the terminal. In becomes the user_input and current_input of the calling thread. Out becomes user_output and current_output. If Error  equals Out an unbuffered stream is associated to the same  destination and linked to user_error. Otherwise Error  is used for user_error. Output buffering for Out is set to line and buffering on Error is disabled. See  also prolog/0  and set_stream/2.  The clib package provides the library library(prolog_server),  creating a TCP/IP server for creating an interactive session to Prolog.",
    "prefix":"set_prolog_IO"
  },
  "set_prolog_flag/2": {
    "body":"set_prolog_flag(${1:Key}, ${2:Value})$3\n$0",
    "description":"[ISO]set_prolog_flag(:Key, +Value).\nDefine a new Prolog flag or change its value. Key is an atom.  If the flag is a system-defined flag that is not marked changeable above, an attempt to modify the flag yields a permission_error. If the provided Value does not  match the type of the flag, a type_error is raised.  Some flags (e.g., unknown)  are maintained on a per-module basis. The addressed module is determined  by the Key argument. \n\nIn addition to ISO, SWI-Prolog allows for user-defined Prolog flags.  The type of the flag is determined from the initial value and cannot be  changed afterwards. Defined types are boolean (if the  initial value is one of false, true, on  or off), atom if the initial value is any other atom, integer  if the value is an integer that can be expressed as a 64-bit signed  value. Any other initial value results in an untyped flag that can  represent any valid Prolog term. \n\nThe behaviour when Key denotes a non-existent key depends  on the Prolog flag user_flags.  The default is to define them silently. New code is encouraged to use create_prolog_flag/3  for portability.\n\n",
    "prefix":"set_prolog_flag"
  },
  "set_prolog_stack/2": {
    "body":"set_prolog_stack(${1:Stack}, ${2:KeyValue})$3\n$0",
    "description":"set_prolog_stack(+Stack, +KeyValue).\nSet a parameter for one of the Prolog runtime stacks. Stack  is one of local, global, trail or argument.  The table below describes the Key(Value) pairs. Value  can be an arithmetic integer expression. For example, to specify a 2GB  limit for the global stack, one can use:  \n\n?- set_prolog_stack(global, limit(2*10**9)).\n\n  Current settings can be retrieved with prolog_stack_property/2. \n\nlimit(+Bytes): Set the limit to which the stack is allowed to grow. If the specified  value is lower than the current usage a permission_error is  raised. If the limit is larger than supported, the system silently  reduces the requested limit to the system limit.\n\nmin_free(+Cells): Minimum amount of free space after trimming or shifting the stack.  Setting this value higher can reduce the number of garbage collections  and stack-shifts at the cost of higher memory usage. The spare stack  amount is reported and specified in `cells'. A cell is 4 bytes in the  32-bit version and 8 bytes on the 64-bit version. See address_bits.  See also trim_stacks/0  and debug/0.\n\nspare(+Cells): All stacks trigger overflow before actually reaching the limit, so the  resulting error can be handled gracefully. The spare stack is used for print_message/2  from the garbage collector and for handling exceptions. The default  suffices, unless the user redefines related hooks. Do not specify large values for this because it reduces the amount  of memory available for your real task.  Related hooks are message_hook/3  (redefining GC messages), prolog_trace_interception/4  and prolog_exception_hook/4.\n\n ",
    "prefix":"set_prolog_stack"
  },
  "set_random/1": {
    "body":"set_random(${1:Option})$2\n$0",
    "description":"set_random(+Option).\nControls the random number generator accessible through the functions random/1  and random_float/0.  Note that the library library(random) provides an  alternative API to the same random primitives.  seed(+Seed): Set the seed of the random generator for this thread. Seed is  an integer or the atom random. If random,  repeat the initialization procedure described with the function random/1. Here is  an example:  \n\n?- set_random(seed(111)), A is random(6).\nA = 5.\n?- set_random(seed(111)), A is random(6).\nA = 5.\n\n \n\nstate(+State): Set the generator to a state fetched using the state property of random_property/1.  Using other values may lead to undefined behaviour.111The  limitations of the underlying (GMP) library are unknown, which makes it  impossible to validate the State.\n\n ",
    "prefix":"set_random"
  },
  "set_sgml_parser/2": {
    "body":"set_sgml_parser(${1:Parser}, ${2:Option})$3\n$0",
    "description":"set_sgml_parser(+Parser, +Option).\nSets attributes to the parser. Currently defined attributes:  file(File): Sets the file for reporting errors and warnings. Sets the line to 1.\n\nline(Line): Sets the current line. Useful if the stream is not at the start of the  (file) object for generating proper line-numbers.\n\nlinepos(LinePos): Sets notion of the current column in the source line.\n\ncharpos(Offset): Sets the current character location. See also the file(File)  option.\n\nposition(Position): Set source location from a stream position term as obtained using stream_property(Stream, position(Position)).\n\ndialect(Dialect): Set the markup dialect. Known dialects:  sgmlThe default dialect is to process as SGML. This implies markup is  case-insensitive and standard SGML abbreviation is allowed (abreviated  attributes and omitted tags).htmlhtml4This is the same as sgml, but implies shorttag(false)  and accepts XML empty element declarations (e.g., <img src=\"...\"/>).html5In addition to html, accept attributes named data-  without warning. This value initialises the charset to UTF-8.xhtmlxhtml5These document types are processed as xml. Dialect xhtml5 accepts attributes named data- without  warning.xmlThis dialect is selected automatically if the processing instruction <?xml ...> is encountered. See section  3.3 for details.xmlnsProcess file as XML file with namespace support. See section  3.3.1 for details. See also the qualify_attributes  option below. \n\nxmlns(+URI): Set the default namespace of the outer environment. This option is  provided to process partial XML content with proper namespace  resolution.\n\nxmlns(+NS, +URI): Specify a namespace for the outer environment. This option is provided  to process partial XML content with proper namespace resolution.\n\nqualify_attributes(Boolean): How to handle unqualified attribute (i.e. without an explicit namespace)  in XML namespace (xmlns) mode. Default and standard  compliant is not to qualify such elements. If true, such  attributes are qualified with the namespace of the element they appear  in. This option is for backward compatibility as this is the behaviour  of older versions. In addition, the namespace document suggests  unqualified attributes are often interpreted in the namespace of their  element.\n\nspace(SpaceMode): Define the initial handling of white-space in PCDATA. This attribute is  described in section 3.2.\n\nnumber(NumberMode): If token (default), attributes of type number are passed as  a Prolog atom. If integer, such attributes are translated  into Prolog integers. If the conversion fails (e.g. due to overflow) a  warning is issued and the value is passed as an atom.\n\nencoding(Encoding): Set the initial encoding. The default initial encoding for XML documents  is UTF-8 and for SGML documents ISO-8859-1. XML documents may change the  encoding using the encoding= attribute in the header.  Explicit use of this option is only required to parse non-conforming  documents. Currently accepted values are iso-8859-1 and utf-8.\n\ndoctype(Element): Defines the toplevel element expected. If a <!DOCTYPE  declaration has been parsed, the default is the defined doctype. The  parser can be instructed to accept the first element encountered as the  toplevel using doctype(_). This feature is especially  useful when parsing part of a document (see the parse  option to sgml_parse/2.\n\n ",
    "prefix":"set_sgml_parser"
  },
  "set_stream/2": {
    "body":"set_stream(${1:Stream}, ${2:Attribute})$3\n$0",
    "description":"set_stream(+Stream, +Attribute).\nModify an attribute of an existing stream. Attribute  specifies the stream property to set. If stream is a pair (see stream_pair/3)  both streams are modified, unless the property is only meaningful on one  of the streams or setting both is not meaningful. In particular, eof_action only applies to the read stream, representation_errors only applies to the write  stream and trying to set alias or line_position  on a pair results in a permission_error exception. See also stream_property/2  and open/4.  alias(AliasName): Set the alias of an already created stream. If AliasName is  the name of one of the standard streams, this stream is rebound. Thus, set_stream(S,  current_input) is the same as set_input/1,  and by setting the alias of a stream to user_input, etc.,  all user terminal input is read from this stream. See also interactor/0.\n\nbuffer(Buffering): Set the buffering mode of an already created stream. Buffering is one of full, line  or false.\n\nbuffer_size(+Size): Set the size of the I/O buffer of the underlying stream to Size  bytes.\n\nclose_on_abort(Bool): Determine whether or not the stream is closed by abort/0.  By default, streams are closed.\n\nclose_on_exec(Bool): Set the close_on_exec property. See stream_property/2.\n\nencoding(Atom): Defines the mapping between bytes and character codes used for the  stream. See section 2.18.1 for  supported encodings. The value bom causes the stream to check whether the current  character is a Unicode BOM marker. If a BOM marker is found, the  encoding is set accordingly and the call succeeds. Otherwise the call  fails.\n\neof_action(Action): Set end-of-file handling to one of eof_code, reset  or error.\n\nfile_name(FileName): Set the filename associated to this stream. This call can be used to set  the file for error locations if Stream corresponds to FileName and is not obtained by opening the file directly  but, for example, through a network service.\n\nline_position(LinePos): Set the line position attribute of the stream. This feature is intended  to correct position management of the stream after sending a terminal  escape sequence (e.g., setting ANSI character attributes). Setting this  attribute raises a permission error if the stream does not record  positions. See line_position/2  and stream_property/2  (property position).\n\nlocale(+Locale): Change the locale of the stream. See section  4.23.\n\nnewline(NewlineMode): Set input or output translation for newlines. See corresponding stream_property/2  for details. In addition to the detected modes, an input stream can be  set in mode detect. It will be set to dos if a \\r  character was removed.\n\ntimeout(Seconds): This option can be used to make streams generate an exception if it  takes longer than Seconds before any new data arrives at the  stream. The value infinite (default) makes the stream block  indefinitely. Like wait_for_input/3,  this call only applies to streams that support the select() system call.  For further information about timeout handling, see wait_for_input/3.  The exception is of the form error(timeout_error(read, Stream), _)\n\ntype(Type): Set the type of the stream to one of text or binary.  See also open/4  and the encoding property of streams. Switching to binary  sets the encoding to octet. Switching to text sets the encoding to the default text encoding.\n\nrecord_position(Bool): Do/do not record the line count and line position (see line_count/2  and line_position/2).\n\nrepresentation_errors(Mode): Change the behaviour when writing characters to the stream that cannot  be represented by the encoding. See also stream_property/2  and section 2.18.1.\n\ntty(Bool): Modify whether Prolog thinks there is a terminal (i.e. human  interaction) connected to this stream. On Unix systems the initial value  comes from isatty(). On Windows, the initial user streams are supposed  to be associated to a terminal. See also stream_property/2.\n\n ",
    "prefix":"set_stream"
  },
  "set_stream_position/2": {
    "body":"set_stream_position(${1:Stream}, ${2:Pos})$3\n$0",
    "description":"[ISO]set_stream_position(+Stream, +Pos).\nSet the current position of Stream to Pos. Pos  is a term as returned by stream_property/2  using the position(Pos) property. See also seek/4.",
    "prefix":"set_stream_position"
  },
  "set_test_options/1": {
    "body":"set_test_options(${1:Options})$2\n$0",
    "description":"set_test_options(+Options).\nDefined options are:  load(+Load): Determines whether or not tests are loaded. When never,  everything between begin_tests/1  and end_tests/1  is simply ignored. When always, tests are always loaded.  Finally, when using the default value normal, tests are  loaded if the code is not compiled with optimisation turned on.\n\nrun(+Run): Specifies when tests are run. Using manual, tests can only  be run using run_tests/0  or run_tests/1.  Using make, tests will be run for reloaded files, but not  for files loaded the first time. Using make(all) make/0  will run all test-suites, not only those that belong to files that are  reloaded.\n\nsilent(+Bool): When true (default is false), send  informational messages using the `silent' level. In practice this means  there is no output except for errors.\n\nsto(+Bool): When true (default false), assume tests are  not subject to occurs check (non-STO) and verify this if the Prolog  implementation supports testing this.\n\n ",
    "prefix":"set_test_options"
  },
  "setarg/3": {
    "body":"setarg(${1:Arg}, ${2:Term}, ${3:Value})$4\n$0",
    "description":"setarg(+Arg, +Term, +Value).\nExtra-logical predicate. Assigns the Arg-th argument of the  compound term Term with the given Value. The  assignment is undone if backtracking brings the state back into a  position before the setarg/3  call. See also nb_setarg/3.  This predicate may be used for destructive assignment to terms, using  them as an extra-logical storage bin. Always try hard to avoid the use  of setarg/3  as it is not supported by many Prolog systems and one has to be very  careful about unexpected copying as well as unexpected noncopying of  terms. A good practice to improve somewhat on this situation is to make  sure that terms whose arguments are subject to setarg/3  have one unused and unshared variable in addition to the used arguments.  This variable avoids unwanted sharing in, e.g., copy_term/2,  and causes the term to be considered as non-ground. An alternative is to  use put_attr/3  to attach information to attributed variables (seesection  7.1).\n\n",
    "prefix":"setarg"
  },
  "setenv/2": {
    "body":"setenv(${1:Name}, ${2:Value})$3\n$0",
    "description":"setenv(+Name, +Value).\nSet an environment variable. Name and Value must  be instantiated to atoms or integers. The environment variable will be  passed to shell/[0-2]  and can be requested using getenv/2.  They also influence expand_file_name/2.  Environment variables are shared between threads. Depending on the  underlying C library, setenv/2  and unsetenv/1  may not be thread-safe and may cause memory leaks. Only changing the  environment once and before starting threads is safe in all versions of  SWI-Prolog.",
    "prefix":"setenv"
  },
  "setlocale/3": {
    "body":"setlocale(${1:Category}, ${2:Old}, ${3:New})$4\n$0",
    "description":"setlocale(+Category, -Old, +New).\nSet/Query the locale setting which tells the C library how to  interpret text files, write numbers, dates, etc. Category is one of all, collate, ctype, messages, monetary, numeric or time. For  details, please consult the C library locale documentation. See also section  2.18.1. Please note that the locale is shared between all threads  and thread-safe usage of setlocale/3  is in general not possible. Do locale operations before starting threads  or thoroughly study threading aspects of locale support in your  environment before using in multithreaded environments. Locale settings  are used by format_time/3, collation_key/2  and locale_sort/2.",
    "prefix":"setlocale"
  },
  "setof/3": {
    "body":"setof(${1:Template}, ${2:Goal}, ${3:Set})$4\n$0",
    "description":"[ISO]setof(+Template, +Goal, -Set).\nEquivalent to bagof/3,  but sorts the result using sort/2  to get a sorted list of alternatives without duplicates.",
    "prefix":"setof"
  },
  "settings:convert_setting_text/3": {
    "body": [
      "convert_setting_text(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"convert_setting_text('Param1','Param2','Param3')",
    "prefix":"convert_setting_text"
  },
  "settings:current_setting/1": {
    "body": ["current_setting(${1:'Param1'})$2\n$0" ],
    "description":"current_setting('Param1')",
    "prefix":"current_setting"
  },
  "settings:list_settings/0": {
    "body": ["list_settings$1\n$0" ],
    "description":"list_settings",
    "prefix":"list_settings"
  },
  "settings:list_settings/1": {
    "body": ["list_settings(${1:'Param1'})$2\n$0" ],
    "description":"list_settings('Param1')",
    "prefix":"list_settings"
  },
  "settings:load_settings/1": {
    "body": ["load_settings(${1:'Param1'})$2\n$0" ],
    "description":"load_settings('Param1')",
    "prefix":"load_settings"
  },
  "settings:load_settings/2": {
    "body": ["load_settings(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"load_settings('Param1','Param2')",
    "prefix":"load_settings"
  },
  "settings:restore_setting/1": {
    "body": ["restore_setting(${1:'Param1'})$2\n$0" ],
    "description":"restore_setting('Param1')",
    "prefix":"restore_setting"
  },
  "settings:save_settings/0": {
    "body": ["save_settings$1\n$0" ],
    "description":"save_settings",
    "prefix":"save_settings"
  },
  "settings:save_settings/1": {
    "body": ["save_settings(${1:'Param1'})$2\n$0" ],
    "description":"save_settings('Param1')",
    "prefix":"save_settings"
  },
  "settings:set_setting/2": {
    "body": ["set_setting(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"set_setting('Param1','Param2')",
    "prefix":"set_setting"
  },
  "settings:set_setting_default/2": {
    "body": ["set_setting_default(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"set_setting_default('Param1','Param2')",
    "prefix":"set_setting_default"
  },
  "settings:setting/2": {
    "body": ["setting(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"setting('Param1','Param2')",
    "prefix":"setting"
  },
  "settings:setting/4": {
    "body": [
      "setting(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"setting('Param1','Param2','Param3','Param4')",
    "prefix":"setting"
  },
  "settings:setting_property/2": {
    "body": ["setting_property(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"setting_property('Param1','Param2')",
    "prefix":"setting_property"
  },
  "setup_call_catcher_cleanup/4": {
    "body":"setup_call_catcher_cleanup(${1:Setup}, ${2:Goal}, ${3:Catcher}, ${4:Cleanup})$5\n$0",
    "description":"setup_call_catcher_cleanup(:Setup, :Goal, +Catcher, :Cleanup).\nSimilar to setup_call_cleanup(Setup, Goal, Cleanup) with  additional information on the reason for calling Cleanup.  Prior to calling Cleanup, Catcher unifies with the  termination code (see below). If this unification fails, Cleanup  is not called.  exit: Goal succeeded without leaving any choice points.\n\nfail: Goal failed.\n\n!: Goal succeeded with choice points and these are now discarded  by the execution of a cut (or other pruning of the search tree such as  if-then-else).\n\nexception(Exception): Goal raised the given Exception.\n\nexternal_exception(Exception): Goal succeeded with choice points and these are now discarded  due to an exception. For example:  \n\n?- setup_call_catcher_cleanup(true, (X=1;X=2),\n                              Catcher, writeln(Catcher)),\n   throw(ball).\nexternal_exception(ball)\nERROR: Unhandled exception: Unknown message: ball\n\n  \n\n ",
    "prefix":"setup_call_catcher_cleanup"
  },
  "setup_call_cleanup/3": {
    "body":"setup_call_cleanup(${1:Setup}, ${2:Goal}, ${3:Cleanup})$4\n$0",
    "description":"setup_call_cleanup(:Setup, :Goal, :Cleanup).\nCalls (once(Setup), Goal). If Setup succeeds, Cleanup  will be called exactly once after Goal is finished: either on  failure, deterministic success, commit, or an exception. The execution  of Setup is protected from asynchronous interrupts like call_with_time_limit/2  (package clib) or thread_signal/2.  In most uses, Setup will perform temporary side-effects required by Goal  that are finally undone by Cleanup.  Success or failure of Cleanup is ignored, and choice  points it created are destroyed (as once/1).  If Cleanup throws an exception, this is executed as normal.bugDuring  the execution of Cleanup, garbage collection and stack-shifts  are disabled. \n\nTypically, this predicate is used to cleanup permanent data storage  required to execute Goal, close file descriptors, etc. The  example below provides a non-deterministic search for a term in a file,  closing the stream as needed. \n\n\n\nterm_in_file(Term, File) :-\n        setup_call_cleanup(open(File, read, In),\n                           term_in_stream(Term, In),\n                           close(In) ).\n\nterm_in_stream(Term, In) :-\n        repeat,\n        read(In, T),\n        (   T == end_of_file\n        ->  !, fail\n        ;   T = Term\n        ).\n\n  Note that it is impossible to implement this predicate in Prolog. The  closest approximation would be to read all terms into a list, close the  file and call member/2.  Without setup_call_cleanup/3  there is no way to gain control if the choice point left by repeat/0  is removed by a cut or an exception. \n\nsetup_call_cleanup/3  can also be used to test determinism of a goal, providing a portable  alternative to deterministic/1: \n\n\n\n?- setup_call_cleanup(true,(X=1;X=2), Det=yes).\n\nX = 1 ;\n\nX = 2,\nDet = yes ;\n\n  This predicate is under consideration for inclusion into the ISO  standard. For compatibility with other Prolog implementations see call_cleanup/2.\n\n",
    "prefix":"setup_call_cleanup"
  },
  "sgml:dtd/2": {
    "body": ["dtd(${1:Type}, ${2:DTD})$3\n$0" ],
    "description":"  dtd(+Type, -DTD) is det.\n\n   DTD is a DTD object created from  the file dtd(Type). Loaded DTD\n   objects are cached. Note that  DTD   objects  may  not be shared\n   between threads. Therefore, dtd/2  maintains   the  pool  of DTD\n   objects  using  a  thread_local  predicate.    DTD  objects  are\n   destroyed if a thread terminates.\n\n   @error existence_error(source_sink, dtd(Type))",
    "prefix":"dtd"
  },
  "sgml:dtd_property/2": {
    "body": ["dtd_property(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"dtd_property('Param1','Param2')",
    "prefix":"dtd_property"
  },
  "sgml:free_dtd/1": {
    "body": ["free_dtd(${1:'Param1'})$2\n$0" ],
    "description":"free_dtd('Param1')",
    "prefix":"free_dtd"
  },
  "sgml:free_sgml_parser/1": {
    "body": ["free_sgml_parser(${1:'Param1'})$2\n$0" ],
    "description":"free_sgml_parser('Param1')",
    "prefix":"free_sgml_parser"
  },
  "sgml:get_sgml_parser/2": {
    "body": ["get_sgml_parser(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"get_sgml_parser('Param1','Param2')",
    "prefix":"get_sgml_parser"
  },
  "sgml:iri_xml_namespace/2": {
    "body": ["iri_xml_namespace(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"iri_xml_namespace('Param1','Param2')",
    "prefix":"iri_xml_namespace"
  },
  "sgml:iri_xml_namespace/3": {
    "body": [
      "iri_xml_namespace(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"iri_xml_namespace('Param1','Param2','Param3')",
    "prefix":"iri_xml_namespace"
  },
  "sgml:load_dtd/2": {
    "body": ["load_dtd(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"load_dtd('Param1','Param2')",
    "prefix":"load_dtd"
  },
  "sgml:load_dtd/3": {
    "body": ["load_dtd(${1:DTD}, ${2:DtdFile}, ${3:Options})$4\n$0" ],
    "description":"  load_dtd(+DTD, +DtdFile, +Options)\n\n   Load DtdFile into a DTD.  Defined options are:\n\n           * dialect(+Dialect)\n           Dialect to use (xml, xmlns, sgml)\n\n           * encoding(+Encoding)\n           Encoding of DTD file\n\n   @param  DTD is a fresh DTD object, normally created using\n           new_dtd/1.",
    "prefix":"load_dtd"
  },
  "sgml:load_html/3": {
    "body": ["load_html(${1:Input}, ${2:DOM}, ${3:Options})$4\n$0" ],
    "description":"  load_html(+Input, -DOM, +Options) is det.\n\n   Load HTML text from Input and  unify the resulting DOM structure\n   with DOM. Options are passed   to load_structure/3, after adding\n   the following default options:\n\n     - dtd(DTD)\n     Pass the DTD for HTML as obtained using dtd(html, DTD).\n     - dialect(Dialect)\n     Current dialect from the Prolog flag =html_dialect=\n     - max_errors(-1)\n     - syntax_errors(quiet)\n     Most HTML encountered in the wild contains errors. Even in the\n     context of errors, the resulting DOM term is often a\n     reasonable guess at the intend of the author.\n\n   You may also want to use  the library(http/http_open) to support\n   loading from HTTP and HTTPS URLs. For example:\n\n   ==\n   :- use_module(library(http/http_open)).\n   :- use_module(library(sgml)).\n\n   load_html_url(URL, DOM) :-\n       load_html(URL, DOM, []).\n   ==",
    "prefix":"load_html"
  },
  "sgml:load_html_file/2": {
    "body": ["load_html_file(${1:File}, ${2:DOM})$3\n$0" ],
    "description":"  load_html_file(+File, -DOM) is det.\n\n   Load HTML from File and unify   the resulting DOM structure with\n   DOM.\n\n   @deprecated     New code should use load_html/3.",
    "prefix":"load_html_file"
  },
  "sgml:load_sgml/3": {
    "body": ["load_sgml(${1:Input}, ${2:DOM}, ${3:Options})$4\n$0" ],
    "description":"  load_sgml(+Input, -DOM, +Options) is det.\n\n   Load SGML text from Input and  unify the resulting DOM structure\n   with DOM. Options are passed   to load_structure/3, after adding\n   the following default options:\n\n     - dialect(sgml)",
    "prefix":"load_sgml"
  },
  "sgml:load_sgml_file/2": {
    "body": ["load_sgml_file(${1:File}, ${2:DOM})$3\n$0" ],
    "description":"  load_sgml_file(+File, -DOM) is det.\n\n   Load SGML from File and unify   the resulting DOM structure with\n   DOM.\n\n   @deprecated     New code should use load_sgml/3.",
    "prefix":"load_sgml_file"
  },
  "sgml:load_structure/3": {
    "body": [
      "load_structure(${1:Source}, ${2:ListOfContent}, ${3:Options})$4\n$0"
    ],
    "description":"  load_structure(+Source, -ListOfContent, :Options) is det.\n\n   Parse   Source   and   return   the   resulting   structure   in\n   ListOfContent. Source is handed to  open_any/5, which allows for\n   processing an extensible set of input sources.\n\n   A proper XML document contains only   a  single toplevel element\n   whose name matches the document type.   Nevertheless,  a list is\n   returned for consistency with  the   representation  of  element\n   content.\n\n   The  encoding(+Encoding)  option   is    treated   special   for\n   compatibility reasons:\n\n     - If `Encoding` is one of =iso-8859-1=, =us-ascii= or =utf-8=,\n       the stream is opened in binary mode and the option is passed\n       to the SGML parser.\n     - If `Encoding` is present, but not one of the above, the\n       stream is opened in text mode using the given encoding.\n     - Otherwise (no `Encoding`), the stream is opened in binary\n       mode and doing the correct decoding is left to the parser.",
    "prefix":"load_structure"
  },
  "sgml:load_xml/3": {
    "body": ["load_xml(${1:Input}, ${2:DOM}, ${3:Options})$4\n$0" ],
    "description":"  load_xml(+Input, -DOM, +Options) is det.\n\n   Load XML text from Input and   unify the resulting DOM structure\n   with DOM. Options are passed   to load_structure/3, after adding\n   the following default options:\n\n     - dialect(xml)",
    "prefix":"load_xml"
  },
  "sgml:load_xml_file/2": {
    "body": ["load_xml_file(${1:File}, ${2:DOM})$3\n$0" ],
    "description":"  load_xml_file(+File, -DOM) is det.\n\n   Load XML from File and unify   the  resulting DOM structure with\n   DOM.\n\n   @deprecated     New code should use load_xml/3.",
    "prefix":"load_xml_file"
  },
  "sgml:new_dtd/2": {
    "body": ["new_dtd(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"new_dtd('Param1','Param2')",
    "prefix":"new_dtd"
  },
  "sgml:new_sgml_parser/2": {
    "body": ["new_sgml_parser(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"new_sgml_parser('Param1','Param2')",
    "prefix":"new_sgml_parser"
  },
  "sgml:open_dtd/3": {
    "body": ["open_dtd(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"open_dtd('Param1','Param2','Param3')",
    "prefix":"open_dtd"
  },
  "sgml:set_sgml_parser/2": {
    "body": ["set_sgml_parser(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"set_sgml_parser('Param1','Param2')",
    "prefix":"set_sgml_parser"
  },
  "sgml:sgml_parse/2": {
    "body": ["sgml_parse(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sgml_parse('Param1','Param2')",
    "prefix":"sgml_parse"
  },
  "sgml:sgml_register_catalog_file/2": {
    "body": ["sgml_register_catalog_file(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sgml_register_catalog_file('Param1','Param2')",
    "prefix":"sgml_register_catalog_file"
  },
  "sgml:xml_basechar/1": {
    "body": ["xml_basechar(${1:CodeOrChar})$2\n$0" ],
    "description":"  xml_basechar(+CodeOrChar) is semidet.\n  xml_ideographic(+CodeOrChar) is semidet.\n  xml_combining_char(+CodeOrChar) is semidet.\n  xml_digit(+CodeOrChar) is semidet.\n  xml_extender(+CodeOrChar) is semidet.\n\n   XML  character  classification   predicates.    Each   of  these\n   predicates accept both a character   (one-character  atom) and a\n   code (integer).\n\n   @see http://www.w3.org/TR/2006/REC-xml-20060816",
    "prefix":"xml_basechar"
  },
  "sgml:xml_combining_char/1": {
    "body": ["xml_combining_char(${1:CodeOrChar})$2\n$0" ],
    "description":"  xml_basechar(+CodeOrChar) is semidet.\n  xml_ideographic(+CodeOrChar) is semidet.\n  xml_combining_char(+CodeOrChar) is semidet.\n  xml_digit(+CodeOrChar) is semidet.\n  xml_extender(+CodeOrChar) is semidet.\n\n   XML  character  classification   predicates.    Each   of  these\n   predicates accept both a character   (one-character  atom) and a\n   code (integer).\n\n   @see http://www.w3.org/TR/2006/REC-xml-20060816",
    "prefix":"xml_combining_char"
  },
  "sgml:xml_digit/1": {
    "body": ["xml_digit(${1:CodeOrChar})$2\n$0" ],
    "description":"  xml_basechar(+CodeOrChar) is semidet.\n  xml_ideographic(+CodeOrChar) is semidet.\n  xml_combining_char(+CodeOrChar) is semidet.\n  xml_digit(+CodeOrChar) is semidet.\n  xml_extender(+CodeOrChar) is semidet.\n\n   XML  character  classification   predicates.    Each   of  these\n   predicates accept both a character   (one-character  atom) and a\n   code (integer).\n\n   @see http://www.w3.org/TR/2006/REC-xml-20060816",
    "prefix":"xml_digit"
  },
  "sgml:xml_extender/1": {
    "body": ["xml_extender(${1:CodeOrChar})$2\n$0" ],
    "description":"  xml_basechar(+CodeOrChar) is semidet.\n  xml_ideographic(+CodeOrChar) is semidet.\n  xml_combining_char(+CodeOrChar) is semidet.\n  xml_digit(+CodeOrChar) is semidet.\n  xml_extender(+CodeOrChar) is semidet.\n\n   XML  character  classification   predicates.    Each   of  these\n   predicates accept both a character   (one-character  atom) and a\n   code (integer).\n\n   @see http://www.w3.org/TR/2006/REC-xml-20060816",
    "prefix":"xml_extender"
  },
  "sgml:xml_ideographic/1": {
    "body": ["xml_ideographic(${1:CodeOrChar})$2\n$0" ],
    "description":"  xml_basechar(+CodeOrChar) is semidet.\n  xml_ideographic(+CodeOrChar) is semidet.\n  xml_combining_char(+CodeOrChar) is semidet.\n  xml_digit(+CodeOrChar) is semidet.\n  xml_extender(+CodeOrChar) is semidet.\n\n   XML  character  classification   predicates.    Each   of  these\n   predicates accept both a character   (one-character  atom) and a\n   code (integer).\n\n   @see http://www.w3.org/TR/2006/REC-xml-20060816",
    "prefix":"xml_ideographic"
  },
  "sgml:xml_is_dom/1": {
    "body": ["xml_is_dom(${1:Term})$2\n$0" ],
    "description":"  xml_is_dom(@Term) is semidet.\n\n   True  if  term  statisfies   the    structure   as  returned  by\n   load_structure/3 and friends.",
    "prefix":"xml_is_dom"
  },
  "sgml:xml_name/1": {
    "body": ["xml_name(${1:Atom})$2\n$0" ],
    "description":"  xml_name(+Atom) is semidet.\n\n   True if Atom is a valid XML name.",
    "prefix":"xml_name"
  },
  "sgml:xml_name/2": {
    "body": ["xml_name(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xml_name('Param1','Param2')",
    "prefix":"xml_name"
  },
  "sgml:xml_quote_attribute/2": {
    "body": ["xml_quote_attribute(${1:In}, ${2:Quoted})$3\n$0" ],
    "description":"  xml_quote_attribute(+In, -Quoted) is det.\n  xml_quote_cdata(+In, -Quoted) is det.\n\n   Backward  compatibility  for  versions  that  allow  to  specify\n   encoding. All characters that cannot fit the encoding are mapped\n   to XML character entities (&#dd;).  Using   ASCII  is the safest\n   value.",
    "prefix":"xml_quote_attribute"
  },
  "sgml:xml_quote_attribute/3": {
    "body": [
      "xml_quote_attribute(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"xml_quote_attribute('Param1','Param2','Param3')",
    "prefix":"xml_quote_attribute"
  },
  "sgml:xml_quote_cdata/2": {
    "body": ["xml_quote_cdata(${1:In}, ${2:Quoted})$3\n$0" ],
    "description":"  xml_quote_attribute(+In, -Quoted) is det.\n  xml_quote_cdata(+In, -Quoted) is det.\n\n   Backward  compatibility  for  versions  that  allow  to  specify\n   encoding. All characters that cannot fit the encoding are mapped\n   to XML character entities (&#dd;).  Using   ASCII  is the safest\n   value.",
    "prefix":"xml_quote_cdata"
  },
  "sgml:xml_quote_cdata/3": {
    "body": [
      "xml_quote_cdata(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"xml_quote_cdata('Param1','Param2','Param3')",
    "prefix":"xml_quote_cdata"
  },
  "sgml:xsd_number_string/2": {
    "body": ["xsd_number_string(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"xsd_number_string('Param1','Param2')",
    "prefix":"xsd_number_string"
  },
  "sgml:xsd_time_string/3": {
    "body": [
      "xsd_time_string(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"xsd_time_string('Param1','Param2','Param3')",
    "prefix":"xsd_time_string"
  },
  "sgml_parse/2": {
    "body":"sgml_parse(${1:Parser}, ${2:Options})$3\n$0",
    "description":"sgml_parse(+Parser, +Options).\nParse an XML file. The parser can operate in two input and two output  modes. Output is either a structured term as described with load_structure/2  or call-backs on predefined events. The first is especially suitable for  manipulating not-too-large documents, while the latter provides a  primitive means for handling very large documents.  Input is a stream. A full description of the option-list is below. \n\ndocument(-Term): A variable that will be unified with a list describing the content of  the document (see load_structure/2).\n\nsource(+Stream): An input stream that is read. This option must be given.\n\ncontent_length(+Characters): Stop parsing after Characters. This option is useful to parse  input embedded in envelopes, such as the HTTP protocol.\n\nparse(Unit): Defines how much of the input is parsed. This option is used to parse  only parts of a file.  fileDefault. Parse everything upto the end of the input.elementThe parser stops after reading the first element. Using source(Stream), this implies reading is stopped as soon as  the element is complete, and another call may be issued on the same  stream to read the next element.contentThe value content is like element but assumes  the element has already been opened. It may be used in a call-back from call(on_begin, Pred) to parse individual  elements after validating their headers.declarationThis may be used to stop the parser after reading the first declaration.  This is especially useful to parse only the doctype  declaration.inputThis option is intended to be used in conjunction with the allowed(Elements) option of get_sgml_parser/2.  It disables the parser's default to complete the parse-tree by closing  all open elements. \n\nmax_errors(+MaxErrors): Set the maximum number of errors. If this number is exceeded further  writes to the stream will yield an I/O error exception. Printing of  errors is suppressed after reaching this value. The default is 50. Using max_errors(-1)  makes the parser continue, no matter how many errors it encounters. error(limit_exceeded(max_errors, Max), _)\n\nsyntax_errors(+ErrorMode): Defines how syntax errors are handled.  quietSuppress all messages.printDefault. Pass messages to print_message/2.stylePrint dubious input such as attempts for redefinitions in the DTD using print_message/2  with severity informational. \n\nxml_no_ns(+Mode): Error handling if an XML namespace is not defined. Default generates an  error. If quiet, the error is suppressed. Can be used  together with call(urlns, Closure) to provide external  expansion of namespaces. See also section  3.3.1.\n\ncall(+Event, :PredicateName): Issue call-backs on the specified events. PredicateName is  the name of the predicate to call on this event, possibly prefixed with  a module identifier. If the handler throws an exception, parsing is  stopped and sgml_parse/2  re-throws the exception. The defined events are:  beginAn open-tag has been parsed. The named handler is called with three  arguments: Handler(+Tag, +Attributes, +Parser).endA close-tag has been parsed. The named handler is called with two  arguments: Handler(+Tag, +Parser).cdataCDATA has been parsed. The named handler is called with two arguments: Handler(+CDATA, +Parser), where CDATA is an atom  representing the data.piA processing instruction has been parsed. The named handler is called  with two arguments: Handler(+Text, +Parser),  where Text is the text of the processing instruction.declA declaration (<!...>) has been read. The named  handler is called with two arguments: Handler(+Text,  +Parser), where Text is the text of the declaration  with comments removed.  This option is expecially useful for highlighting declarations and  comments in editor support, where the location of the declaration is  extracted using get_sgml_parser/2.errorAn error has been encountered. the named handler is called with three  arguments: Handler(+Severity, +Message, +Parser),  where Severity is one of warning or error  and Message is an atom representing the diagnostic message. The  location of the error can be determined using get_sgml_parser/2  If this option is present, errors and warnings are not reported using print_message/3xmlnsWhen parsing an in xmlns mode, a new namespace declaraction  is pushed on the environment. The named handler is called with three  arguments: Handler(+NameSpace, +URL, +Parser).  See section 3.3.1 for details.urlnsWhen parsing an in xmlns mode, this predicate can be used  to map a url into either a canonical URL for this namespace or another  internal identifier. See section 3.3.1  for details. \n\n ",
    "prefix":"sgml_parse"
  },
  "sgml_write:html_write/2": {
    "body": ["html_write(${1:Data}, ${2:Options})$3\n$0" ],
    "description":"  xml_write(+Data, +Options) is det.\n  sgml_write(+Data, +Options) is det.\n  html_write(+Data, +Options) is det.\n  xml_write(+Stream, +Data, +Options) is det.\n  sgml_write(+Stream, +Data, +Options) is det.\n  html_write(+Stream, +Data, +Options) is det.\n\n   Write a term as created by the SGML/XML parser to a stream in\n   SGML or XML format.  Options:\n\n           * cleanns(Bool)\n           If `true` (default), remove duplicate `xmlns`\n           attributes.\n           * dtd(DTD)\n           The DTD.  This is needed for SGML documents that contain\n           elements with content model EMPTY.  Characters which may\n           not be written directly in the Stream's encoding will be\n           written using character data entities from the DTD if at\n           all possible, otherwise as numeric character references.\n           Note that the DTD will NOT be written out at all; as yet\n           there is no way to write out an internal subset,  though\n           it would not be hard to add one.\n\n           * doctype(DocType)\n           Document type for the SGML document type declaration.\n           If omitted it is taken from the root element.  There is\n           never any point in having this be disagree with the\n           root element.  A <!DOCTYPE> declaration will be written\n           if and only if at least one of doctype(_), public(_), or\n           system(_) is provided in Options.\n\n           * public(PubId)\n           The public identifier to be written in the <!DOCTYPE> line.\n\n           * system(SysId)\n           The system identifier to be written in the <!DOCTYPE> line.\n\n           * header(Bool)\n           If Bool is 'false', do not emit the <xml ...> header\n           line.  (xml_write/3 only)\n\n           * nsmap(Map:list(Id=URI))\n           When emitting embedded XML, assume these namespaces\n           are already defined from the environment.  (xml_write/3\n           only).\n\n           * indent(Indent)\n           Indentation of the document (for embedding)\n\n           * layout(Bool)\n           Emit/do not emit layout characters to make output\n           readable.\n\n           * net(Bool)\n           Use/do not use Null End Tags.\n           For XML, this applies only to empty elements, so you get\n\n           ==\n               <foo/>      (default, net(true))\n               <foo><\/foo> (net(false))\n           ==\n\n           For SGML, this applies to empty elements, so you get\n\n           ==\n               <foo>       (if foo is declared to be EMPTY in the DTD)\n               <foo><\/foo> (default, net(false))\n               <foo//      (net(true))\n           ==\n\n           and also to elements with character content not containing /\n\n           ==\n               <b>xxx<\/b>  (default, net(false))\n               <b/xxx/     (net(true)).\n           ==\n\n   Note that if the stream is UTF-8, the system will write special\n   characters as UTF-8 sequences, while if it is ISO Latin-1 it\n   will use (character) entities if there is a DTD that provides\n   them, otherwise it will use numeric character references.",
    "prefix":"html_write"
  },
  "sgml_write:html_write/3": {
    "body": ["html_write(${1:Stream}, ${2:Data}, ${3:Options})$4\n$0" ],
    "description":"  xml_write(+Data, +Options) is det.\n  sgml_write(+Data, +Options) is det.\n  html_write(+Data, +Options) is det.\n  xml_write(+Stream, +Data, +Options) is det.\n  sgml_write(+Stream, +Data, +Options) is det.\n  html_write(+Stream, +Data, +Options) is det.\n\n   Write a term as created by the SGML/XML parser to a stream in\n   SGML or XML format.  Options:\n\n           * cleanns(Bool)\n           If `true` (default), remove duplicate `xmlns`\n           attributes.\n           * dtd(DTD)\n           The DTD.  This is needed for SGML documents that contain\n           elements with content model EMPTY.  Characters which may\n           not be written directly in the Stream's encoding will be\n           written using character data entities from the DTD if at\n           all possible, otherwise as numeric character references.\n           Note that the DTD will NOT be written out at all; as yet\n           there is no way to write out an internal subset,  though\n           it would not be hard to add one.\n\n           * doctype(DocType)\n           Document type for the SGML document type declaration.\n           If omitted it is taken from the root element.  There is\n           never any point in having this be disagree with the\n           root element.  A <!DOCTYPE> declaration will be written\n           if and only if at least one of doctype(_), public(_), or\n           system(_) is provided in Options.\n\n           * public(PubId)\n           The public identifier to be written in the <!DOCTYPE> line.\n\n           * system(SysId)\n           The system identifier to be written in the <!DOCTYPE> line.\n\n           * header(Bool)\n           If Bool is 'false', do not emit the <xml ...> header\n           line.  (xml_write/3 only)\n\n           * nsmap(Map:list(Id=URI))\n           When emitting embedded XML, assume these namespaces\n           are already defined from the environment.  (xml_write/3\n           only).\n\n           * indent(Indent)\n           Indentation of the document (for embedding)\n\n           * layout(Bool)\n           Emit/do not emit layout characters to make output\n           readable.\n\n           * net(Bool)\n           Use/do not use Null End Tags.\n           For XML, this applies only to empty elements, so you get\n\n           ==\n               <foo/>      (default, net(true))\n               <foo><\/foo> (net(false))\n           ==\n\n           For SGML, this applies to empty elements, so you get\n\n           ==\n               <foo>       (if foo is declared to be EMPTY in the DTD)\n               <foo><\/foo> (default, net(false))\n               <foo//      (net(true))\n           ==\n\n           and also to elements with character content not containing /\n\n           ==\n               <b>xxx<\/b>  (default, net(false))\n               <b/xxx/     (net(true)).\n           ==\n\n   Note that if the stream is UTF-8, the system will write special\n   characters as UTF-8 sequences, while if it is ISO Latin-1 it\n   will use (character) entities if there is a DTD that provides\n   them, otherwise it will use numeric character references.",
    "prefix":"html_write"
  },
  "sgml_write:sgml_write/2": {
    "body": ["sgml_write(${1:Data}, ${2:Options})$3\n$0" ],
    "description":"  xml_write(+Data, +Options) is det.\n  sgml_write(+Data, +Options) is det.\n  html_write(+Data, +Options) is det.\n  xml_write(+Stream, +Data, +Options) is det.\n  sgml_write(+Stream, +Data, +Options) is det.\n  html_write(+Stream, +Data, +Options) is det.\n\n   Write a term as created by the SGML/XML parser to a stream in\n   SGML or XML format.  Options:\n\n           * cleanns(Bool)\n           If `true` (default), remove duplicate `xmlns`\n           attributes.\n           * dtd(DTD)\n           The DTD.  This is needed for SGML documents that contain\n           elements with content model EMPTY.  Characters which may\n           not be written directly in the Stream's encoding will be\n           written using character data entities from the DTD if at\n           all possible, otherwise as numeric character references.\n           Note that the DTD will NOT be written out at all; as yet\n           there is no way to write out an internal subset,  though\n           it would not be hard to add one.\n\n           * doctype(DocType)\n           Document type for the SGML document type declaration.\n           If omitted it is taken from the root element.  There is\n           never any point in having this be disagree with the\n           root element.  A <!DOCTYPE> declaration will be written\n           if and only if at least one of doctype(_), public(_), or\n           system(_) is provided in Options.\n\n           * public(PubId)\n           The public identifier to be written in the <!DOCTYPE> line.\n\n           * system(SysId)\n           The system identifier to be written in the <!DOCTYPE> line.\n\n           * header(Bool)\n           If Bool is 'false', do not emit the <xml ...> header\n           line.  (xml_write/3 only)\n\n           * nsmap(Map:list(Id=URI))\n           When emitting embedded XML, assume these namespaces\n           are already defined from the environment.  (xml_write/3\n           only).\n\n           * indent(Indent)\n           Indentation of the document (for embedding)\n\n           * layout(Bool)\n           Emit/do not emit layout characters to make output\n           readable.\n\n           * net(Bool)\n           Use/do not use Null End Tags.\n           For XML, this applies only to empty elements, so you get\n\n           ==\n               <foo/>      (default, net(true))\n               <foo><\/foo> (net(false))\n           ==\n\n           For SGML, this applies to empty elements, so you get\n\n           ==\n               <foo>       (if foo is declared to be EMPTY in the DTD)\n               <foo><\/foo> (default, net(false))\n               <foo//      (net(true))\n           ==\n\n           and also to elements with character content not containing /\n\n           ==\n               <b>xxx<\/b>  (default, net(false))\n               <b/xxx/     (net(true)).\n           ==\n\n   Note that if the stream is UTF-8, the system will write special\n   characters as UTF-8 sequences, while if it is ISO Latin-1 it\n   will use (character) entities if there is a DTD that provides\n   them, otherwise it will use numeric character references.",
    "prefix":"sgml_write"
  },
  "sgml_write:sgml_write/3": {
    "body": ["sgml_write(${1:Stream}, ${2:Data}, ${3:Options})$4\n$0" ],
    "description":"  xml_write(+Data, +Options) is det.\n  sgml_write(+Data, +Options) is det.\n  html_write(+Data, +Options) is det.\n  xml_write(+Stream, +Data, +Options) is det.\n  sgml_write(+Stream, +Data, +Options) is det.\n  html_write(+Stream, +Data, +Options) is det.\n\n   Write a term as created by the SGML/XML parser to a stream in\n   SGML or XML format.  Options:\n\n           * cleanns(Bool)\n           If `true` (default), remove duplicate `xmlns`\n           attributes.\n           * dtd(DTD)\n           The DTD.  This is needed for SGML documents that contain\n           elements with content model EMPTY.  Characters which may\n           not be written directly in the Stream's encoding will be\n           written using character data entities from the DTD if at\n           all possible, otherwise as numeric character references.\n           Note that the DTD will NOT be written out at all; as yet\n           there is no way to write out an internal subset,  though\n           it would not be hard to add one.\n\n           * doctype(DocType)\n           Document type for the SGML document type declaration.\n           If omitted it is taken from the root element.  There is\n           never any point in having this be disagree with the\n           root element.  A <!DOCTYPE> declaration will be written\n           if and only if at least one of doctype(_), public(_), or\n           system(_) is provided in Options.\n\n           * public(PubId)\n           The public identifier to be written in the <!DOCTYPE> line.\n\n           * system(SysId)\n           The system identifier to be written in the <!DOCTYPE> line.\n\n           * header(Bool)\n           If Bool is 'false', do not emit the <xml ...> header\n           line.  (xml_write/3 only)\n\n           * nsmap(Map:list(Id=URI))\n           When emitting embedded XML, assume these namespaces\n           are already defined from the environment.  (xml_write/3\n           only).\n\n           * indent(Indent)\n           Indentation of the document (for embedding)\n\n           * layout(Bool)\n           Emit/do not emit layout characters to make output\n           readable.\n\n           * net(Bool)\n           Use/do not use Null End Tags.\n           For XML, this applies only to empty elements, so you get\n\n           ==\n               <foo/>      (default, net(true))\n               <foo><\/foo> (net(false))\n           ==\n\n           For SGML, this applies to empty elements, so you get\n\n           ==\n               <foo>       (if foo is declared to be EMPTY in the DTD)\n               <foo><\/foo> (default, net(false))\n               <foo//      (net(true))\n           ==\n\n           and also to elements with character content not containing /\n\n           ==\n               <b>xxx<\/b>  (default, net(false))\n               <b/xxx/     (net(true)).\n           ==\n\n   Note that if the stream is UTF-8, the system will write special\n   characters as UTF-8 sequences, while if it is ISO Latin-1 it\n   will use (character) entities if there is a DTD that provides\n   them, otherwise it will use numeric character references.",
    "prefix":"sgml_write"
  },
  "sgml_write:xml_write/2": {
    "body": ["xml_write(${1:Data}, ${2:Options})$3\n$0" ],
    "description":"  xml_write(+Data, +Options) is det.\n  sgml_write(+Data, +Options) is det.\n  html_write(+Data, +Options) is det.\n  xml_write(+Stream, +Data, +Options) is det.\n  sgml_write(+Stream, +Data, +Options) is det.\n  html_write(+Stream, +Data, +Options) is det.\n\n   Write a term as created by the SGML/XML parser to a stream in\n   SGML or XML format.  Options:\n\n           * cleanns(Bool)\n           If `true` (default), remove duplicate `xmlns`\n           attributes.\n           * dtd(DTD)\n           The DTD.  This is needed for SGML documents that contain\n           elements with content model EMPTY.  Characters which may\n           not be written directly in the Stream's encoding will be\n           written using character data entities from the DTD if at\n           all possible, otherwise as numeric character references.\n           Note that the DTD will NOT be written out at all; as yet\n           there is no way to write out an internal subset,  though\n           it would not be hard to add one.\n\n           * doctype(DocType)\n           Document type for the SGML document type declaration.\n           If omitted it is taken from the root element.  There is\n           never any point in having this be disagree with the\n           root element.  A <!DOCTYPE> declaration will be written\n           if and only if at least one of doctype(_), public(_), or\n           system(_) is provided in Options.\n\n           * public(PubId)\n           The public identifier to be written in the <!DOCTYPE> line.\n\n           * system(SysId)\n           The system identifier to be written in the <!DOCTYPE> line.\n\n           * header(Bool)\n           If Bool is 'false', do not emit the <xml ...> header\n           line.  (xml_write/3 only)\n\n           * nsmap(Map:list(Id=URI))\n           When emitting embedded XML, assume these namespaces\n           are already defined from the environment.  (xml_write/3\n           only).\n\n           * indent(Indent)\n           Indentation of the document (for embedding)\n\n           * layout(Bool)\n           Emit/do not emit layout characters to make output\n           readable.\n\n           * net(Bool)\n           Use/do not use Null End Tags.\n           For XML, this applies only to empty elements, so you get\n\n           ==\n               <foo/>      (default, net(true))\n               <foo><\/foo> (net(false))\n           ==\n\n           For SGML, this applies to empty elements, so you get\n\n           ==\n               <foo>       (if foo is declared to be EMPTY in the DTD)\n               <foo><\/foo> (default, net(false))\n               <foo//      (net(true))\n           ==\n\n           and also to elements with character content not containing /\n\n           ==\n               <b>xxx<\/b>  (default, net(false))\n               <b/xxx/     (net(true)).\n           ==\n\n   Note that if the stream is UTF-8, the system will write special\n   characters as UTF-8 sequences, while if it is ISO Latin-1 it\n   will use (character) entities if there is a DTD that provides\n   them, otherwise it will use numeric character references.",
    "prefix":"xml_write"
  },
  "sgml_write:xml_write/3": {
    "body": ["xml_write(${1:Stream}, ${2:Data}, ${3:Options})$4\n$0" ],
    "description":"  xml_write(+Data, +Options) is det.\n  sgml_write(+Data, +Options) is det.\n  html_write(+Data, +Options) is det.\n  xml_write(+Stream, +Data, +Options) is det.\n  sgml_write(+Stream, +Data, +Options) is det.\n  html_write(+Stream, +Data, +Options) is det.\n\n   Write a term as created by the SGML/XML parser to a stream in\n   SGML or XML format.  Options:\n\n           * cleanns(Bool)\n           If `true` (default), remove duplicate `xmlns`\n           attributes.\n           * dtd(DTD)\n           The DTD.  This is needed for SGML documents that contain\n           elements with content model EMPTY.  Characters which may\n           not be written directly in the Stream's encoding will be\n           written using character data entities from the DTD if at\n           all possible, otherwise as numeric character references.\n           Note that the DTD will NOT be written out at all; as yet\n           there is no way to write out an internal subset,  though\n           it would not be hard to add one.\n\n           * doctype(DocType)\n           Document type for the SGML document type declaration.\n           If omitted it is taken from the root element.  There is\n           never any point in having this be disagree with the\n           root element.  A <!DOCTYPE> declaration will be written\n           if and only if at least one of doctype(_), public(_), or\n           system(_) is provided in Options.\n\n           * public(PubId)\n           The public identifier to be written in the <!DOCTYPE> line.\n\n           * system(SysId)\n           The system identifier to be written in the <!DOCTYPE> line.\n\n           * header(Bool)\n           If Bool is 'false', do not emit the <xml ...> header\n           line.  (xml_write/3 only)\n\n           * nsmap(Map:list(Id=URI))\n           When emitting embedded XML, assume these namespaces\n           are already defined from the environment.  (xml_write/3\n           only).\n\n           * indent(Indent)\n           Indentation of the document (for embedding)\n\n           * layout(Bool)\n           Emit/do not emit layout characters to make output\n           readable.\n\n           * net(Bool)\n           Use/do not use Null End Tags.\n           For XML, this applies only to empty elements, so you get\n\n           ==\n               <foo/>      (default, net(true))\n               <foo><\/foo> (net(false))\n           ==\n\n           For SGML, this applies to empty elements, so you get\n\n           ==\n               <foo>       (if foo is declared to be EMPTY in the DTD)\n               <foo><\/foo> (default, net(false))\n               <foo//      (net(true))\n           ==\n\n           and also to elements with character content not containing /\n\n           ==\n               <b>xxx<\/b>  (default, net(false))\n               <b/xxx/     (net(true)).\n           ==\n\n   Note that if the stream is UTF-8, the system will write special\n   characters as UTF-8 sequences, while if it is ISO Latin-1 it\n   will use (character) entities if there is a DTD that provides\n   them, otherwise it will use numeric character references.",
    "prefix":"xml_write"
  },
  "shell/1": {
    "body":"shell(${1:Command})$2\n$0",
    "description":"shell(+Command).\nEquivalent to `shell(Command, 0)'. See shell/2  for details.",
    "prefix":"shell"
  },
  "shell/2": {
    "body":"shell(${1:Command}, ${2:Status})$3\n$0",
    "description":"shell(+Command, -Status).\nExecute Command on the operating system. Command  is given to the Bourne shell (/bin/sh). Status is unified  with the exit status of the command.  On Windows, shell/[1,2]  executes the command using the CreateProcess() API and waits for the  command to terminate. If the command ends with a & sign, the command is handed to the WinExec() API,  which does not wait for the new task to terminate. See also win_exec/2  and win_shell/2.  Please note that the CreateProcess() API does not imply the  Windows command interpreter (cmd.exe and therefore commands that  are built in the command interpreter can only be activated using the  command interpreter. For example, a file can be compied using the  command below. \n\n\n\n?- shell('cmd.exe /C copy file1.txt file2.txt').\n\n  Note that many of the operations that can be achieved using the shell  built-in commands can easily be achieved using Prolog primitives. See make_directory/1, delete_file/1, rename_file/2,  etc. The clib package provides library(filesex),  implementing various high level file operations such as copy_file/2.  Using Prolog primitives instead of shell commands improves the  portability of your program. \n\nThe library library(process) provides process_create/3  and several related primitives that support more fine-grained  interaction with processes, including I/O redirection and management of  asynchronous processes.\n\n",
    "prefix":"shell"
  },
  "shell:cd/0": {
    "body": ["cd$1\n$0" ],
    "description":"  cd.\n  cd(Dir).\n\n   Change working directory",
    "prefix":"cd"
  },
  "shell:cd/1": {
    "body": ["cd(${1:Dir})$2\n$0" ],
    "description":"  cd.\n  cd(Dir).\n\n   Change working directory",
    "prefix":"cd"
  },
  "shell:dirs/0": {
    "body": ["dirs$1\n$0" ],
    "description":"  pushd.\n  pushd(+Dir).\n  popd.\n  dirs.\n\n   Manage the _directory stack_:\n\n     - pushd/1 is as cd/1, pushing th old directory on a stack\n     - pushd/0 swaps the current directory with the top of the\n       stack\n     - popd/0 pops to the top of the stack\n     - dirs/0 lists the current directory and the stack.",
    "prefix":"dirs"
  },
  "shell:ls/0": {
    "body": ["ls$1\n$0" ],
    "description":"  ls.\n  ls(+Pattern).\n\n   Listing similar to Unix =ls -F=, flagging directories with =/=.",
    "prefix":"ls"
  },
  "shell:ls/1": {
    "body": ["ls(${1:Pattern})$2\n$0" ],
    "description":"  ls.\n  ls(+Pattern).\n\n   Listing similar to Unix =ls -F=, flagging directories with =/=.",
    "prefix":"ls"
  },
  "shell:mv/2": {
    "body": ["mv(${1:From}, ${2:To})$3\n$0" ],
    "description":"  mv(+From, +To) is det.\n\n   Move (Rename) a file. If To is   a directory, From is moved into\n   the directory.",
    "prefix":"mv"
  },
  "shell:popd/0": {
    "body": ["popd$1\n$0" ],
    "description":"  pushd.\n  pushd(+Dir).\n  popd.\n  dirs.\n\n   Manage the _directory stack_:\n\n     - pushd/1 is as cd/1, pushing th old directory on a stack\n     - pushd/0 swaps the current directory with the top of the\n       stack\n     - popd/0 pops to the top of the stack\n     - dirs/0 lists the current directory and the stack.",
    "prefix":"popd"
  },
  "shell:pushd/0": {
    "body": ["pushd$1\n$0" ],
    "description":"  pushd.\n  pushd(+Dir).\n  popd.\n  dirs.\n\n   Manage the _directory stack_:\n\n     - pushd/1 is as cd/1, pushing th old directory on a stack\n     - pushd/0 swaps the current directory with the top of the\n       stack\n     - popd/0 pops to the top of the stack\n     - dirs/0 lists the current directory and the stack.",
    "prefix":"pushd"
  },
  "shell:pushd/1": {
    "body": ["pushd(${1:Dir})$2\n$0" ],
    "description":"  pushd.\n  pushd(+Dir).\n  popd.\n  dirs.\n\n   Manage the _directory stack_:\n\n     - pushd/1 is as cd/1, pushing th old directory on a stack\n     - pushd/0 swaps the current directory with the top of the\n       stack\n     - popd/0 pops to the top of the stack\n     - dirs/0 lists the current directory and the stack.",
    "prefix":"pushd"
  },
  "shell:pwd/0": {
    "body": ["pwd$1\n$0" ],
    "description":"  pwd\n\n   Print current working directory",
    "prefix":"pwd"
  },
  "shell:rm/1": {
    "body": ["rm(${1:File})$2\n$0" ],
    "description":"  rm(+File) is det.\n\n   Remove (unlink) a file",
    "prefix":"rm"
  },
  "shell:shell/0": {
    "body": ["shell$1\n$0" ],
    "description":"  shell\n\n   Execute an interactive shell. The executed   shell is defined by\n   the environment =SHELL= or =comspec=   (Windows).  If neither is\n   defined, =|/bin/sh|= is used.",
    "prefix":"shell"
  },
  "shift/1": {
    "body":"shift(${1:Ball})$2\n$0",
    "description":"shift(+Ball).\nAbandon the execution of the current goal, returning control to just after the matching reset/3  call. This is similar to throw/1  except that (1) nothing is `undone' and (2) the 3th argument of reset/3  is unified with the continuation, which allows the code calling reset/3  to resume the current goal.",
    "prefix":"shift"
  },
  "shlib:call_shared_object_function/2": {
    "body":"call_shared_object_function(${1:Handle}, ${2:Function})$3\n$0",
    "description":"call_shared_object_function(+Handle, +Function).\nCall the named function in the loaded shared library. The function is  called without arguments and the return value is ignored. Normally this  function installs foreign language predicates using calls to PL_register_foreign().",
    "prefix":"call_shared_object_function"
  },
  "shlib:close_shared_object/1": {
    "body":"close_shared_object(${1:Handle})$2\n$0",
    "description":"close_shared_object(+Handle).\nDetach the shared object identified by Handle.",
    "prefix":"close_shared_object"
  },
  "shlib:current_foreign_library/2": {
    "body":"current_foreign_library(${1:File}, ${2:Public})$3\n$0",
    "description":"current_foreign_library(?File, ?Public).\nQuery currently loaded shared libraries.",
    "prefix":"current_foreign_library"
  },
  "shlib:load_foreign_library/1": {
    "body":"load_foreign_library(${1:FileSpec})$2\n$0",
    "description":"[det]load_foreign_library(:FileSpec).\n",
    "prefix":"load_foreign_library"
  },
  "shlib:load_foreign_library/2": {
    "body":"load_foreign_library(${1:FileSpec}, ${2:Entry})$3\n$0",
    "description":"[det]load_foreign_library(:FileSpec, +Entry:atom).\nLoad a shared object or DLL. After loading the Entry  function is called without arguments. The default entry function is  composed from =install_=, followed by the file base-name. E.g., the  load-call below calls the function install_mylib(). If the platform prefixes extern functions  with =_=, this prefix is added before calling.  \n\n      ...\n      load_foreign_library(foreign(mylib)),\n      ...\n\n  FileSpec is a specification for absolute_file_name/3.  If searching the file fails, the plain name is passed to the OS to try  the default method of the OS for locating foreign objects. The default  definition of file_search_path/2  searches <prolog home>/lib/<arch>  on Unix and <prolog home>/bin on Windows.   See also: use_foreign_library/1,2  are intended for use in directives.\n\n ",
    "prefix":"load_foreign_library"
  },
  "shlib:open_shared_object/2": {
    "body":"open_shared_object(${1:File}, ${2:Handle})$3\n$0",
    "description":"open_shared_object(+File, -Handle).\nFile is the name of a shared object file (DLL in MS-Windows).  This file is attached to the current process, and Handle is unified with a handle to the library. Equivalent to open_shared_object(File, Handle, []). See also open_shared_object/3  and load_foreign_library/1.  On errors, an exception shared_object(Action, Message)  is raised. Message is the return value from dlerror().\n\n",
    "prefix":"open_shared_object"
  },
  "shlib:open_shared_object/3": {
    "body":"open_shared_object(${1:File}, ${2:Handle}, ${3:Options})$4\n$0",
    "description":"open_shared_object(+File, -Handle, +Options).\nAs open_shared_object/2,  but allows for additional flags to be passed. Options is a list of atoms. now implies the  symbols are resolved immediately rather than lazy (default). global  implies symbols of the loaded object are visible while loading other  shared objects (by default they are local). Note that these flags may  not be supported by your operating system. Check the documentation of  dlopen() or equivalent on your operating system. Unsupported flags are  silently ignored.",
    "prefix":"open_shared_object"
  },
  "shlib:reload_foreign_libraries/0": {
    "body":"reload_foreign_libraries$1\n$0",
    "description":"reload_foreign_libraries.\nReload all foreign libraries loaded (after restore of a state created  using qsave_program/2.",
    "prefix":"reload_foreign_libraries"
  },
  "shlib:unload_foreign_library/1": {
    "body":"unload_foreign_library(${1:FileSpec})$2\n$0",
    "description":"[det]unload_foreign_library(+FileSpec).\n",
    "prefix":"unload_foreign_library"
  },
  "shlib:unload_foreign_library/2": {
    "body":"unload_foreign_library(${1:FileSpec}, ${2:Exit})$3\n$0",
    "description":"[det]unload_foreign_library(+FileSpec, +Exit:atom).\nUnload a shared object or DLL. After calling the Exit  function, the shared object is removed from the process. The default  exit function is composed from =uninstall_=, followed by the file  base-name.",
    "prefix":"unload_foreign_library"
  },
  "shlib:use_foreign_library/1": {
    "body":"use_foreign_library(${1:FileSpec})$2\n$0",
    "description":"[det]use_foreign_library(+FileSpec).\n",
    "prefix":"use_foreign_library"
  },
  "shlib:use_foreign_library/2": {
    "body":"use_foreign_library(${1:FileSpec}, ${2:Entry})$3\n$0",
    "description":"[det]use_foreign_library(+FileSpec, +Entry:atom).\nLoad and install a foreign library as load_foreign_library/1,2  and register the installation using initialization/2  with the option now. This is similar to using:  \n\n:- initialization(load_foreign_library(foreign(mylib))).\n\n  but using the initialization/1  wrapper causes the library to be loaded after loading of the file  in which it appears is completed, while use_foreign_library/1  loads the library immediately. I.e. the difference is only relevant if the  remainder of the file uses functionality of the C-library.\n\n",
    "prefix":"use_foreign_library"
  },
  "show_coverage/1": {
    "body":"show_coverage(${1:Goal})$2\n$0",
    "description":"show_coverage(:Goal).\nRun Goal and write a report on which percentage of the  clauses in each file are used by the program and which percentage of the  clauses always fail.",
    "prefix":"show_coverage"
  },
  "show_profile/1": {
    "body":"show_profile(${1:Options})$2\n$0",
    "description":"show_profile(+Options).\nThis predicate first calls prolog:show_profile_hook/1. If XPCE is  loaded, this hook is used to activate a GUI interface to visualise the  profile results. If not, a report is printed to the terminal according  to Options:  top(+N): Show the only top N predicates. Default is 25.\n\ncumulative(+Bool): If true (default false), include the time  spent in children in the time reported for a predicate.\n\n ",
    "prefix":"show_profile"
  },
  "sign/1": {
    "body":"sign(${1:Expr})$2\n$0",
    "description":"[ISO]sign(+Expr).\nEvaluate to -1 if Expr < 0, 1 if Expr  > 0 and 0 if Expr = 0. If Expr evaluates to a float,  the return value is a float (e.g., -1.0, 0.0 or 1.0). In particular,  note that sign(-0.0) evaluates to 0.0. See also copysign/2",
    "prefix":"sign"
  },
  "simplex:assignment/2": {
    "body":"assignment(${1:Cost}, ${2:Assignment})$3\n$0",
    "description":"assignment(+Cost, -Assignment).\nSolves a linear assignment problem. Cost is a list of lists  representing the quadratic cost matrix, where element (i,j) denotes the  integer cost of assigning entity $i$ to entity $j$. An assignment with  minimal cost is computed and unified with Assignment as a list of lists, representing an adjacency  matrix.",
    "prefix":"assignment"
  },
  "simplex:constraint/3": {
    "body":"constraint(${1:Constraint}, ${2:S0}, ${3:S})$4\n$0",
    "description":"constraint(+Constraint, +S0, -S).\nAdds a linear or integrality constraint to the linear program  corresponding to state S0. A linear constraint is of the form Left Op C,  where Left is a list of Coefficient*Variable  terms (variables in the context of linear programs can be atoms or  compound terms) and C is a non-negative numeric constant. The  list represents the sum of its elements. Op can be =, =<  or >=. The coefficient 1 can be omitted. An  integrality constraint is of the form integral(Variable)  and constrains Variable to an integral value.",
    "prefix":"constraint"
  },
  "simplex:constraint/4": {
    "body":"constraint(${1:Name}, ${2:Constraint}, ${3:S0}, ${4:S})$5\n$0",
    "description":"constraint(+Name, +Constraint, +S0, -S).\nLike constraint/3,  and attaches the name Name (an atom or compound term) to the  new constraint.",
    "prefix":"constraint"
  },
  "simplex:constraint_add/4": {
    "body":"constraint_add(${1:Name}, ${2:Left}, ${3:S0}, ${4:S})$5\n$0",
    "description":"constraint_add(+Name, +Left, +S0, -S).\nLeft is a list of Coefficient*Variable terms.  The terms are added to the left-hand side of the constraint named Name. S  is unified with the resulting state.",
    "prefix":"constraint_add"
  },
  "simplex:gen_state/1": {
    "body":"gen_state(${1:State})$2\n$0",
    "description":"gen_state(-State).\nGenerates an initial state corresponding to an empty linear program.",
    "prefix":"gen_state"
  },
  "simplex:gen_state_clpr/1": {
    "body": ["gen_state_clpr(${1:'Param1'})$2\n$0" ],
    "description":"gen_state_clpr('Param1')",
    "prefix":"gen_state_clpr"
  },
  "simplex:gen_state_clpr/2": {
    "body": ["gen_state_clpr(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"gen_state_clpr('Param1','Param2')",
    "prefix":"gen_state_clpr"
  },
  "simplex:maximize/3": {
    "body":"maximize(${1:Objective}, ${2:S0}, ${3:S})$4\n$0",
    "description":"maximize(+Objective, +S0, -S).\nMaximizes the objective function, stated as a list of Coefficient*Variable terms that represents the sum of its  elements, with respect to the linear program corresponding to state S0. \\arg{S} is unified with an  internal representation of the solved instance.",
    "prefix":"maximize"
  },
  "simplex:minimize/3": {
    "body":"minimize(${1:Objective}, ${2:S0}, ${3:S})$4\n$0",
    "description":"minimize(+Objective, +S0, -S).\nAnalogous to maximize/3.",
    "prefix":"minimize"
  },
  "simplex:objective/2": {
    "body":"objective(${1:State}, ${2:Objective})$3\n$0",
    "description":"objective(+State, -Objective).\nUnifies Objective with the result of the objective function  at the obtained extremum. State must correspond to a solved  instance.",
    "prefix":"objective"
  },
  "simplex:shadow_price/3": {
    "body":"shadow_price(${1:State}, ${2:Name}, ${3:Value})$4\n$0",
    "description":"shadow_price(+State, +Name, -Value).\nUnifies Value with the shadow price corresponding to the  linear constraint whose name is Name. State must  correspond to a solved instance.",
    "prefix":"shadow_price"
  },
  "simplex:transportation/4": {
    "body":"transportation(${1:Supplies}, ${2:Demands}, ${3:Costs}, ${4:Transport})$5\n$0",
    "description":"transportation(+Supplies, +Demands, +Costs, -Transport).\nSolves a transportation problem. Supplies and Demands  must be lists of non-negative integers. Their respective sums must be  equal. Costs is a list of lists representing the cost matrix,  where an entry (i,j) denotes the integer cost of  transporting one unit from i to j. A transportation plan  having minimum cost is computed and unified with Transport in  the form of a list of lists that represents the transportation matrix,  where element (i,j) denotes how many units to ship from i  to j.",
    "prefix":"transportation"
  },
  "simplex:variable_value/3": {
    "body":"variable_value(${1:State}, ${2:Variable}, ${3:Value})$4\n$0",
    "description":"variable_value(+State, +Variable, -Value).\nValue is unified with the value obtained for Variable. State  must correspond to a solved instance.",
    "prefix":"variable_value"
  },
  "sin/1": {
    "body":"sin(${1:Expr})$2\n$0",
    "description":"[ISO]sin(+Expr).\nResult = sin(Expr). Expr is  the angle in radians.",
    "prefix":"sin"
  },
  "sinh/1": {
    "body":"sinh(${1:Expr})$2\n$0",
    "description":"sinh(+Expr).\nResult = sinh(Expr). The hyperbolic  sine of X is defined as e ** X - e ** -X / 2.",
    "prefix":"sinh"
  },
  "size_file/2": {
    "body":"size_file(${1:File}, ${2:Size})$3\n$0",
    "description":"size_file(+File, -Size).\nUnify Size with the size of File in bytes.",
    "prefix":"size_file"
  },
  "skip/1": {
    "body":"skip(${1:Code})$2\n$0",
    "description":"skip(+Code).\nRead the input until Code or the end of the file is  encountered. A subsequent call to get_code/1  will read the first character after Code.",
    "prefix":"skip"
  },
  "skip/2": {
    "body":"skip(${1:Stream}, ${2:Code})$3\n$0",
    "description":"skip(+Stream, +Code).\nSkip input (as skip/1)  on Stream.",
    "prefix":"skip"
  },
  "sleep/1": {
    "body":"sleep(${1:Time})$2\n$0",
    "description":"sleep(+Time).\nSuspend execution Time seconds. Time is either a  floating point number or an integer. Granularity is dependent on the  system's timer granularity. A negative time causes the timer to return  immediately. On most non-realtime operating systems we can only ensure  execution is suspended for at least Time seconds.  On Unix systems the sleep/1  predicate is realised ---in order of preference--- by nanosleep(),  usleep(), select() if the time is below 1 minute, or sleep(). On Windows  systems Sleep() is used.\n\n",
    "prefix":"sleep"
  },
  "snowball:atom_to_stem_list/2": {
    "body":"atom_to_stem_list(${1:In}, ${2:ListOfStems})$3\n$0",
    "description":"atom_to_stem_list(+In, -ListOfStems).\nCombines the three above routines, returning a list holding an atom with  the stem of each word encountered and numbers for encountered numbers.",
    "prefix":"atom_to_stem_list"
  },
  "snowball:snowball/3": {
    "body":"snowball(${1:Algorithm}, ${2:Input}, ${3:Stem})$4\n$0",
    "description":"[det]snowball(+Algorithm, +Input, -Stem).\nApply the Snowball Algorithm on Input and unify  the result (an atom) with Stem.  The implementation maintains a cache of stemmers for each thread that  accesses snowball/3, providing  high-perfomance and thread-safety without locking.\n\nAlgorithm is the (english) name  for desired algorithm or an 2 or 3 letter ISO 639 language code. Input is the word to be  stemmed. It is either an atom, string or list of chars/codes. The  library accepts Unicode characters. Input must be lowercase. See downcase_atom/2.   Errors: - domain_error(snowball_algorithm, Algorithm)  - type_error(atom, Algorithm)  - type_error(text, Input)\n\n ",
    "prefix":"snowball"
  },
  "snowball:snowball_current_algorithm/1": {
    "body":"snowball_current_algorithm(${1:Algorithm})$2\n$0",
    "description":"[nondet]snowball_current_algorithm(?Algorithm).\nTrue if Algorithm is the official name of an algorithm  suported by snowball/3. The  predicate is semidet if Algorithm is given.",
    "prefix":"snowball_current_algorithm"
  },
  "socket:add_stream_to_pool/2": {
    "body":"add_stream_to_pool(${1:Stream}, ${2:Goal})$3\n$0",
    "description":"add_stream_to_pool(+Stream, :Goal).\nAdd Stream, which must be an input stream and ---on non-unix  systems--- connected to a socket to the pool. If input is available on Stream, Goal  is called.",
    "prefix":"add_stream_to_pool"
  },
  "socket:close_stream_pool/0": {
    "body":"close_stream_pool$1\n$0",
    "description":"close_stream_pool.\nEmpty the pool, closing all streams that are part of it.",
    "prefix":"close_stream_pool"
  },
  "socket:delete_stream_from_pool/1": {
    "body":"delete_stream_from_pool(${1:Stream})$2\n$0",
    "description":"delete_stream_from_pool(+Stream).\nDelete the given stream from the pool. Succeeds, even if Stream  is no member of the pool. If Stream is unbound the entire  pool is emtied but unlike close_stream_pool/0  the streams are not closed.",
    "prefix":"delete_stream_from_pool"
  },
  "socket:dispatch_stream_pool/1": {
    "body":"dispatch_stream_pool(${1:TimeOut})$2\n$0",
    "description":"dispatch_stream_pool(+TimeOut).\nWait for maximum of TimeOut for input on any of the streams  in the pool. If there is input, call the Goal associated with add_stream_to_pool/2.  If Goal fails or raises an exception a message is printed. TimeOut  is described with wait_for_input/3.  If Goal is called, there is some input on the  associated stream. Goal must be careful not to block as this  will block the entire pool.1This  is hard to achieve at the moment as none of the Prolog read-commands  provide for a timeout.\n\n",
    "prefix":"dispatch_stream_pool"
  },
  "socket:gethostname/1": {
    "body":"gethostname(${1:Hostname})$2\n$0",
    "description":"[det]gethostname(-Hostname).\nReturn the canonical fully qualified name of this host. This is achieved  by calling gethostname() and return the canonical name  returned by getaddrinfo().",
    "prefix":"gethostname"
  },
  "socket:negotiate_socks_connection/2": {
    "body":"negotiate_socks_connection(${1:DesiredEndpoint}, ${2:StreamPair})$3\n$0",
    "description":"[det]negotiate_socks_connection(+DesiredEndpoint, +StreamPair).\nNegotiate a connection to DesiredEndpoint over StreamPair. DesiredEndpoint should be in the form of either:  \n\nhostname : port\nip(A,B,C,D) : port\n\n  Errors: socks_error(Details) if the SOCKS negotiation failed.\n\n ",
    "prefix":"negotiate_socks_connection"
  },
  "socket:proxy_for_url/3": {
    "body":"proxy_for_url(${1:URL}, ${2:Hostname}, ${3:Proxy})$4\n$0",
    "description":"[nondet,multifile]proxy_for_url(+URL, +Hostname, -Proxy).\nThis hook can be implemented to return a proxy to try when connecting to URL.  Returned proxies are tried in the order in which they are returned by  the multifile hook try_proxy/4.  Pre-defined proxy methods are:  direct: connect directly to the resource\n\nproxy(Host, Port): Connect to the resource using an HTTP proxy. If the resource is not an  HTTP URL, then try to connect using the CONNECT verb,  otherwise, use the GET verb.\n\nsocks(Host, Port): Connect to the resource via a SOCKS5 proxy\n\n  These correspond to the proxy methods defined by PAC http://en.wikipedia.org/wiki/Proxy_auto-configProxy  auto-config . Additional methods can be returned if suitable clauses for http:http_connection_over_proxy/6 or try_proxy/4  are defined.\n\n",
    "prefix":"proxy_for_url"
  },
  "socket:stream_pool_main_loop/0": {
    "body":"stream_pool_main_loop$1\n$0",
    "description":"stream_pool_main_loop.\nCalls dispatch_stream_pool/1  in a loop until the pool is empty.",
    "prefix":"stream_pool_main_loop"
  },
  "socket:tcp_accept/3": {
    "body":"tcp_accept(${1:Socket}, ${2:Slave}, ${3:Peer})$4\n$0",
    "description":"[det]tcp_accept(+Socket, -Slave, -Peer).\nThis predicate waits on a server socket for a connection request by a  client. On success, it creates a new socket for the client and binds the  identifier to Slave. Peer is bound to the  IP-address of the client.",
    "prefix":"tcp_accept"
  },
  "socket:tcp_bind/2": {
    "body":"tcp_bind(${1:SocketId}, ${2:Address})$3\n$0",
    "description":"[det]tcp_bind(SocketId, ?Address).\nBind the socket to Address on the current machine. This  operation, together with tcp_listen/2  and tcp_accept/3 implement the server-side  of the socket interface. Address is either an plain Port  or a term HostPort. The first form binds the socket to the given port on  all interfaces, while the second only binds to the matching interface. A  typical example is below, causing the socket to listen only on port 8080  on the local machine's network.  \n\n  tcp_bind(Socket, localhost:8080)\n\n  If Port is unbound, the system picks an arbitrary free  port and unifies Port with the selected port number. Port  is either an integer or the name of a registered service. See also tcp_connect/4.\n\n",
    "prefix":"tcp_bind"
  },
  "socket:tcp_close_socket/1": {
    "body":"tcp_close_socket(${1:SocketId})$2\n$0",
    "description":"[det]tcp_close_socket(+SocketId).\nCloses the indicated socket, making SocketId invalid.  Normally, sockets are closed by closing both stream handles returned by open_socket/3. There are two cases where tcp_close_socket/1  is used because there are no stream-handles:  \n\nIf, after tcp_accept/3, the  server uses fork/1 to handle the  client in a sub-process. In this case the accepted socket is not longer  needed from the main server and must be discarded using tcp_close_socket/1.\nIf, after discovering the connecting client with tcp_accept/3, the server does  not want to accept the connection, it should discard the accepted socket  immediately using tcp_close_socket/1.\n\n",
    "prefix":"tcp_close_socket"
  },
  "socket:tcp_connect/2": {
    "body":"tcp_connect(${1:SocketId}, ${2:HostAndPort})$3\n$0",
    "description":"[det]tcp_connect(+SocketId, +HostAndPort).\nConnect SocketId. After successful completion, tcp_open_socket/3  can be used to create I/O-Streams to the remote socket. This predicate  is part of the low level client API. A connection to a particular host  and port is realised using these steps:  \n\n    tcp_socket(Socket),\n    tcp_connect(Socket, Host:Port),\n    tcp_open_socket(Socket, StreamPair)\n\n  Typical client applications should use the high level interface  provided by tcp_connect/3  which avoids resource leaking if a step in the process fails, and can be  hooked to support proxies. For example: \n\n\n\n    setup_call_cleanup(\n        tcp_connect(Host:Port, StreamPair, []),\n        talk(StreamPair),\n        close(StreamPair))\n\n ",
    "prefix":"tcp_connect"
  },
  "socket:tcp_connect/3": {
    "body":"tcp_connect(${1:Socket}, ${2:Address}, ${3:StreamPair})$4\n$0",
    "description":"[det]tcp_connect(+Socket, +Address, -StreamPair).\nEstablish a TCP communication as a client. The +,-,+ mode is the  preferred way for a client to establish a connection. This predicate can  be hooked to support network proxies. To use a proxy, the hook proxy_for_url/3  must be defined. Permitted options are:  bypass_proxy(+Boolean): Defaults to false. If true, do not attempt to  use any proxies to obtain the connection\n\nnodelay(+Boolean): Defaults to false. If true, set nodelay on the  resulting socket using tcp_setopt(Socket, nodelay)\n\n  The +,+,- mode is deprecated and does not support proxies. It behaves  like tcp_connect/4, but  creates a stream pair (see stream_pair/3). \n\nErrors: proxy_error(tried(ResultList)) is raised by mode (+,-,+) if  proxies are defines by proxy_for_url/3  but no proxy can establsh the connection. ResultList contains  one or more terms of the form false(Proxy) for a hook that  simply failed or error(Proxy, ErrorTerm) for a hook that raised an  exception.\n\nSee also: library(http/http_proxy) defines a hook that allows to  connect through HTTP proxies that support the CONNECT  method.\n\n ",
    "prefix":"tcp_connect"
  },
  "socket:tcp_connect/4": {
    "body":"tcp_connect(${1:Socket}, ${2:Address}, ${3:Read}, ${4:Write})$5\n$0",
    "description":"[det]tcp_connect(+Socket, +Address, -Read, -Write).\nConnect a (client) socket to Address and return a  bi-directional connection through the stream-handles Read and Write.  This predicate may be hooked by defining socket:tcp_connect_hook/4  with the same signature. Hooking can be used to deal with proxy  connections. E.g.,  \n\n:- multifile socket:tcp_connect_hook/4.\n\nsocket:tcp_connect_hook(Socket, Address, Read, Write) :-\n    proxy(ProxyAdress),\n    tcp_connect(Socket, ProxyAdress),\n    tcp_open_socket(Socket, Read, Write),\n    proxy_connect(Address, Read, Write).\n\n  deprecated: New code should use tcp_connect/3  called as tcp_connect(+Address, -StreamPair, +Options).\n\n ",
    "prefix":"tcp_connect"
  },
  "socket:tcp_fcntl/3": {
    "body":"tcp_fcntl(${1:Stream}, ${2:Action}, ${3:Argument})$4\n$0",
    "description":"[det]tcp_fcntl(+Stream, +Action, ?Argument).\nInterface to the fcntl() call. Currently only suitable to  deal switch stream to non-blocking mode using:  \n\n  tcp_fcntl(Stream, setfl, nonblock),\n\n  An attempt to read from a non-blocking stream while there is no data  available returns -1 (or end_of_file for read/1),  but at_end_of_stream/1 fails. On actual  end-of-input, at_end_of_stream/1 succeeds.\n\n",
    "prefix":"tcp_fcntl"
  },
  "socket:tcp_host_to_address/2": {
    "body":"tcp_host_to_address(${1:HostName}, ${2:Address})$3\n$0",
    "description":"[det]tcp_host_to_address(?HostName, ?Address).\nTranslate between a machines host-name and it's (IP-)address. If HostName is an atom, it is resolved using getaddrinfo()  and the IP-number is unified to Address using a term of the  format ip(Byte1,Byte2,Byte3,Byte4). Otherwise, if Address  is bound to an ip(Byte1,Byte2,Byte3,Byte4) term, it is  resolved by gethostbyaddr() and the canonical hostname is unified with HostName.  To be done: This function should support more functionality provided by  gethostbyaddr, probably by adding an option-list.\n\n ",
    "prefix":"tcp_host_to_address"
  },
  "socket:tcp_listen/2": {
    "body":"tcp_listen(${1:SocketId}, ${2:BackLog})$3\n$0",
    "description":"[det]tcp_listen(+SocketId, +BackLog).\nTells, after tcp_bind/2, the  socket to listen for incoming requests for connections. Backlog  indicates how many pending connection requests are allowed. Pending  requests are requests that are not yet acknowledged using tcp_accept/3.  If the indicated number is exceeded, the requesting client will be  signalled that the service is currently not available. A commonly used  default value for Backlog is 5.",
    "prefix":"tcp_listen"
  },
  "socket:tcp_open_socket/2": {
    "body":"tcp_open_socket(${1:SocketId}, ${2:StreamPair})$3\n$0",
    "description":"[det]tcp_open_socket(+SocketId, -StreamPair).\nCreate streams to communicate to SocketId. If SocketId  is a master socket (see tcp_bind/2), StreamPair  should be used for tcp_accept/3. If SocketId  is a connected (see tcp_connect/2)  or accepted socket (see tcp_accept/3), StreamPair  is unified to a stream pair (see stream_pair/3)  that can be used for reading and writing. The stream or pair must be  closed with close/1, which also closes SocketId.",
    "prefix":"tcp_open_socket"
  },
  "socket:tcp_open_socket/3": {
    "body":"tcp_open_socket(${1:SocketId}, ${2:InStream}, ${3:OutStream})$4\n$0",
    "description":"[det]tcp_open_socket(+SocketId, -InStream, -OutStream).\nSimilar to tcp_open_socket/2,  but creates two separate sockets where tcp_open_socket/2  would have created a stream pair.  deprecated: New code should use tcp_open_socket/2  because closing a stream pair is much easier to perform safely.\n\n ",
    "prefix":"tcp_open_socket"
  },
  "socket:tcp_select/3": {
    "body":"tcp_select(${1:ListOfStreams}, ${2:ReadyList}, ${3:TimeOut})$4\n$0",
    "description":"tcp_select(+ListOfStreams, -ReadyList, +TimeOut).\nSame as the built-in wait_for_input/3, but  integrates better with event processing and the various options of  sockets for Windows. On non-windows systems this simply calls wait_for_input/3.",
    "prefix":"tcp_select"
  },
  "socket:tcp_setopt/2": {
    "body":"tcp_setopt(${1:SocketId}, ${2:Option})$3\n$0",
    "description":"[det]tcp_setopt(+SocketId, +Option).\nSet options on the socket. Defined options are:  reuseaddr: Allow servers to reuse a port without the system being completely sure  the port is no longer in use.\n\nbindtodevice(+Device): Bind the socket to Device (an atom). For example, the code  below binds the socket to the loopback device that is typically  used to realise the localhost. See the manual pages for setsockopt()  and the socket interface (e.g., socket(7) on Linux) for details.  \n\ntcp_socket(Socket),\ntcp_setopt(Socket, bindtodevice(lo))\n\n \n\nnodelay: nodelay(true): If true, disable the Nagle optimization on this socket,  which is enabled by default on almost all modern TCP/IP stacks. The  Nagle optimization joins small packages, which is generally desirable,  but sometimes not. Please note that the underlying TCP_NODELAY setting  to setsockopt() is not available on all platforms and  systems may require additional privileges to change this option. If the  option is not supported, tcp_setopt/2  raises a domain_error exception. See http://en.wikipedia.org/wiki/Nagle's_algorithmWikipedia for details.\n\nbroadcast: UDP sockets only: broadcast the package to all addresses matching the  address. The address is normally the address of the local subnet (i.e.  192.168.1.255). See udp_send/4.\n\ndispatch(+Boolean): In GUI environments (using XPCE or the Windows swipl-win.exe  executable) this flags defines whether or not any events are dispatched  on behalf of the user interface. Default is true. Only very specific situations require setting this to false.\n\n ",
    "prefix":"tcp_setopt"
  },
  "socket:tcp_socket/1": {
    "body":"tcp_socket(${1:SocketId})$2\n$0",
    "description":"[det]tcp_socket(-SocketId).\nCreates an INET-domain stream-socket and unifies an identifier to it  with SocketId. On MS-Windows, if the socket library is not  yet initialised, this will also initialise the library.",
    "prefix":"tcp_socket"
  },
  "socket:try_proxy/4": {
    "body":"try_proxy(${1:Proxy}, ${2:TargetAddress}, ${3:Socket}, ${4:StreamPair})$5\n$0",
    "description":"[semidet,multifile]try_proxy(+Proxy, +TargetAddress, -Socket, -StreamPair).\nAttempt a socket-level connection via the given proxy to TargetAddress. The Proxy argument must match the  output argument of proxy_for_url/3.  The predicate tcp_connect/3  (and http_open/3 from the library(http/http_open))  collect the results of failed proxies and raise an exception no proxy is  capable of realizing the connection.  The default implementation recognises the values for Proxy  described below. The library(http/http_proxy) adds proxy(Host,Port) which allows for HTTP proxies using the CONNECT method. \n\ndirect: Do not use any proxy\n\nsocks(Host, Port): Use a SOCKS5 proxy\n\n ",
    "prefix":"try_proxy"
  },
  "socket:udp_receive/4": {
    "body":"udp_receive(${1:Socket}, ${2:Data}, ${3:From}, ${4:Options})$5\n$0",
    "description":"udp_receive(+Socket, -Data, -From, +Options).\nWait for and return the next datagram. The data is returned as a Prolog  string object (see string_to_list/2). From  is a term of the format ip(A,B,C,D):Port  indicating the sender of the message. Socket can be waited  for using wait_for_input/3.  Defined Options:  as(+Type): Defines the returned term-type. Type is one of atom, codes or string (default).\n\nmax_message_size(+Size): Specify the maximum number of bytes to read from a UDP datagram. Size  must be within the range 0-65535. If unspecified, a maximum of 4096  bytes will be read.\n\n  The typical sequence to receive UDP data is: \n\n\n\nreceive(Port) :-\n        udp_socket(S),\n        tcp_bind(S, Port),\n        repeat,\n            udp_receive(Socket, Data, From, [as(atom)]),\n            format('Got ~q from ~q~n', [Data, From]),\n            fail.\n\n ",
    "prefix":"udp_receive"
  },
  "socket:udp_send/4": {
    "body":"udp_send(${1:Socket}, ${2:Data}, ${3:To}, ${4:Options})$5\n$0",
    "description":"udp_send(+Socket, +Data, +To, +Options).\nSend a UDP message. Data is a string, atom or code-list providing the  data. To is an address of the form Host:Port  where Host is either the hostname or a term ip/4. Options  is currently unused.  A simple example to send UDP data is: \n\n\n\nsend(Host, Port, Message) :-\n        udp_socket(S),\n        udp_send(S, Message, Host:Port, []),\n        tcp_close_socket(S).\n\n  A broadcast is achieved by using tcp_setopt(Socket, broadcast)  prior to sending the datagram and using the local network broadcast  address as a ip/4  term.\n\n",
    "prefix":"udp_send"
  },
  "socket:udp_socket/1": {
    "body":"udp_socket(${1:Socket})$2\n$0",
    "description":"udp_socket(-Socket).\nSimilar to tcp_socket/1,  but create a socket using the SOCK_DGRAM protocol, ready  for UDP connections.",
    "prefix":"udp_socket"
  },
  "solution_sequences:distinct/1": {
    "body":"distinct(${1:Goal})$2\n$0",
    "description":"distinct(:Goal).\n",
    "prefix":"distinct"
  },
  "solution_sequences:distinct/2": {
    "body":"distinct(${1:Witness}, ${2:Goal})$3\n$0",
    "description":"distinct(?Witness, :Goal).\nTrue if Goal is true and no previous solution of Goal  bound Witness to the same value. As previous answers need to be  copied, equivalence testing is based on term variance (=@=/2).  The variant distinct/1  is equivalent to distinct(Goal,Goal).  If the answers are ground terms, the predicate behaves as the code  below, but answers are returned as soon as they become available rather  than first computing the complete answer set. \n\n\n\ndistinct(Goal) :-\n    findall(Goal, Goal, List),\n    list_to_set(List, Set),\n    member(Goal, Set).\n\n ",
    "prefix":"distinct"
  },
  "solution_sequences:group_by/4": {
    "body":"group_by(${1:By}, ${2:Template}, ${3:Goal}, ${4:Bag})$5\n$0",
    "description":"[nondet]group_by(+By, +Template, :Goal, -Bag).\nGroup bindings of Template that have the same value for By.  This predicate is almost the same as bagof/3,  but instead of specifying the existential variables we specify the free  variables. It is provided for consistency and complete coverage of the  common database vocabulary.",
    "prefix":"group_by"
  },
  "solution_sequences:limit/2": {
    "body":"limit(${1:Count}, ${2:Goal})$3\n$0",
    "description":"limit(+Count, :Goal).\nLimit the number of solutions. True if Goal is true,  returning at most Count solutions. Solutions are returned as  soon as they become available.",
    "prefix":"limit"
  },
  "solution_sequences:offset/2": {
    "body":"offset(${1:Count}, ${2:Goal})$3\n$0",
    "description":"offset(+Count, :Goal).\nIgnore the first Count solutions. True if Goal is  true and produces more than Count solutions. This predicate  computes and ignores the first Count solutions.",
    "prefix":"offset"
  },
  "solution_sequences:order_by/2": {
    "body":"order_by(${1:Spec}, ${2:Goal})$3\n$0",
    "description":"order_by(Spec, Goal).\nOrder solutions according to Spec. Spec is a list  of terms, where each element is one of. The ordering of solutions of Goal  that only differ in variables that are not shared with Spec  is not changed.  asc(Term): Order solution according to ascending Term\n\ndesc(Term): Order solution according to descending Term\n\n ",
    "prefix":"order_by"
  },
  "sort/2": {
    "body":"sort(${1:List}, ${2:Sorted})$3\n$0",
    "description":"[ISO]sort(+List, -Sorted).\nTrue if Sorted can be unified with a list holding the  elements of List, sorted to the standard order of terms (see section 4.7). Duplicates are  removed. The implementation is in C, using natural merge sort.117Contributed  by Richard O'Keefe. The sort/2  predicate can sort a cyclic list, returning a non-cyclic version with  the same elements.",
    "prefix":"sort"
  },
  "sort/4": {
    "body":"sort(${1:Key}, ${2:Order}, ${3:List}, ${4:Sorted})$5\n$0",
    "description":"sort(+Key, +Order, +List, -Sorted).\nTrue when Sorted can be unified with a list holding the  element of List. Key determines which part of each element in List is used for comparing two term and Order  describes the relation between each set of consecutive elements in Sorted.118The  definition of this predicate was established after discussion with  Joachim Schimpf from the ECLiPSe team. ECLiPSe currently only accepts <, =<, >  and >= for the Order argument  but this is likely to change. SWI-Prolog extends this predicate to deal  with dicts.  If Key is the integer zero (0), the entire term is used to  compare two elements. Using Key=0 can be used to sort  arbitrary Prolog terms. Other values for Key can only be used  with compound terms or dicts (see section  5.4). An integer key extracts the Key-th argument from a  compound term. An integer or atom key extracts the value from a dict  that is associated with the given key. A type_error is raised if the  list element is of the wrong type and an existence_error is raised if  the compound has not enough argument or the dict does not contain the  requested key. \n\nDeeper nested elements of structures can be selected by using a list  of keys for the Key argument. \n\nThe Order argument is described in the table below119For  compatibility with ECLiPSe, the values <, =<, >  and >= are allowed as synonyms. \n\n\n\nOrderOrderingDuplicate handling @< ascendingremove @=< ascendingkeep @> descendingremove @>= descendingkeep   The sort is stable, which implies that, if duplicates are  kept, the order of duplicates is not changed. If duplicates are removed,  only the first element of a sequence of duplicates appears in Sorted. \n\nThis predicate supersedes most of the other sorting primitives, for  example: \n\n\n\nsort(List, Sorted)     :- sort(0,  @<, List,  Sorted).\nmsort(List, Sorted)    :- sort(0, @=<, List,  Sorted).\nkeysort(Pairs, Sorted) :- sort(1, @=<, Pairs, Sorted).\n\n  The following example sorts a list of rows, for example resulting  from csv_read_file/2)  ascending on the 3th column and descending on the 4th column: \n\n\n\n    sort(4, @>=, Rows0, Rows1),\n    sort(3, @=<, Rows1, Sorted).\n\n  See also sort/2  (ISO), msort/2, keysort/2, predsort/3  and order_by/2.\n\n",
    "prefix":"sort"
  },
  "sort:locale_sort/2": {
    "body": ["locale_sort(${1:List}, ${2:Sorted})$3\n$0" ],
    "description":"  locale_sort(+List, -Sorted) is det.\n\n   Sort a list of atoms using the current locale.\n\n   @param List     List of atoms\n   @param Sorted   Sorted atoms.",
    "prefix":"locale_sort"
  },
  "sort:predsort/3": {
    "body": ["predsort(${1:Compare}, ${2:List}, ${3:Sorted})$4\n$0" ],
    "description":"  predsort(:Compare, +List, -Sorted) is det.\n\n   Sorts similar to sort/2, but determines   the order of two terms\n   by calling Compare(-Delta, +E1, +E2). This call must unify Delta\n   with one of <, > or =.  If built-in predicate compare/3 is used,\n   the result is the same as sort/2 (but sort/2 is built using more\n   low-level primitives and is considerably faster).\n\n   @see keysort/2 provides an more portable way to sort on\n   arbitrary keys that is usually faster.",
    "prefix":"predsort"
  },
  "source_exports/2": {
    "body":"source_exports(${1:Spec}, ${2:Export})$3\n$0",
    "description":"source_exports(+Spec, +Export).\nIs true if source Spec exports Export, a predicate  indicator. Fails without error otherwise.",
    "prefix":"source_exports"
  },
  "source_file/1": {
    "body":"source_file(${1:File})$2\n$0",
    "description":"source_file(?File).\nTrue if File is a loaded Prolog source file. File  is the absolute and canonical path to the source file.",
    "prefix":"source_file"
  },
  "source_file/2": {
    "body":"source_file(${1:Pred}, ${2:File})$3\n$0",
    "description":"source_file(:Pred, ?File).\nTrue if the predicate specified by Pred is owned by file File, where File is an absolute path name (see absolute_file_name/2).  Can be used with any instantiation pattern, but the database only  maintains the source file for each predicate. If Pred is a multifile predicate this predicate  succeeds for all files that contribute clauses to Pred.45The  current implementation performs a linear scan through all clauses to  establish this set of files. See also clause_property/2.  Note that the relation between files and predicates is more complicated  if include/1  is used. The predicate describes the owner of the predicate.  See include/1  for details.",
    "prefix":"source_file"
  },
  "source_file_property/2": {
    "body":"source_file_property(${1:File}, ${2:Property})$3\n$0",
    "description":"source_file_property(?File, ?Property).\nTrue when Property is a property of the loaded file File.  If File is non-var, it can be a file specification that is  valid for load_files/2.  Defined properties are:  derived_from(Original, OriginalModified): File was generated from the file Original, which  was last modified at time OriginalModified at the time it was  loaded. This property is available if File was loaded using  the derived_from(Original) option to load_files/2.\n\nincludes(IncludedFile, IncludedFileModified): File used include/1  to include IncludedFile. The last modified time of IncludedFile  was IncludedFileModified at the time it was included.\n\nincluded_in(MasterFile, Line): File was included into MasterFile from line Line.  This is the inverse of the includes property.\n\nload_context(Module, Location, Options): Module is the module into which the file was loaded. If File  is a module, this is the module into which the exports are imported.  Otherwise it is the module into which the clauses of the non-module file  are loaded. Location describes the file location from which  the file was loaded. It is either a term <file>:<line>  or the atom user if the file was loaded from the terminal or another  unknown source. Options are the options passed to load_files/2.  Note that all predicates to load files are mapped to load_files/2,  using the option argument to specify the exact behaviour.\n\nload_count(-Count): Count is the number of times the file have been loaded, i.e.,  1 (one) if the file has been loaded once.\n\nmodified(Stamp): File modification time when File was loaded. This is used by make/0  to find files whose modification time is different from when it was  loaded.\n\nmodule(Module): File is a module file that declares the module Module.\n\nnumber_of_clauses(Count): Count is the number of clauses associated with File.  Note that clauses loaded from included files are counted as part of the  main file.\n\nreloading: Present if the file is currently being reloaded.\n\n ",
    "prefix":"source_file_property"
  },
  "source_location/2": {
    "body":"source_location(${1:File}, ${2:Line})$3\n$0",
    "description":"source_location(-File, -Line).\nIf the last term has been read from a physical file (i.e., not from the  file user or a string), unify File with an  absolute path to the file and Line with the line number in  the file. New code should use prolog_load_context/2.",
    "prefix":"source_location"
  },
  "sp_fcompile:pce_fcompile/1": {
    "body": ["pce_fcompile(${1:'Param1'})$2\n$0" ],
    "description":"pce_fcompile('Param1')",
    "prefix":"pce_fcompile"
  },
  "sp_fcompile:pce_fcompile_boot_files/0": {
    "body": ["pce_fcompile_boot_files$1\n$0" ],
    "description":"pce_fcompile_boot_files",
    "prefix":"pce_fcompile_boot_files"
  },
  "sp_fcompile:pce_fcompile_directory/1": {
    "body": ["pce_fcompile_directory(${1:'Param1'})$2\n$0" ],
    "description":"pce_fcompile_directory('Param1')",
    "prefix":"pce_fcompile_directory"
  },
  "sp_fcompile:pce_fcompile_libraries/0": {
    "body": ["pce_fcompile_libraries$1\n$0" ],
    "description":"pce_fcompile_libraries",
    "prefix":"pce_fcompile_libraries"
  },
  "sp_fcompile:pce_frecompile_directory/1": {
    "body": ["pce_frecompile_directory(${1:'Param1'})$2\n$0" ],
    "description":"pce_frecompile_directory('Param1')",
    "prefix":"pce_frecompile_directory"
  },
  "sp_fcompile:pce_frecompile_libraries/0": {
    "body": ["pce_frecompile_libraries$1\n$0" ],
    "description":"pce_frecompile_libraries",
    "prefix":"pce_frecompile_libraries"
  },
  "split_string/4": {
    "body":"split_string(${1:String}, ${2:SepChars}, ${3:PadChars}, ${4:SubStrings})$5\n$0",
    "description":"[det]split_string(+String, +SepChars, +PadChars, -SubStrings).\nBreak String into SubStrings. The SepChars  argument provides the characters that act as separators and thus the  length of SubStrings is one more than the number of separators found if SepChars and PadChars do not have common  characters. If SepChars and PadChars are equal, sequences of  adjacent separators act as a single separator. Leading and trailing  characters for each substring that appear in PadChars are  removed from the substring. The input arguments can be either atoms,  strings or char/code lists. Compatible with ECLiPSe. Below are some  examples:  \n\n% a simple split\n?- split_string(\"a.b.c.d\", \".\", \"\", L).\nL = [\"a\", \"b\", \"c\", \"d\"].\n% Consider sequences of separators as a single one\n?- split_string(\"/home//jan///nice/path\", \"/\", \"/\", L).\nL = [\"home\", \"jan\", \"nice\", \"path\"].\n% split and remove white space\n?- split_string(\"SWI-Prolog, 7.0\", \",\", \" \", L).\nL = [\"SWI-Prolog\", \"7.0\"].\n% only remove leading and trailing white space\n?- split_string(\"  SWI-Prolog  \", \"\", \"\\s\\t\\n\", L).\nL = [\"SWI-Prolog\"].\n\n  In the typical use cases, SepChars either does not overlap PadChars or is equivalent to handle multiple adjacent  separators as a single (often white space). The behaviour with partially  overlapping sets of padding and separators should be considered  undefined. See also read_string/5.\n\n",
    "prefix":"split_string"
  },
  "spy/1": {
    "body":"spy(${1:Pred})$2\n$0",
    "description":"spy(+Pred).\nPut a spy point on all predicates meeting the predicate specification Pred. See section 4.5.",
    "prefix":"spy"
  },
  "sqrt/1": {
    "body":"sqrt(${1:Expr})$2\n$0",
    "description":"[ISO]sqrt(+Expr).\nResult = sqrt(Expr)",
    "prefix":"sqrt"
  },
  "ssl:cert_accept_any/5": {
    "body":"cert_accept_any(${1:SSL}, ${2:ProblemCertificate}, ${3:AllCertificates}, ${4:FirstCertificate}, ${5:Error})$6\n$0",
    "description":"[det]cert_accept_any(+SSL, +ProblemCertificate, +AllCertificates, +FirstCertificate, +Error).\nImplementation for the hook `cert_verify_hook(:Hook)` that accepts any  certificate. This is intended for http_open/3  if no certificate verification is desired as illustrated below.  \n\n  http_open('https:/...', In,\n            [ cert_verify_hook(cert_accept_any)\n            ])\n\n  \n\n",
    "prefix":"cert_accept_any"
  },
  "ssl:load_certificate/2": {
    "body":"load_certificate(${1:Stream}, ${2:Certificate})$3\n$0",
    "description":"[det]load_certificate(+Stream, -Certificate).\nLoads a certificate from a PEM- or DER-encoded stream, returning a term  which will unify with the same certificate if presented in  cert_verify_hook. A certificate is a list containing the following  terms: issuer_name/1, hash/1, signature/1, signature_algorithm/1, version/1, notbefore/1, notafter/1, serial/1, subject/1  and key/1. subject/1  and issuer_name/1 are both lists of =/2  terms representing the name. With OpenSSL 1.0.2 and greater, to_be_signed/1  is also available, yielding the hexadecimal representation of the TBS  (to-be-signed) portion of the certificate.  Note that the OpenSSL CA.pl utility creates certificates  that have a human readable textual representation in front of the PEM  representation. You can use the following to skip to the certificate if  you know it is a PEM certificate: \n\n\n\nskip_to_pem_cert(In) :-\n      repeat,\n      (   peek_char(In, '-')\n      ->  !\n      ;   skip(In, 0'\\n),\n          at_end_of_stream(In), !\n      ).\n\n ",
    "prefix":"load_certificate"
  },
  "ssl:load_crl/2": {
    "body":"load_crl(${1:Stream}, ${2:CRL})$3\n$0",
    "description":"[det]load_crl(+Stream, -CRL).\nLoads a CRL from a PEM- or DER-encoded stream, returning a  term containing terms hash/1, signature/1, issuer_name/1  and revocations/1, which is a list of revoked/2  terms. Each revoked/2 term is of the form revoked(+Serial, DateOfRevocation)",
    "prefix":"load_crl"
  },
  "ssl:load_private_key/3": {
    "body":"load_private_key(${1:Stream}, ${2:Password}, ${3:PrivateKey})$4\n$0",
    "description":"[det]load_private_key(+Stream, +Password, -PrivateKey).\nLoad a private key PrivateKey from the given stream Stream,  using Password to decrypt the key if it is encrypted. Note  that the password is currently only supported for PEM files. DER-encoded  keys which are password protected will not load. The key must be an RSA  or EC key. DH and DSA keys are not supported, and PrivateKey  will be bound to an atom (dh_key or dsa_key) if you try and load such a  key. Otherwise PrivateKey will be unified with private_key(KeyTerm)  where KeyTerm is an rsa/8 term  representing an RSA key, or ec/3 for EC  keys.",
    "prefix":"load_private_key"
  },
  "ssl:load_public_key/2": {
    "body":"load_public_key(${1:Stream}, ${2:PublicKey})$3\n$0",
    "description":"[det]load_public_key(+Stream, -PublicKey).\nLoad a public key PublicKey from the given stream Stream.  Supports loading both DER- and PEM-encoded keys. The key must be an RSA  or EC key. DH and DSA keys are not supported, and PublicKey will be bound to an atom (dh_key or dsa_key) if you  try and load such a key. Otherwise PublicKey will be unified  with public_key(KeyTerm) where KeyTerm is an rsa/8  term representing an RSA key, or ec/3 for  EC keys.",
    "prefix":"load_public_key"
  },
  "ssl:ssl_add_certificate_key/4": {
    "body":"ssl_add_certificate_key(${1:SSL0}, ${2:Certificate}, ${3:Key}, ${4:SSL})$5\n$0",
    "description":"ssl_add_certificate_key(+SSL0, +Certificate, +Key, -SSL).\nAdd an additional certificate/key pair to SSL0, yielding SSL. Certificate and Key are either strings or atoms  that hold the PEM-encoded certificate plus certificate chain and private  key, respectively. Using strings is preferred for security reasons.  This predicate allows dual-stack RSA and ECDSA servers (for example),  and is an alternative for using the certificate_key_pairs/1 option. As of OpenSSL 1.0.2,  multiple certificate types with completely independent certificate  chains are supported. If a certificate of the same type is added  repeatedly to a context, the result is undefined. Currently, up to 12  additional certificates of different types are admissible.\n\n",
    "prefix":"ssl_add_certificate_key"
  },
  "ssl:ssl_context/3": {
    "body":"ssl_context(${1:Role}, ${2:SSL}, ${3:Options})$4\n$0",
    "description":"[det]ssl_context(+Role, -SSL, :Options).\nCreate an SSL context. The context defines several properties  of the SSL connection such as involved keys, preferred  encryption, and passwords. After establishing a context, an SSL  connection can be negotiated using ssl_negotiate/5,  turning two arbitrary plain Prolog streams into encrypted streams. This  predicate processes the options below.  host(+HostName): For the client, the host to which it connects. This option should be specified when Role is client.  Otherwise, certificate verification may fail when negotiating a secure  connection.\n\ncertificate_file(+FileName): Specify where the certificate file can be found. This can be the same as  the key_file(+FileName) option. A server must have  at least one certificate before clients can connect. A client must have a certificate only if the server demands the client to  identify itself with a client certificate using the peer_cert(true) option. If a certificate is provided, it is  necessary to also provide a matching private key via the key_file/1 option. To configure multiple  certificates, use the option certificate_key_pairs/1  instead. Alternatively, use ssl_add_certificate_key/4  to add certificates and keys to an existing context.\n\nkey_file(+FileName): Specify where the private key that matches the certificate can be found.  If the key is encrypted with a password, this must be supplied using the password(+Text)  or pem_password_hook(:Goal) option.\n\ncertificate_key_pairs(+Pairs): Alternative method for specifying certificates and keys. The argument is  a list of pairs of the form Certificate-Key, where each component  is a string or an atom that holds, respectively, the PEM-encoded  certificate and key. To each certificate, further certificates of the  chain can be appended. Multiple types of certificates can be present at  the same time to enable different ciphers. Using multiple certificate  types with completely independent certificate chains requires OpenSSL  1.0.2 or greater.\n\npassword(+Text): Specify the password the private key is protected with (if any). If you  do not want to store the password you can also specify an application  defined handler to return the password (see next option). Text  is either an atom or string. Using a string is preferred as strings are  volatile and local resources.\n\npem_password_hook(:Goal): In case a password is required to access the private key the supplied  predicate will be called to fetch it. The hook is called as call(Goal, +SSL, -Password)  and typically unifies Password with a string containing the password.\n\nrequire_crl(+Boolean): If true (default is false), then all certificates will be considered  invalid unless they can be verified as not being revoked. You can do  this explicity by passing a list of CRL filenames via the crl/1  option, or by doing it yourself in the cert_verify_hook. If you specify require_crl(true)  and provide neither of these options, verification will necessarily fail\n\ncrl(+ListOfFileNames): Provide a list of filenames of PEM-encoded CRLs that will be given to  the context to attempt to establish that a chain of certificates is not  revoked. You must also set require_crl(true) if you want  CRLs to actually be checked by OpenSSL.\n\ncacert_file(+FileName): Specify a file containing certificate keys of trusted  certificates. The peer is trusted if its certificate is signed  (ultimately) by one of the provided certificates. Using the FileName system(root_certificates)  uses a list of trusted root certificates as provided by the OS. See system_root_certificates/1  for details.  Additional verification of the peer certificate as well as accepting  certificates that are not trusted by the given set can be realised using  the hook cert_verify_hook(:Goal).\n\ncert_verify_hook(:Goal): The predicate ssl_negotiate/5  calls Goal as follows:  \n\ncall(Goal, +SSL,\n     +ProblemCertificate, +AllCertificates, +FirstCertificate,\n     +Error)\n\n  In case the certificate was verified by one of the provided  certifications from the cacert_file option, Error is  unified with the atom verified. Otherwise it contains the  error string passed from OpenSSL. Access will be granted iff the  predicate succeeds. See load_certificate/2  for a description of the certificate terms. See cert_accept_any/5  for a dummy implementation that accepts any certificate.\n\ncipher_list(+Atom): Specify a cipher preference list (one or more cipher strings separated  by colons, commas or spaces).\n\necdh_curve(+Atom): Specify a curve for ECDHE ciphers. If this option is not specified, the  OpenSSL default parameters are used. With OpenSSL prior to 1.1.0, prime256v1  is used by default.\n\npeer_cert(+Boolean): Trigger the request of our peer's certificate while establishing the SSL  layer. This option is automatically turned on in a client SSL  socket. It can be used in a server to ask the client to identify itself  using an SSL certificate.\n\nclose_parent(+Boolean): If true, close the raw streams if the SSL  streams are closed. Default is false.\n\nclose_notify(+Boolean): If true (default is false), the server sends  TLS close_notify when closing the connection. In addition, this  mitigates truncation attacks for both client and server role: If  EOF is encountered without having received a TLS shutdown, an exception  is raised. Well-designed protocols are self-terminating, and this attack  is therefore very rarely a concern.\n\nmin_protocol_version(+Atom): Set the minimum protocol version that can be negotiated. Atom is one of sslv3, tlsv1, tlsv1_1  and tlsv1_2. This option is available with OpenSSL 1.1.0  and later, and should be used instead of disable_ssl_methods/1.\n\nmax_protocol_version(+Atom): Set the maximum protocol version that can be negotiated. Atom is one of sslv3, tlsv1, tlsv1_1  and tlsv1_2. This option is available with OpenSSL 1.1.0  and later, and should be used instead of disable_ssl_methods/1.\n\ndisable_ssl_methods(+List): A list of methods to disable. Unsupported methods will be ignored.  Methods include sslv2, sslv3, sslv23, tlsv1, tlsv1_1 and tlsv1_2. This  option is deprecated starting with OpenSSL 1.1.0. Use min_protocol_version/1  and max_protocol_version/1 instead.\n\nssl_method(+Method): Specify the explicit Method to use when negotiating. For  allowed values, see the list for disable_ssl_methods above.  Using this option is discouraged. When using OpenSSL 1.1.0 or later,  this option is ignored, and a version-flexible method is used to  negotiate the connection. Using version-specific methods is deprecated  in recent OpenSSL versions, and this option will become obsolete and  ignored in the future.\n\nsni_hook(:Goal): This option provides Server Name Indication (SNI) for SSL  servers. This means that depending on the host to which a client  connects, different options (certificates etc.) can be used for the  server. This TLS extension allows you to host different domains using  the same IP address and physical machine. When a TLS connection is  negotiated with a client that has provided a host name via SNI, the hook  is called as follows:  \n\ncall(Goal, +SSL0, +HostName, -SSL)\n\n  Given the current context SSL0, and the host name of the client  request, the predicate computes SSL which is used as the  context for negotiating the connection. The first solution is used. If  the predicate fails, the default options are used, which are those of  the encompassing ssl_context/3  call. In that case, if no default certificate and key are specified, the  client connection is rejected.\n\n  Role is one of server  or client and denotes whether the SSL instance will have a server or client role in the  established connection. SSL is a SWI-Prolog blob  of type ssl_context, i.e., the type-test for an SSL  context is blob(SSL, ssl_context). ",
    "prefix":"ssl_context"
  },
  "ssl:ssl_negotiate/5": {
    "body":"ssl_negotiate(${1:SSL}, ${2:PlainRead}, ${3:PlainWrite}, ${4:SSLRead}, ${5:SSLWrite})$6\n$0",
    "description":"[det]ssl_negotiate(+SSL, +PlainRead, +PlainWrite, -SSLRead, -SSLWrite).\nOnce a connection is established and a read/write stream pair is  available, (PlainRead and PlainWrite), this  predicate can be called to negotiate an SSL session over the  streams. If the negotiation is successful, SSLRead and SSLWrite  are returned.  After a successful handshake and finishing the communication the user  must close SSLRead and SSLWrite, for example using call_cleanup(close(SSLWrite), close(SSLRead)). If the SSL context (created with ssl_context/3  has the option close_parent(true) (default false), closing SSLRead  and SSLWrite also closes the original PlainRead and PlainWrite  streams. Otherwise these must be closed explicitly by the user. \n\nErrors: ssl_error(Code, LibName, FuncName, Reason) is raised if the  negotiation fails. The streams PlainRead and PlainWrite  are not closed, but an unknown amount of data may have been read  and written.\n\n ",
    "prefix":"ssl_negotiate"
  },
  "ssl:ssl_peer_certificate/2": {
    "body":"ssl_peer_certificate(${1:Stream}, ${2:Certificate})$3\n$0",
    "description":"[semidet]ssl_peer_certificate(+Stream, -Certificate).\nTrue if the peer certificate is provided (this is always the case for a  client connection) and Certificate unifies with the peer  certificate. The example below uses this to obtain the Common Name of the peer after establishing an https client  connection:  \n\n  http_open(HTTPS_url, In, []),\n  ssl_peer_certificate(In, Cert),\n  memberchk(subject(Subject), Cert),\n  memberchk('CN' = CommonName), Subject)\n\n ",
    "prefix":"ssl_peer_certificate"
  },
  "ssl:ssl_peer_certificate_chain/2": {
    "body":"ssl_peer_certificate_chain(${1:Stream}, ${2:Certificates})$3\n$0",
    "description":"[det]ssl_peer_certificate_chain(+Stream, -Certificates).\nCertificates is the certificate chain provided by the peer,  represented as a list of certificates.",
    "prefix":"ssl_peer_certificate_chain"
  },
  "ssl:ssl_session/2": {
    "body":"ssl_session(${1:Stream}, ${2:Session})$3\n$0",
    "description":"[det]ssl_session(+Stream, -Session).\nRetrieves (debugging) properties from the SSL context associated with Stream.  If Stream is not an SSL stream, the predicate raises a domain  error. Session is a list of properties, containing the  members described below. Except for Version, all information  are byte arrays that are represented as Prolog strings holding  characters in the range 0..255.  ssl_version(Version): The negotiated version of the session as an integer.\n\ncipher(Cipher): The negotiated cipher for this connection.\n\nsession_key(Key): The key material used in SSLv2 connections (if present).\n\nmaster_key(Key): The key material comprising the master secret. This is generated from  the server_random, client_random and pre-master key.\n\nclient_random(Random): The random data selected by the client during handshaking.\n\nserver_random(Random): The random data selected by the server during handshaking.\n\nsession_id(SessionId): The SSLv3 session ID. Note that if ECDHE is being used (which is the  default for newer versions of OpenSSL), this data will not actually be  sent to the server.\n\n ",
    "prefix":"ssl_session"
  },
  "ssl:ssl_set_sni_hook/3": {
    "body":"ssl_set_sni_hook(${1:SSL0}, ${2:Goal}, ${3:SSL})$4\n$0",
    "description":"ssl_set_sni_hook(+SSL0, :Goal, -SSL).\nSSL is the same as SSL0, except that the SNI hook  of SSL is Goal. See the sni_hook(:Goal)  option of ssl_context/3 for  more information about this hook.",
    "prefix":"ssl_set_sni_hook"
  },
  "ssl:system_root_certificates/1": {
    "body":"system_root_certificates(${1:List})$2\n$0",
    "description":"[det]system_root_certificates(-List).\nList is a list of trusted root certificates as provided by  the OS. This is the list used by ssl_context/3  when using the option system(root_certificates). The list is obtained using an OS  specific process. The current implementation is as follows:  \n\nOn Windows, CertOpenSystemStore() is used to import the \"ROOT\"  certificates from the OS.\nOn MacOSX, the trusted keys are loaded from the SystemRootCertificates key chain. The Apple API for this requires  the SSL interface to be compiled with an XCode compiler, i.e., not  with native gcc.\nOtherwise, certificates are loaded from a file defined by the Prolog  flag system_cacert_filename. The initial value of this flag  is operating system dependent. For security reasons, the flag can only  be set prior to using the SSL library. For example:  :- use_module(library(ssl)). :- set_prolog_flag(system_cacert_filename,                    '/home/jan/ssl/ca-bundle.crt').  \n\n",
    "prefix":"system_root_certificates"
  },
  "stamp_date_time/3": {
    "body":"stamp_date_time(${1:TimeStamp}, ${2:DateTime}, ${3:TimeZone})$4\n$0",
    "description":"stamp_date_time(+TimeStamp, -DateTime, +TimeZone).\nConvert a TimeStamp to a DateTime in the given  timezone. See section 4.35.2.1 for  details on the data types. TimeZone describes the timezone  for the conversion. It is one of local to extract the local  time, 'UTC' to extract a UTC time or an integer describing  the seconds west of Greenwich.",
    "prefix":"stamp_date_time"
  },
  "start_emacs:emacs/0": {
    "body": ["emacs$1\n$0" ],
    "description":"  emacs is det.\n\n   Create PceEmacs and open the *scratch* buffer.",
    "prefix":"emacs"
  },
  "start_emacs:emacs/1": {
    "body": ["emacs(${1:Location})$2\n$0" ],
    "description":"  emacs(+Location) is det.\n\n   Create PceEmacs and edit  Location.  Location   is  one  of  the\n   following, where File must be an atom   and Line and LinePos are\n   integers.\n\n     - File:Line:LinePos\n     - File:Line\n     - File",
    "prefix":"emacs"
  },
  "start_emacs:emacs_server/0": {
    "body": ["emacs_server$1\n$0" ],
    "description":"  emacs_server is det.\n\n   Create a PceEmacs, ready to run as an unattended background\n   server.",
    "prefix":"emacs_server"
  },
  "start_emacs:emacs_toplevel/0": {
    "body": ["emacs_toplevel$1\n$0" ],
    "description":"  emacs_toplevel is det.\n\n   Prepare to run PceEmacs as a stand-alone executable.",
    "prefix":"emacs_toplevel"
  },
  "start_emacs:start_emacs/0": {
    "body": ["start_emacs$1\n$0" ],
    "description":"  start_emacs is det.\n\n   Create PceEmacs, but no buffers nor windows.",
    "prefix":"start_emacs"
  },
  "statistics/0": {
    "body":"statistics$1\n$0",
    "description":"statistics.\nDisplay a table of system statistics on the stream user_error.",
    "prefix":"statistics"
  },
  "statistics/2": {
    "body":"statistics(${1:Key}, ${2:Value})$3\n$0",
    "description":"statistics(+Key, -Value).\nUnify system statistics determined by Key with Value.  The possible keys are given in the table  6. This predicate supports additional keys for compatibility  reasons. These keys are described in table  7.  \n\nNative keys (times as float  in seconds)agcNumber of atom garbage collections  performed agc_gainedNumber of atoms removed agc_timeTime spent in atom garbage  collections atomsTotal number of defined atoms c_stackSystem (C-) stack limit. 0 if not  known. cgcNumber of clause garbage collections  performed cgc_gainedNumber of clauses reclaimed cgc_timeTime spent in clause garbage  collections clausesTotal number of clauses in the  program codesTotal size of (virtual) executable  code in words cputime(User) CPU  time since thread was started in seconds epochTime stamp when thread was started functorsTotal number of defined name/arity  pairs globalAllocated size of the global stack  in bytes globalusedNumber of bytes in use on the  global stack globallimitSize to which the global stack  is allowed to grow global_shiftsNumber of global stack  expansions heapusedBytes of heap in use by Prolog (0  if not maintained) inferencesTotal number of passes via the  call and redo ports since Prolog was started modulesTotal number of defined modules localAllocated size of the local stack in  bytes local_shiftsNumber of local stack  expansions locallimitSize to which the local stack is  allowed to grow localusedNumber of bytes in use on the  local stack table_space_usedAmount of bytes in use by  the thread's answer tables trailAllocated size of the trail stack in  bytes trail_shiftsNumber of trail stack  expansions traillimitSize to which the trail stack is  allowed to grow trailusedNumber of bytes in use on the  trail stack shift_timeTime spent in stack-shifts stackTotal memory in use for stacks in all  threads predicatesTotal number of predicates. This  includes predicates that are undefined or not yet resolved. process_epochTime stamp when Prolog was  started process_cputime(User) CPU  time since Prolog was started in seconds thread_cputimeMT-version: Seconds CPU time  used by finished threads. Basically non-portable. Works on Linux,  MacOSX, Windows and probably some more. threadsMT-version: number of active  threads threads_createdMT-version: number of  created threads enginesMT-version: number of existing  engines engines_createdMT-version: number of  created engines  Table 6 : Keys for statistics/2.  Space is expressed in bytes. Time is expressed in seconds, represented  as a floating point number.   \n\nCompatibility keys (times in  milliseconds)runtime[ CPU time, CPU time since last ]  (milliseconds, excluding time spent in garbage collection) system_time[ System CPU time, System CPU  time since last ] (milliseconds)real_time[ Wall time, Wall time since last  ] (integer seconds. See get_time/1) walltime[ Wall time since start, Wall time  since last] (milliseconds, SICStus compatibility) memory[ Total unshared data, free memory ]  (Uses getrusage() if available, otherwise incomplete own statistics.) stacks[ global use, local use ] program[ heap, 0 ] global_stack[ global use, global free ] local_stack[ local use, local free ] trail[ trail use, trail free ] garbage_collection[ number of GC, bytes  gained, time spent, bytes left ] The last column is a SWI-Prolog  extension. It contains the sum of the memory left after each collection,  which can be divided by the count to find the average working set size  after GC. Use [Count, Gained, Time|_] for compatiblity. stack_shifts[ global shifts, local shifts,  time spent ] atoms[ number, memory use, 0 ] atom_garbage_collection[ number of AGC,  bytes gained, time spent ] clause_garbage_collection[ number of CGC,  clauses gained, time spent ] coreSame as memory  Table 7 : Compatibility keys for statistics/2.  Time is expressed in milliseconds. ",
    "prefix":"statistics"
  },
  "stayup_popup:install_unfocus_hook/0": {
    "body": ["install_unfocus_hook$1\n$0" ],
    "description":"install_unfocus_hook",
    "prefix":"install_unfocus_hook"
  },
  "stream_info:stream_info/1": {
    "body": ["stream_info(${1:Stream})$2\n$0" ],
    "description":"  stream_info(+Stream) is det.\n\n   Print detailed information about a stream   or  a file-number to\n   the error output. The  output  of   this  command  is  meant for\n   experts and requires  knowledge  about   the  implementation  of\n   streams. It has been  added  to   diagnose  leaking  streams  in\n   web-servers. For example,  on  linux   systems  we  can  examine\n   process file-descriptors using\n\n   ==\n   % ls -l /proc/<pid>/fd\n   ==\n\n   If now (say) descriptor 15 is open   where  it should not be, we\n   can this command to find the associated Prolog streams and print\n   as mush as possible information about the stream.\n\n   ==\n   ?- stream_info(15).\n   ==\n\n   @param  Stream  A stream-handle, alias name, (integer) system\n           file handle or `'<stream>(address)'` atom.",
    "prefix":"stream_info"
  },
  "stream_pair/3": {
    "body":"stream_pair(${1:StreamPair}, ${2:Read}, ${3:Write})$4\n$0",
    "description":"stream_pair(?StreamPair, ?Read, ?Write).\nThis predicate can be used in mode (-,+,+) to create a stream-pair from an input stream and an output stream. Mode  (+,-,-) can be used to get access to the underlying streams. If a stream  has already been closed, the corresponding argument is left unbound. If  mode (+,-,-) is used on a single stream, either Read or Write is unified with the stream while the other argument is  left unbound. This behaviour simplifies writing code that must operate  both on streams and stream pairs.  Stream-pairs can be used by all I/O operations on streams, where the  operation selects the appropriate member of the pair. The predicate close/1  closes the still open streams of the pair.80As  of version 7.1.19, it is allowed to close one of the members of the  stream directly and close the pair later. The output stream  is closed before the input stream. If closing the output stream results  in an error, the input stream is still closed. Success is only returned  if both streams were closed successfully.\n\n",
    "prefix":"stream_pair"
  },
  "stream_pool:add_stream_to_pool/2": {
    "body": ["add_stream_to_pool(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"add_stream_to_pool('Param1','Param2')",
    "prefix":"add_stream_to_pool"
  },
  "stream_pool:close_stream_pool/0": {
    "body": ["close_stream_pool$1\n$0" ],
    "description":"close_stream_pool",
    "prefix":"close_stream_pool"
  },
  "stream_pool:delete_stream_from_pool/1": {
    "body": ["delete_stream_from_pool(${1:'Param1'})$2\n$0" ],
    "description":"delete_stream_from_pool('Param1')",
    "prefix":"delete_stream_from_pool"
  },
  "stream_pool:dispatch_stream_pool/1": {
    "body": ["dispatch_stream_pool(${1:'Param1'})$2\n$0" ],
    "description":"dispatch_stream_pool('Param1')",
    "prefix":"dispatch_stream_pool"
  },
  "stream_pool:stream_pool_main_loop/0": {
    "body": ["stream_pool_main_loop$1\n$0" ],
    "description":"stream_pool_main_loop",
    "prefix":"stream_pool_main_loop"
  },
  "stream_position_data/3": {
    "body":"stream_position_data(${1:Field}, ${2:Pos}, ${3:Data})$4\n$0",
    "description":"stream_position_data(?Field, +Pos, -Data).\nExtracts information from the opaque stream position term as returned by stream_property/2  requesting the position(Pos) property. Field is one of line_count, line_position, char_count or byte_count. See also line_count/2, line_position/2, character_count/2  and byte_count/2.81Introduced  in version 5.6.4 after extending the position term with a byte count.  Compatible with SICStus Prolog.",
    "prefix":"stream_position_data"
  },
  "stream_property/2": {
    "body":"stream_property(${1:Stream}, ${2:StreamProperty})$3\n$0",
    "description":"[ISO]stream_property(?Stream, ?StreamProperty).\nTrue when StreamProperty is a property of Stream.  If enumeration of streams or properties is demanded because either Stream or StreamProperty are unbound, the  implementation enumerates all candidate streams and properties while  locking the stream database. Properties are fetched without locking the  stream and may be outdated before this predicate returns due to  asynchronous activity.  alias(Atom): If Atom is bound, test if the stream has the specified alias.  Otherwise unify Atom with the first alias of the stream.bugBacktracking  does not give other aliases.\n\nbuffer(Buffering): SWI-Prolog extension to query the buffering mode of this stream. Buffering is one of full, line or false.  See also open/4.\n\nbuffer_size(Integer): SWI-Prolog extension to query the size of the I/O buffer associated to a  stream in bytes. Fails if the stream is not buffered.\n\nbom(Bool): If present and true, a BOM (Byte Order Mark) was  detected while opening the file for reading, or a BOM was written while  opening the stream. See section  2.18.1.1 for details.\n\nclose_on_abort(Bool): Determine whether or not abort/0  closes the stream. By default streams are closed.\n\nclose_on_exec(Bool): Determine whether or not the stream is closed when executing a new  process (exec() in Unix, CreateProcess() in Windows). Default is to  close streams. This maps to fcntl() F_SETFD using the flag FD_CLOEXEC on Unix and (negated) HANDLE_FLAG_INHERIT  on Windows.\n\nencoding(Encoding): Query the encoding used for text. See section  2.18.1 for an overview of wide character and encoding issues in  SWI-Prolog.\n\nend_of_stream(E): If Stream is an input stream, unify E with one of  the atoms not, at or past. See  also at_end_of_stream/[0,1].\n\neof_action(A): Unify A with one of eof_code, reset  or error. See open/4  for details.\n\nfile_name(Atom): If Stream is associated to a file, unify Atom to  the name of this file.\n\nfile_no(Integer): If the stream is associated with a POSIX file descriptor, unify Integer with the descriptor number. SWI-Prolog extension used  primarily for integration with foreign code. See also Sfileno() from SWI-Stream.h.\n\ninput: True if Stream has mode read.\n\nlocale(Locale): True when Locale is the current locale associated with the  stream. See section 4.23.\n\nmode(IOMode): Unify IOMode to the mode given to open/4  for opening the stream. Values are: read, write, append  and the SWI-Prolog extension update.\n\nnewline(NewlineMode): One of posix or dos. If dos, text  streams will emit \\r\\n for \\n and discard \\r  from input streams. Default depends on the operating system.\n\nnlink(-Count): Number of hard links to the file. This expresses the number of `names'  the file has. Not supported on all operating systems and the value might  be bogus. See the documentation of fstat() for your OS and the value st_nlink.\n\noutput: True if Stream has mode write, append  or update.\n\nposition(Pos): Unify Pos with the current stream position. A stream position  is an opaque term whose fields can be extracted using stream_position_data/3.  See also set_stream_position/2.\n\nreposition(Bool): Unify Bool with true if the position of the stream  can be set (see seek/4).  It is assumed the position can be set if the stream has a seek-function  and is not based on a POSIX file descriptor that is not associated to a  regular file.\n\nrepresentation_errors(Mode): Determines behaviour of character output if the stream cannot represent  a character. For example, an ISO Latin-1 stream cannot represent  Cyrillic characters. The behaviour is one of error (throw  an I/O error exception), prolog (write \\...\\  escape code) or xml (write &#...; XML  character entity). The initial mode is prolog for the user  streams and error for all other streams. See also section  2.18.1 and set_stream/2.\n\ntimeout(-Time): Time is the timeout currently associated with the stream. See set_stream/2  with the same option. If no timeout is specified, Time is unified to the atom infinite.\n\ntype(Type): Unify Type with text or binary.\n\ntty(Bool): This property is reported with Bool equal to true  if the stream is associated with a terminal. See also set_stream/2.\n\n ",
    "prefix":"stream_property"
  },
  "string/1": {
    "body":"string(${1:Term})$2\n$0",
    "description":"string(@Term).\nTrue if Term is bound to a string. Note that string here  refers to the built-in atomic type string as described in section  5.2. Starting with version7, the syntax for a string object is  text between double quotes, such as \"hello\".51In  traditional Prolog systems, double quoted text is often mapped to a list  of character codes. See also the Prolog flag double_quotes.",
    "prefix":"string"
  },
  "string_chars/2": {
    "body":"string_chars(${1:String}, ${2:Chars})$3\n$0",
    "description":"string_chars(?String, ?Chars).\nBi-directional conversion between a string and a list of characters  (one-character atoms). At least one of the two arguments must be  instantiated.",
    "prefix":"string_chars"
  },
  "string_code/3": {
    "body":"string_code(${1:Index}, ${2:String}, ${3:Code})$4\n$0",
    "description":"string_code(?Index, +String, ?Code).\nTrue when Code represents the character at the 1-based Index  position in String. If Index is unbound the string  is scanned from index 1. Raises a domain error if Index is  negative. Fails silently if Index is zero or greater than the  length of String. The mode string_code(-,+,+) is  deterministic if the searched-for Code appears only once in String.  See also sub_string/5.",
    "prefix":"string_code"
  },
  "string_codes/2": {
    "body":"string_codes(${1:String}, ${2:Codes})$3\n$0",
    "description":"string_codes(?String, ?Codes).\nBi-directional conversion between a string and a list of character  codes. At least one of the two arguments must be instantiated.",
    "prefix":"string_codes"
  },
  "string_concat/3": {
    "body":"string_concat(${1:String1}, ${2:String2}, ${3:String3})$4\n$0",
    "description":"string_concat(?String1, ?String2, ?String3).\nSimilar to atom_concat/3,  but the unbound argument will be unified with a string object rather  than an atom. Also, if both String1 and String2 are unbound and String3 is bound to text,  it breaks String3, unifying the start with String1 and the  end with String2 as append does with lists. Note that this is not  particularly fast on long strings, as for each redo the system has to  create two entirely new strings, while the list equivalent only creates  a single new list-cell and moves some pointers around.",
    "prefix":"string_concat"
  },
  "string_length/2": {
    "body":"string_length(${1:String}, ${2:Length})$3\n$0",
    "description":"string_length(+String, -Length).\nUnify Length with the number of characters in String.  This predicate is functionally equivalent to atom_length/2  and also accepts atoms, integers and floats as its first argument.",
    "prefix":"string_length"
  },
  "string_lower/2": {
    "body":"string_lower(${1:String}, ${2:LowerCase})$3\n$0",
    "description":"string_lower(+String, LowerCase).\nConvert String to lower case and unify the result with LowerCase.",
    "prefix":"string_lower"
  },
  "string_upper/2": {
    "body":"string_upper(${1:String}, ${2:UpperCase})$3\n$0",
    "description":"string_upper(+String, -UpperCase).\nConvert String to upper case and unify the result with UpperCase.",
    "prefix":"string_upper"
  },
  "strip_module/3": {
    "body":"strip_module(${1:Term}, ${2:Module}, ${3:Plain})$4\n$0",
    "description":"strip_module(+Term, -Module, -Plain).\nUsed in module-transparent predicates or meta-predicates to extract the  referenced module and plain term. If Term is a  module-qualified term, i.e. of the format Module:Plain, Module  and Plain are unified to these values. Otherwise, Plain  is unified to Term and Module to the context module.",
    "prefix":"strip_module"
  },
  "style_check/1": {
    "body":"style_check(${1:Spec})$2\n$0",
    "description":"style_check(+Spec).\nModify/query style checking options. Spec is one of the terms  below or a list of these.  \n\n+Style enables a style check\n-Style disables a style check\n?(Style) queries a style check (note the brackets). If Style  is unbound, all active style check options are returned on backtracking.\n\n  Loading a file using load_files/2  or one of its derived predicates reset the style checking options to  their value before loading the file, scoping the option to the remainder  of the file and all files loaded after changing the style checking. \n\nsingleton(true): The predicate read_clause/3  (used by the compiler to read source code) warns on variables appearing  only once in a term (clause) which have a name not starting with an  underscore. See section 2.15.1.9  for details on variable handling and warnings.\n\nno_effect(true): This warning is generated by the compiler for BIPs (built-in predicates)  that are inlined by the compiler and for which the compiler can prove  that they are meaningless. An example is using ==/2  against a not-yet-initialised variable as illustrated in the example  below. This comparison is always false.  \n\nalways_false(X) :-\n        X == Y,\n        write(Y).\n\n \n\nvar_branches(false): Verifies that if a variable is introduced in a branch and used after the branch, it is introduced in all branches. This code  aims at bugs following the skeleton below, where p(Next)  may be called with Next unbound.  \n\np(Arg) :-\n        (  Cond\n        -> Next = value1\n        ;  true\n        ),\n        p(Next).\n\n  If a variable V is intended to be left unbound, one can  use V=_. This construct is removed by the compiler and thus has  no implications for the performance of your program. This check was suggested together with semantic singleton  checking. The SWI-Prolog libraries contain about a hundred clauses that  are triggered by this style check. Unlike semantic singleton analysis,  only a tiny fraction of these clauses proofed faulty. In most cases, the  branches failing to bind the variable fail or raise an exception or the  caller handles the case where the variable is unbound. The status of  this style check is unclear. It might be removed in the future or it  might be enhanced with a deeper analysis to be more precise.\n\natom(true): The predicate read/1  and derived predicates produce an error message on quoted atoms or  strings with more than 6 unescaped newlines. Newlines may be  escaped with \\ or \\c.  This flag also enables warnings on \\<newline>  followed by blank space in native mode. See section  2.15.1.3. Note that the ISO standard does not allow for unescaped  newlines in quoted atoms.\n\ndiscontiguous(true): Warn if the clauses for a predicate are not together in the same source  file. It is advised to disable the warning for discontiguous predicates  using the discontiguous/1  directive.\n\ncharset(false): Warn on atoms and variable names holding non-ASCII characters that are  not quoted. See also section 2.15.1.1.\n\n ",
    "prefix":"style_check"
  },
  "sub_atom/5": {
    "body":"sub_atom(${1:Atom}, ${2:Before}, ${3:Len}, ${4:After}, ${5:Sub})$6\n$0",
    "description":"[ISO]sub_atom(+Atom, ?Before, ?Len, ?After, ?Sub).\nISO predicate for breaking atoms. It maintains the following relation: Sub is a sub-atom of Atom that starts at Before,  has Len characters, and Atom contains After  characters after the match.  \n\n?- sub_atom(abc, 1, 1, A, S).\n\nA = 1, S = b\n\n  The implementation minimises non-determinism and creation of atoms.  This is a flexible predicate that can do search, prefix- and  suffix-matching, etc.\n\n",
    "prefix":"sub_atom"
  },
  "sub_atom_icasechk/3": {
    "body":"sub_atom_icasechk(${1:Haystack}, ${2:Start}, ${3:Needle})$4\n$0",
    "description":"[semidet]sub_atom_icasechk(+Haystack, ?Start, +Needle).\nTrue when Needle is a sub atom of Haystack  starting at Start. The match is `half case insensitive', i.e., uppercase  letters in Needle only match themselves, while lowercase  letters in Needle match case insensitively. Start  is the first 0-based offset inside Haystack where Needle  matches.99This predicate replaces $apropos_match/2,  used by the help system, while extending it with locating the (first)  match and performing case insensitive prefix matching. We are still not  happy with the name and interface.",
    "prefix":"sub_atom_icasechk"
  },
  "sub_string/3": {
    "body":"sub_string(${1:Table}, ${2:Sub}, ${3:String})$4\n$0",
    "description":"sub_string(+Table, +Sub, +String).\nSucceeds if Sub is a substring of String using the named Table.",
    "prefix":"sub_string"
  },
  "sub_string/5": {
    "body":"sub_string(${1:String}, ${2:Before}, ${3:Length}, ${4:After}, ${5:SubString})$6\n$0",
    "description":"sub_string(+String, ?Before, ?Length, ?After, ?SubString).\nSubString is a substring of String. There are Before  characters in String before SubString, SubString  contains Length character and is followed by After  characters in String. If not enough information is provided  to compute the start of the match, String is scanned  left-to-right. This predicate is functionally equivalent to sub_atom/5,  but operates on strings. The following example splits a string of the  form <name>=<value> into the name part (an  atom) and the value (a string).  \n\nname_value(String, Name, Value) :-\n        sub_string(String, Before, _, After, \"=\"), !,\n        sub_string(String, 0, Before, _, NameString),\n        atom_string(Name, NameString),\n        sub_string(String, _, After, 0, Value).\n\n ",
    "prefix":"sub_string"
  },
  "subsumes_term/2": {
    "body":"subsumes_term(${1:Generic}, ${2:Specific})$3\n$0",
    "description":"[ISO]subsumes_term(@Generic, @Specific).\nTrue if Generic can be made equivalent to Specific  by only binding variables in Generic. The current  implementation performs the unification and ensures that the variable  set of Specific is not changed by the unification. On  success, the bindings are undone.57This  predicate is often named subsumes_chk/2  in older Prolog dialects. The current name was established in the ISO  WG17 meeting in Edinburgh (2010). The chk postfix was  considered to refer to determinism as in e.g., memberchk/2.  This predicate respects constraints.",
    "prefix":"subsumes_term"
  },
  "succ/2": {
    "body":"succ(${1:Int1}, ${2:Int2})$3\n$0",
    "description":"succ(?Int1, ?Int2).\nTrue if Int2 = Int1 + 1 and Int1  >= 0. At least one of the arguments must be instantiated to a  natural number. This predicate raises the domain error not_less_than_zero  if called with a negative integer. E.g. succ(X, 0) fails  silently and succ(X, -1) raises a domain error.102The  behaviour to deal with natural numbers only was defined by Richard  O'Keefe to support the common count-down-to-zero in a natural way. Up to  5.1.8, succ/2  also accepted negative integers.",
    "prefix":"succ"
  },
  "suite/1": {
    "body":"suite(${1:N})$2\n$0",
    "description":"suite(+N).\nRun test N using the file suite/tN.rdf and  display the RDF source, the intermediate Prolog representation and the  resulting triples.",
    "prefix":"suite"
  },
  "swi_ide:prolog_ide/0": {
    "body": ["prolog_ide$1\n$0" ],
    "description":"prolog_ide",
    "prefix":"prolog_ide"
  },
  "swi_ide:prolog_ide/1": {
    "body": ["prolog_ide(${1:Action})$2\n$0" ],
    "description":"  prolog_ide(+Action)\n\n   Invoke an action on the (SWI-)Prolog  IDE application. This is a\n   predicate to ensure  optimal  delaying   of  loading  and object\n   creation for accessing the  various   components  of  the Prolog\n   Integrated Development Environment.",
    "prefix":"prolog_ide"
  },
  "swi_option:dict_options/2": {
    "body": ["dict_options(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"dict_options('Param1','Param2')",
    "prefix":"dict_options"
  },
  "swi_option:merge_options/3": {
    "body": ["merge_options(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"merge_options('Param1','Param2','Param3')",
    "prefix":"merge_options"
  },
  "swi_option:meta_options/3": {
    "body": ["meta_options(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"meta_options('Param1','Param2','Param3')",
    "prefix":"meta_options"
  },
  "swi_option:option/2": {
    "body": ["option(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"option('Param1','Param2')",
    "prefix":"option"
  },
  "swi_option:option/3": {
    "body": ["option(${1:Option}, ${2:OptionList}, ${3:Default})$4\n$0" ],
    "description":"  option(?Option, +OptionList, +Default) is semidet.\n\n   Get  an  Option  from  OptionList.  OptionList  can  use  the\n   Name=Value as well as the Name(Value) convention.\n\n   @param Option   Term of the form Name(?Value).",
    "prefix":"option"
  },
  "swi_option:select_option/3": {
    "body": ["select_option(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"select_option('Param1','Param2','Param3')",
    "prefix":"select_option"
  },
  "swi_option:select_option/4": {
    "body": [
      "select_option(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"select_option('Param1','Param2','Param3','Param4')",
    "prefix":"select_option"
  },
  "swi_system_utilities:lock_predicate/1": {
    "body": ["lock_predicate(${1:PredInd})$2\n$0" ],
    "description":"  lock_predicate(+PredInd)\n\n   Transform a predicate into a system predicate.",
    "prefix":"lock_predicate"
  },
  "swi_system_utilities:system_mode/1": {
    "body": ["system_mode(${1:Boolean})$2\n$0" ],
    "description":"  system_mode(+Boolean) is det.\n\n   Switch the system into system or user mode.  When in system mode,\n   system predicates loose most of their special properties, so it\n   becomes possible to trace and even redefine them.\n\n   @deprecated  New code should use the prolog flag =access_level=.",
    "prefix":"system_mode"
  },
  "swi_system_utilities:system_module/0": {
    "body": ["system_module$1\n$0" ],
    "description":"  system_module\n\n   Any predicate defined after this declaraction   uptil the end of\n   the file will become a system   predicate. Normally invoked by a\n   directive immediately following the module declaration.",
    "prefix":"system_module"
  },
  "swi_system_utilities:unlock_predicate/1": {
    "body": ["unlock_predicate(${1:PredInd})$2\n$0" ],
    "description":"  unlock_predicate(+PredInd)\n\n   Transform a system predicate into a normal system predicate.",
    "prefix":"unlock_predicate"
  },
  "swritef/2": {
    "body":"swritef(${1:String}, ${2:Format})$3\n$0",
    "description":"[deprecated]swritef(-String, +Format).\nEquivalent to swritef(String, Format, []).",
    "prefix":"swritef"
  },
  "swritef/3": {
    "body":"swritef(${1:String}, ${2:Format}, ${3:Arguments})$4\n$0",
    "description":"[deprecated]swritef(-String, +Format, +Arguments).\nEquivalent to writef/2,  but ``writes'' the result on String instead of the current  output stream. Example:  \n\n?- swritef(S, '%15L%w', ['Hello', 'World']).\n\nS = \"Hello          World\"\n\n ",
    "prefix":"swritef"
  },
  "syslog:closelog/0": {
    "body": ["closelog$1\n$0" ],
    "description":"  closelog is det.\n\n   Close the system log.",
    "prefix":"closelog"
  },
  "syslog:openlog/3": {
    "body":"openlog(${1:Ident}, ${2:Options}, ${3:Facility})$4\n$0",
    "description":"[det]openlog(+Ident:atom, +Options:list(atom), +Facility:atom).\nOpen system log. This predicate provides a direct interface into the openlog()  library call. If the library call is successful, it runs at_halt(closelog)  to ensure closing the system log on clean exit. Ident prepended to every  message, and is typically set to the program name. Options is a list of options.  Values are corresponding C options, after removing =LOG_= and  translation to lower case: cons, ndelay, nowait, odelay, perror, pid. Facility is one of auth, authpriv, cron, daemon, ftp, kern, local0 ... local7, lpr, mail, news, syslog, user or uucp. ",
    "prefix":"openlog"
  },
  "syslog:set_user_and_group/2": {
    "body":"set_user_and_group(${1:User}, ${2:Group})$3\n$0",
    "description":"[det]set_user_and_group(+User, +Group).\nSet the UID and GID to the User. User is either a  UID or a user name. If Group is not specified, the primary  group of User is used. If initgroups/2  is available, the resulting group access list of the calling process  consists of the registered groups for User and the specified Group.",
    "prefix":"set_user_and_group"
  },
  "syslog:syslog/2": {
    "body":"syslog(${1:Priority}, ${2:Message})$3\n$0",
    "description":"[det]syslog(+Priority, +Message).\nSend a message to the system log. Note that syslog/2  implicitly opens a connection to the system log if such a connection has  not been opened explicitly using openlog/3. Priority is one of emerg, alert, crit, err, warning, notice, info or debug. ",
    "prefix":"syslog"
  },
  "syslog:syslog/3": {
    "body":"syslog(${1:Priority}, ${2:Format}, ${3:Args})$4\n$0",
    "description":"[det]syslog(+Priority, +Format, +Args).\nSend a formatted message to the system log if system logging is opened  using openlog/3. This predicate  combined format/3 with syslog/2. If there is no open  syslog connection, syslog/3 calls print_message/2.",
    "prefix":"syslog"
  },
  "tab/1": {
    "body":"tab(${1:Amount})$2\n$0",
    "description":"tab(+Amount).\nWrite Amount spaces on the current output stream. Amount  should be an expression that evaluates to a positive integer (see section 4.27).",
    "prefix":"tab"
  },
  "tab/2": {
    "body":"tab(${1:Stream}, ${2:Amount})$3\n$0",
    "description":"tab(+Stream, +Amount).\nWrite Amount spaces to Stream.",
    "prefix":"tab"
  },
  "table:close_table/1": {
    "body": ["close_table(${1:'Param1'})$2\n$0" ],
    "description":"close_table('Param1')",
    "prefix":"close_table"
  },
  "table:compare_strings/4": {
    "body": [
      "compare_strings(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"compare_strings('Param1','Param2','Param3','Param4')",
    "prefix":"compare_strings"
  },
  "table:free_table/1": {
    "body": ["free_table(${1:'Param1'})$2\n$0" ],
    "description":"free_table('Param1')",
    "prefix":"free_table"
  },
  "table:get_table_attribute/3": {
    "body": [
      "get_table_attribute(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"get_table_attribute('Param1','Param2','Param3')",
    "prefix":"get_table_attribute"
  },
  "table:in_table/3": {
    "body": ["in_table(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"in_table('Param1','Param2','Param3')",
    "prefix":"in_table"
  },
  "table:new_order_table/2": {
    "body": ["new_order_table(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"new_order_table('Param1','Param2')",
    "prefix":"new_order_table"
  },
  "table:new_table/4": {
    "body": [
      "new_table(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"new_table('Param1','Param2','Param3','Param4')",
    "prefix":"new_table"
  },
  "table:open_table/1": {
    "body": ["open_table(${1:'Param1'})$2\n$0" ],
    "description":"open_table('Param1')",
    "prefix":"open_table"
  },
  "table:order_table_mapping/3": {
    "body": [
      "order_table_mapping(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"order_table_mapping('Param1','Param2','Param3')",
    "prefix":"order_table_mapping"
  },
  "table:prefix_string/3": {
    "body": ["prefix_string(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"prefix_string('Param1','Param2','Param3')",
    "prefix":"prefix_string"
  },
  "table:prefix_string/4": {
    "body": [
      "prefix_string(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"prefix_string('Param1','Param2','Param3','Param4')",
    "prefix":"prefix_string"
  },
  "table:read_table_fields/4": {
    "body": [
      "read_table_fields(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"read_table_fields('Param1','Param2','Param3','Param4')",
    "prefix":"read_table_fields"
  },
  "table:read_table_record/4": {
    "body": [
      "read_table_record(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"read_table_record('Param1','Param2','Param3','Param4')",
    "prefix":"read_table_record"
  },
  "table:read_table_record_data/4": {
    "body": [
      "read_table_record_data(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"read_table_record_data('Param1','Param2','Param3','Param4')",
    "prefix":"read_table_record_data"
  },
  "table:sub_string/3": {
    "body": ["sub_string(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"sub_string('Param1','Param2','Param3')",
    "prefix":"sub_string"
  },
  "table:table_previous_record/3": {
    "body": [
      "table_previous_record(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0"
    ],
    "description":"table_previous_record('Param1','Param2','Param3')",
    "prefix":"table_previous_record"
  },
  "table:table_start_of_record/4": {
    "body": [
      "table_start_of_record(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"table_start_of_record('Param1','Param2','Param3','Param4')",
    "prefix":"table_start_of_record"
  },
  "table:table_version/2": {
    "body": ["table_version(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"table_version('Param1','Param2')",
    "prefix":"table_version"
  },
  "table:table_window/3": {
    "body": ["table_window(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"table_window('Param1','Param2','Param3')",
    "prefix":"table_window"
  },
  "table_previous_record/3": {
    "body":"table_previous_record(${1:Handle}, ${2:Here}, ${3:Previous})$4\n$0",
    "description":"table_previous_record(+Handle, +Here, -Previous).\nIf Here is the start of a record, find the start of the  record before it. If Here points at an arbitrary location in  a record, the start of this record will be returned.",
    "prefix":"table_previous_record"
  },
  "table_start_of_record/4": {
    "body":"table_start_of_record(${1:Handle}, ${2:From}, ${3:To}, ${4:Start})$5\n$0",
    "description":"table_start_of_record(+Handle, +From, +To, -Start).\nEnumerates (on backtracking) the start of records in the table in the  region [From, To). Together with read_table_record/4,  this may be used to read the table's data.",
    "prefix":"table_start_of_record"
  },
  "table_util:sort_table/2": {
    "body": ["sort_table(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"sort_table('Param1','Param2')",
    "prefix":"sort_table"
  },
  "table_util:verify_table_order/1": {
    "body": ["verify_table_order(${1:'Param1'})$2\n$0" ],
    "description":"verify_table_order('Param1')",
    "prefix":"verify_table_order"
  },
  "table_version/2": {
    "body":"table_version(${1:Version}, ${2:CompileDate})$3\n$0",
    "description":"table_version(-Version, -CompileDate).\nUnify Version with an atom identifying the version of this  package, and CompileDate with the date this package was  compiled.",
    "prefix":"table_version"
  },
  "table_window/3": {
    "body":"table_window(${1:Handle}, ${2:Start}, ${3:Size})$4\n$0",
    "description":"table_window(+Handle, +Start, +Size).\nIf only part of the file represents the table, this call may be used to  define a window on the file. Start defines the start of the  window relative to the start of the file. Size is the size in  characters. Skipping a header is one of the possible purposes for this  call.",
    "prefix":"table_window"
  },
  "tabling:abolish_all_tables/0": {
    "body":"abolish_all_tables$1\n$0",
    "description":"abolish_all_tables.\nRemove all tables. This is normally used to free up the space or  recompute the result after predicates on which the result for some  tabled predicates depend.  Errors: permission_error(abolish, table, all) if tabling is in  progress.\n\n ",
    "prefix":"abolish_all_tables"
  },
  "tabling:abolish_table_subgoals/1": {
    "body":"abolish_table_subgoals(${1:Subgoal})$2\n$0",
    "description":"[det]abolish_table_subgoals(:Subgoal).\nAbolish all tables that unify with SubGoal.",
    "prefix":"abolish_table_subgoals"
  },
  "tabling:current_table/2": {
    "body": ["current_table(${1:Variant}, ${2:Trie})$3\n$0" ],
    "description":"  current_table(:Variant, -Trie) is nondet.\n\n   True when Trie is the answer table for Variant.",
    "prefix":"current_table"
  },
  "tabling:start_tabling/2": {
    "body": ["start_tabling(${1:Variant}, ${2:Implementation})$3\n$0" ],
    "description":"  start_tabling(+Variant, +Implementation)\n\n   Execute Implementation using tabling. This  predicate should not\n   be called directly. The table/1 directive  causes a predicate to\n   be translated into a renamed implementation   and a wrapper that\n   involves this predicate.\n\n   @compat This interface may change or disappear without notice\n           from future versions.",
    "prefix":"start_tabling"
  },
  "tabling:table/1": {
    "body": ["table(${1:PredicateIndicators})$2\n$0" ],
    "description":"  table(+PredicateIndicators)\n\n   Prepare the given PredicateIndicators for   tabling. Can only be\n   used as a directive. The example   below  prepares the predicate\n   edge/2 and the non-terminal statement//1 for tabled execution.\n\n     ==\n     :- table edge/2, statement//1.\n     ==",
    "prefix":"table"
  },
  "tan/1": {
    "body":"tan(${1:Expr})$2\n$0",
    "description":"[ISO]tan(+Expr).\nResult = tan(Expr). Expr is  the angle in radians.",
    "prefix":"tan"
  },
  "tanh/1": {
    "body":"tanh(${1:Expr})$2\n$0",
    "description":"tanh(+Expr).\nResult = tanh(Expr). The hyperbolic  tangent of X is defined as sinh( X ) / cosh( X ).",
    "prefix":"tanh"
  },
  "tell/1": {
    "body":"tell(${1:SrcDest})$2\n$0",
    "description":"tell(+SrcDest).\nOpen SrcDest for writing and make it the current output (see set_output/1).  If SrcDest is a stream handle, just make this stream the  current output. See the introduction of section  4.17.3 for details.",
    "prefix":"tell"
  },
  "telling/1": {
    "body":"telling(${1:SrcDest})$2\n$0",
    "description":"telling(?SrcDest).\nSame as current_output/1,  except that user is returned if the current output is the  stream user_output to improve compatibility with  traditional Edinburgh I/O. See the introduction of section 4.17.3 for details.",
    "prefix":"telling"
  },
  "term_attvars/2": {
    "body":"term_attvars(${1:Term}, ${2:AttVars})$3\n$0",
    "description":"term_attvars(+Term, -AttVars).\nAttVars is a list of all attributed variables in Term  and its attributes. That is, term_attvars/2  works recursively through attributes. This predicate is cycle-safe. The  goal term_attvars(Term,[]) in an efficient test that Term  has no attributes; scanning the term is aborted after the first  attributed variable is found.",
    "prefix":"term_attvars"
  },
  "term_expansion/2": {
    "body":"term_expansion(${1:Term1}, ${2:Term2})$3\n$0",
    "description":"term_expansion(+Term1, -Term2).\nDynamic and multifile predicate, normally not defined. When defined by  the user all terms read during consulting are given to this predicate.  If the predicate succeeds Prolog will assert Term2 in the  database rather than the read term (Term1). Term2  may be a term of the form ?- Goal. or :- Goal. Goal  is then treated as a directive. If Term2 is a list, all terms  of the list are stored in the database or called (for directives). If Term2 is of the form below, the system will assert Clause  and record the indicated source location with it: '$source_location'(<File>, <Line>):<Clause>  When compiling a module (see chapter  6 and the directive module/2), expand_term/2  will first try term_expansion/2  in the module being compiled to allow for term expansion rules that are  local to a module. If there is no local definition, or the local  definition fails to translate the term, expand_term/2  will try term_expansion/2  in module user. For compatibility with SICStus and Quintus Prolog,  this feature should not be used. See also expand_term/2, goal_expansion/2  and expand_goal/2.\n\n",
    "prefix":"term_expansion"
  },
  "term_expansion/4": {
    "body":"term_expansion(${1:Term1}, ${2:Layout1}, ${3:Term2}, ${4:Layout2})$5\n$0",
    "description":"term_expansion(+Term1, ?Layout1, -Term2, -Layout2).\n",
    "prefix":"term_expansion"
  },
  "term_hash/2": {
    "body":"term_hash(${1:Term}, ${2:HashKey})$3\n$0",
    "description":"[det]term_hash(+Term, -HashKey).\nIf Term is a ground term (see ground/1), HashKey  is unified with a positive integer value that may be used as a hash key  to the value. If Term is not ground, the predicate leaves HashKey  an unbound variable. Hash keys are in the range 0 ... 16,777,215,  the maximal integer that can be stored efficiently on both 32 and 64 bit  platforms.  This predicate may be used to build hash tables as well as to exploit  argument indexing to find complex terms more quickly. \n\nThe hash key does not rely on temporary information like addresses of  atoms and may be assumed constant over different invocations and  versions of SWI-Prolog.72Last  change: version 5.10.4 Hashes differ between big and little  endian machines. The term_hash/2  predicate is cycle-safe.bugAll  arguments that (indirectly) lead to a cycle have the same hash key.\n\n",
    "prefix":"term_hash"
  },
  "term_hash/4": {
    "body":"term_hash(${1:Term}, ${2:Depth}, ${3:Range}, ${4:HashKey})$5\n$0",
    "description":"[det]term_hash(+Term, +Depth, +Range, -HashKey).\nAs term_hash/2,  but only considers Term to the specified Depth. The top-level term has depth 1, its arguments have  depth 2, etc. That is, Depth = 0 hashes nothing; Depth  = 1 hashes atomic values or the functor and arity of a compound  term, not its arguments; Depth = 2 also indexes  the immediate arguments, etc.  HashKey is in the range [0 ...Range-1]. Range  must be in the range [1 ... 2147483647]\n\n",
    "prefix":"term_hash"
  },
  "term_string/2": {
    "body":"term_string(${1:Term}, ${2:String})$3\n$0",
    "description":"term_string(?Term, ?String).\nBi-directional conversion between a term and a string. If String  is instantiated, it is parsed and the result is unified with Term.  Otherwise Term is `written' using the option quoted(true)  and the result is converted to String.",
    "prefix":"term_string"
  },
  "term_string/3": {
    "body":"term_string(${1:Term}, ${2:String}, ${3:Options})$4\n$0",
    "description":"term_string(?Term, ?String, +Options).\nAs term_string/2,  passing Options to either read_term/2  or write_term/2.  For example:  \n\n?- term_string(Term, 'a(A)', [variable_names(VNames)]).\nTerm = a(_G1466),\nVNames = ['A'=_G1466].\n\n ",
    "prefix":"term_string"
  },
  "term_subsumer/3": {
    "body":"term_subsumer(${1:Special1}, ${2:Special2}, ${3:General})$4\n$0",
    "description":"term_subsumer(+Special1, +Special2, -General).\nGeneral is the most specific term that is a generalisation of Special1 and Special2. The implementation can  handle cyclic terms.",
    "prefix":"term_subsumer"
  },
  "term_to_atom/2": {
    "body":"term_to_atom(${1:Term}, ${2:Atom})$3\n$0",
    "description":"term_to_atom(?Term, ?Atom).\nTrue if Atom describes a term that unifies with Term.  When Atom is instantiated, Atom is parsed and the  result unified with Term. If Atom has no valid  syntax, a syntax_error exception is raised. Otherwise Term  is ``written'' on Atom using write_term/2  with the option quoted(true). See also format/3, with_output_to/2  and term_string/2.",
    "prefix":"term_to_atom"
  },
  "term_to_json:term_to_json/2": {
    "body":"term_to_json(${1:Term}, ${2:JsonTerm})$3\n$0",
    "description":"[det]term_to_json(+Term, -JsonTerm).\nConvert any general Prolog term into a JSON term. Prolog lists are  treated in a special way. Also, JSON terms are not converted. Mapping:  \n\nVariable: {\"type\":\"var\", \"name\":<string>}\nAtom: {\"type\":\"atom\", \"value\":<string>}\nInteger: {\"type\":\"integer\", \"value\":<integer>}\nFloat: {\"type\":\"float\", \"value\":<float>}\nList: JSON array\nDict: a JSON object. Values are processed recursively. (the tag is  ignored)\njson([Key=Value, ...]): a JSON object Values are  processed recursively.\ncompound: {\"type\":\"compound\", \"functor\":<string>, \"args\":<array>}\n\n Bindings is a list of Name=Var  terms for variables that get their name from the environment. ",
    "prefix":"term_to_json"
  },
  "term_to_json:term_to_json/3": {
    "body":"term_to_json(${1:Term}, ${2:Bindings}, ${3:JsonTerm})$4\n$0",
    "description":"[det]term_to_json(+Term, +Bindings, -JsonTerm).\n",
    "prefix":"term_to_json"
  },
  "term_variables/2": {
    "body":"term_variables(${1:Term}, ${2:List})$3\n$0",
    "description":"[ISO]term_variables(+Term, -List).\nUnify List with a list of variables, each sharing with a  unique variable of Term.93This  predicate used to be called free_variables/2 . The name term_variables/2  is more widely used. The old predicate is still available from the  library library(backcomp). The variables in List  are ordered in order of appearance traversing Term  depth-first and left-to-right. See also term_variables/3.  For example:  \n\n?- term_variables(a(X, b(Y, X), Z), L).\nL = [X, Y, Z].\n\n ",
    "prefix":"term_variables"
  },
  "term_variables/3": {
    "body":"term_variables(${1:Term}, ${2:List}, ${3:Tail})$4\n$0",
    "description":"term_variables(+Term, -List, ?Tail).\nDifference list version of term_variables/2.  That is, Tail is the tail of the variable list List.",
    "prefix":"term_variables"
  },
  "terms:cyclic_term/1": {
    "body": ["cyclic_term(${1:'Param1'})$2\n$0" ],
    "description":"cyclic_term('Param1')",
    "prefix":"cyclic_term"
  },
  "terms:subsumes/2": {
    "body": ["subsumes(${1:Generic}, ${2:Specific})$3\n$0" ],
    "description":"  subsumes(+Generic, @Specific)\n\n   True  if  Generic  is  unified   to  Specific  without  changing\n   Specific.\n\n   @deprecated It turns out that calls to this predicate almost\n   always should have used subsumes_term/2.  Also the name is\n   misleading.  In case this is really needed, one is adviced to\n   follow subsumes_term/2 with an explicit unification.",
    "prefix":"subsumes"
  },
  "terms:subsumes_chk/2": {
    "body": ["subsumes_chk(${1:Generic}, ${2:Specific})$3\n$0" ],
    "description":"  subsumes_chk(@Generic, @Specific)\n\n   True if Generic can be made equivalent to Specific without\n   changing Specific.\n\n   @deprecated Replace by subsumes_term/2.",
    "prefix":"subsumes_chk"
  },
  "terms:term_factorized/3": {
    "body": ["term_factorized(${1:Term}, ${2:Skeleton}, ${3:Substiution})$4\n$0" ],
    "description":"  term_factorized(+Term, -Skeleton, -Substiution)\n\n   Is true when Skeleton is  Term   where  all subterms that appear\n   multiple times are replaced by a  variable and Substitution is a\n   list of Var=Value that provides the subterm at the location Var.\n   I.e., After unifying all substitutions  in Substiutions, Term ==\n   Skeleton. Term may be cyclic. For example:\n\n     ==\n     ?- X = a(X), term_factorized(b(X,X), Y, S).\n     Y = b(_G255, _G255),\n     S = [_G255=a(_G255)].\n     ==",
    "prefix":"term_factorized"
  },
  "terms:term_hash/2": {
    "body": ["term_hash(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"term_hash('Param1','Param2')",
    "prefix":"term_hash"
  },
  "terms:term_hash/4": {
    "body": [
      "term_hash(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'}, ${4:'Param4'})$5\n$0"
    ],
    "description":"term_hash('Param1','Param2','Param3','Param4')",
    "prefix":"term_hash"
  },
  "terms:term_size/2": {
    "body": ["term_size(${1:Term}, ${2:Size})$3\n$0" ],
    "description":"  term_size(@Term, -Size) is det.\n\n   True if Size is the size  in   _cells_  occupied  by Term on the\n   global (term) stack. A _cell_ is 4  bytes on 32-bit machines and\n   8 bytes on 64-bit machines. The  calculation does take _sharing_\n   into account. For example:\n\n   ```\n   ?- A = a(1,2,3), term_size(A,S).\n   S = 4.\n   ?- A = a(1,2,3), term_size(a(A,A),S).\n   S = 7.\n   ?- term_size(a(a(1,2,3), a(1,2,3)), S).\n   S = 11.\n   ```\n\n   Note that small objects such as atoms  and small integers have a\n   size 0. Space is allocated for   floats, large integers, strings\n   and compound terms.",
    "prefix":"term_size"
  },
  "terms:term_subsumer/3": {
    "body": ["term_subsumer(${1:Special1}, ${2:Special2}, ${3:General})$4\n$0" ],
    "description":"  term_subsumer(+Special1, +Special2, -General) is det.\n\n   General is the most specific term   that  is a generalisation of\n   Special1 and Special2. The  implementation   can  handle  cyclic\n   terms.\n\n   @compat SICStus\n   @author Inspired by LOGIC.PRO by Stephen Muggleton",
    "prefix":"term_subsumer"
  },
  "terms:term_variables/3": {
    "body": ["term_variables(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"term_variables('Param1','Param2','Param3')",
    "prefix":"term_variables"
  },
  "terms:variant/2": {
    "body": ["variant(${1:Term1}, ${2:Term2})$3\n$0" ],
    "description":"  variant(@Term1, @Term2) is semidet.\n\n   Same as SWI-Prolog =|Term1 =@= Term2|=.",
    "prefix":"variant"
  },
  "test/0": {
    "body":"test$1\n$0",
    "description":"test.\nRun all tests and classify the result.",
    "prefix":"test"
  },
  "test_report/1": {
    "body":"test_report(${1:What})$2\n$0",
    "description":"test_report(+What).\nPrint report on the executed tests. What defines the type of  report. Currently this only supports fixme, providing  details on how the fixme-flagged tests proceeded.",
    "prefix":"test_report"
  },
  "test_wizard:make_test/3": {
    "body": ["make_test(${1:Query}, ${2:Module}, ${3:Test})$4\n$0" ],
    "description":"  make_test(+Query:callable, -Module, -Test:term) is det.\n\n   Generate a test from a query. Test   is  returned as a clause of\n   test/1  or  test/2  to  be   inserted  between  begin_tests  and\n   end_tests.",
    "prefix":"make_test"
  },
  "test_wizard:make_tests/3": {
    "body": ["make_tests(${1:Module}, ${2:File}, ${3:Out})$4\n$0" ],
    "description":"  make_tests(+Module, +File, +Out) is det.\n\n   Create tests from queries stored in File and write the tests for\n   Module to the stream Out.",
    "prefix":"make_tests"
  },
  "text_to_string/2": {
    "body":"text_to_string(${1:Text}, ${2:String})$3\n$0",
    "description":"[det]text_to_string(+Text, -String).\nConverts Text to a string. Text is an atom, string  or list of characters (codes or chars). When running in --traditional mode, '[]' is ambiguous and  interpreted as an empty string.",
    "prefix":"text_to_string"
  },
  "thread:concurrent/3": {
    "body": ["concurrent(${1:N}, ${2:Goals}, ${3:Options})$4\n$0" ],
    "description":"  concurrent(+N, :Goals, Options) is semidet.\n\n   Run Goals in parallel using N   threads.  This call blocks until\n   all work has been done.  The   Goals  must  be independent. They\n   should not communicate using shared  variables   or  any form of\n   global data. All Goals must be thread-safe.\n\n   Execution succeeds if all goals  have   succeeded.  If  one goal\n   fails or throws an exception,  other   workers  are abandoned as\n   soon as possible and the entire   computation fails or re-throws\n   the exception. Note that if  multiple   goals  fail  or raise an\n   error it is not defined which error or failure is reported.\n\n   On successful completion, variable bindings   are returned. Note\n   however that threads have independent   stacks and therefore the\n   goal is copied to the worker  thread   and  the result is copied\n   back to the caller of concurrent/3.\n\n   Choosing the right number of threads is not always obvious. Here\n   are some scenarios:\n\n     * If the goals are CPU intensive and normally all succeeding,\n     typically the number of CPUs is the optimal number of\n     threads.  Less does not use all CPUs, more wastes time in\n     context switches and also uses more memory.\n\n     * If the tasks are I/O bound the number of threads is\n     typically higher than the number of CPUs.\n\n     * If one or more of the goals may fail or produce an errors,\n     using a higher number of threads may find this earlier.\n\n   @param N Number of worker-threads to create. Using 1, no threads\n          are created.  If N is larger than the number of Goals we\n          create exactly as many threads as there are Goals.\n   @param Goals List of callable terms.\n   @param Options Passed to thread_create/3 for creating the\n          workers.  Only options changing the stack-sizes can\n          be used. In particular, do not pass the detached or alias\n          options.\n   @see In many cases, concurrent_maplist/2 and friends\n        is easier to program and is tractable to program\n        analysis.",
    "prefix":"concurrent"
  },
  "thread:concurrent_maplist/2": {
    "body": ["concurrent_maplist(${1:Goal}, ${2:List})$3\n$0" ],
    "description":"  concurrent_maplist(:Goal, +List).\n  concurrent_maplist(:Goal, +List1, +List2).\n  concurrent_maplist(:Goal, +List1, +List2, +List3).\n\n   Concurrent   version   of   maplist/2.   This   predicate   uses\n   concurrent/3, using multiple _worker_  threads.   The  number of\n   threads is the minimum of the  list   length  and  the number of\n   cores available. The number of  cores   is  determined using the\n   prolog flag =cpu_count=. If this flag is absent or 1 or List has\n   less  than  two  elements,  this   predicate  simply  calls  the\n   corresponding maplist/N version.\n\n   Note that the the overhead of this predicate is considerable and\n   therefore Goal must be fairly  expensive   before  one reaches a\n   speedup.",
    "prefix":"concurrent_maplist"
  },
  "thread:concurrent_maplist/3": {
    "body": ["concurrent_maplist(${1:Goal}, ${2:List1}, ${3:List2})$4\n$0" ],
    "description":"  concurrent_maplist(:Goal, +List).\n  concurrent_maplist(:Goal, +List1, +List2).\n  concurrent_maplist(:Goal, +List1, +List2, +List3).\n\n   Concurrent   version   of   maplist/2.   This   predicate   uses\n   concurrent/3, using multiple _worker_  threads.   The  number of\n   threads is the minimum of the  list   length  and  the number of\n   cores available. The number of  cores   is  determined using the\n   prolog flag =cpu_count=. If this flag is absent or 1 or List has\n   less  than  two  elements,  this   predicate  simply  calls  the\n   corresponding maplist/N version.\n\n   Note that the the overhead of this predicate is considerable and\n   therefore Goal must be fairly  expensive   before  one reaches a\n   speedup.",
    "prefix":"concurrent_maplist"
  },
  "thread:concurrent_maplist/4": {
    "body": [
      "concurrent_maplist(${1:Goal}, ${2:List1}, ${3:List2}, ${4:List3})$5\n$0"
    ],
    "description":"  concurrent_maplist(:Goal, +List).\n  concurrent_maplist(:Goal, +List1, +List2).\n  concurrent_maplist(:Goal, +List1, +List2, +List3).\n\n   Concurrent   version   of   maplist/2.   This   predicate   uses\n   concurrent/3, using multiple _worker_  threads.   The  number of\n   threads is the minimum of the  list   length  and  the number of\n   cores available. The number of  cores   is  determined using the\n   prolog flag =cpu_count=. If this flag is absent or 1 or List has\n   less  than  two  elements,  this   predicate  simply  calls  the\n   corresponding maplist/N version.\n\n   Note that the the overhead of this predicate is considerable and\n   therefore Goal must be fairly  expensive   before  one reaches a\n   speedup.",
    "prefix":"concurrent_maplist"
  },
  "thread:first_solution/3": {
    "body": ["first_solution(${1:X}, ${2:Goals}, ${3:Options})$4\n$0" ],
    "description":"  first_solution(-X, :Goals, +Options) is semidet.\n\n   Try  alternative  solvers  concurrently,   returning  the  first\n   answer. In a typical scenario, solving any of the goals in Goals\n   is satisfactory for the application to  continue. As soon as one\n   of the tried alternatives is  successful,   all  the others are\n   killed and first_solution/3 succeeds.\n\n   For example, if it is unclear whether   it is better to search a\n   graph breadth-first or depth-first we can use:\n\n   ==\n   search_graph(Grap, Path) :-\n            first_solution(Path, [ breadth_first(Graph, Path),\n                                   depth_first(Graph, Path)\n                                 ],\n                           []).\n   ==\n\n   Options include thread stack-sizes passed   to thread_create, as\n   well as the options =on_fail= and   =on_error= that specify what\n   to do if a  solver  fails  or   triggers  an  error.  By default\n   execution of all  solvers  is  terminated   and  the  result  is\n   returned. Sometimes one may wish to  continue. One such scenario\n   is if one of the solvers may run  out of resources or one of the\n   solvers is known to be incomplete.\n\n           * on_fail(Action)\n           If =stop= (default), terminate all threads and stop with\n           the failure.  If =continue=, keep waiting.\n           * on_error(Action)\n           As above, re-throwing the error if an error appears.\n\n   @bug    first_solution/3 cannot deal with non-determinism.  There\n           is no obvious way to fit non-determinism into it.  If multiple\n           solutions are needed wrap the solvers in findall/3.",
    "prefix":"first_solution"
  },
  "thread_at_exit/1": {
    "body":"thread_at_exit(${1:Goal})$2\n$0",
    "description":"thread_at_exit(:Goal).\nRun Goal just before releasing the thread resources. This is  to be compared to at_halt/1,  but only for the current thread. These hooks are run regardless of why  the execution of the thread has been completed. When these hooks are  run, the return code is already available through thread_property/2  using the result of thread_self/1  as thread identifier. Note that there are two scenarios for using exit  hooks. Using thread_at_exit/1  is typically used if the thread creates a side-effect that must be  reverted if the thread dies. Another scenario is where the creator of  the thread wants to be informed when the thread ends. That cannot be  guaranteed by means of thread_at_exit/1  because it is possible that the thread cannot be created or dies almost  instantly due to a signal or resource error. The at_exit(Goal)  option of thread_create/3  is designed to deal with this scenario.",
    "prefix":"thread_at_exit"
  },
  "thread_create/3": {
    "body":"thread_create(${1:Goal}, ${2:Id}, ${3:Options})$4\n$0",
    "description":"thread_create(:Goal, -Id, +Options).\nCreate a new Prolog thread (and underlying operating system thread) and  start it by executing Goal. If the thread is created  successfully, the thread identifier of the created thread is unified to Id.  Id is the alias name if the option alias(name)  is given. Otherwise it is a blob of type thread.  The anonymous blobs are subject to atom garbage collection. If a thread  handle is garbage collected and the thread is not detached, it  is joined if it has already terminated (see thread_join/2)  and detached otherwise (see thread_detach/1).149Up  to version 7.3.23, anonymous thread handles were integers. Using  integers did not allow for safe checking of the thread's status as the  thread may have died and the handle may have been reused and did not  allow for garbage collection to take care of forgotten threads.  The thread identifier blobs are printed as <thread>(I,Ptr),  where I is the internal thread identifier and Ptr  is the unique address of the identifier. The I is accepted as  input argument for all thread APIs that accept a thread identifier for  convenient interaction from the toplevel. See also thread_property/2. \n\nOptions is a list of options. The currently defined  options are below. Stack size options can also take the value inf  or infinite, which is mapped to the maximum stack size  supported by the platform. \n\nalias(AliasName): Associate an `alias name' with the thread. This name may be used to  refer to the thread and remains valid until the thread is joined (see thread_join/2).\n\nat_exit(:AtExit): Register AtExit as using thread_at_exit/1  before entering the thread goal. Unlike calling thread_at_exit/1  as part of the normal Goal, this ensures the AtExit is called.  Using thread_at_exit/1,  the thread may be signalled or run out of resources before thread_at_exit/1  is reached.\n\ndebug(+Bool): Enable/disable debugging the new thread. If false (default true), the new thread is created with the property debug(false) and debugging is disabled before the new  thread is started. The thread debugging predicates such as tspy/1  and tdebug/0  do not signal threads with the debug property set to false.150Currently,  the flag is only used as a hint for the the various debugging  primitives, i.e., the system does not really enforce that the target  thread stays in nodebug mode.\n\ndetached(Bool): If false (default), the thread can be waited for using thread_join/2. thread_join/2  must be called on this thread to reclaim all resources associated with  the thread. If true, the system will reclaim all associated  resources automatically after the thread finishes. Please note that  thread identifiers are freed for reuse after a detached thread finishes  or a normal thread has been joined. See also thread_join/2  and thread_detach/1.  If a detached thread dies due to failure or exception of the initial  goal, the thread prints a message using print_message/2.  If such termination is considered normal, the code must be wrapped using ignore/1  and/or catch/3  to ensure successful completion.\n\ninherit_from(+ThreadId): Inherit defaults from the given ThreadId instead of the  calling thread. This option was added to ensure that the __thread_pool_manager (see thread_create_in_pool/4),  which is created lazily, has a predictable state. The following  properties are inherited:  The prompt (see prompt/2)\nThe typein module (see module/1)\nThe standard streams (user_input, etc.)\nThe default encoding (see encoding)\nThe default locale (see setlocale/1)\nAll prolog flags\nThe limits of Prolog stacks (see set_prolog_stack/2)\n\n\n\nglobal(K-Bytes): Set the limit to which the global stack of this thread may grow. If  omitted, the limit of the calling thread is used. See also the -G command line option.\n\nlocal(K-Bytes): Set the limit to which the local stack of this thread may grow. If  omitted, the limit of the calling thread is used. See also the -L command line option.\n\nc_stack(K-Bytes): Set the limit to which the system stack of this thread may grow. The  default, minimum and maximum values are system-dependent.151Older  versions used stack. This is still accepted as a synonym.\n\ntrail(K-Bytes): Set the limit to which the trail stack of this thread may grow. If  omitted, the limit of the calling thread is used. See also the -T command line option.\n\n  The Goal argument is copied to the new Prolog  engine. This implies that further instantiation of this term in either  thread does not have consequences for the other thread: Prolog threads  do not share data from their stacks.\n\n",
    "prefix":"thread_create"
  },
  "thread_detach/1": {
    "body":"thread_detach(${1:Id})$2\n$0",
    "description":"thread_detach(+Id).\nSwitch thread into detached state (see detached(Bool)  option at thread_create/3)  at runtime. Id is the identifier of the thread placed in  detached state. This may be the result of thread_self/1.  One of the possible applications is to simplify debugging. Threads  that are created as detached leave no traces if they crash. For  non-detached threads the status can be inspected using thread_property/2.  Threads nobody is waiting for may be created normally and detach  themselves just before completion. This way they leave no traces on  normal completion and their reason for failure can be inspected.\n\n",
    "prefix":"thread_detach"
  },
  "thread_exit/1": {
    "body":"thread_exit(${1:Term})$2\n$0",
    "description":"[deprecated]thread_exit(+Term).\nTerminates the thread immediately, leaving exited(Term) as  result state for thread_join/2.  If the thread has the attribute detached(true) it terminates, but its exit status cannot be  retrieved using thread_join/2,  making the value of Term irrelevant. The Prolog stacks and C  thread are reclaimed.  The current implementation does not guarantee proper releasing of all  mutexes and proper cleanup in setup_call_cleanup/3,  etc. Please use the exception mechanism (throw/1)  to abort execution using non-standard control.\n\n",
    "prefix":"thread_exit"
  },
  "thread_get_message/1": {
    "body":"thread_get_message(${1:Term})$2\n$0",
    "description":"thread_get_message(?Term).\nExamines the thread message queue and if necessary blocks execution  until a term that unifies to Term arrives in the queue. After  a term from the queue has been unified to Term, the term is  deleted from the queue.  Please note that non-unifying messages remain in the queue. After the  following has been executed, thread 1 has the term b(gnu)  in its queue and continues execution using A=gnat. \n\n\n\n   <thread 1>\n   thread_get_message(a(A)),\n\n   <thread 2>\n   thread_send_message(Thread_1, b(gnu)),\n   thread_send_message(Thread_1, a(gnat)),\n\n  See also thread_peek_message/1.\n\n",
    "prefix":"thread_get_message"
  },
  "thread_get_message/2": {
    "body":"thread_get_message(${1:Queue}, ${2:Term})$3\n$0",
    "description":"[det]thread_get_message(+Queue, ?Term).\nAs thread_get_message/1,  operating on a given queue. It is allowed (but not advised) to get  messages from the queue of other threads. This predicate raises an  existence error exception if Queue doesn't exist or is  destroyed using message_queue_destroy/1  while this predicate is waiting.",
    "prefix":"thread_get_message"
  },
  "thread_get_message/3": {
    "body":"thread_get_message(${1:Queue}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"[semidet]thread_get_message(+Queue, ?Term, +Options).\nAs thread_get_message/2,  but providing additional Options:  deadline(+AbsTime): The call fails (silently) if no message has arrived before AbsTime. See get_time/1  for the representation of absolute time. If AbsTime is  earlier then the current time, thread_get_message/3  fails immediately. Both resolution and maximum wait time is  platform-dependent.156The  implementation uses MsgWaitForMultipleObjects() on MS-Windows and  pthread_cond_timedwait() on other systems.\n\ntimeout(+Time): Time is a float or integer and specifies the maximum time to  wait in seconds. This is a relative-time version of the deadline  option. If both options are provided, the earlier time is effective.  If Time is 0 or 0.0, thread_get_message/3  examines the queue but does not suspend if no matching term is  available. Note that unlike thread_peek_message/2,  a matching term is removed from the queue. If Time < 0, thread_get_message/3  fails immediately without removing any message from the queue.\n\n ",
    "prefix":"thread_get_message"
  },
  "thread_join/2": {
    "body":"thread_join(${1:Id}, ${2:Status})$3\n$0",
    "description":"thread_join(+Id, -Status).\nWait for the termination of the thread with the given Id.  Then unify the result status of the thread with Status. After  this call, Id becomes invalid and all resources associated  with the thread are reclaimed. Note that threads with the attribute detached(true) cannot be joined. See also thread_property/2.  A thread that has been completed without thread_join/2  being called on it is partly reclaimed: the Prolog stacks are released  and the C thread is destroyed. A small data structure representing the  exit status of the thread is retained until thread_join/2  is called on the thread. Defined values for Status are: \n\ntrue: The goal has been proven successfully.\n\nfalse: The goal has failed.\n\nexception(Term): The thread is terminated on an exception. See print_message/2  to turn system exceptions into readable messages.\n\nexited(Term): The thread is terminated on thread_exit/1  using the argument Term.\n\n ",
    "prefix":"thread_join"
  },
  "thread_message_hook/3": {
    "body":"thread_message_hook(${1:Term}, ${2:Kind}, ${3:Lines})$4\n$0",
    "description":"thread_message_hook(+Term, +Kind, +Lines).\nAs message_hook/3,  but this predicate is local to the calling thread (see thread_local/1).  This hook is called before message_hook/3.  The `pre-hook' is indented to catch messages they may be produced by  calling some goal without affecting other threads.",
    "prefix":"thread_message_hook"
  },
  "thread_peek_message/1": {
    "body":"thread_peek_message(${1:Term})$2\n$0",
    "description":"thread_peek_message(?Term).\nExamines the thread message queue and compares the queued terms with Term  until one unifies or the end of the queue has been reached. In the first  case the call succeeds, possibly instantiating Term. If no term from the queue unifies, this call fails.  I.e., thread_peek_message/1  never waits and does not remove any term from the queue. See also thread_get_message/3.",
    "prefix":"thread_peek_message"
  },
  "thread_peek_message/2": {
    "body":"thread_peek_message(${1:Queue}, ${2:Term})$3\n$0",
    "description":"[semidet]thread_peek_message(+Queue, ?Term).\nAs thread_peek_message/1,  operating on a given queue. It is allowed to peek into another thread's  message queue, an operation that can be used to check whether a thread  has swallowed a message sent to it.",
    "prefix":"thread_peek_message"
  },
  "thread_pool:create_pool/1": {
    "body":"create_pool(${1:PoolName})$2\n$0",
    "description":"[semidet,multifile]create_pool(+PoolName).\nHook to create a thread pool lazily. The hook is called if thread_create_in_pool/4  discovers that the thread pool does not exist. If the hook succeeds, thread_create_in_pool/4  retries creating the thread. For example, we can use the following  declaration to create threads in the pool media, which  holds a maximum of 20 threads.  \n\n:- multifile thread_pool:create_pool/1.\n\nthread_pool:create_pool(media) :-\n    thread_pool_create(media, 20, []).\n\n  \n\n",
    "prefix":"create_pool"
  },
  "thread_pool:current_thread_pool/1": {
    "body":"current_thread_pool(${1:Name})$2\n$0",
    "description":"[nondet]current_thread_pool(?Name).\nTrue if Name refers to a defined thread pool.",
    "prefix":"current_thread_pool"
  },
  "thread_pool:thread_create_in_pool/4": {
    "body":"thread_create_in_pool(${1:Pool}, ${2:Goal}, ${3:Id}, ${4:Options})$5\n$0",
    "description":"[det]thread_create_in_pool(+Pool, :Goal, -Id, +Options).\nCreate a thread in Pool. Options overrule default  thread creation options associated to the pool. In addition, the  following option is defined:  wait(+Boolean): If true (default) and the pool is full, wait until a member  of the pool completes. If false, throw a resource_error.\n\n  Errors: - resource_error(threads_in_pool(Pool)) is raised if wait  is false or the backlog limit has been reached.  - existence_error(thread_pool, Pool) if Pool  does not exist.\n\n ",
    "prefix":"thread_create_in_pool"
  },
  "thread_pool:thread_pool_create/3": {
    "body":"thread_pool_create(${1:Pool}, ${2:Size}, ${3:Options})$4\n$0",
    "description":"[det]thread_pool_create(+Pool, +Size, +Options).\nCreate a pool of threads. A pool of threads is a declaration for  creating threads with shared properties (stack sizes) and a limited  number of threads. Threads are created using thread_create_in_pool/4.  If all threads in the pool are in use, the behaviour depends on the wait  option of thread_create_in_pool/4  and the backlog option described below. Options  are passed to thread_create/3,  except for  backlog(+MaxBackLog): Maximum number of requests that can be suspended. Default is infinite.  Otherwise it must be a non-negative integer. Using backlog(0)  will never delay thread creation for this pool.\n\n  The pooling mechanism does not interact with the detached  state of a thread. Threads can be created both detached and  normal and must be joined using thread_join/2  if they are not detached.\n\n",
    "prefix":"thread_pool_create"
  },
  "thread_pool:thread_pool_destroy/1": {
    "body":"thread_pool_destroy(${1:Name})$2\n$0",
    "description":"[det]thread_pool_destroy(+Name).\nDestroy the thread pool named Name.  Errors: existence_error(thread_pool, Name).\n\n ",
    "prefix":"thread_pool_destroy"
  },
  "thread_pool:thread_pool_property/2": {
    "body":"thread_pool_property(${1:Name}, ${2:Property})$3\n$0",
    "description":"[nondet]thread_pool_property(?Name, ?Property).\nTrue if Property is a property of thread pool Name.  Defined properties are:  options(Options): Thread creation options for this pool\n\nfree(Size): Number of free slots on this pool\n\nsize(Size): Total number of slots on this pool\n\nmembers(ListOfIDs): ListOfIDs is the list or threads running in this pool\n\nrunning(Running): Number of running threads in this pool\n\nbacklog(Size): Number of delayed thread creations on this pool\n\n ",
    "prefix":"thread_pool_property"
  },
  "thread_property/2": {
    "body":"thread_property(${1:Id}, ${2:Property})$3\n$0",
    "description":"thread_property(?Id, ?Property).\nTrue if thread Id has Property. Either or both  arguments may be unbound, enumerating all relations on backtracking.  Calling thread_property/2  does not influence any thread. See also thread_join/2.  For threads that have an alias name, this name is returned in Id  instead of the opaque thread identifier. Defined properties are:  alias(Alias): Alias is the alias name of thread Id.\n\ndetached(Boolean): Current detached status of the thread.\n\nid(Integer): Integer identifier for the thread. Can be used as argument to the thread  predicates, but applications must be aware that these references are  reused.\n\nstatus(Status): Current status of the thread. Status is one of:  runningThe thread is running. This is the initial status of a thread. Please  note that threads waiting for something are considered running too.suspendedOnly if the thread is an engine (see section  10). Indicates that the engine is currently not associated with an  OS thread.falseThe Goal of the thread has been completed and failed.trueThe Goal of the thread has been completed and succeeded.exited(Term)The Goal of the thread has been terminated using thread_exit/1  with Term as argument. If the underlying native thread has  exited (using pthread_exit()) Term is unbound.exception(Term)The Goal of the thread has been terminated due to an uncaught  exception (see throw/1  and catch/3). \n\nengine(Boolean): If the thread is an engine (see chapter  10), Boolean is true. Othwerwise the property is not present.\n\nthread(ThreadId): If the thread is an engine that is currently attached to a thread, ThreadId is the thread that executes the engine.\n\nsystem_thread_id(Integer): Thread identifier used by the operating system for the calling thread.  Not available on all OSes. This is the same as the Prolog flag system_thread_id  for the calling thread. Access to the system thread identifier can, on  some systems, be used to gain additional control over or information  about Prolog threads.\n\n  See also thread_statistics/3  to obtain resource usage information and message_queue_property/2  to get the number of queued messages for a thread.\n\n",
    "prefix":"thread_property"
  },
  "thread_self/1": {
    "body":"thread_self(${1:Id})$2\n$0",
    "description":"thread_self(-Id).\nGet the Prolog thread identifier of the running thread. If the thread  has an alias, the alias name is returned.",
    "prefix":"thread_self"
  },
  "thread_send_message/2": {
    "body":"thread_send_message(${1:QueueOrThreadId}, ${2:Term})$3\n$0",
    "description":"thread_send_message(+QueueOrThreadId, +Term).\nPlace Term in the given queue or default queue of the  indicated thread (which can even be the message queue of itself, see thread_self/1).  Any term can be placed in a message queue, but note that the term is  copied to the receiving thread and variable bindings are thus lost. This  call returns immediately.  If more than one thread is waiting for messages on the given queue  and at least one of these is waiting with a partially instantiated Term, the waiting threads are all sent a wake-up  signal, starting a rush for the available messages in the queue. This  behaviour can seriously harm performance with many threads waiting on  the same queue as all-but-the-winner perform a useless scan of the  queue. If there is only one waiting thread or all waiting threads wait  with an unbound variable, an arbitrary thread is restarted to scan the  queue.153See the documentation for  the POSIX thread functions pthread_cond_signal() v.s. pthread_cond_broadcast()  for background information.\n\n",
    "prefix":"thread_send_message"
  },
  "thread_send_message/3": {
    "body":"thread_send_message(${1:Queue}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"[semidet]thread_send_message(+Queue, +Term, +Options).\nAs thread_send_message/2,  but providing additional Options. These are to deal with the  case that the queue has a finite maximum size and is full: whereas thread_send_message/2  will block until the queue has drained sufficiently to accept a new  message, thread_send_message/3  can accept a time-out or deadline analogously to thread_get_message/3.  The options are:  deadline(+AbsTime): The call fails (silently) if no space has become available before AbsTime. See get_time/1  for the representation of absolute time. If AbsTime is  earlier then the current time, thread_send_message/3  fails immediately. Both resolution and maximum wait time is  platform-dependent.154The  implementation uses MsgWaitForMultipleObjects() on MS-Windows and  pthread_cond_timedwait() on other systems.\n\ntimeout(+Time): Time is a float or integer and specifies the maximum time to  wait in seconds. This is a relative-time version of the deadline  option. If both options are provided, the earlier time is effective.  If Time is 0 or 0.0, thread_send_message/3  examines the queue and sends the message if space is availabel, but does  not suspend if no space is available, failing immediately instead. If Time < 0, thread_send_message/3  fails immediately without sending the message.\n\n ",
    "prefix":"thread_send_message"
  },
  "thread_setconcurrency/2": {
    "body":"thread_setconcurrency(${1:Old}, ${2:New})$3\n$0",
    "description":"thread_setconcurrency(-Old, +New).\nDetermine the concurrency of the process,  which is defined as the maximum number of concurrently active threads.  `Active' here means they are using CPU time. This option is provided if  the thread implementation provides pthread_setconcurrency(). Solaris is  a typical example of this family. On other systems this predicate  unifies Old to 0 (zero) and succeeds silently.",
    "prefix":"thread_setconcurrency"
  },
  "thread_signal/2": {
    "body":"thread_signal(${1:ThreadId}, ${2:Goal})$3\n$0",
    "description":"thread_signal(+ThreadId, :Goal).\nMake thread ThreadId execute Goal at the first  opportunity. In the current implementation, this implies at the first  pass through the Call port. The predicate thread_signal/2  itself places Goal into the signalled thread's signal queue  and returns immediately.  Signals (interrupts) do not cooperate well with the world of  multithreading, mainly because the status of mutexes cannot be  guaranteed easily. At the call port, the Prolog virtual machine holds no  locks and therefore the asynchronous execution is safe. \n\nGoal can be any valid Prolog goal, including throw/1  to make the receiving thread generate an exception, and trace/0  to start tracing the receiving thread. \n\nIn the Windows version, the receiving thread immediately executes the  signal if it reaches a Windows GetMessage() call, which generally  happens if the thread is waiting for (user) input.\n\n",
    "prefix":"thread_signal"
  },
  "thread_statistics/3": {
    "body":"thread_statistics(${1:Id}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"thread_statistics(+Id, +Key, -Value).\nObtains statistical information on thread Id as statistics/2  does in single-threaded applications. This call supports all keys of statistics/2,  although only stack sizes, cputime, inferences and epoch yield different values  for each thread.152There is no  portable interface to obtain thread-specific CPU time and some operating  systems provide no access to this information at all. On such systems  the total process CPU is returned. Thread CPU time is supported on  MS-Windows, Linux and MacOSX.",
    "prefix":"thread_statistics"
  },
  "thread_util:attach_console/0": {
    "body": ["attach_console$1\n$0" ],
    "description":"  attach_console is det.\n\n   Create an xterm-console and make the standard Prolog streams point to\n   it.",
    "prefix":"attach_console"
  },
  "thread_util:interactor/0": {
    "body": ["interactor$1\n$0" ],
    "description":"  interactor\n\n   Run a Prolog toplevel in another thread with a new console window.",
    "prefix":"interactor"
  },
  "thread_util:join_threads/0": {
    "body": ["join_threads$1\n$0" ],
    "description":"  join_threads\n\n   Join all terminated threads.",
    "prefix":"join_threads"
  },
  "thread_util:tdebug/0": {
    "body": ["tdebug$1\n$0" ],
    "description":"  tdebug is det.\n  tdebug(+Thread) is det.\n\n   Enable debug-mode, trapping the graphical debugger on reaching\n   spy-points or errors.",
    "prefix":"tdebug"
  },
  "thread_util:tdebug/1": {
    "body": ["tdebug(${1:Thread})$2\n$0" ],
    "description":"  tdebug is det.\n  tdebug(+Thread) is det.\n\n   Enable debug-mode, trapping the graphical debugger on reaching\n   spy-points or errors.",
    "prefix":"tdebug"
  },
  "thread_util:thread_has_console/0": {
    "body": ["thread_has_console$1\n$0" ],
    "description":"  thread_has_console is semidet.\n\n   True when the calling thread has an attached console.\n\n   @see attach_console/0",
    "prefix":"thread_has_console"
  },
  "thread_util:thread_run_interactor/0": {
    "body": ["thread_run_interactor$1\n$0" ],
    "description":"thread_run_interactor",
    "prefix":"thread_run_interactor"
  },
  "thread_util:threads/0": {
    "body": ["threads$1\n$0" ],
    "description":"  threads\n\n   List currently known threads with their status.",
    "prefix":"threads"
  },
  "thread_util:tnodebug/0": {
    "body": ["tnodebug$1\n$0" ],
    "description":"  tnodebug is det.\n  tnodebug(+Thread) is det.\n\n   Disable debug-mode in all threads or the specified Thread.",
    "prefix":"tnodebug"
  },
  "thread_util:tnodebug/1": {
    "body": ["tnodebug(${1:Thread})$2\n$0" ],
    "description":"  tnodebug is det.\n  tnodebug(+Thread) is det.\n\n   Disable debug-mode in all threads or the specified Thread.",
    "prefix":"tnodebug"
  },
  "thread_util:tprofile/1": {
    "body": ["tprofile(${1:Thread})$2\n$0" ],
    "description":"  tprofile(+Thread) is det.\n\n   Profile the operation of Thread until the user hits a key.",
    "prefix":"tprofile"
  },
  "thread_util:tspy/1": {
    "body": ["tspy(${1:Spec})$2\n$0" ],
    "description":"  tspy(:Spec) is det.\n  tspy(:Spec, +ThreadId) is det.\n\n   Trap the graphical debugger on reaching Spec in the specified or\n   any thread.",
    "prefix":"tspy"
  },
  "thread_util:tspy/2": {
    "body": ["tspy(${1:Spec}, ${2:ThreadId})$3\n$0" ],
    "description":"  tspy(:Spec) is det.\n  tspy(:Spec, +ThreadId) is det.\n\n   Trap the graphical debugger on reaching Spec in the specified or\n   any thread.",
    "prefix":"tspy"
  },
  "threadutil:attach_console/0": {
    "body":"attach_console$1\n$0",
    "description":"attach_console.\nIf the current thread has no console attached yet, attach one and  redirect the user streams (input, output, and error) to the new console  window. On Unix systems the console is an xterm application. On  Windows systems this requires the GUI version swipl-win.exe  rather than the console-based swipl.exe.  This predicate has a couple of useful applications. One is to  separate (debugging) I/O of different threads. Another is to start  debugging a thread that is running in the background. If thread 10 is  running, the following sequence starts the tracer on this thread: \n\n\n\n?- thread_signal(10, (attach_console, trace)).\n\n ",
    "prefix":"attach_console"
  },
  "threadutil:interactor/0": {
    "body":"interactor$1\n$0",
    "description":"interactor.\nCreate a new console and run the Prolog top level in this new console.  See also attach_console/0.  In the Windows version a new interactor can also be created from the Run/New  thread menu.",
    "prefix":"interactor"
  },
  "threadutil:join_threads/0": {
    "body":"join_threads$1\n$0",
    "description":"join_threads.\nJoin all terminated threads. For normal applications, dealing with  terminated threads must be part of the application logic, either  detaching the thread before termination or making sure it will be  joined. The predicate join_threads/0  is intended for interactive sessions to reclaim resources from threads  that died unexpectedly during development.",
    "prefix":"join_threads"
  },
  "threadutil:tdebug/0": {
    "body":"tdebug$1\n$0",
    "description":"tdebug.\nCall tdebug/1  in all running threads.",
    "prefix":"tdebug"
  },
  "threadutil:tdebug/1": {
    "body":"tdebug(${1:ThreadId})$2\n$0",
    "description":"tdebug(+ThreadId).\nPrepare ThreadId for debugging using the graphical tracer.  This implies installing the tracer hooks in the thread and switching the  thread to debug mode using debug/0.  The call is injected into the thread using thread_signal/2.  We refer to the documentation of this predicate for asynchronous  interaction with threads. New threads created inherit their debug mode  from the thread that created them.",
    "prefix":"tdebug"
  },
  "threadutil:threads/0": {
    "body":"threads$1\n$0",
    "description":"threads.\nLists all current threads and their status.",
    "prefix":"threads"
  },
  "threadutil:tnodebug/0": {
    "body":"tnodebug$1\n$0",
    "description":"tnodebug.\nDisable debugging in all threads.",
    "prefix":"tnodebug"
  },
  "threadutil:tnodebug/1": {
    "body":"tnodebug(${1:ThreadId})$2\n$0",
    "description":"tnodebug(+ThreadId).\nDisable debugging thread ThreadId.",
    "prefix":"tnodebug"
  },
  "threadutil:tprofile/1": {
    "body":"tprofile(${1:ThreadId})$2\n$0",
    "description":"tprofile(+ThreadId).\nStart collecting profile data in ThreadId and ask the user to  hit <return> to stop the profiler. See section  4.41 for details on the execution profiler.",
    "prefix":"tprofile"
  },
  "threadutil:tspy/1": {
    "body":"tspy(${1:Spec})$2\n$0",
    "description":"tspy(:Spec).\nSet a spy point as spy/1  and enable debugging in all threads using tdebug/0.  Note that removing spy points can be done using nospy/1.  Disabling spy points in a specific thread is achieved by tnodebug/1.",
    "prefix":"tspy"
  },
  "threadutil:tspy/2": {
    "body":"tspy(${1:Spec}, ${2:ThreadId})$3\n$0",
    "description":"tspy(:Spec, +ThreadId).\nSet a spy point as spy/1  and enable the thread for debugging using tdebug/1.  Note that a spy point is a global flag on a predicate that is visible  from all threads. Spy points are honoured in all threads that are in  debug mode and ignored in threads that are in nodebug mode.",
    "prefix":"tspy"
  },
  "throw/1": {
    "body":"throw(${1:Exception})$2\n$0",
    "description":"[ISO]throw(+Exception).\nRaise an exception. The system looks for the innermost catch/3  ancestor for which Exception unifies with the Catcher  argument of the catch/3  call. See catch/3  for details.  ISO demands that throw/1  make a copy of Exception, walk up the stack to a catch/3  call, backtrack and try to unify the copy of Exception with Catcher. SWI-Prolog delays  backtracking until it actually finds a matching catch/3  goal. The advantage is that we can start the debugger at the first  possible location while preserving the entire exception context if there  is no matching catch/3  goal. This approach can lead to different behaviour if Goal  and Catcher of catch/3  call shared variables. We assume this to be highly unlikely and could  not think of a scenario where this is useful.63I'd  like to acknowledge Bart Demoen for his clarifications on these matters. \n\nIn addition to explicit calls to throw/1,  many built-in predicates throw exceptions directly from C. If the Exception  term cannot be copied due to lack of stack space, the following actions  are tried in order: \n\n\n\nIf the exception is of the form error(Formal,  ImplementationDefined), try to raise the exception without the ImplementationDefined  part.\nTry to raise error(resource_error(stack), global).\nAbort (see abort/0).\n\n  If an exception is raised in a call-back from C (see chapter  11) and not caught in the same call-back, PL_next_solution()  fails and the exception context can be retrieved using PL_exception().\n\n",
    "prefix":"throw"
  },
  "time/1": {
    "body":"time(${1:Goal})$2\n$0",
    "description":"time(:Goal).\nExecute Goal just like call/1  and print time used, number of logical inferences and the average number  of lips (logical inferences per second). Note that SWI-Prolog  counts the actual executed number of inferences rather than the number  of passes through the call and redo ports of the theoretical 4-port  model. If Goal is non-deterministic, print statistics for  each solution, where the reported values are relative to the previous  answer.",
    "prefix":"time"
  },
  "time:alarm/3": {
    "body": ["alarm(${1:Time}, ${2:Callable}, ${3:Id})$4\n$0" ],
    "description":"  alarm(+Time, :Callable, -Id) is det.\n  alarm(+Time, :Callable, -Id, +Options) is det.\n\n   Set up an alarm to be  signaled   Time  seconds from now. If the\n   alarm expires, Callable is called   asynchronously. Callable can\n   be used to raise  an  exception   using  throw/1  to  abort some\n   execution.\n\n   Options is a list of Name(Value) options.  Currently defined\n   options are:\n\n           * remove(Bool)\n           If =true= (default =false=), remove the alarm-event (as\n           remove_alarm/1) after it has been fired.\n           * install(Bool)\n           If =false= (default =true=) do not install the alarm.\n           It must be installed separately using install_alarm/1.",
    "prefix":"alarm"
  },
  "time:alarm/4": {
    "body": ["alarm(${1:Time}, ${2:Callable}, ${3:Id}, ${4:Options})$5\n$0" ],
    "description":"  alarm(+Time, :Callable, -Id) is det.\n  alarm(+Time, :Callable, -Id, +Options) is det.\n\n   Set up an alarm to be  signaled   Time  seconds from now. If the\n   alarm expires, Callable is called   asynchronously. Callable can\n   be used to raise  an  exception   using  throw/1  to  abort some\n   execution.\n\n   Options is a list of Name(Value) options.  Currently defined\n   options are:\n\n           * remove(Bool)\n           If =true= (default =false=), remove the alarm-event (as\n           remove_alarm/1) after it has been fired.\n           * install(Bool)\n           If =false= (default =true=) do not install the alarm.\n           It must be installed separately using install_alarm/1.",
    "prefix":"alarm"
  },
  "time:alarm_at/3": {
    "body": ["alarm_at(${1:Time}, ${2:Callable}, ${3:Id})$4\n$0" ],
    "description":"  alarm_at(+Time, :Callable, -Id) is det.\n  alarm_at(+Time, :Callable, -Id, +Options) is det.\n\n   As alarm/3 and alarm/4, but schedule   the  alarm at an absolute\n   point in time.\n\n   @see date_time_stamp/2.",
    "prefix":"alarm_at"
  },
  "time:alarm_at/4": {
    "body": ["alarm_at(${1:Time}, ${2:Callable}, ${3:Id}, ${4:Options})$5\n$0" ],
    "description":"  alarm_at(+Time, :Callable, -Id) is det.\n  alarm_at(+Time, :Callable, -Id, +Options) is det.\n\n   As alarm/3 and alarm/4, but schedule   the  alarm at an absolute\n   point in time.\n\n   @see date_time_stamp/2.",
    "prefix":"alarm_at"
  },
  "time:call_with_time_limit/2": {
    "body": ["call_with_time_limit(${1:Time}, ${2:Goal})$3\n$0" ],
    "description":"  call_with_time_limit(+Time, :Goal) is semidet.\n\n   Call Goal, while watching out for   a (wall-time) limit. If this\n   limit  is  exceeded,  the   exception  =time_limit_exceeded=  is\n   raised. Goal is called as in once/1.\n\n   @throws =time_limit_exceeded=",
    "prefix":"call_with_time_limit"
  },
  "time:current_alarm/4": {
    "body": ["current_alarm(${1:Time}, ${2:Goal}, ${3:Id}, ${4:Status})$5\n$0" ],
    "description":"  current_alarm(?Time, :Goal, ?Id, ?Status) is nondet.\n\n   Enumerate the alarms in the schedule.  Time is the absolute time\n   the event is scheduled for (see   also  get_time/1). Goal is the\n   goal to execute,  Id  is  the   identifier  and  Status  is  the\n   scheduling status. It takes the value   =done=  if the alarm has\n   been fired, =next= if the event is   the next to be executed and\n   =scheduled= otherwise.",
    "prefix":"current_alarm"
  },
  "time:install_alarm/1": {
    "body": ["install_alarm(${1:Id})$2\n$0" ],
    "description":"  install_alarm(+Id) is det.\n  install_alarm(+Id, +RelTime) is det.\n\n   Install an alarm allocated using alarm/4 with the install(false)\n   option or de-activated using  uninstall_alarm/1.   With  a given\n   RelTime, the alarm  is  scheduled  at   the  RelTime  from  now.\n   Otherwise it is scheduled on the   same (absolute) time on which\n   is was created.",
    "prefix":"install_alarm"
  },
  "time:install_alarm/2": {
    "body": ["install_alarm(${1:Id}, ${2:RelTime})$3\n$0" ],
    "description":"  install_alarm(+Id) is det.\n  install_alarm(+Id, +RelTime) is det.\n\n   Install an alarm allocated using alarm/4 with the install(false)\n   option or de-activated using  uninstall_alarm/1.   With  a given\n   RelTime, the alarm  is  scheduled  at   the  RelTime  from  now.\n   Otherwise it is scheduled on the   same (absolute) time on which\n   is was created.",
    "prefix":"install_alarm"
  },
  "time:remove_alarm/1": {
    "body": ["remove_alarm(${1:Id})$2\n$0" ],
    "description":"  remove_alarm(+Id) is det.\n\n   Remove an alarm.  If it has not yet been fired, it never will.",
    "prefix":"remove_alarm"
  },
  "time:uninstall_alarm/1": {
    "body": ["uninstall_alarm(${1:Id})$2\n$0" ],
    "description":"  uninstall_alarm(+Id) is det.\n\n   De-activate an alarm. This does _not_ invalidate Id, but ensures\n   that the alarm will not fire. The alarm can be rescheduled to\n   the original time using install_alarm/1 or to a new time using\n   install_alarm/2.",
    "prefix":"uninstall_alarm"
  },
  "time_file/2": {
    "body":"time_file(${1:File}, ${2:Time})$3\n$0",
    "description":"time_file(+File, -Time).\nUnify the last modification time of File with Time. Time is a floating point number expressing the seconds  elapsed since Jan1, 1970. See also convert_time/[2,8]  and get_time/1.",
    "prefix":"time_file"
  },
  "tipc/tipc:tipc_accept/3": {
    "body": ["tipc_accept(${1:Socket}, ${2:Slave}, ${3:Peer})$4\n$0" ],
    "description":"   tipc_accept(+Socket, -Slave, -Peer) is det.\n\n    Blocks on a server socket  and   waits  for connection requests\n    from clients. On success,  it  creates   a  new  socket for the\n    client and binds the identifier to Slave.  Peer is bound to the\n    TIPC address, port_id/2, of the client.",
    "prefix":"tipc_accept"
  },
  "tipc/tipc:tipc_bind/3": {
    "body": ["tipc_bind(${1:Socket}, ${2:Address}, ${3:ScopingOption})$4\n$0" ],
    "description":"   tipc_bind(+Socket, +Address, +ScopingOption) is det.\n\n    Associates/disassociates a socket with the name/3 or name_seq/3\n    address specified in Address. It also registers/unregisters it in\n    the  topology  server  name  table.   This  makes  the  address\n    visible/invisible to the rest of the   network according to the\n    scope specified in ScopingOption. ScopingOption   is a grounded\n    term that is one of:\n\n     $ scope(Scope) : where Scope is  one of: =zone=, =cluster=, or\n     =node=. Servers may bind to more   than  one address by making\n     successive calls to tipc_bind/3, one for  each address that it\n     wishes to advertise. The server will   receive traffic for all\n     of them. A server may, for  example, register one address with\n     node scope, another with cluster scope,  and a third with zone\n     scope. A client may then limit   the scope of its transmission\n     by specifying the appropriate address.\n\n     $ no_scope(Scope) : where Scope is as defined above. An\n     application may target a specific address for removal from its\n     collection of addresses by specifying the address and its\n     scope. The scoping option, =|no_scope(all)|=, may be used to\n     unbind the socket from all of its registered addresses. This\n     feature allows an application to gracefully exit from service.\n     Because the socket remains open, the application may continue\n     to service current transactions to completion. TIPC however,\n     will not schedule any new work for the server instance. If no\n     other servers are available, the work will be rejected or\n     dropped according to the socket options specified by the\n     client.\n\n    Connection-oriented, byte-stream services are  implemented with\n    this predicate combined with   tipc_listen/2 and tipc_accept/3.\n    Connectionless, datagram services  may   be  implemented  using\n    tipc_receive/4.\n\n    Note that clients do not  need  to   bind  to  any address. Its\n    port-id is sufficient for this role.   And server sockets (e.g.\n    those that are bound to name/3   or  name_seq/3, addresses) may\n    not act as clients. That is, they may not originate connections\n    from the socket using tipc_connect/2. Servers however, may\n    originate datagrams from bound sockets using tipc_send/4.\n    Please see the TIPC programmers's guide for other restrictions.",
    "prefix":"tipc_bind"
  },
  "tipc/tipc:tipc_canonical_address/2": {
    "body": ["tipc_canonical_address(${1:CanonicalAddress}, ${2:PortId})$3\n$0" ],
    "description":"  tipc_canonical_address(-CanonicalAddress, +PortId) is det.\n\n   Translates a port_id/2 address into canonical TIPC form:\n\n   * tipc_address(Zone, Cluster, Node, Reference)\n\n   It is provided for debugging an printing purposes only. The\n   canonical address is not used for any other purpose.",
    "prefix":"tipc_canonical_address"
  },
  "tipc/tipc:tipc_close_socket/1": {
    "body": ["tipc_close_socket(${1:SocketId})$2\n$0" ],
    "description":"   tipc_close_socket(+SocketId) is det.\n\n    Closes the indicated socket, making SocketId invalid. In stream\n    applications, sockets are closed by closing both stream handles\n    returned by tipc_open_socket/3.  There  are   two  cases  where\n    tipc_close_socket/1   is   used   because     there    are   no\n    stream-handles:\n\n     * After tipc_accept/3, the server does  a fork/1 to handle the\n     client in a sub-process. In this   case the accepted socket is\n     not longer needed from the main   server and must be discarded\n     using tipc_close_socket/1.\n\n     *  If,  after  discovering   the    connecting   client   with\n     tipc_accept/3,  the  server  does  not   want  to  accept  the\n     connection, it should discard the  accepted socket immediately\n     using tipc_close_socket/1.\n\n    @param SocketId the socket identifier returned by tipc_socket/2\n    or tipc_accept/3.\n\n    @error socket_error('Invalid argument) is thrown  if an attempt\n    is made to close a  socket   identifier  that  has already been\n    closed.",
    "prefix":"tipc_close_socket"
  },
  "tipc/tipc:tipc_connect/2": {
    "body": ["tipc_connect(${1:Socket}, ${2:TIPC_address})$3\n$0" ],
    "description":"   tipc_connect(+Socket, +TIPC_address) is det.\n\n    Provides a connection-oriented, client-interface   to connect a\n    socket to a given TIPC_address.   After  successful completion,\n    tipc_open_socket/3 may be used  to   create  I/O-Streams to the\n    remote socket.\n\n    @throws socket_error('Connection refused'), if there are\n    no servers bound to the specified address.\n\n    @throws socket_error('Connection timed out'), if no server that\n    is bound to the specified address accepts the connect\n    request within the specified time limit. See also\n    tipc_setopt/2.",
    "prefix":"tipc_connect"
  },
  "tipc/tipc:tipc_get_name/2": {
    "body": ["tipc_get_name(${1:Socket}, ${2:TIPC_address})$3\n$0" ],
    "description":"   tipc_get_name(+Socket, -TIPC_address) is det.\n\n    Unifies TIPC_address with the port-id assigned to the socket.",
    "prefix":"tipc_get_name"
  },
  "tipc/tipc:tipc_get_peer_name/2": {
    "body": ["tipc_get_peer_name(${1:Socket}, ${2:TIPC_address})$3\n$0" ],
    "description":"   tipc_get_peer_name(+Socket, -TIPC_address) is det.\n\n    Unifies TIPC_address with the port-id assigned to the socket\n    that this socket is connected to.\n\n    @throws socket_error('Transport endpoint is not connected'), if\n    an attempt is made to obtain a peer's name of an unconnected\n    socket.",
    "prefix":"tipc_get_peer_name"
  },
  "tipc/tipc:tipc_initialize/0": {
    "body": ["tipc_initialize$1\n$0" ],
    "description":"     tipc_initialize is semidet.\n\n      causes the TIPC service and the TIPC stack to be initialized\n      and made ready for service. An application must call this\n      predicate as part of its initialization prior to any use of\n      TIPC predicates. _|Please note the change of the API.|_\n\n      @throws socket_error('Address family not supported by protocol')\n      if a TIPC server is not available on the current host.\n",
    "prefix":"tipc_initialize"
  },
  "tipc/tipc:tipc_listen/2": {
    "body": ["tipc_listen(${1:Socket}, ${2:Backlog})$3\n$0" ],
    "description":"   tipc_listen(+Socket,+Backlog) is det.\n\n    Listens for incoming requests for connections. Backlog\n    indicates how many pending connection requests are allowed.\n    Pending requests are requests that are not yet acknowledged\n    using tipc_accept/3. If the indicated number is exceeded, the\n    requesting client will be signalled that the service is\n    currently not available. A suggested default value is 5.",
    "prefix":"tipc_listen"
  },
  "tipc/tipc:tipc_open_socket/3": {
    "body": [
      "tipc_open_socket(${1:SocketId}, ${2:InStream}, ${3:OutStream})$4\n$0"
    ],
    "description":"   tipc_open_socket(+SocketId, -InStream, -OutStream) is det.\n\n    Opens two SWI-Prolog I/O-streams, one to   deal with input from\n    the socket and one with output   to  the socket. If tipc_bind/3\n    has been called on the socket, OutStream is useless and will\n    not be created. After closing both InStream and OutStream, the\n    socket itself is discarded.",
    "prefix":"tipc_open_socket"
  },
  "tipc/tipc:tipc_receive/4": {
    "body": [
      "tipc_receive(${1:Socket}, ${2:Data}, ${3:From}, ${4:OptionList})$5\n$0"
    ],
    "description":"   tipc_receive(+Socket, -Data, -From, +OptionList) is det.\n\n    Waits  for,  and  returns  the  next  datagram.  Like  its  UDP\n    counterpart, the data are returned as   a  Prolog string object\n    (see string_codes/2). From is  an   address  structure of the\n    form port_id/2, indicating the sender of the message.\n\n     Defined options are:\n\n      * as(+Type)\n      Defines the returned term-type. Type is one of atom, codes or\n      string (default).\n\n      * nonblock\n      Poll the socket and return immediately. If a message is\n      present, it is returned. If not, then an exception,\n      error(socket_error('Resource temporarily unavailable'), _),\n      will be thrown. Users are cautioned not to \"spin\"\n      unnecessarily on non-blocking receives as they may prevent\n      the system from servicing other background activities such as\n      XPCE event dispatching.\n\n    The typical sequence to receive a connectionless TIPC datagram is:\n\n    ==\n    receive :-\n            tipc_socket(S, dgram),\n            tipc_bind(S, name(18888, 10, 0), scope(zone)),\n            repeat,\n                tipc_receive(Socket, Data, From, [as(atom)]),\n                format('Got ~q from ~q~n', [Data, From]),\n                Data == quit,\n            !, tipc_close_socket(S).\n    ==\n",
    "prefix":"tipc_receive"
  },
  "tipc/tipc:tipc_send/4": {
    "body": ["tipc_send(${1:Socket}, ${2:Data}, ${3:To}, ${4:Options})$5\n$0" ],
    "description":"   tipc_send(+Socket, +Data, +To, +Options) is det.\n\n    sends a TIPC datagram to one or more destinations. Like its UDP\n    counterpart, Data is a string, atom  or code-list providing the\n    data to be sent.  To  is   a  name/3,  name_seq/3, or port_id/2\n    address structure. See tipc_overview.txt, for more information\n    on TIPC Address Structures. Options is currently unused.\n\n    A simple example to send a connectionless TIPC datagram is:\n\n    ==\n    send(Message) :-\n            tipc_socket(S, dgram),\n            tipc_send(S, Message, name(18888, 10,0), []),\n            tipc_close_socket(S).\n    ==\n\n    Messages are delivered silently unless  some form of congestion\n    was encountered and the   =|dest_droppable(false)|=  option was\n    issued on the sender's socket. In  this case, the send succeeds\n    but a notification in the form of  an empty message is returned\n    to the sender from  the  receiver,   indicating  some  kind  of\n    delivery failure. The port-id of the   receiver  is returned in\n    congestion conditions. A =|port_id(0,0)|=, is   returned if the\n    destination address was invalid. Senders   and receivers should\n    beware of this possibility.\n\n",
    "prefix":"tipc_send"
  },
  "tipc/tipc:tipc_service_exists/1": {
    "body": ["tipc_service_exists(${1:Address})$2\n$0" ],
    "description":"  tipc_service_exists(+Address, +Timeout) is semidet.\n  tipc_service_exists(+Address) is semidet.\n\n   Interrogates the TIPC topology server to see if a service is\n   available at an advertised Address.\n\n   @param Address is one of:   =|name(Type,  Instance, Domain)|= or\n   =|name_seq(Type,  Lower,  Upper)|=.   A    name/3,   address  is\n   translated to a name_seq/3, following, where Lower and Upper are\n   assigned the value of Instance. Domain is unused and must be\n   zero. A =|name_seq(Type, Lower, Upper)|= is a multi-cast\n   address. This predicate succeeds if there is at least one\n   service that would answer according to multi-cast addressing\n   rules.\n\n   @param Timeout is optional. It is a non-negative real number\n   that specifies the amount of time in seconds to block and wait\n   for a service to become available. Fractions of a second are\n   also permissible.\n",
    "prefix":"tipc_service_exists"
  },
  "tipc/tipc:tipc_service_exists/2": {
    "body": ["tipc_service_exists(${1:Address}, ${2:Timeout})$3\n$0" ],
    "description":"  tipc_service_exists(+Address, +Timeout) is semidet.\n  tipc_service_exists(+Address) is semidet.\n\n   Interrogates the TIPC topology server to see if a service is\n   available at an advertised Address.\n\n   @param Address is one of:   =|name(Type,  Instance, Domain)|= or\n   =|name_seq(Type,  Lower,  Upper)|=.   A    name/3,   address  is\n   translated to a name_seq/3, following, where Lower and Upper are\n   assigned the value of Instance. Domain is unused and must be\n   zero. A =|name_seq(Type, Lower, Upper)|= is a multi-cast\n   address. This predicate succeeds if there is at least one\n   service that would answer according to multi-cast addressing\n   rules.\n\n   @param Timeout is optional. It is a non-negative real number\n   that specifies the amount of time in seconds to block and wait\n   for a service to become available. Fractions of a second are\n   also permissible.\n",
    "prefix":"tipc_service_exists"
  },
  "tipc/tipc:tipc_service_port_monitor/2": {
    "body": ["tipc_service_port_monitor(${1:Addresses}, ${2:Goal})$3\n$0" ],
    "description":"  tipc_service_port_monitor(+Addresses, :Goal) is det.\n  tipc_service_port_monitor(+Addresses, :Goal, ?Timeout) is det.\n\n   Monitors a collection of worker threads that are bound to a list\n   of Addresses. A single port monitor may be used to provide\n   surveillance over workers that are providing a number of\n   different services. For a given address type, discontiguous\n   port ranges may be specified, but overlapping port ranges may\n   not. Goal for example, may simply choose to broadcast the\n   notification, thus delegating the notification event handling to\n   others.\n\n   @param Addresses is a list of name/3 or name_seq/3 addresses\n   for the services to be monitored.\n\n   @param Goal is a predicate that will be called when a\n   worker's publication status changes. The Goal\n   is called exactly once per event with its the last argument\n   unified with the structure:\n\n   $ published(-NameSeq, -PortId) : when the worker binds\n   its socket to the address.\n\n   $ withdrawn(-NameSeq, -PortId) : when the worker\n   unbinds its socket from the address.\n\n   @param Timeout is optional.  It  is   one  of:\n\n   $ Timeout : a non-negative real number that specifies the\n   number of seconds that surveillance is to be continued.\n\n   $ infinite : causes the monitor to run forever in the current\n   thread (e.g. never returns).\n\n   $ detached(-ThreadId) : causes the monitor to run\n   forever as a separate thread. ThreadId is unified with the\n   thread identifier of the monitor thread. This is useful when the\n   monitor is required to provide continuous surveillance, while\n   operating in the background.\n",
    "prefix":"tipc_service_port_monitor"
  },
  "tipc/tipc:tipc_service_port_monitor/3": {
    "body": [
      "tipc_service_port_monitor(${1:Addresses}, ${2:Goal}, ${3:Timeout})$4\n$0"
    ],
    "description":"  tipc_service_port_monitor(+Addresses, :Goal) is det.\n  tipc_service_port_monitor(+Addresses, :Goal, ?Timeout) is det.\n\n   Monitors a collection of worker threads that are bound to a list\n   of Addresses. A single port monitor may be used to provide\n   surveillance over workers that are providing a number of\n   different services. For a given address type, discontiguous\n   port ranges may be specified, but overlapping port ranges may\n   not. Goal for example, may simply choose to broadcast the\n   notification, thus delegating the notification event handling to\n   others.\n\n   @param Addresses is a list of name/3 or name_seq/3 addresses\n   for the services to be monitored.\n\n   @param Goal is a predicate that will be called when a\n   worker's publication status changes. The Goal\n   is called exactly once per event with its the last argument\n   unified with the structure:\n\n   $ published(-NameSeq, -PortId) : when the worker binds\n   its socket to the address.\n\n   $ withdrawn(-NameSeq, -PortId) : when the worker\n   unbinds its socket from the address.\n\n   @param Timeout is optional.  It  is   one  of:\n\n   $ Timeout : a non-negative real number that specifies the\n   number of seconds that surveillance is to be continued.\n\n   $ infinite : causes the monitor to run forever in the current\n   thread (e.g. never returns).\n\n   $ detached(-ThreadId) : causes the monitor to run\n   forever as a separate thread. ThreadId is unified with the\n   thread identifier of the monitor thread. This is useful when the\n   monitor is required to provide continuous surveillance, while\n   operating in the background.\n",
    "prefix":"tipc_service_port_monitor"
  },
  "tipc/tipc:tipc_service_probe/1": {
    "body": ["tipc_service_probe(${1:Address})$2\n$0" ],
    "description":"  tipc_service_probe(?Address) is nondet.\n  tipc_service_probe(?Address, ?PortId) is nondet.\n   Allows a user to discover the instance ranges and/or port-ids\n   for a particular service.\n\n   @param Address is a name_seq/3 address. The address type must be\n   grounded.\n\n   @param PortId is  unified  with  the   port-id  for  a  specific\n   name_sequence address.\n",
    "prefix":"tipc_service_probe"
  },
  "tipc/tipc:tipc_service_probe/2": {
    "body": ["tipc_service_probe(${1:Address}, ${2:PortId})$3\n$0" ],
    "description":"  tipc_service_probe(?Address) is nondet.\n  tipc_service_probe(?Address, ?PortId) is nondet.\n   Allows a user to discover the instance ranges and/or port-ids\n   for a particular service.\n\n   @param Address is a name_seq/3 address. The address type must be\n   grounded.\n\n   @param PortId is  unified  with  the   port-id  for  a  specific\n   name_sequence address.\n",
    "prefix":"tipc_service_probe"
  },
  "tipc/tipc:tipc_setopt/2": {
    "body": ["tipc_setopt(${1:Socket}, ${2:Option})$3\n$0" ],
    "description":"   tipc_setopt(+Socket,+Option) is det.\n\n    Sets options on the socket. Defined options are:\n\n    $ importance(+Priority) :\n    Allow sockets to assign a priority   to their traffic. Priority\n    is one of : =low= (default), =medium=, =high=, or =critical=.\n\n    $ src_droppable(+Boolean) :\n    Allow TIPC to silently discard packets in congested situations,\n    rather than queuing them for later transmission.\n\n    $ dest_droppable(+Boolean) :\n    Allow TIPC to silently discard packets in congested situations,\n    rather than returning them to the sender as undeliverable.\n\n    $ conn_timeout(+Seconds) :\n    Specifies the time interval that tipc_connect/2 will use before\n    abandoning a connection attempt. Default: 8.000 sec.",
    "prefix":"tipc_setopt"
  },
  "tipc/tipc:tipc_socket/2": {
    "body": ["tipc_socket(${1:SocketId}, ${2:SocketType})$3\n$0" ],
    "description":"   tipc_socket(-SocketId, +SocketType) is det.\n\n    Creates  a  TIPC-domain  socket  of    the  type  specified  by\n    SocketType, and unifies it to an  identifier, SocketId.\n\n    @param SocketType is one of  the   following  atoms:\n\n    * rdm - unnumbered, reliable datagram service,\n    * dgram - unnumbered, unreliable datagram service,\n    * seqpacket - numbered, reliable datagram service, and\n    * stream - reliable, connection-oriented byte-stream\n      service\n\n    @error socket_error('Address family not supported by\n    protocol') is thrown if a TIPC server is not available on\n    the current host.\n",
    "prefix":"tipc_socket"
  },
  "tipc/tipc_broadcast:tipc_host_to_address/2": {
    "body": ["tipc_host_to_address(${1:Service}, ${2:Address})$3\n$0" ],
    "description":"  tipc_host_to_address(?Service, ?Address) is nondet.\n\n   locates a TIPC service by name. Service  is an atom or grounded term\n   representing the common name  of  the   service.  Address  is a TIPC\n   address structure. A server may advertise   its  services by name by\n   including  the  fact,    tipc:host_to_address(+Service,   +Address),\n   somewhere in its source. This predicate can  also be used to perform\n   reverse searches. That is it  will  also   resolve  an  Address to a\n   Service name. The search is zone-wide. Locating a service however,\n   does not imply that the service is actually reachable from any\n   particular node within the zone.\n",
    "prefix":"tipc_host_to_address"
  },
  "tipc/tipc_broadcast:tipc_initialize/0": {
    "body": ["tipc_initialize$1\n$0" ],
    "description":"  tipc_initialize is semidet.\n   See tipc:tipc_initialize/0\n",
    "prefix":"tipc_initialize"
  },
  "tipc/tipc_linda:bagof_in_noblock/3": {
    "body": ["bagof_in_noblock(${1:Template}, ${2:Tuple}, ${3:Bag})$4\n$0" ],
    "description":"  bagof_in_noblock(?Template, ?Tuple, -Bag) is nondet.\n  bagof_rd_noblock(?Template, ?Tuple, -Bag) is nondet.\n\n    Bag is the list of all instances of Template such that Tuple exists\n    in the tuple-space. The behavior of variables in Tuple and Template\n    is as in bagof/3. The variables   could be existentially quantified\n    with ^/2 as in bagof/3. The  operation   is  performed as an atomic\n    operation. This predicate can  fail  due   to  a  timeout. Example:\n    Assume that only one client is connected to the server and that the\n    tuple-space initially is empty.\n\n  ==\n    ?- out(x(a,3)), out(x(a,4)), out(x(b,3)), out(x(c,3)).\n\n    true.\n    ?- bagof_rd_noblock(C-N, x(C,N), L).\n\n    L = [a-3,a-4,b-3,c-3] .\n\n    true.\n    ?- bagof_rd_noblock(C, N^x(C,N), L).\n\n    L = [a,a,b,c] .\n\n    true.\n  ==",
    "prefix":"bagof_in_noblock"
  },
  "tipc/tipc_linda:bagof_rd_noblock/3": {
    "body": ["bagof_rd_noblock(${1:Template}, ${2:Tuple}, ${3:Bag})$4\n$0" ],
    "description":"  bagof_in_noblock(?Template, ?Tuple, -Bag) is nondet.\n  bagof_rd_noblock(?Template, ?Tuple, -Bag) is nondet.\n\n    Bag is the list of all instances of Template such that Tuple exists\n    in the tuple-space. The behavior of variables in Tuple and Template\n    is as in bagof/3. The variables   could be existentially quantified\n    with ^/2 as in bagof/3. The  operation   is  performed as an atomic\n    operation. This predicate can  fail  due   to  a  timeout. Example:\n    Assume that only one client is connected to the server and that the\n    tuple-space initially is empty.\n\n  ==\n    ?- out(x(a,3)), out(x(a,4)), out(x(b,3)), out(x(c,3)).\n\n    true.\n    ?- bagof_rd_noblock(C-N, x(C,N), L).\n\n    L = [a-3,a-4,b-3,c-3] .\n\n    true.\n    ?- bagof_rd_noblock(C, N^x(C,N), L).\n\n    L = [a,a,b,c] .\n\n    true.\n  ==",
    "prefix":"bagof_rd_noblock"
  },
  "tipc/tipc_linda:close_client/0": {
    "body": ["close_client$1\n$0" ],
    "description":"  close_client is det.\n\n Closes the connection to  the  Linda-server.   Causes  the  server  to\n release resources associated with this client.",
    "prefix":"close_client"
  },
  "tipc/tipc_linda:in/1": {
    "body": ["in(${1:Tuple})$2\n$0" ],
    "description":"  in(?Tuple) is det.\n\n    Atomically removes the tuple Tuple from   Linda's tuple-space if it\n    is there. The tuple will be returned   to exactly one requestor. If\n    no tuple is available, the predicate   blocks until it is available\n    (that is, someone performs an out/1).",
    "prefix":"in"
  },
  "tipc/tipc_linda:in/2": {
    "body": ["in(${1:TupleList}, ${2:Tuple})$3\n$0" ],
    "description":"  in(+TupleList, -Tuple) is det.\n\n    As in/1 but succeeds when any  one   of  the tuples in TupleList is\n    available. Tuple is unified with the fetched tuple.",
    "prefix":"in"
  },
  "tipc/tipc_linda:in_noblock/1": {
    "body": ["in_noblock(${1:Tuple})$2\n$0" ],
    "description":"  in_noblock(?Tuple) is semidet.\n\n    Atomically removes the tuple Tuple from   Linda's tuple-space if it\n    is there. If not, the predicate fails.  This predicate can fail due\n    to a timeout.",
    "prefix":"in_noblock"
  },
  "tipc/tipc_linda:linda/0": {
    "body": ["linda$1\n$0" ],
    "description":"  linda is det.\n  linda(:Goal) is det.\n   Starts a Linda-server in this process. The\n   network address is written to current output stream as a TIPC\n   port_id/2 reference (e.g. port_id('<1.1.1:3200515722>') ). This\n   predicates looks to see if a server is already listening on the\n   cluster. If so, it reports the address of the existing server.\n   Otherwise, it registers a new server and reports its address.\n\n ==\n ?- linda.\n    TIPC Linda server now listening at: port_id('<1.1.1:3200515722>')\n    true.\n\n ?- linda.\n    TIPC Linda server still listening at: port_id('<1.1.1:3200515722>')\n    true.\n ==\n\n  The following will call my_init/0 in the current module after the\n  server is successfully started or is found already listening.\n  my_init/0 could start client-processes, initialize the tuple space,\n  etc.\n\n ==\n ?- linda(my_init).\n ==\n",
    "prefix":"linda"
  },
  "tipc/tipc_linda:linda/1": {
    "body": ["linda(${1:Goal})$2\n$0" ],
    "description":"  linda is det.\n  linda(:Goal) is det.\n   Starts a Linda-server in this process. The\n   network address is written to current output stream as a TIPC\n   port_id/2 reference (e.g. port_id('<1.1.1:3200515722>') ). This\n   predicates looks to see if a server is already listening on the\n   cluster. If so, it reports the address of the existing server.\n   Otherwise, it registers a new server and reports its address.\n\n ==\n ?- linda.\n    TIPC Linda server now listening at: port_id('<1.1.1:3200515722>')\n    true.\n\n ?- linda.\n    TIPC Linda server still listening at: port_id('<1.1.1:3200515722>')\n    true.\n ==\n\n  The following will call my_init/0 in the current module after the\n  server is successfully started or is found already listening.\n  my_init/0 could start client-processes, initialize the tuple space,\n  etc.\n\n ==\n ?- linda(my_init).\n ==\n",
    "prefix":"linda"
  },
  "tipc/tipc_linda:linda_client/1": {
    "body": ["linda_client(${1:Domain})$2\n$0" ],
    "description":"  linda_client(+Domain) is semidet.\n\n    Establishes a connection to a Linda-server  providing a named tuple\n    space. Domain is  an  atom   specifying  a  particular tuple-space,\n    selected from a universe of tuple-spaces.  At present however, only\n    one tuple-space, =global=, is supported. A client may interact with\n    any server reachable on the TIPC  cluster. This predicate will fail\n    if no server is reachable for that tuple space.\n",
    "prefix":"linda_client"
  },
  "tipc/tipc_linda:linda_eval/1": {
    "body": ["linda_eval(${1:Goal})$2\n$0" ],
    "description":"  linda_eval(:Goal) is det.\n  linda_eval(?Head, :Goal) is det.\n  linda_eval_detached(:Goal) is det.\n  linda_eval_detached(?Head, :Goal) is det.\n\n  Causes Goal to be evaluated in parallel  with a parent predicate. The\n  child  thread  is  a  full-fledged    client,   possessing  the  same\n  capabilities as the  parent.  Upon   successful  completion  of Goal,\n  unbound variables are unified and the  result   is  sent to the Linda\n  server via out/1, where  it  is   made  available  to  others. linda_eval/2\n  evaluates Goal, then unifies the result  with Head, providing a means\n  of customizing the resulting output structure.   In linda_eval/1, Head, and\n  Goal are identical, except that the module  name for Head is stripped\n  before output. If the child fails  or receives an uncaught exception,\n  no such output occurs.\n\n  *|Joining Threads:|* Threads created using linda_eval/(1-2) are not allowed\n  to linger. They are joined (blocking  the parent, if necessary) under\n  three conditions: backtracking on failure into an linda_eval/(1-2), receipt\n  of an uncaught  exception,  and  cut   of  choice-points.  Goals  are\n  evaluated   using   forall/2.   They   are    expected   to   provide\n  nondeterministic behavior. That is they  may   succeed  zero  or more\n  times on backtracking. They must however,  eventually fail or succeed\n  deterministically.  Otherwise,  the  thread  will  hang,  which  will\n  eventually hang the parent  thread.  Cutting   choice  points  in the\n  parent's body has the effect of joining   all children created by the\n  parent. This provides a  barrier  that   guarantees  that  all  child\n  instances of Goal have run to completion before the parent proceeds.\n  Detached threads behave as above, except that they operate\n  independently and cannot be joined. They will continue to run while\n  the host process continues to run.\n\n Here is an example of a parallel quicksort:\n\n ==\n qksort([], []).\n\n qksort([X | List], Sorted) :-\n       partition(@>(X), List, Less, More),\n       linda_eval(qksort(More, SortedMore)),\n       qksort(Less, SortedLess), !,\n       in_noblock(qksort(More, SortedMore)),\n       append(SortedLess, [X | SortedMore], Sorted).\n ==\n",
    "prefix":"linda_eval"
  },
  "tipc/tipc_linda:linda_eval/2": {
    "body": ["linda_eval(${1:Head}, ${2:Goal})$3\n$0" ],
    "description":"  linda_eval(:Goal) is det.\n  linda_eval(?Head, :Goal) is det.\n  linda_eval_detached(:Goal) is det.\n  linda_eval_detached(?Head, :Goal) is det.\n\n  Causes Goal to be evaluated in parallel  with a parent predicate. The\n  child  thread  is  a  full-fledged    client,   possessing  the  same\n  capabilities as the  parent.  Upon   successful  completion  of Goal,\n  unbound variables are unified and the  result   is  sent to the Linda\n  server via out/1, where  it  is   made  available  to  others. linda_eval/2\n  evaluates Goal, then unifies the result  with Head, providing a means\n  of customizing the resulting output structure.   In linda_eval/1, Head, and\n  Goal are identical, except that the module  name for Head is stripped\n  before output. If the child fails  or receives an uncaught exception,\n  no such output occurs.\n\n  *|Joining Threads:|* Threads created using linda_eval/(1-2) are not allowed\n  to linger. They are joined (blocking  the parent, if necessary) under\n  three conditions: backtracking on failure into an linda_eval/(1-2), receipt\n  of an uncaught  exception,  and  cut   of  choice-points.  Goals  are\n  evaluated   using   forall/2.   They   are    expected   to   provide\n  nondeterministic behavior. That is they  may   succeed  zero  or more\n  times on backtracking. They must however,  eventually fail or succeed\n  deterministically.  Otherwise,  the  thread  will  hang,  which  will\n  eventually hang the parent  thread.  Cutting   choice  points  in the\n  parent's body has the effect of joining   all children created by the\n  parent. This provides a  barrier  that   guarantees  that  all  child\n  instances of Goal have run to completion before the parent proceeds.\n  Detached threads behave as above, except that they operate\n  independently and cannot be joined. They will continue to run while\n  the host process continues to run.\n\n Here is an example of a parallel quicksort:\n\n ==\n qksort([], []).\n\n qksort([X | List], Sorted) :-\n       partition(@>(X), List, Less, More),\n       linda_eval(qksort(More, SortedMore)),\n       qksort(Less, SortedLess), !,\n       in_noblock(qksort(More, SortedMore)),\n       append(SortedLess, [X | SortedMore], Sorted).\n ==\n",
    "prefix":"linda_eval"
  },
  "tipc/tipc_linda:linda_eval_detached/1": {
    "body": ["linda_eval_detached(${1:Goal})$2\n$0" ],
    "description":"  linda_eval(:Goal) is det.\n  linda_eval(?Head, :Goal) is det.\n  linda_eval_detached(:Goal) is det.\n  linda_eval_detached(?Head, :Goal) is det.\n\n  Causes Goal to be evaluated in parallel  with a parent predicate. The\n  child  thread  is  a  full-fledged    client,   possessing  the  same\n  capabilities as the  parent.  Upon   successful  completion  of Goal,\n  unbound variables are unified and the  result   is  sent to the Linda\n  server via out/1, where  it  is   made  available  to  others. linda_eval/2\n  evaluates Goal, then unifies the result  with Head, providing a means\n  of customizing the resulting output structure.   In linda_eval/1, Head, and\n  Goal are identical, except that the module  name for Head is stripped\n  before output. If the child fails  or receives an uncaught exception,\n  no such output occurs.\n\n  *|Joining Threads:|* Threads created using linda_eval/(1-2) are not allowed\n  to linger. They are joined (blocking  the parent, if necessary) under\n  three conditions: backtracking on failure into an linda_eval/(1-2), receipt\n  of an uncaught  exception,  and  cut   of  choice-points.  Goals  are\n  evaluated   using   forall/2.   They   are    expected   to   provide\n  nondeterministic behavior. That is they  may   succeed  zero  or more\n  times on backtracking. They must however,  eventually fail or succeed\n  deterministically.  Otherwise,  the  thread  will  hang,  which  will\n  eventually hang the parent  thread.  Cutting   choice  points  in the\n  parent's body has the effect of joining   all children created by the\n  parent. This provides a  barrier  that   guarantees  that  all  child\n  instances of Goal have run to completion before the parent proceeds.\n  Detached threads behave as above, except that they operate\n  independently and cannot be joined. They will continue to run while\n  the host process continues to run.\n\n Here is an example of a parallel quicksort:\n\n ==\n qksort([], []).\n\n qksort([X | List], Sorted) :-\n       partition(@>(X), List, Less, More),\n       linda_eval(qksort(More, SortedMore)),\n       qksort(Less, SortedLess), !,\n       in_noblock(qksort(More, SortedMore)),\n       append(SortedLess, [X | SortedMore], Sorted).\n ==\n",
    "prefix":"linda_eval_detached"
  },
  "tipc/tipc_linda:linda_eval_detached/2": {
    "body": ["linda_eval_detached(${1:Head}, ${2:Goal})$3\n$0" ],
    "description":"  linda_eval(:Goal) is det.\n  linda_eval(?Head, :Goal) is det.\n  linda_eval_detached(:Goal) is det.\n  linda_eval_detached(?Head, :Goal) is det.\n\n  Causes Goal to be evaluated in parallel  with a parent predicate. The\n  child  thread  is  a  full-fledged    client,   possessing  the  same\n  capabilities as the  parent.  Upon   successful  completion  of Goal,\n  unbound variables are unified and the  result   is  sent to the Linda\n  server via out/1, where  it  is   made  available  to  others. linda_eval/2\n  evaluates Goal, then unifies the result  with Head, providing a means\n  of customizing the resulting output structure.   In linda_eval/1, Head, and\n  Goal are identical, except that the module  name for Head is stripped\n  before output. If the child fails  or receives an uncaught exception,\n  no such output occurs.\n\n  *|Joining Threads:|* Threads created using linda_eval/(1-2) are not allowed\n  to linger. They are joined (blocking  the parent, if necessary) under\n  three conditions: backtracking on failure into an linda_eval/(1-2), receipt\n  of an uncaught  exception,  and  cut   of  choice-points.  Goals  are\n  evaluated   using   forall/2.   They   are    expected   to   provide\n  nondeterministic behavior. That is they  may   succeed  zero  or more\n  times on backtracking. They must however,  eventually fail or succeed\n  deterministically.  Otherwise,  the  thread  will  hang,  which  will\n  eventually hang the parent  thread.  Cutting   choice  points  in the\n  parent's body has the effect of joining   all children created by the\n  parent. This provides a  barrier  that   guarantees  that  all  child\n  instances of Goal have run to completion before the parent proceeds.\n  Detached threads behave as above, except that they operate\n  independently and cannot be joined. They will continue to run while\n  the host process continues to run.\n\n Here is an example of a parallel quicksort:\n\n ==\n qksort([], []).\n\n qksort([X | List], Sorted) :-\n       partition(@>(X), List, Less, More),\n       linda_eval(qksort(More, SortedMore)),\n       qksort(Less, SortedLess), !,\n       in_noblock(qksort(More, SortedMore)),\n       append(SortedLess, [X | SortedMore], Sorted).\n ==\n",
    "prefix":"linda_eval_detached"
  },
  "tipc/tipc_linda:linda_timeout/1": {
    "body": ["linda_timeout(${1:NewTime})$2\n$0" ],
    "description":"  linda_timeout(+NewTime) is semidet.\n\n Temporarily sets Linda's timeout. Internally,  the original timeout is\n saved and then the timeout is set  to NewTime. NewTime is as described\n in linda_timeout/2. The original timeout  is restored automatically on\n cut of choice points, failure on backtracking, or uncaught exception.\n",
    "prefix":"linda_timeout"
  },
  "tipc/tipc_linda:linda_timeout/2": {
    "body": ["linda_timeout(${1:OldTime}, ${2:NewTime})$3\n$0" ],
    "description":"  linda_timeout(?OldTime, ?NewTime) is semidet.\n\n Controls Linda's message-passing timeout. It specifies the time window\n where clients will accept server replies in  response to =in= and =rd=\n requests.  Replies  arriving  outside  of  this  window  are  silently\n ignored. OldTime is unified with the old   timeout and then timeout is\n set to NewTime.  NewTime  is  of   the  form  Seconds:Milliseconds.  A\n non-negative real number, seconds, is also  recognized. The default is\n 0.250 seconds. This timeout is thread local and is _not_  inherited\n from its parent. New threads are initialized to the default.\n\n *|Note:|* The synchronous behavior  afforded by in/1 and rd/1\n is implemented by periodically polling the   server.  The poll rate is\n set according to this timeout. Setting the timeout too small may\n result in substantial network traffic that is of little value.\n\n @throws error(feature_not_supported). SICStus Linda can\n disable the timeout by specifying =off= as NewTime. This feature does\n not exist for safety reasons.\n",
    "prefix":"linda_timeout"
  },
  "tipc/tipc_linda:out/1": {
    "body": ["out(${1:Tuple})$2\n$0" ],
    "description":"  out(+Tuple) is det.\n\n    Places a Tuple in Linda's tuple-space.\n",
    "prefix":"out"
  },
  "tipc/tipc_linda:rd/1": {
    "body": ["rd(${1:Tuple})$2\n$0" ],
    "description":"  rd(?Tuple) is nondet.\n\n    Succeeds  nondeterministically  if  Tuple  is    available  in  the\n    tuple-space, suspends otherwise until it is available. Compare this\n    with in/1: the tuple is not removed.",
    "prefix":"rd"
  },
  "tipc/tipc_linda:rd/2": {
    "body": ["rd(${1:TupleList}, ${2:Tuple})$3\n$0" ],
    "description":"  rd(?TupleList, -Tuple) is nondet.\n\n    As in/2 but provides a  choice  point   that  does  not  remove any\n    tuples.",
    "prefix":"rd"
  },
  "tipc/tipc_linda:rd_noblock/1": {
    "body": ["rd_noblock(${1:Tuple})$2\n$0" ],
    "description":"  rd_noblock(?Tuple) is nondet.\n\n    Succeeds  nondeterministically  if  Tuple  is    available  in  the\n    tuple-space, fails otherwise. This predicate  can   fail  due  to a\n    timeout.",
    "prefix":"rd_noblock"
  },
  "tipc/tipc_linda:tipc_initialize/0": {
    "body": ["tipc_initialize$1\n$0" ],
    "description":"  tipc_initialize is semidet.\n\n   See tipc:tipc_initialize/0.\n",
    "prefix":"tipc_initialize"
  },
  "tipc/tipc_linda:tipc_linda_server/0": {
    "body": ["tipc_linda_server$1\n$0" ],
    "description":" tipc_linda_server is nondet.\n\n   Acts as a stand-alone Linda server.   This predicate initializes the\n   TIPC stack and then starts a Linda  server in the current thread. If\n   a client performs  an  =|out(server_quit)|=,   the  server's  Prolog\n   process will exit via halt/1. It is intended for use in scripting as\n   follows:\n\n   ==\n   swipl -q -g 'use_module(library(tipc/tipc_linda)),\n          tipc_linda_server' -t 'halt(1)'\n   ==\n\n   See also manual section 2.10.2.1 Using PrologScript.\n\n   *|Note:|*  Prolog  will  return  a  non-zero  exit  status  if  this\n   predicate is executed on  a  cluster   that  already  has  an active\n   server. An exit status of zero is returned on graceful shutdown.\n\n   @throws error(permission_error(halt,thread,2),context(halt/1,Only\n   from thread 'main')), if this predicate is executed in a thread\n   other than =main=.\n\n",
    "prefix":"tipc_linda_server"
  },
  "tipc/tipc_linda:tuple/1": {
    "body": ["tuple(${1:Goal})$2\n$0" ],
    "description":"  tuple(:Goal) is det.\n  tuple(?Head, :Goal) is det.\n\n  registers Head as a virtual tuple  in   TIPC  Linda's tuple space. On\n  success, any client on the  cluster   may  reference the tuple, Head,\n  using rd/1 or rd_noblock/1.  On  reference,   Goal  is  executed by a\n  separate thread of execution in the host client's Prolog process. The\n  result is unified with Head, which  is   then  returned  to the guest\n  client. As in linda_eval/(1-2) above, Goal is evaluated using forall/2. The\n  virtual tuple is unregistered  on   backtracking  into a tuple/(1-2),\n  receipt of uncaught exception, or cut   of choice-points. In tuple/1,\n  Head and Goal are identical, except that  the module name is stripped\n  from Head.\n\n  *|Note:|* A virtual tuple is an extension  of the server. Even though\n  it is operating in the client's  Prolog environment, it is restricted\n  in the server operations that it may   perform.  It is generally safe\n  for tuple predicates to perform out/1   operations,  but it is unsafe\n  for them to perform any variant of   =in= or =rd=, either directly or\n  indirectly. This restriction is however, relaxed   if  the server and\n  client are operating in separate  heavyweight processes (not threads)\n  on the node or cluster. This is   most  easily achieved by starting a\n  stand-alone   Linda   server   somewhere   on    the   cluster.   See\n  tipc_linda_server/0, below.\n",
    "prefix":"tuple"
  },
  "tipc/tipc_linda:tuple/2": {
    "body": ["tuple(${1:Head}, ${2:Goal})$3\n$0" ],
    "description":"  tuple(:Goal) is det.\n  tuple(?Head, :Goal) is det.\n\n  registers Head as a virtual tuple  in   TIPC  Linda's tuple space. On\n  success, any client on the  cluster   may  reference the tuple, Head,\n  using rd/1 or rd_noblock/1.  On  reference,   Goal  is  executed by a\n  separate thread of execution in the host client's Prolog process. The\n  result is unified with Head, which  is   then  returned  to the guest\n  client. As in linda_eval/(1-2) above, Goal is evaluated using forall/2. The\n  virtual tuple is unregistered  on   backtracking  into a tuple/(1-2),\n  receipt of uncaught exception, or cut   of choice-points. In tuple/1,\n  Head and Goal are identical, except that  the module name is stripped\n  from Head.\n\n  *|Note:|* A virtual tuple is an extension  of the server. Even though\n  it is operating in the client's  Prolog environment, it is restricted\n  in the server operations that it may   perform.  It is generally safe\n  for tuple predicates to perform out/1   operations,  but it is unsafe\n  for them to perform any variant of   =in= or =rd=, either directly or\n  indirectly. This restriction is however, relaxed   if  the server and\n  client are operating in separate  heavyweight processes (not threads)\n  on the node or cluster. This is   most  easily achieved by starting a\n  stand-alone   Linda   server   somewhere   on    the   cluster.   See\n  tipc_linda_server/0, below.\n",
    "prefix":"tuple"
  },
  "tipc/tipc_paxos:tipc_initialize/0": {
    "body": ["tipc_initialize$1\n$0" ],
    "description":"  tipc_initialize is semidet.\n   See tipc:tipc_initialize/0.\n",
    "prefix":"tipc_initialize"
  },
  "tipc/tipc_paxos:tipc_paxos_get/1": {
    "body": ["tipc_paxos_get(${1:Term})$2\n$0" ],
    "description":" tipc_paxos_get(?Term) is semidet.\n unifies Term with the entry   retrieved  from the Paxon's\n ledger. If no such entry exists in   the member's local cache, then the\n quorum is asked to provide a value,  which is verified for consistency.\n An implied tipc_paxos_set/1 follows. This predicate succeeds if a term with\n the same functor and arity exists in the Paxon's ledger, and fails\n otherwise.\n\n @param Term is a compound.  Any   unbound  variables  are unified with\n those provided in the ledger entry.\n",
    "prefix":"tipc_paxos_get"
  },
  "tipc/tipc_paxos:tipc_paxos_on_change/2": {
    "body": ["tipc_paxos_on_change(${1:Term}, ${2:Goal})$3\n$0" ],
    "description":" tipc_paxos_on_change(?Term, :Goal) is det.\n executes the specified Goal when Term changes. tipc_paxos_on_change/2\n listens for paxos_changed/1 notifications for Term, which are emitted\n as the result of successful tipc_paxos_set/1 transactions. When one is\n received for Term, then Goal is executed in a separate thread of\n execution.\n\n  @param Term is a compound, identical to that used for\n  tipc_paxos_get/1.\n  @param Goal is one of:\n   * a callable atom or term, or\n   * the atom =ignore=, which causes monitoring for Term to be\n   discontinued.\n",
    "prefix":"tipc_paxos_on_change"
  },
  "tipc/tipc_paxos:tipc_paxos_replicate/1": {
    "body": ["tipc_paxos_replicate(${1:Term})$2\n$0" ],
    "description":" tipc_paxos_replicate(?Term) is det.\n declares that Term is to be automatically replicated to the quorum\n each time it becomes grounded. It uses the behavior afforded by\n when/2.\n\n @param Term is an ungrounded Term\n",
    "prefix":"tipc_paxos_replicate"
  },
  "tipc/tipc_paxos:tipc_paxos_set/1": {
    "body": ["tipc_paxos_set(${1:Term})$2\n$0" ],
    "description":"  tipc_paxos_set(?Term) is semidet.\n  tipc_paxos_set(?Term, +Retries) is semidet.\n     negotiates to have Term recorded in  the   ledger  for  each of the\n quorum's members. This predicate  succeeds   if  the quorum unanimously\n accepts the proposed term. If  no  such   entry  exists  in the Paxon's\n ledger, then one is silently created.   tipc_paxos_set/1 will retry the\n transaction several times (default: 20) before failing. Failure is rare\n and is usually the result of a collision of two or more writers writing\n to the same term at precisely the  same   time.  On  failure, it may be\n useful to wait  some  random  period  of   time,  and  then  retry  the\n transaction. By specifying a retry count of zero, tipc_paxos_set/2 will\n succeed iff the first ballot succeeds.\n\n On success, tipc_paxos_set/1 will also broadcast the term\n =|paxos_changed(Term)|=, to the quorum.\n\n @param Term is a compound  that   may  have  unbound variables.\n @param Retries (optional) is a non-negative integer  specifying the\n number of retries that will be performed before a set is abandoned.\n",
    "prefix":"tipc_paxos_set"
  },
  "tipc/tipc_paxos:tipc_paxos_set/2": {
    "body": ["tipc_paxos_set(${1:Term}, ${2:Retries})$3\n$0" ],
    "description":"  tipc_paxos_set(?Term) is semidet.\n  tipc_paxos_set(?Term, +Retries) is semidet.\n     negotiates to have Term recorded in  the   ledger  for  each of the\n quorum's members. This predicate  succeeds   if  the quorum unanimously\n accepts the proposed term. If  no  such   entry  exists  in the Paxon's\n ledger, then one is silently created.   tipc_paxos_set/1 will retry the\n transaction several times (default: 20) before failing. Failure is rare\n and is usually the result of a collision of two or more writers writing\n to the same term at precisely the  same   time.  On  failure, it may be\n useful to wait  some  random  period  of   time,  and  then  retry  the\n transaction. By specifying a retry count of zero, tipc_paxos_set/2 will\n succeed iff the first ballot succeeds.\n\n On success, tipc_paxos_set/1 will also broadcast the term\n =|paxos_changed(Term)|=, to the quorum.\n\n @param Term is a compound  that   may  have  unbound variables.\n @param Retries (optional) is a non-negative integer  specifying the\n number of retries that will be performed before a set is abandoned.\n",
    "prefix":"tipc_paxos_set"
  },
  "tipc:tipc_accept/3": {
    "body":"tipc_accept(${1:Socket}, ${2:Slave}, ${3:Peer})$4\n$0",
    "description":"[det]tipc_accept(+Socket, -Slave, -Peer).\nBlocks on a server socket and waits for connection requests from  clients. On success, it creates a new socket for the client and binds  the identifier to Slave. Peer is bound to the TIPC  address, port_id/2, of the client.",
    "prefix":"tipc_accept"
  },
  "tipc:tipc_bind/3": {
    "body":"tipc_bind(${1:Socket}, ${2:Address}, ${3:ScopingOption})$4\n$0",
    "description":"[det]tipc_bind(+Socket, +Address, +ScopingOption).\nAssociates/disassociates a socket with the name/3  or name_seq/3 address specified in Address.  It also registers/unregisters it in the topology server name table. This  makes the address visible/invisible to the rest of the network according  to the scope specified in ScopingOption. ScopingOption  is a grounded term that is one of:  scope(Scope): where Scope is one of: zone, cluster, or node. Servers may bind to more than one address by making  successive calls to tipc_bind/3,  one for each address that it wishes to advertise. The server will  receive traffic for all of them. A server may, for example, register one  address with node scope, another with cluster scope, and a third with  zone scope. A client may then limit the scope of its transmission by  specifying the appropriate address.\n\nno_scope(Scope): where Scope is as defined above. An application may target a specific  address for removal from its collection of addresses by specifying the  address and its scope. The scoping option, no_scope(all),  may be used to unbind the socket from all of its registered addresses.  This feature allows an application to gracefully exit from service.  Because the socket remains open, the application may continue to service  current transactions to completion. TIPC however, will not schedule any  new work for the server instance. If no other servers are available, the  work will be rejected or dropped according to the socket options  specified by the client.\n\n  Connection-oriented, byte-stream services are implemented with this  predicate combined with tipc_listen/2  and tipc_accept/3.  Connectionless, datagram services may be implemented using tipc_receive/4. \n\nNote that clients do not need to bind to any address. Its port-id is  sufficient for this role. And server sockets (e.g. those that are bound  to name/3 or name_seq/3,  addresses) may not act as clients. That is, they may not originate  connections from the socket using tipc_connect/2.  Servers however, may originate datagrams from bound sockets using tipc_send/4.  Please see the TIPC programmers's guide for other restrictions.\n\n",
    "prefix":"tipc_bind"
  },
  "tipc:tipc_canonical_address/2": {
    "body":"tipc_canonical_address(${1:CanonicalAddress}, ${2:PortId})$3\n$0",
    "description":"[det]tipc_canonical_address(-CanonicalAddress, +PortId).\nTranslates a port_id/2 address into  canonical TIPC form:  tipc_address(Zone, Cluster, Node, Reference): It is provided for debugging an printing purposes only. The canonical  address is not used for any other purpose.\n\n ",
    "prefix":"tipc_canonical_address"
  },
  "tipc:tipc_close_socket/1": {
    "body":"tipc_close_socket(${1:SocketId})$2\n$0",
    "description":"[det]tipc_close_socket(+SocketId).\nCloses the indicated socket, making SocketId invalid. In  stream applications, sockets are closed by closing both stream handles  returned by tipc_open_socket/3.  There are two cases where tipc_close_socket/1 is  used because there are no stream-handles:  \n\nAfter tipc_accept/3, the  server does a fork/1 to handle the client  in a sub-process. In this case the accepted socket is not longer needed  from the main server and must be discarded using tipc_close_socket/1.\nIf, after discovering the connecting client with tipc_accept/3, the server does  not want to accept the connection, it should discard the accepted socket  immediately using tipc_close_socket/1.\n\n SocketId the socket identifier  returned by tipc_socket/2 or tipc_accept/3.   Errors: socket_error('Invalid argument) is thrown if an attempt is made to close  a socket identifier that has already been closed.\n\n ",
    "prefix":"tipc_close_socket"
  },
  "tipc:tipc_connect/2": {
    "body":"tipc_connect(${1:Socket}, ${2:TIPC_address})$3\n$0",
    "description":"[det]tipc_connect(+Socket, +TIPC_address).\nProvides a connection-oriented, client-interface to connect a socket to  a given TIPC_address. After successful completion, tipc_open_socket/3 may be  used to create I/O-Streams to the remote socket.  throws: - socket_error('Connection refused'), if there are no  servers bound to the specified address.  - socket_error('Connection timed out'), if no server that  is bound to the specified address accepts the connect request within the  specified time limit. See also tipc_setopt/2.\n\n ",
    "prefix":"tipc_connect"
  },
  "tipc:tipc_get_name/2": {
    "body":"tipc_get_name(${1:Socket}, ${2:TIPC_address})$3\n$0",
    "description":"[det]tipc_get_name(+Socket, -TIPC_address).\nUnifies TIPC_address with the port-id assigned to the socket.",
    "prefix":"tipc_get_name"
  },
  "tipc:tipc_get_peer_name/2": {
    "body":"tipc_get_peer_name(${1:Socket}, ${2:TIPC_address})$3\n$0",
    "description":"[det]tipc_get_peer_name(+Socket, -TIPC_address).\nUnifies TIPC_address with the port-id assigned to the socket  that this socket is connected to.  throws: socket_error('Transport endpoint is not connected'), if an  attempt is made to obtain a peer's name of an unconnected socket.\n\n ",
    "prefix":"tipc_get_peer_name"
  },
  "tipc:tipc_listen/2": {
    "body":"tipc_listen(${1:Socket}, ${2:Backlog})$3\n$0",
    "description":"[det]tipc_listen(+Socket, +Backlog).\nListens for incoming requests for connections. Backlog  indicates how many pending connection requests are allowed. Pending  requests are requests that are not yet acknowledged using tipc_accept/3.  If the indicated number is exceeded, the requesting client will be  signalled that the service is currently not available. A suggested  default value is 5.",
    "prefix":"tipc_listen"
  },
  "tipc:tipc_open_socket/3": {
    "body":"tipc_open_socket(${1:SocketId}, ${2:InStream}, ${3:OutStream})$4\n$0",
    "description":"[det]tipc_open_socket(+SocketId, -InStream, -OutStream).\nOpens two SWI-Prolog I/O-streams, one to deal with input from the socket  and one with output to the socket. If tipc_bind/3  has been called on the socket, OutStream is useless and will  not be created. After closing both InStream and OutStream,  the socket itself is discarded.",
    "prefix":"tipc_open_socket"
  },
  "tipc:tipc_receive/4": {
    "body":"tipc_receive(${1:Socket}, ${2:Data}, ${3:From}, ${4:OptionList})$5\n$0",
    "description":"[det]tipc_receive(+Socket, -Data, -From, +OptionList).\nWaits for, and returns the next datagram. Like its UDP counterpart, the  data are returned as a Prolog string object (see string_codes/2). From  is an address structure of the form port_id/2,  indicating the sender of the message.  Defined options are: \n\nas(+Type): Defines the returned term-type. Type is one of atom, codes or  string (default).\n\nnonblock: Poll the socket and return immediately. If a message is present, it is  returned. If not, then an exception, error(socket_error('Resource temporarily unavailable'), _),  will be thrown. Users are cautioned not to \"spin\" unnecessarily on  non-blocking receives as they may prevent the system from servicing  other background activities such as XPCE event dispatching.\n\n  The typical sequence to receive a connectionless TIPC datagram is: \n\n\n\nreceive :-\n        tipc_socket(S, dgram),\n        tipc_bind(S, name(18888, 10, 0), scope(zone)),\n        repeat,\n            tipc_receive(Socket, Data, From, [as(atom)]),\n            format('Got ~q from ~q~n', [Data, From]),\n            Data == quit,\n        !, tipc_close_socket(S).\n\n ",
    "prefix":"tipc_receive"
  },
  "tipc:tipc_send/4": {
    "body":"tipc_send(${1:Socket}, ${2:Data}, ${3:To}, ${4:Options})$5\n$0",
    "description":"[det]tipc_send(+Socket, +Data, +To, +Options).\nsends a TIPC datagram to one or more destinations. Like its UDP  counterpart, Data is a string, atom or code-list providing  the data to be sent. To is a name/3, name_seq/3,  or port_id/2 address structure. See tipc_overview.txt,  for more information on TIPC Address Structures. Options is  currently unused.  A simple example to send a connectionless TIPC datagram is: \n\n\n\nsend(Message) :-\n        tipc_socket(S, dgram),\n        tipc_send(S, Message, name(18888, 10,0), []),\n        tipc_close_socket(S).\n\n  Messages are delivered silently unless some form of congestion was  encountered and the dest_droppable(false) option was issued  on the sender's socket. In this case, the send succeeds but a  notification in the form of an empty message is returned to the sender  from the receiver, indicating some kind of delivery failure. The port-id  of the receiver is returned in congestion conditions. A port_id(0,0),  is returned if the destination address was invalid. Senders and  receivers should beware of this possibility.\n\n",
    "prefix":"tipc_send"
  },
  "tipc:tipc_service_exists/1": {
    "body":"tipc_service_exists(${1:Address})$2\n$0",
    "description":"[semidet]tipc_service_exists(+Address).\nInterrogates the TIPC topology server to see if a service is available  at an advertised Address. Address is one of: name(Type, Instance, Domain)  or name_seq(Type, Lower, Upper). A name/3,  address is translated to a name_seq/3,  following, where Lower and Upper are assigned the value of Instance.  Domain is unused and must be zero. A name_seq(Type, Lower, Upper)  is a multi-cast address. This predicate succeeds if there is at least  one service that would answer according to multi-cast addressing rules. Timeout is optional. It is a  non-negative real number that specifies the amount of time in seconds to  block and wait for a service to become available. Fractions of a second  are also permissible. ",
    "prefix":"tipc_service_exists"
  },
  "tipc:tipc_service_exists/2": {
    "body":"tipc_service_exists(${1:Address}, ${2:Timeout})$3\n$0",
    "description":"[semidet]tipc_service_exists(+Address, +Timeout).\n",
    "prefix":"tipc_service_exists"
  },
  "tipc:tipc_service_port_monitor/2": {
    "body":"tipc_service_port_monitor(${1:Addresses}, ${2:Goal})$3\n$0",
    "description":"[det]tipc_service_port_monitor(+Addresses, :Goal).\n",
    "prefix":"tipc_service_port_monitor"
  },
  "tipc:tipc_service_port_monitor/3": {
    "body":"tipc_service_port_monitor(${1:Addresses}, ${2:Goal}, ${3:Timeout})$4\n$0",
    "description":"[det]tipc_service_port_monitor(+Addresses, :Goal, ?Timeout).\nMonitors a collection of worker threads that are bound to a list of Addresses.  A single port monitor may be used to provide surveillance over workers  that are providing a number of different services. For a given address  type, discontiguous port ranges may be specified, but overlapping port  ranges may not. Goal for example, may simply choose to  broadcast the notification, thus delegating the notification event  handling to others. Addresses is a list of name/3  or name_seq/3 addresses for the services  to be monitored. Goal is a predicate that will  be called when a worker's publication status changes. The Goal  is called exactly once per event with its the last argument unified with  the structure:  published(-NameSeq, -PortId): when the worker binds its socket to the address.\n\nwithdrawn(-NameSeq, -PortId): when the worker unbinds its socket from the address.\n\n  \n\nTimeout is optional. It is one  of:  Timeout: a non-negative real number that specifies the number of seconds that  surveillance is to be continued.\n\ninfinite: causes the monitor to run forever in the current thread (e.g. never  returns).\n\ndetached(-ThreadId): causes the monitor to run forever as a separate thread. ThreadId is  unified with the thread identifier of the monitor thread. This is useful  when the monitor is required to provide continuous surveillance, while  operating in the background.\n\n  \n\n",
    "prefix":"tipc_service_port_monitor"
  },
  "tipc:tipc_service_probe/1": {
    "body":"tipc_service_probe(${1:Address})$2\n$0",
    "description":"[nondet]tipc_service_probe(?Address).\n",
    "prefix":"tipc_service_probe"
  },
  "tipc:tipc_service_probe/2": {
    "body":"tipc_service_probe(${1:Address}, ${2:PortId})$3\n$0",
    "description":"[nondet]tipc_service_probe(?Address, ?PortId).\nAllows a user to discover the instance ranges and/or port-ids for a  particular service. Address is a name_seq/3  address. The address type must be grounded. PortId is unified with the  port-id for a specific name_sequence address. ",
    "prefix":"tipc_service_probe"
  },
  "tipc:tipc_setopt/2": {
    "body":"tipc_setopt(${1:Socket}, ${2:Option})$3\n$0",
    "description":"[det]tipc_setopt(+Socket, +Option).\nSets options on the socket. Defined options are:  importance(+Priority): Allow sockets to assign a priority to their traffic. Priority is one of  : low (default), medium, high, or critical.\n\nsrc_droppable(+Boolean): Allow TIPC to silently discard packets in congested situations, rather  than queuing them for later transmission.\n\ndest_droppable(+Boolean): Allow TIPC to silently discard packets in congested situations, rather  than returning them to the sender as undeliverable.\n\nconn_timeout(+Seconds): Specifies the time interval that tipc_connect/2  will use before abandoning a connection attempt. Default: 8.000 sec.\n\n ",
    "prefix":"tipc_setopt"
  },
  "tipc:tipc_socket/2": {
    "body":"tipc_socket(${1:SocketId}, ${2:SocketType})$3\n$0",
    "description":"[det]tipc_socket(-SocketId, +SocketType).\nCreates a TIPC-domain socket of the type specified by SocketType, and unifies it to an identifier, SocketId. SocketType is one of the  following atoms:  \n\nrdm - unnumbered, reliable datagram service,\ndgram - unnumbered, unreliable datagram service,\nseqpacket - numbered, reliable datagram service, and\nstream - reliable, connection-oriented byte-stream service\n\n  \n\n  Errors: socket_error('Address family not supported by protocol') is  thrown if a TIPC server is not available on the current host.\n\n ",
    "prefix":"tipc_socket"
  },
  "tipc_broadcast:tipc_host_to_address/2": {
    "body":"tipc_host_to_address(${1:Service}, ${2:Address})$3\n$0",
    "description":"[nondet]tipc_host_to_address(?Service, ?Address).\nlocates a TIPC service by name. Service is an atom or  grounded term representing the common name of the service. Address  is a TIPC address structure. A server may advertise its services by name  by including the fact, tipc:host_to_address(+Service, +Address),  somewhere in its source. This predicate can also be used to perform  reverse searches. That is it will also resolve an Address to  a Service name. The search is zone-wide. Locating a service  however, does not imply that the service is actually reachable from any  particular node within the zone.",
    "prefix":"tipc_host_to_address"
  },
  "tipc_linda:bagof_in_noblock/3": {
    "body":"bagof_in_noblock(${1:Template}, ${2:Tuple}, ${3:Bag})$4\n$0",
    "description":"[nondet]bagof_in_noblock(?Template, ?Tuple, -Bag).\n",
    "prefix":"bagof_in_noblock"
  },
  "tipc_linda:bagof_rd_noblock/3": {
    "body":"bagof_rd_noblock(${1:Template}, ${2:Tuple}, ${3:Bag})$4\n$0",
    "description":"[nondet]bagof_rd_noblock(?Template, ?Tuple, -Bag).\nBag is the list of all instances of Template such  that Tuple exists in the tuple-space. The behavior of  variables in Tuple and Template is as in bagof/3.  The variables could be existentially quantified with ^/2  as in bagof/3. The operation is performed  as an atomic operation. This predicate can fail due to a timeout.  Example: Assume that only one client is connected to the server and that  the tuple-space initially is empty.  \n\n  ?- out(x(a,3)), out(x(a,4)), out(x(b,3)), out(x(c,3)).\n\n  true.\n  ?- bagof_rd_noblock(C-N, x(C,N), L).\n\n  L = [a-3,a-4,b-3,c-3] .\n\n  true.\n  ?- bagof_rd_noblock(C, N^x(C,N), L).\n\n  L = [a,a,b,c] .\n\n  true.\n\n ",
    "prefix":"bagof_rd_noblock"
  },
  "tipc_linda:in/1": {
    "body":"in(${1:Tuple})$2\n$0",
    "description":"[det]in(?Tuple).\nAtomically removes the tuple Tuple from Linda's tuple-space  if it is there. The tuple will be returned to exactly one requestor. If  no tuple is available, the predicate blocks until it is available (that  is, someone performs an out/1).",
    "prefix":"in"
  },
  "tipc_linda:in/2": {
    "body":"in(${1:TupleList}, ${2:Tuple})$3\n$0",
    "description":"[det]in(+TupleList, -Tuple).\nAs in/1 but succeeds when any one of  the tuples in TupleList is available. Tuple is  unified with the fetched tuple.",
    "prefix":"in"
  },
  "tipc_linda:in_noblock/1": {
    "body":"in_noblock(${1:Tuple})$2\n$0",
    "description":"[semidet]in_noblock(?Tuple).\nAtomically removes the tuple Tuple from Linda's tuple-space  if it is there. If not, the predicate fails. This predicate can fail due  to a timeout.",
    "prefix":"in_noblock"
  },
  "tipc_linda:linda/1": {
    "body":"linda(${1:Goal})$2\n$0",
    "description":"[det]linda(:Goal).\nStarts a Linda-server in this process. The network address is written to  current output stream as a TIPC port_id/2 reference (e.g. port_id('<1.1.1:3200515722>')  ). This predicates looks to see if a server is already listening on the  cluster. If so, it reports the address of the existing server.  Otherwise, it registers a new server and reports its address.  \n\n?- linda.\n   TIPC Linda server now listening at: port_id('<1.1.1:3200515722>')\n   true.\n\n?- linda.\n   TIPC Linda server still listening at: port_id('<1.1.1:3200515722>')\n   true.\n\n  The following will call my_init/0 in  the current module after the server is successfully started or is found  already listening. my_init/0 could start client-processes,  initialize the tuple space, etc. \n\n\n\n?- linda(my_init).\n\n ",
    "prefix":"linda"
  },
  "tipc_linda:linda_client/1": {
    "body":"linda_client(${1:Domain})$2\n$0",
    "description":"[semidet]linda_client(+Domain).\nEstablishes a connection to a Linda-server providing a named tuple  space. Domain is an atom specifying a particular tuple-space,  selected from a universe of tuple-spaces. At present however, only one  tuple-space, global, is supported. A client may interact  with any server reachable on the TIPC cluster. This predicate will fail  if no server is reachable for that tuple space.",
    "prefix":"linda_client"
  },
  "tipc_linda:linda_eval/1": {
    "body":"linda_eval(${1:Goal})$2\n$0",
    "description":"[det]linda_eval(:Goal).\n",
    "prefix":"linda_eval"
  },
  "tipc_linda:linda_eval/2": {
    "body":"linda_eval(${1:Head}, ${2:Goal})$3\n$0",
    "description":"[det]linda_eval(?Head, :Goal).\n",
    "prefix":"linda_eval"
  },
  "tipc_linda:linda_eval_detached/1": {
    "body":"linda_eval_detached(${1:Goal})$2\n$0",
    "description":"[det]linda_eval_detached(:Goal).\n",
    "prefix":"linda_eval_detached"
  },
  "tipc_linda:linda_eval_detached/2": {
    "body":"linda_eval_detached(${1:Head}, ${2:Goal})$3\n$0",
    "description":"[det]linda_eval_detached(?Head, :Goal).\nCauses Goal to be evaluated in parallel with a parent  predicate. The child thread is a full-fledged client, possessing the  same capabilities as the parent. Upon successful completion of Goal,  unbound variables are unified and the result is sent to the Linda server  via out/1, where it is made available  to others. linda_eval/2  evaluates Goal, then unifies the result with Head,  providing a means of customizing the resulting output structure. In linda_eval/1, Head,  and Goal are identical, except that the module name for Head  is stripped before output. If the child fails or receives an uncaught  exception, no such output occurs.  Joining Threads: Threads created using linda_eval/(1-2) are  not allowed to linger. They are joined (blocking the parent, if  necessary) under three conditions: backtracking on failure into an  linda_eval/(1-2), receipt of an uncaught exception, and cut of  choice-points. Goals are evaluated using forall/2.  They are expected to provide nondeterministic behavior. That is they may  succeed zero or more times on backtracking. They must however,  eventually fail or succeed deterministically. Otherwise, the thread will  hang, which will eventually hang the parent thread. Cutting choice  points in the parent's body has the effect of joining all children  created by the parent. This provides a barrier that guarantees that all  child instances of Goal have run to completion before the  parent proceeds. Detached threads behave as above, except that they  operate independently and cannot be joined. They will continue to run  while the host process continues to run. \n\nHere is an example of a parallel quicksort: \n\n\n\nqksort([], []).\n\nqksort([X | List], Sorted) :-\n      partition(@>(X), List, Less, More),\n      linda_eval(qksort(More, SortedMore)),\n      qksort(Less, SortedLess), !,\n      in_noblock(qksort(More, SortedMore)),\n      append(SortedLess, [X | SortedMore], Sorted).\n\n ",
    "prefix":"linda_eval_detached"
  },
  "tipc_linda:linda_timeout/1": {
    "body":"linda_timeout(${1:NewTime})$2\n$0",
    "description":"[semidet]linda_timeout(+NewTime).\nTemporarily sets Linda's timeout. Internally, the original timeout is  saved and then the timeout is set to NewTime. NewTime  is as described in linda_timeout/2.  The original timeout is restored automatically on cut of choice points,  failure on backtracking, or uncaught exception.",
    "prefix":"linda_timeout"
  },
  "tipc_linda:linda_timeout/2": {
    "body":"linda_timeout(${1:OldTime}, ${2:NewTime})$3\n$0",
    "description":"[semidet]linda_timeout(?OldTime, ?NewTime).\nControls Linda's message-passing timeout. It specifies the time window  where clients will accept server replies in response to in  and rd requests. Replies arriving outside of this window  are silently ignored. OldTime is unified with the old timeout  and then timeout is set to NewTime. NewTime is of  the form Seconds:Milliseconds. A non-negative real number, seconds, is  also recognized. The default is 0.250 seconds. This timeout is thread  local and is not inherited from its parent. New threads are  initialized to the default.  Note: The synchronous behavior afforded by in/1  and rd/1 is implemented by periodically  polling the server. The poll rate is set according to this timeout.  Setting the timeout too small may result in substantial network traffic  that is of little value. \n\nthrows: error(feature_not_supported). SICStus Linda can disable the  timeout by specifying off as NewTime. This  feature does not exist for safety reasons.\n\n ",
    "prefix":"linda_timeout"
  },
  "tipc_linda:out/1": {
    "body":"out(${1:Tuple})$2\n$0",
    "description":"[det]out(+Tuple).\nPlaces a Tuple in Linda's tuple-space.",
    "prefix":"out"
  },
  "tipc_linda:rd/1": {
    "body":"rd(${1:Tuple})$2\n$0",
    "description":"[nondet]rd(?Tuple).\nSucceeds nondeterministically if Tuple is available in the  tuple-space, suspends otherwise until it is available. Compare this with in/1:  the tuple is not removed.",
    "prefix":"rd"
  },
  "tipc_linda:rd/2": {
    "body":"rd(${1:TupleList}, ${2:Tuple})$3\n$0",
    "description":"[nondet]rd(?TupleList, -Tuple).\nAs in/2 but provides a choice point  that does not remove any tuples.",
    "prefix":"rd"
  },
  "tipc_linda:rd_noblock/1": {
    "body":"rd_noblock(${1:Tuple})$2\n$0",
    "description":"[nondet]rd_noblock(?Tuple).\nSucceeds nondeterministically if Tuple is available in the  tuple-space, fails otherwise. This predicate can fail due to a timeout.",
    "prefix":"rd_noblock"
  },
  "tipc_linda:tuple/1": {
    "body":"tuple(${1:Goal})$2\n$0",
    "description":"[det]tuple(:Goal).\n",
    "prefix":"tuple"
  },
  "tipc_linda:tuple/2": {
    "body":"tuple(${1:Head}, ${2:Goal})$3\n$0",
    "description":"[det]tuple(?Head, :Goal).\nregisters Head as a virtual tuple in TIPC Linda's tuple  space. On success, any client on the cluster may reference the tuple, Head,  using rd/1 or rd_noblock/1.  On reference, Goal is executed by a separate thread of  execution in the host client's Prolog process. The result is unified  with Head, which is then returned to the guest client. As in  linda_eval/(1-2) above, Goal is evaluated using forall/2.  The virtual tuple is unregistered on backtracking into a tuple/(1-2),  receipt of uncaught exception, or cut of choice-points. In tuple/1, Head and Goal are identical, except that the  module name is stripped from Head.  Note: A virtual tuple is an extension of the server. Even  though it is operating in the client's Prolog environment, it is  restricted in the server operations that it may perform. It is generally  safe for tuple predicates to perform out/1  operations, but it is unsafe for them to perform any variant of in  or rd, either directly or indirectly. This restriction is  however, relaxed if the server and client are operating in separate  heavyweight processes (not threads) on the node or cluster. This is most  easily achieved by starting a stand-alone Linda server somewhere on the  cluster. See tipc_linda_server/0,  below.\n\n",
    "prefix":"tuple"
  },
  "tipc_paxos:tipc_paxos_get/1": {
    "body":"tipc_paxos_get(${1:Term})$2\n$0",
    "description":"[semidet]tipc_paxos_get(?Term).\nunifies Term with the entry retrieved from the Paxon's  ledger. If no such entry exists in the member's local cache, then the  quorum is asked to provide a value, which is verified for consistency.  An implied tipc_paxos_set/1  follows. This predicate succeeds if a term with the same functor and  arity exists in the Paxon's ledger, and fails otherwise. Term is a compound. Any unbound  variables are unified with those provided in the ledger entry. ",
    "prefix":"tipc_paxos_get"
  },
  "tipc_paxos:tipc_paxos_on_change/2": {
    "body":"tipc_paxos_on_change(${1:Term}, ${2:Goal})$3\n$0",
    "description":"[det]tipc_paxos_on_change(?Term, :Goal).\nexecutes the specified Goal when Term changes. tipc_paxos_on_change/2  listens for paxos_changed/1 notifications  for Term, which are emitted as the result of successful tipc_paxos_set/1  transactions. When one is received for Term, then Goal  is executed in a separate thread of execution. Term is a compound, identical  to that used for tipc_paxos_get/1. Goal is one of:  \n\na callable atom or term, or\nthe atom ignore, which causes monitoring for Term  to be discontinued.\n\n  \n\n",
    "prefix":"tipc_paxos_on_change"
  },
  "tipc_paxos:tipc_paxos_replicate/1": {
    "body":"tipc_paxos_replicate(${1:Term})$2\n$0",
    "description":"[det]tipc_paxos_replicate(?Term).\ndeclares that Term is to be automatically replicated to the  quorum each time it becomes grounded. It uses the behavior afforded by when/2. Term is an ungrounded Term ",
    "prefix":"tipc_paxos_replicate"
  },
  "tipc_paxos:tipc_paxos_set/1": {
    "body":"tipc_paxos_set(${1:Term})$2\n$0",
    "description":"[semidet]tipc_paxos_set(?Term).\n",
    "prefix":"tipc_paxos_set"
  },
  "tipc_paxos:tipc_paxos_set/2": {
    "body":"tipc_paxos_set(${1:Term}, ${2:Retries})$3\n$0",
    "description":"[semidet]tipc_paxos_set(?Term, +Retries).\nnegotiates to have Term recorded in the ledger for each of  the quorum's members. This predicate succeeds if the quorum unanimously  accepts the proposed term. If no such entry exists in the Paxon's  ledger, then one is silently created. tipc_paxos_set/1  will retry the transaction several times (default: 20) before failing.  Failure is rare and is usually the result of a collision of two or more  writers writing to the same term at precisely the same time. On failure,  it may be useful to wait some random period of time, and then retry the  transaction. By specifying a retry count of zero, tipc_paxos_set/2  will succeed iff the first ballot succeeds.  On success, tipc_paxos_set/1  will also broadcast the term paxos_changed(Term), to the quorum.\n\nTerm is a compound that may  have unbound variables. Retries (optional) is a  non-negative integer specifying the number of retries that will be  performed before a set is abandoned. ",
    "prefix":"tipc_paxos_set"
  },
  "tmp_file/2": {
    "body":"tmp_file(${1:Base}, ${2:TmpName})$3\n$0",
    "description":"[deprecated]tmp_file(+Base, -TmpName).\nCreate a name for a temporary file. Base is an identifier for  the category of file. The TmpName is guaranteed to be unique.  If the system halts, it will automatically remove all created temporary  files. Base is used as part of the final filename. Portable  applications should limit themselves to alphanumeric characters.  Because it is possible to guess the generated filename, attackers may  create the filesystem entry as a link and possibly create a security  issue. New code should use tmp_file_stream/3.\n\n",
    "prefix":"tmp_file"
  },
  "tmp_file_stream/3": {
    "body":"tmp_file_stream(${1:Encoding}, ${2:FileName}, ${3:Stream})$4\n$0",
    "description":"tmp_file_stream(+Encoding, -FileName, -Stream).\nCreate a temporary filename FileName and open it for writing  in the given Encoding. Encoding is a text-encoding  name or binary. Stream is the output stream. If the OS  supports it, the created file is only accessible to the current user. If  the OS supports it, the file is created using the open()-flag O_EXCL,  which guarantees that the file did not exist before this call. This  predicate is a safe replacement of tmp_file/2.  Note that in those cases where the temporary file is needed to store  output from an external command, the file must be closed first. E.g.,  the following downloads a file from a URL to a temporary file and opens  the file for reading (on Unix systems you can delete the file for  cleanup after opening it for reading):  \n\nopen_url(URL, In) :-\n        tmp_file_stream(text, File, Stream),\n        close(Stream),\n        process_create(curl, ['-o', File, URL], []),\n        open(File, read, In),\n        delete_file(File).              % Unix-only\n\n  Temporary files created using this call are removed if the Prolog  process terminates gracefully. Calling delete_file/1  using FileName removes the file and removes the entry from the  administration of files-to-be-deleted.\n\n",
    "prefix":"tmp_file_stream"
  },
  "tokenize_atom/2": {
    "body":"tokenize_atom(${1:In}, ${2:TokenList})$3\n$0",
    "description":"tokenize_atom(+In, -TokenList).\nBreak the text In into words, numbers and punctuation  characters. Tokens are created to the following rules:  \n\n[-+][0-9]+(\\.[0-9]+)?([eE][-+][0-9]+)? number [:alpha:][:alnum:]+ word [:space:]+ skipped anything elsesingle-character  Character classification is based on the C-library iswalnum() etc. functions.  Recognised numbers are passed to Prolog read/1,  supporting unbounded integers. \n\nIt is likely that future versions of this library will provide tokenize_atom/3  with additional options to modify space handling as well as the  definition of words.\n\n",
    "prefix":"tokenize_atom"
  },
  "told/0": {
    "body":"told$1\n$0",
    "description":"told.\nClose the current output stream. The new output stream becomes user_output.",
    "prefix":"told"
  },
  "trace/0": {
    "body":"trace$1\n$0",
    "description":"trace.\nStart the tracer. trace/0  itself cannot be seen in the tracer. Note that the Prolog top level  treats trace/0  special; it means `trace the next goal'.",
    "prefix":"trace"
  },
  "trace/1": {
    "body":"trace(${1:Pred})$2\n$0",
    "description":"trace(+Pred).\nEquivalent to trace(Pred, +all).",
    "prefix":"trace"
  },
  "trace/2": {
    "body":"trace(${1:Pred}, ${2:Ports})$3\n$0",
    "description":"trace(+Pred, +Ports).\nPut a trace point on all predicates satisfying the predicate  specification Pred. Ports is a list of port names (call, redo, exit, fail). The atom all  refers to all ports. If the port is preceded by a -  sign, the trace point is cleared for the port. If it is preceded by a +,  the trace point is set.  The predicate trace/2  activates debug mode (see debug/0).  Each time a port (of the 4-port model) is passed that has a trace point  set, the goal is printed as with trace/0.  Unlike trace/0,  however, the execution is continued without asking for further  information. Examples: \n\n\n\n?- trace(hello). Trace all  ports of hello with any arity in any module. ?- trace(foo/2, +fail). Trace  failures of foo/2 in any module. ?- trace(bar/1, -all). Stop  tracing bar/1.  The predicate debugging/0  shows all currently defined trace points.\n\n",
    "prefix":"trace"
  },
  "tracing/0": {
    "body":"tracing$1\n$0",
    "description":"tracing.\nTrue if the tracer is currently switched on. tracing/0  itself cannot be seen in the tracer.",
    "prefix":"tracing"
  },
  "trie_destroy/1": {
    "body":"trie_destroy(${1:Trie})$2\n$0",
    "description":"trie_destroy(+Trie).\nDestroy Trie. This removes all nodes from the trie and causes  further access to Trie to raise an existence_error exception.  The handle itself is reclaimed by atom garbage collection.",
    "prefix":"trie_destroy"
  },
  "trie_gen/3": {
    "body":"trie_gen(${1:Trie}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"[nondet]trie_gen(+Trie, ?Key, -Value).\nTrue when Key is associated with Value in Trie.  Backtracking retrieves all pairs. Currently scans the entire trie, even  if Key is partly known. Currently unsafe if Trie  is modified while the values are being enumerated.",
    "prefix":"trie_gen"
  },
  "trie_insert/3": {
    "body":"trie_insert(${1:Trie}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"trie_insert(+Trie, +Key, +Value).\nInsert the term Key into Trie and associate it  with Value. Currently, Value is either an atom or small  integer. Future versions will probably allow for arbitrary terms.",
    "prefix":"trie_insert"
  },
  "trie_insert_new/3": {
    "body":"trie_insert_new(${1:Trie}, ${2:Term}, ${3:Handle})$4\n$0",
    "description":"trie_insert_new(+Trie, +Term, -Handle).\nAdd Term to Trie and return a handle to the node.  Fails if Term is already part of the Trie. The handle can  used with trie_term/2  to retrieve (a copy of) Term. This predicate is currently  unsafe as Handle is an integer used to encode a pointer. It  was used to implement a pure Prolog version of the library(tabling)  library.",
    "prefix":"trie_insert_new"
  },
  "trie_lookup/3": {
    "body":"trie_lookup(${1:Trie}, ${2:Key}, ${3:Value})$4\n$0",
    "description":"trie_lookup(+Trie, +Key, -Value).\nTrue if the term Key is in Trie and associated  with Value.",
    "prefix":"trie_lookup"
  },
  "trie_new/1": {
    "body":"trie_new(${1:Trie})$2\n$0",
    "description":"trie_new(-Trie).\nCreate a new trie and unify Trie with a handle to the trie.  The trie handle is a blob. Tries are subject to atom garbage  collection.",
    "prefix":"trie_new"
  },
  "trie_property/2": {
    "body":"trie_property(${1:Trie}, ${2:Property})$3\n$0",
    "description":"[nondet]trie_property(?Trie, ?Property).\nTrue if Trie exists with Property. Intended for  debugging and statistical purposes. Retrieving some of these properties  visit all nodes of the trie. Defined properties are  value_count(-Count): Number of key-value pairs in the trie.\n\nnode_count(-Count): Number of nodes in the trie.\n\nsize(-Bytes): Required storage space of the trie.\n\nhashed(-Count): Number of nodes that use a hashed index to its children.\n\n ",
    "prefix":"trie_property"
  },
  "trie_term/2": {
    "body":"trie_term(${1:Handle}, ${2:Term})$3\n$0",
    "description":"trie_term(+Handle, -Term).\nTrue when Term is a copy of the term associated with Handle.  The result is undefined (including crashes) if Handle is not  a handle returned by trie_insert_new/3  or the node has been removed afterwards.",
    "prefix":"trie_term"
  },
  "trim_stacks/0": {
    "body":"trim_stacks$1\n$0",
    "description":"trim_stacks.\nRelease stack memory resources that are not in use at this moment,  returning them to the operating system. It can be used to release memory  resources in a backtracking loop, where the iterations require typically  seconds of execution time and very different, potentially large, amounts  of stack space. Such a loop can be written as follows:  \n\nloop :-\n        generator,\n            trim_stacks,\n            potentially_expensive_operation,\n        stop_condition, !.\n\n  The Prolog top-level loop is written this way, reclaiming memory  resources after every user query.\n\n",
    "prefix":"trim_stacks"
  },
  "truncate/1": {
    "body":"truncate(${1:Expr})$2\n$0",
    "description":"[ISO]truncate(+Expr).\nTruncate Expr to an integer. If Expr >= 0  this is the same as floor(Expr). For Expr <  0 this is the same as ceil(Expr). That is, truncate/1  rounds towards zero.",
    "prefix":"truncate"
  },
  "tty:menu/3": {
    "body": ["menu(${1:Title}, ${2:Options}, ${3:Choice})$4\n$0" ],
    "description":"  menu(+Title, +Options, -Choice) is semidet.\n\n   Show a menu. The display is cleared,   the  title is centered at\n   the top, the options are displayed  and finally the user actions\n   are parsed and the user's choice   is returned. The screen looks\n   like this:\n\n   ==\n           --------------------------------------------\n           |                                          |\n           |                  Title                   |\n           |                                          |\n           |   1) Option One                          |\n           |   2) Option Two                          |\n           |   3) Quit                                |\n           |                                          |\n           |   Your Choice? *                         |\n           |                                          |\n   ==\n\n   The user selects an item by pressing the number of the item, or\n   the first letter of the option. If more then one option match,\n   the common prefix of the matching options is given and the user\n   is expected to type the next character.  On illegal input the\n   screen is flashed (or a beep is given if the terminal can't flash\n   the screen).\n\n   Text fields (the title and option texts) are either plain atoms\n   or terms Fmt/Args.  In the latter case the argument is transformed\n   into an atom using format/3.\n\n   The specification of an option is a term PrologName:UserName.\n   PrologName is an atom, which is returned as choice if the user\n   selects this menu item.  UserName is processed as a text field\n   (see above) and displayed.  The entries are numbered automatically.\n\n   The example above could be defined as:\n\n   ==\n   get_action(Choice) :-\n           menu('Title',\n                   [ option_1 : 'Option One'\n                   , option_2 : 'Option Two'\n                   , quit     : 'Quit'\n                   ], Choice).\n   ==",
    "prefix":"menu"
  },
  "tty:tty_clear/0": {
    "body": ["tty_clear$1\n$0" ],
    "description":"  tty_clear\n\n   Clear the display.",
    "prefix":"tty_clear"
  },
  "tty:tty_flash/0": {
    "body": ["tty_flash$1\n$0" ],
    "description":"  tty_flash\n\n   Give visual signal if possible, otherwise beep.",
    "prefix":"tty_flash"
  },
  "tty_get_capability/3": {
    "body":"tty_get_capability(${1:Name}, ${2:Type}, ${3:Result})$4\n$0",
    "description":"tty_get_capability(+Name, +Type, -Result).\nGet the capability named Name from the termcap library. See  termcap(5) for the capability names. Type specifies the type  of the expected result, and is one of string, number  or bool. String results are returned as an atom, number  results as an integer, and bool results as the atom on or off.  If an option cannot be found, this predicate fails silently. The results  are only computed once. Successive queries on the same capability are  fast.",
    "prefix":"tty_get_capability"
  },
  "tty_goto/2": {
    "body":"tty_goto(${1:X}, ${2:Y})$3\n$0",
    "description":"tty_goto(+X, +Y).\nGoto position (X, Y) on the screen. Note that the  predicates line_count/2  and line_position/2  will not have a well-defined behaviour while using this predicate.",
    "prefix":"tty_goto"
  },
  "tty_put/2": {
    "body":"tty_put(${1:Atom}, ${2:Lines})$3\n$0",
    "description":"tty_put(+Atom, +Lines).\nPut an atom via the termcap library function tputs(). This function  decodes padding information in the strings returned by tty_get_capability/3  and should be used to output these strings. Lines is the  number of lines affected by the operation, or 1 if not applicable (as in  almost all cases).",
    "prefix":"tty_put"
  },
  "tty_size/2": {
    "body":"tty_size(${1:Rows}, ${2:Columns})$3\n$0",
    "description":"tty_size(-Rows, -Columns).\nDetermine the size of the terminal. Platforms:  Unix: If the system provides ioctl calls for this, these are used and tty_size/2  properly reflects the actual size after a user resize of the window. The ioctl  is issued on teh file descriptor associated with the user_input  stream. As a fallback, the system uses tty_get_capability/3  using li and co capabilities. In this case the  reported size reflects the size at the first call and is not updated  after a user-initiated resize of the terminal.\n\nWindows: Getting the size of the terminal is provided for swipl-win.exe.  The requested value reflects the current size. For the multithreaded  version the console that is associated with the user_input stream is used.\n\n ",
    "prefix":"tty_size"
  },
  "ttyflush/0": {
    "body":"ttyflush$1\n$0",
    "description":"ttyflush.\nFlush pending output on stream user. See also flush_output/[0,1].",
    "prefix":"ttyflush"
  },
  "udp_broadcast:rlimit/3": {
    "body":"rlimit(${1:Resource}, ${2:Old}, ${3:New})$4\n$0",
    "description":"rlimit(+Resource, -Old, +New).\nQuery and/or set the limit for Resource. Time-values are in  seconds and size-values are counted in bytes. The following values are  supported by this library. Please note that not all resources may be  available and accessible on all platforms. This predicate can throw a  variety of exceptions. In portable code this should be guarded with catch/3.  The defined resources are: as Max address space cpu CPU time in seconds fsize Maximum filesize data max data size stack max stack size core max core file size rss max resident set size nproc max number of processes nofile max number of open  files memlock max locked-in-memory  address   When the process hits a limit POSIX systems normally send the process  a signal that terminates it. These signals may be catched using  SWI-Prolog's on_signal/3  primitive. The code below illustrates this behaviour. Please note that  asynchronous signal handling is dangerous, especially when using  threads. 100% fail-safe operation cannot be guaranteed, but this  procedure will inform the user properly `most of the time'. \n\n\n\nrlimit_demo :-\n        rlimit(cpu, _, 2),\n        on_signal(xcpu, _, cpu_exceeded),\n        ( repeat, fail ).\n\ncpu_exceeded(_Sig) :-\n        format(user_error, 'CPU time exceeded~n', []),\n        halt(1).\n\n  \n\n",
    "prefix":"rlimit"
  },
  "udp_broadcast:udp_broadcast_initialize/2": {
    "body":"udp_broadcast_initialize(${1:IPAddress}, ${2:SubnetMask})$3\n$0",
    "description":"[semidet]udp_broadcast_initialize(+IPAddress, +SubnetMask).\ncauses any required runtime initialization to occur. At present, proper  operation of UDP broadcast depends on local information that is not  easily obtained mechanically. In order to determine the appropriate UDP  broadcast address, you must supply the IPAddress and SubnetMask for the node that is  running this module. These data are supplied in the form of ip/4  terms. This is now required to be included in an applications  intialization directive.",
    "prefix":"udp_broadcast_initialize"
  },
  "udp_broadcast:udp_broadcast_service/2": {
    "body":"udp_broadcast_service(${1:Domain}, ${2:Address})$3\n$0",
    "description":"[nondet]udp_broadcast_service(?Domain, ?Address).\nprovides the UDP broadcast address for a given Domain. At  present, only one domain is supported, udp_subnet.",
    "prefix":"udp_broadcast_service"
  },
  "udp_broadcast:udp_host_to_address/2": {
    "body":"udp_host_to_address(${1:Service}, ${2:Address})$3\n$0",
    "description":"[nondet]udp_host_to_address(?Service, ?Address).\nlocates a UDP service by name. Service is an atom or grounded  term representing the common name of the service. Address is  a UDP address structure. A server may advertise its services by name by  including the fact, udp:host_to_address(+Service, +Address),  somewhere in its source. This predicate can also be used to perform  reverse searches. That is it will also resolve an Address to  a Service name.",
    "prefix":"udp_host_to_address"
  },
  "ugraphs:add_edges/3": {
    "body":"add_edges(${1:Graph}, ${2:Edges}, ${3:NewGraph})$4\n$0",
    "description":"add_edges(+Graph, +Edges, -NewGraph).\nUnify NewGraph with a new graph obtained by adding the list  of Edges to Graph. Example:  \n\n?- add_edges([1-[3,5],2-[4],3-[],4-[5],\n              5-[],6-[],7-[],8-[]],\n             [1-6,2-3,3-2,5-7,3-2,4-5],\n             NL).\nNL = [1-[3,5,6], 2-[3,4], 3-[2], 4-[5],\n      5-[7], 6-[], 7-[], 8-[]]\n\n ",
    "prefix":"add_edges"
  },
  "ugraphs:add_vertices/3": {
    "body":"add_vertices(${1:Graph}, ${2:Vertices}, ${3:NewGraph})$4\n$0",
    "description":"add_vertices(+Graph, +Vertices, -NewGraph).\nUnify NewGraph with a new graph obtained by adding the list  of Vertices to Graph. Example:  \n\n?- add_vertices([1-[3,5],2-[]], [0,1,2,9], NG).\nNG = [0-[], 1-[3,5], 2-[], 9-[]]\n\n ",
    "prefix":"add_vertices"
  },
  "ugraphs:complement/2": {
    "body":"complement(${1:Graph}, ${2:NewGraph})$3\n$0",
    "description":"complement(+Graph, -NewGraph).\nUnify NewGraph with the graph complementary to Graph.  Example:  \n\n?- complement([1-[3,5],2-[4],3-[],\n               4-[1,2,7,5],5-[],6-[],7-[],8-[]], NL).\nNL = [1-[2,4,6,7,8],2-[1,3,5,6,7,8],3-[1,2,4,5,6,7,8],\n      4-[3,5,6,8],5-[1,2,3,4,6,7,8],6-[1,2,3,4,5,7,8],\n      7-[1,2,3,4,5,6,8],8-[1,2,3,4,5,6,7]]\n\n ",
    "prefix":"complement"
  },
  "ugraphs:compose/3": {
    "body":"compose(${1:LeftGraph}, ${2:RightGraph}, ${3:NewGraph})$4\n$0",
    "description":"compose(+LeftGraph, +RightGraph, -NewGraph).\nCompose NewGraph by connecting the drains of LeftGraph  to the sources of RightGraph. Example:  \n\n?- compose([1-[2],2-[3]],[2-[4],3-[1,2,4]],L).\nL = [1-[4], 2-[1,2,4], 3-[]]\n\n ",
    "prefix":"compose"
  },
  "ugraphs:del_edges/3": {
    "body":"del_edges(${1:Graph}, ${2:Edges}, ${3:NewGraph})$4\n$0",
    "description":"del_edges(+Graph, +Edges, -NewGraph).\nUnify NewGraph with a new graph obtained by removing the list  of Edges from Graph. Notice that no vertices are  deleted. Example:  \n\n?- del_edges([1-[3,5],2-[4],3-[],4-[5],5-[],6-[],7-[],8-[]],\n             [1-6,2-3,3-2,5-7,3-2,4-5,1-3],\n             NL).\nNL = [1-[5],2-[4],3-[],4-[],5-[],6-[],7-[],8-[]]\n\n ",
    "prefix":"del_edges"
  },
  "ugraphs:del_vertices/3": {
    "body":"del_vertices(${1:Graph}, ${2:Vertices}, ${3:NewGraph})$4\n$0",
    "description":"del_vertices(+Graph, +Vertices, -NewGraph).\nUnify NewGraph with a new graph obtained by deleting the list  of Vertices and all edges that start from or go to a vertex in Vertices from Graph. Example:  \n\n?- del_vertices([2,1],\n                [1-[3,5],2-[4],3-[],4-[5],\n                 5-[],6-[],7-[2,6],8-[]],\n                NL).\nNL = [3-[],4-[5],5-[],6-[],7-[6],8-[]]\n\n ",
    "prefix":"del_vertices"
  },
  "ugraphs:edges/2": {
    "body":"edges(${1:Graph}, ${2:Edges})$3\n$0",
    "description":"edges(+Graph, -Edges).\nUnify Edges with all edges appearing in Graph.  Example:  \n\n?- edges([1-[3,5],2-[4],3-[],4-[5],5-[]], L).\nL = [1-3, 1-5, 2-4, 4-5]\n\n ",
    "prefix":"edges"
  },
  "ugraphs:neighbors/3": {
    "body":"neighbors(${1:Vertex}, ${2:Graph}, ${3:Vertices})$4\n$0",
    "description":"neighbors(+Vertex, +Graph, -Vertices).\nAmerican version of neighbours/3.",
    "prefix":"neighbors"
  },
  "ugraphs:neighbours/3": {
    "body":"neighbours(${1:Vertex}, ${2:Graph}, ${3:Vertices})$4\n$0",
    "description":"neighbours(+Vertex, +Graph, -Vertices).\nUnify Vertices with the list of neighbours of vertex Vertex  in Graph. Example:  \n\n?- neighbours(4,[1-[3,5],2-[4],3-[],\n                 4-[1,2,7,5],5-[],6-[],7-[],8-[]], NL).\nNL = [1,2,7,5]\n\n ",
    "prefix":"neighbours"
  },
  "ugraphs:reachable/3": {
    "body":"reachable(${1:Vertex}, ${2:Graph}, ${3:Vertices})$4\n$0",
    "description":"reachable(+Vertex, +Graph, -Vertices).\nUnify Vertices with the set of all vertices in Graph  that are reachable from Vertex. Example:  \n\n?- reachable(1,[1-[3,5],2-[4],3-[],4-[5],5-[]],V).\nV = [1, 3, 5]\n\n  \n\n",
    "prefix":"reachable"
  },
  "ugraphs:top_sort/2": {
    "body":"top_sort(${1:Graph}, ${2:Sort})$3\n$0",
    "description":"top_sort(+Graph, -Sort).\nGenerate the set of nodes Sort as a topological sorting of Graph, if one is possible. A toplogical sort is possible if  the graph is connected and acyclic. In the example we show how  topological sorting works for a linear graph:  \n\n?- top_sort([1-[2], 2-[3], 3-[]], L).\nL = [1, 2, 3]\n\n ",
    "prefix":"top_sort"
  },
  "ugraphs:top_sort/3": {
    "body":"top_sort(${1:Graph}, ${2:Sort0}, ${3:Sort})$4\n$0",
    "description":"top_sort(+Graph, -Sort0, -Sort).\nGenerate the difference list Sort-Sort0 as a topological sorting of Graph, if one is possible.",
    "prefix":"top_sort"
  },
  "ugraphs:transitive_closure/2": {
    "body":"transitive_closure(${1:Graph}, ${2:Closure})$3\n$0",
    "description":"transitive_closure(+Graph, -Closure).\nGenerate the graph Closure as the transitive closure of Graph. Example:  \n\n ?- transitive_closure([1-[2,3],2-[4,5],4-[6]],L).\nL = [1-[2,3,4,5,6], 2-[4,5,6], 4-[6]]\n\n ",
    "prefix":"transitive_closure"
  },
  "ugraphs:transpose_ugraph/2": {
    "body":"transpose_ugraph(${1:Graph}, ${2:NewGraph})$3\n$0",
    "description":"transpose_ugraph(+Graph, -NewGraph).\nUnify NewGraph with a new graph obtained from Graph  by replacing all edges of the form V1-V2 by edges of the form V2-V1. The  cost is O(|V|^2). Notice that an undirected graph is its own  transpose. Example:  \n\n?- transpose_ugraph([1-[3,5],2-[4],3-[],4-[5],\n              5-[],6-[],7-[],8-[]], NL).\nNL = [1-[],2-[],3-[1],4-[2],5-[1,4],6-[],7-[],8-[]]\n\n ",
    "prefix":"transpose_ugraph"
  },
  "ugraphs:ugraph_union/3": {
    "body":"ugraph_union(${1:Graph1}, ${2:Graph2}, ${3:NewGraph})$4\n$0",
    "description":"ugraph_union(+Graph1, +Graph2, -NewGraph).\nNewGraph is the union of Graph1 and Graph2.  Example:  \n\n?- ugraph_union([1-[2],2-[3]],[2-[4],3-[1,2,4]],L).\nL = [1-[2], 2-[3,4], 3-[1,2,4]]\n\n ",
    "prefix":"ugraph_union"
  },
  "ugraphs:vertices/2": {
    "body":"vertices(${1:Graph}, ${2:Vertices})$3\n$0",
    "description":"vertices(+Graph, -Vertices).\nUnify Vertices with all vertices appearing in Graph.  Example:  \n\n?- vertices([1-[3,5],2-[4],3-[],4-[5],5-[]], L).\nL = [1, 2, 3, 4, 5]\n\n ",
    "prefix":"vertices"
  },
  "ugraphs:vertices_edges_to_ugraph/3": {
    "body":"vertices_edges_to_ugraph(${1:Vertices}, ${2:Edges}, ${3:Graph})$4\n$0",
    "description":"vertices_edges_to_ugraph(+Vertices, +Edges, -Graph).\nGiven a graph with a set of Vertices and a set of Edges, Graph must unify with the corresponding S-representation.  Note that vertices without edges will appear in Vertices but  not in Edges. Moreover, it is sufficient for a vertex to appear in Edges.  \n\n?- vertices_edges_to_ugraph([],[1-3,2-4,4-5,1-5], L).\nL = [1-[3,5], 2-[4], 3-[], 4-[5], 5-[]]\n\n  In this case all vertices are defined implicitly. The next example  shows three unconnected vertices: \n\n\n\n?- vertices_edges_to_ugraph([6,7,8],[1-3,2-4,4-5,1-5], L).\nL = [1-[3,5], 2-[4], 3-[], 4-[5], 5-[], 6-[], 7-[], 8-[]] ?\n\n ",
    "prefix":"vertices_edges_to_ugraph"
  },
  "uid:delete_directory_contents/1": {
    "body":"delete_directory_contents(${1:Dir})$2\n$0",
    "description":"[det]delete_directory_contents(+Dir).\nRemove all content from directory Dir, without removing Dir  itself. Similar to delete_directory_and_contents/2,  if symbolic links are encountered in Dir, the links are  removed rather than their content.",
    "prefix":"delete_directory_contents"
  },
  "uid:getegid/1": {
    "body":"getegid(${1:GID})$2\n$0",
    "description":"[det]getegid(-GID).\nGID is the effective group ID of the calling process.",
    "prefix":"getegid"
  },
  "uid:geteuid/1": {
    "body":"geteuid(${1:UID})$2\n$0",
    "description":"[det]geteuid(-UID).\nUID is the effective user ID of the calling process.",
    "prefix":"geteuid"
  },
  "uid:getgid/1": {
    "body":"getgid(${1:GID})$2\n$0",
    "description":"[det]getgid(-GID).\nGID is the real group ID of the calling process.",
    "prefix":"getgid"
  },
  "uid:getgroups/1": {
    "body":"getgroups(${1:GroupsIDs})$2\n$0",
    "description":"[det]getgroups(-GroupsIDs:list(integer)).\nGroupsIDs is the set of supplementary group IDs of the  calling process. Note that these are numeric identifiers. Use group_info/2 to obtain details  on the returned group identifiers.",
    "prefix":"getgroups"
  },
  "uid:getuid/1": {
    "body":"getuid(${1:UID})$2\n$0",
    "description":"[det]getuid(-UID).\nUID is the real user ID of the calling process.",
    "prefix":"getuid"
  },
  "uid:group_data/3": {
    "body":"group_data(${1:Field}, ${2:GroupData}, ${3:Value})$4\n$0",
    "description":"group_data(?Field, ?GroupData, ?Value).\nValue is the value for Field GroupData.  Defined fields are:  name: Name of the user\n\npassword: Password hash of the user (or x if this is not accessible)\n\ngid: Numeric group id of the group\n\nmembers: List of user-names that are member of this group.\n\n ",
    "prefix":"group_data"
  },
  "uid:group_info/2": {
    "body":"group_info(${1:Group}, ${2:GroupData})$3\n$0",
    "description":"[det]group_info(+Group, -GroupData).\nGroupData represent the group information for Group. Group  is either a numeric GID or a group name. The predicate group_data/3  can be used to extract information from GroupData.",
    "prefix":"group_info"
  },
  "uid:initgroups/2": {
    "body":"initgroups(${1:User}, ${2:Group})$3\n$0",
    "description":"[det]initgroups(+User, +Group).\nInitialise the group access list of the calling process to the  registered groups for User and the group Group.  This predicate is only available if the underlying OS provides it.",
    "prefix":"initgroups"
  },
  "uid:set_user_and_group/1": {
    "body":"set_user_and_group(${1:User})$2\n$0",
    "description":"[det]set_user_and_group(+User).\n",
    "prefix":"set_user_and_group"
  },
  "uid:set_user_and_group/2": {
    "body":"set_user_and_group(${1:User}, ${2:Group})$3\n$0",
    "description":"[det]set_user_and_group(+User, +Group).\nSet the UID and GID to the User. User is either a  UID or a user name. If Group is not specified, the primary  group of User is used. If initgroups/2  is available, the resulting group access list of the calling process  consists of the registered groups for User and the specified Group.",
    "prefix":"set_user_and_group"
  },
  "uid:setegid/1": {
    "body":"setegid(${1:GID})$2\n$0",
    "description":"setegid(+GID).\nSet the effective group id of the calling process.",
    "prefix":"setegid"
  },
  "uid:seteuid/1": {
    "body":"seteuid(${1:UID})$2\n$0",
    "description":"seteuid(+UID).\nSet the effective user id of the calling process.",
    "prefix":"seteuid"
  },
  "uid:setgid/1": {
    "body":"setgid(${1:GID})$2\n$0",
    "description":"setgid(+GID).\nSet the group id of the calling process.",
    "prefix":"setgid"
  },
  "uid:setgroups/1": {
    "body":"setgroups(${1:Groups})$2\n$0",
    "description":"[det]setgroups(+Groups:list(integer)).\nSet the group access list of the caling process to the indicated groups.  This predicate is only available if the underlying OS provides it.",
    "prefix":"setgroups"
  },
  "uid:setuid/1": {
    "body":"setuid(${1:UID})$2\n$0",
    "description":"setuid(+UID).\nSet the user id of the calling process.",
    "prefix":"setuid"
  },
  "uid:user_data/3": {
    "body":"user_data(${1:Field}, ${2:UserData}, ${3:Value})$4\n$0",
    "description":"user_data(?Field, ?UserData, ?Value).\nValue is the value for Field in UserData.  Defined fields are:  name: Name of the user\n\npassword: Password hash of the user (or x if this is not accessible)\n\nuid: Numeric user id of the user\n\ngid: Numeric primary group id of the user\n\ncomment: The gecos field\n\nhome: Home directory of the user\n\nshell: Default (login) shell of the user.\n\n ",
    "prefix":"user_data"
  },
  "uid:user_info/2": {
    "body":"user_info(${1:User}, ${2:UserData})$3\n$0",
    "description":"[det]user_info(+User, -UserData).\nUserData represent the passwd information for User. User  is either a numeric UID or a user name. The predicate user_data/3  can be used to extract information from UserData.",
    "prefix":"user_info"
  },
  "unaccent_atom/2": {
    "body":"unaccent_atom(${1:In}, ${2:ASCII})$3\n$0",
    "description":"unaccent_atom(+In, -ASCII).\nIf In is general ISO Latin-1 text with accents, ASCII  is unified with a plain ASCII version of the string. Note that the  current version only deals with ISO Latin-1 atoms.",
    "prefix":"unaccent_atom"
  },
  "unicode/unicode_blocks:unicode_block/3": {
    "body": ["unicode_block(${1:BlockName}, ${2:Start}, ${3:End})$4\n$0" ],
    "description":"  unicode_block(?BlockName, ?Start, ?End)\n\n   Provides the names of the  basic   unicode  blocks. Derived from\n   UNICODE 4.1.0 from www.unicode.org",
    "prefix":"unicode_block"
  },
  "unicode/unicode_data:unicode_property/2": {
    "body": ["unicode_property(${1:'Param1'}, ${2:'Param2'})$3\n$0" ],
    "description":"unicode_property('Param1','Param2')",
    "prefix":"unicode_property"
  },
  "unicode:unicode_map/3": {
    "body":"unicode_map(${1:In}, ${2:Out}, ${3:Options})$4\n$0",
    "description":"[det]unicode_map(+In, -Out, +Options).\nPerform unicode normalization operations. Options is a list  of operations. Defined operations are:  stable: Unicode Versioning Stability has to be respected.\n\ncompat: Compatiblity decomposition (i.e. formatting information is lost)\n\ncompose: Return a result with composed characters.\n\ndecompose: Return a result with decomposed characters.\n\nignore: Strip \"default ignorable characters\"\n\nrejectna: Return an error, if the input contains unassigned code points.\n\nnlf2ls: Indicating that NLF-sequences (LF, CRLF, CR, NEL) are representing a  line break, and should be converted to the unicode character for line  separation (LS).\n\nnlf2ps: Indicating that NLF-sequences are representing a paragraph break, and  should be converted to the unicode character for paragraph separation  (PS).\n\nnlf2lf: Indicating that the meaning of NLF-sequences is unknown.\n\nstripcc: Strips and/or convers control characters. NLF-sequences are transformed  into space, except if one of the NLF2LS/PS/LF options is given.  HorizontalTab (HT) and FormFeed (FF) are treated as a NLF-sequence in  this case. All other control characters are simply removed.\n\ncasefold: Performs unicode case folding, to be able to do a case-insensitive  string comparison.\n\ncharbound: Inserts 0xFF bytes at the beginning of each sequence which is  representing a single grapheme cluster (see UAX#29).\n\nlump: (e.g. HYPHEN U+2010 and MINUS U+2212 to ASCII \"-\"). (See module header  for details.) If NLF2LF is set, this includes a transformation of  paragraph and line separators to ASCII line-feed (LF).\n\nstripmark: Strips all character markings (non-spacing, spacing and enclosing) (i.e.  accents) NOTE: this option works only with compose or decompose.\n\n ",
    "prefix":"unicode_map"
  },
  "unicode:unicode_nfc/2": {
    "body":"unicode_nfc(${1:In}, ${2:Out})$3\n$0",
    "description":"[det]unicode_nfc(+In, -Out).\nCharacters are decomposed and then recomposed by canonical equivalence.  It is possible for the result to be a different sequence of characters  than the original.  See also: http://en.wikipedia.org/wiki/Unicode_equivalence#Normal_forms\n\n ",
    "prefix":"unicode_nfc"
  },
  "unicode:unicode_nfd/2": {
    "body":"unicode_nfd(${1:In}, ${2:Out})$3\n$0",
    "description":"[det]unicode_nfd(+In, -Out).\nCharacters are decomposed by canonical equivalence.",
    "prefix":"unicode_nfd"
  },
  "unicode:unicode_nfkc/2": {
    "body":"unicode_nfkc(${1:In}, ${2:Out})$3\n$0",
    "description":"[det]unicode_nfkc(+In, -Out).\nCharacters are decomposed by compatibility equivalence, then recomposed  by canonical equivalence.",
    "prefix":"unicode_nfkc"
  },
  "unicode:unicode_nfkd/2": {
    "body":"unicode_nfkd(${1:In}, ${2:Out})$3\n$0",
    "description":"[det]unicode_nfkd(+In, -Out).\nCharacters are decomposed by compatibility equivalence.",
    "prefix":"unicode_nfkd"
  },
  "unicode:unicode_property/2": {
    "body":"unicode_property(${1:Char}, ${2:Property})$3\n$0",
    "description":"[nondet]unicode_property(?Char, ?Property).\nTrue if Property is defined for Char. Property  is a term Name(Value). Defined property-names are:  category(atom): Unicode code category of Char. This is one of Cc, Cf, Cn, Co,  Cs, Ll, Lm, Lo, Lt, Lu, Mc, Me, Mn, Nd, Nl, No, Pc, Pd, Pe, Pf, Pi, Po,  Ps, Sc, Sk, Sm, So, Zl, Zp, Zs. When testing, a single letter stands for  all its subcategories. E.g. to test form a letter, you can use  \n\nunicode_property(C, category('L'))\n\n \n\ncombining_class(integer): bidi_class(atom): decomp_type(atom): decomp_mapping(list(code)): bidi_mirrored(bool): uppercase_mapping(code): lowercase_mapping(code): titlecase_mapping(code): comb1st_index(code): comb2nd_index(code): comp_exclusion(bool): ignorable(bool): control_boundary(bool): extend(bool): casefold_mapping(list(code)): \n\n  To be done: Complete documentation\n\n ",
    "prefix":"unicode_property"
  },
  "unifiable/3": {
    "body":"unifiable(${1:X}, ${2:Y}, ${3:Unifier})$4\n$0",
    "description":"unifiable(@X, @Y, -Unifier).\nIf X and Y can unify, unify Unifier  with a list of Var = Value, representing the bindings required to  make X and Y equivalent.58This  predicate was introduced for the implementation of dif/2  and when/2  after discussion with Tom Schrijvers and Bart Demoen. None of us is  really happy with the name and therefore suggestions for a new name are  welcome. This predicate can handle cyclic terms. Attributed  variables are handled as normal variables. Associated hooks are not  executed.",
    "prefix":"unifiable"
  },
  "unify_with_occurs_check/2": {
    "body":"unify_with_occurs_check(${1:Term1}, ${2:Term2})$3\n$0",
    "description":"[ISO]unify_with_occurs_check(+Term1, +Term2).\nAs =/2, but using sound  unification. That is, a variable only unifies to a term if this  term does not contain the variable itself. To illustrate this, consider  the two queries below.  \n\n1 ?- A = f(A).\nA = f(A).\n2 ?- unify_with_occurs_check(A, f(A)).\nfalse.\n\n  The first statement creates a cyclic  term, also called a rational tree. The second executes logically sound unification  and thus fails. Note that the behaviour of unification through =/2 as well as implicit  unification in the head can be changed using the Prolog flag occurs_check. \n\nThe SWI-Prolog implementation of unify_with_occurs_check/2  is cycle-safe and only guards against creating cycles, not  against cycles that may already be present in one of the arguments. This  is illustrated in the following two queries: \n\n\n\n?- X = f(X), Y = X, unify_with_occurs_check(X, Y).\nX = Y, Y = f(Y).\n?- X = f(X), Y = f(Y), unify_with_occurs_check(X, Y).\nX = Y, Y = f(Y).\n\n  Some other Prolog systems interpret unify_with_occurs_check/2  as if defined by the clause below, causing failure on the above two  queries. Direct use of acyclic_term/1  is portable and more appropriate for such applications. \n\n\n\nunify_with_occurs_check(X,X) :- acyclic_term(X).\n\n ",
    "prefix":"unify_with_occurs_check"
  },
  "unix/1": {
    "body":"unix(${1:Command})$2\n$0",
    "description":"unix(+Command).\nThis predicate comes from the Quintus compatibility library and provides  a partial implementation thereof. It provides access to some operating  system features and unlike the name suggests, is not operating system  specific. Defined Command's are below.  system(+Command): Equivalent to calling shell/1.  Use for compatibility only.\n\nshell(+Command): Equivalent to calling shell/1.  Use for compatibility only.\n\nshell: Equivalent to calling shell/0.  Use for compatibility only.\n\ncd: Equivalent to calling working_directory/2  to the expansion (see expand_file_name/2)  of ~. For compatibility only.\n\ncd(+Directory): Equivalent to calling working_directory/2.  Use for compatibility only.\n\nargv(-Argv): Unify Argv with the list of command line arguments provided  to this Prolog run. Please note that Prolog system arguments and  application arguments are separated by --. Integer  arguments are passed as Prolog integers, float arguments and Prolog  floating point numbers and all other arguments as Prolog atoms. New  applications should use the Prolog flag argv.  See also the Prolog flag argv.  A stand-alone program could use the following skeleton to handle  command line arguments. See also section  2.10.2.4. \n\nmain :-\n        current_prolog_flag(argv, Argv),\n        append(_PrologArgs, [--|AppArgs], Argv), !,\n        main(AppArgs).\n\n  \n\n ",
    "prefix":"unix"
  },
  "unix:call_with_time_limit/2": {
    "body":"call_with_time_limit(${1:Time}, ${2:Goal})$3\n$0",
    "description":"call_with_time_limit(+Time, :Goal).\nTrue if Goal completes within Time seconds. Goal  is executed as in once/1.  If Goal doesn't complete within Time seconds (wall  time), exit using the exception time_limit_exceeded. See catch/3.  Please note that this predicate uses alarm/4  and therefore its effect on long-running foreign code and system calls  is undefined. Blocking I/O can be handled using the timeout option of read_term/3.\n\n",
    "prefix":"call_with_time_limit"
  },
  "unix:detach_IO/0": {
    "body": ["detach_IO$1\n$0" ],
    "description":"  detach_IO is det.\n\n   Detach I/O similar to detach_IO/1. The  output streams are bound\n   to a file =|/tmp/pl-out.<pid>|=. Output   is  line buffered (see\n   set_stream/2).\n\n   @compat Older versions of this predicate only created this file\n           if there was output.\n   @see    library(syslog) allows for sending output to the Unix\n           logging service.",
    "prefix":"detach_IO"
  },
  "unix:detach_IO/1": {
    "body":"detach_IO(${1:Stream})$2\n$0",
    "description":"[det]detach_IO(+Stream).\nThis predicate is intended to create Unix deamon processes. It  performs two actions.  \n\nThe I/O streams user_input, user_output  and user_error are closed if they are connected to a terminal  (see tty property in stream_property/2).  Input streams are rebound to a dummy stream that returns EOF. Output  streams are reboud to forward their output to Stream.\nThe process is detached from the current process-group and its  controlling terminal. This is achieved using setsid() if  provided or using ioctl() TIOCNOTTY on /dev/tty.\n\n  To ignore all output, it may be rebound to a null stream. For  example: \n\n\n\n      ...,\n      open_null_stream(Out),\n      detach_IO(Out).\n\n  The detach_IO/1 should be  called only once per process. Subsequent calls silently succeed without  any side effects. \n\nSee also: detach_IO/0 and library(syslog).\n\n ",
    "prefix":"detach_IO"
  },
  "unix:dup/2": {
    "body":"dup(${1:FromStream}, ${2:ToStream})$3\n$0",
    "description":"[det]dup(+FromStream, +ToStream).\nInterface to Unix dup2(), copying the underlying  filedescriptor and thus making both streams point to the same underlying  object. This is normally used together with fork/1  and pipe/2 to talk to an external  program that is designed to communicate using standard I/O.  Both FromStream and ToStream either refer to a  Prolog stream or an integer descriptor number to refer directly to OS  descriptors. See also demo/pipe.pl in the  source-distribution of this package.\n\n",
    "prefix":"dup"
  },
  "unix:environ/1": {
    "body": ["environ(${1:'Param1'})$2\n$0" ],
    "description":"environ('Param1')",
    "prefix":"environ"
  },
  "unix:exec/1": {
    "body":"exec(${1:Command})$2\n$0",
    "description":"exec(+Command).\nReplace the running program by starting Command. Command  is a callable term. The functor is the command and the arguments provide  the command-line arguments for the command. Each command-line argument  must be atomic and is converted to a string before passed to the Unix  call execvp(). Here are some examples:  \n\nexec(ls('-l'))\nexec('/bin/ls'('-l', '/home/jan'))\n\n  Unix exec() is the only way to start an executable file  executing. It is commonly used together with fork/1.  For example to start netscape on an URL in the background, do: \n\n\n\nrun_netscape(URL) :-\n        (    fork(child),\n             exec(netscape(URL))\n        ;    true\n        ).\n\n  Using this code, netscape remains part of the process-group of the  invoking Prolog process and Prolog does not wait for netscape to  terminate. The predicate wait/2  allows waiting for a child, while detach_IO/0  disconnects the child as a deamon process.\n\n",
    "prefix":"exec"
  },
  "unix:fork/1": {
    "body":"fork(${1:Pid})$2\n$0",
    "description":"[det]fork(-Pid).\nClone the current process into two branches. In the child, Pid  is unified to child. In the original process, Pid is unified  to the process identifier of the created child. Both parent and child  are fully functional Prolog processes running the same program. The  processes share open I/O streams that refer to Unix native streams, such  as files, sockets and pipes. Data is not shared, though on most Unix  systems data is initially shared and duplicated only if one of the  programs attempts to modify the data.  Unix fork() is the only way to create new processes and fork/1  is a simple direct interface to it. \n\nErrors: permission_error(fork, process, main) is raised if the  calling thread is not the only thread in the process. Forking a Prolog  process with threads will typically deadlock because only the calling  thread is cloned in the fork, while all thread synchronization are  cloned.\n\n ",
    "prefix":"fork"
  },
  "unix:fork_exec/1": {
    "body":"fork_exec(${1:Command})$2\n$0",
    "description":"[det]fork_exec(+Command).\nFork (as fork/1) and exec (using exec/1)  the child immediately. This behaves as the code below, but bypasses the  check for the existence of other threads because this is a safe  scenario.  \n\nfork_exec(Command) :-\n      (   fork(child)\n      ->  exec(Command)\n      ;   true\n      ).\n\n ",
    "prefix":"fork_exec"
  },
  "unix:kill/2": {
    "body":"kill(${1:Pid}, ${2:Signal})$3\n$0",
    "description":"[det]kill(+Pid, +Signal).\nDeliver a software interrupt to the process with identifier Pid  using software-interrupt number Signal. See also on_signal/2.  Signals can be specified as an integer or signal name, where signal  names are derived from the C constant by dropping the SIG prefix and mapping to lowercase. E.g. int  is the same as SIGINT in C. The meaning of the signal numbers can be found  in the Unix manual.",
    "prefix":"kill"
  },
  "unix:pipe/2": {
    "body":"pipe(${1:InSream}, ${2:OutStream})$3\n$0",
    "description":"[det]pipe(-InSream, -OutStream).\nCreate a communication-pipe. This is normally used to make a child  communicate to its parent. After pipe/2,  the process is cloned and, depending on the desired direction, both  processes close the end of the pipe they do not use. Then they use the  remaining stream to communicate. Here is a simple example:  \n\n:- use_module(library(unix)).\n\nfork_demo(Result) :-\n        pipe(Read, Write),\n        fork(Pid),\n        (   Pid == child\n        ->  close(Read),\n            format(Write, '~q.~n',\n                   [hello(world)]),\n            flush_output(Write),\n            halt\n        ;   close(Write),\n            read(Read, Result),\n            close(Read)\n        ).\n\n ",
    "prefix":"pipe"
  },
  "unix:prctl/1": {
    "body":"prctl(${1:Option})$2\n$0",
    "description":"[det]prctl(+Option).\nAccess to Linux process control operations. Defines values for Option are:  set_dumpable(+Boolean): Control whether the process is allowed to dump core. This right is  dropped under several uid and gid conditions.\n\nget_dumpable(-Boolean): Get the value of the dumpable flag.\n\n ",
    "prefix":"prctl"
  },
  "unix:rlimit/3": {
    "body":"rlimit(${1:Resource}, ${2:Old}, ${3:New})$4\n$0",
    "description":"rlimit(+Resource, -Old, +New).\nQuery and/or set the limit for Resource. Time-values are in  seconds and size-values are counted in bytes. The following values are  supported by this library. Please note that not all resources may be  available and accessible on all platforms. This predicate can throw a  variety of exceptions. In portable code this should be guarded with catch/3.  The defined resources are: as Max address space cpu CPU time in seconds fsize Maximum filesize data max data size stack max stack size core max core file size rss max resident set size nproc max number of processes nofile max number of open  files memlock max locked-in-memory  address   When the process hits a limit POSIX systems normally send the process  a signal that terminates it. These signals may be catched using  SWI-Prolog's on_signal/3  primitive. The code below illustrates this behaviour. Please note that  asynchronous signal handling is dangerous, especially when using  threads. 100% fail-safe operation cannot be guaranteed, but this  procedure will inform the user properly `most of the time'. \n\n\n\nrlimit_demo :-\n        rlimit(cpu, _, 2),\n        on_signal(xcpu, _, cpu_exceeded),\n        ( repeat, fail ).\n\ncpu_exceeded(_Sig) :-\n        format(user_error, 'CPU time exceeded~n', []),\n        halt(1).\n\n  \n\n",
    "prefix":"rlimit"
  },
  "unix:sysconf/1": {
    "body":"sysconf(${1:Conf})$2\n$0",
    "description":"[semidet]sysconf(+Conf).\nAccess system configuration. See sysconf(1) for details. Conf  is a term Config(Value), where Value is always an integer. Config is the sysconf()  name after removing =SC= and conversion to lowercase. Currently  support the following configuration info: arg_max, child_max, clk_tck, open_max, pagesize, phys_pages, avphys_pages, nprocessors_conf  and nprocessors_onln. Note that not all values may be supported  on all operating systems.",
    "prefix":"sysconf"
  },
  "unix:wait/2": {
    "body":"wait(${1:Pid}, ${2:Status})$3\n$0",
    "description":"[det]wait(?Pid, -Status).\nWait for a child to change status. Then report the child that changed  status as well as the reason. If Pid is bound on entry then  the status of the specified child is reported. If not, then the status  of any child is reported. Status is unified with exited(ExitCode) if the child with pid Pid was  terminated by calling exit() (Prolog halt/1).  ExitCode is the return status. Status is unified with signaled(Signal) if the  child died due to a software interrupt (see kill/2).  Signal contains the signal number. Finally, if the process suspended  execution due to a signal, Status is unified with stopped(Signal).",
    "prefix":"wait"
  },
  "unknown/2": {
    "body":"unknown(${1:Old}, ${2:New})$3\n$0",
    "description":"unknown(-Old, +New).\nEdinburgh-Prolog compatibility predicate, interfacing to the ISO Prolog  flag unknown. Values  are trace (meaning error) and fail.  If the unknown flag  is set to warning, unknown/2  reports the value as trace.",
    "prefix":"unknown"
  },
  "unload_file/1": {
    "body":"unload_file(${1:File})$2\n$0",
    "description":"unload_file(+File).\nRemove all clauses loaded from File. If File  loaded a module, clear the module's export list and disassociate it from  the file. File is a canonical filename or a file indicator  that is valid for load_files/2.  This predicate should be used with care. The multithreaded nature of  SWI-Prolog makes removing static code unsafe. Attempts to do this should  be reserved for development or situations where the application can  guarantee that none of the clauses associated to File are  active.\n\n",
    "prefix":"unload_file"
  },
  "unsetenv/1": {
    "body":"unsetenv(${1:Name})$2\n$0",
    "description":"unsetenv(+Name).\nRemove an environment variable from the environment. Some systems lack  the underlying unsetenv() library function. On these systems unsetenv/1  sets the variable to the empty string.",
    "prefix":"unsetenv"
  },
  "upcase_atom/2": {
    "body":"upcase_atom(${1:AnyCase}, ${2:UpperCase})$3\n$0",
    "description":"upcase_atom(+AnyCase, -UpperCase).\nConverts, similar to downcase_atom/2,  an atom to uppercase.",
    "prefix":"upcase_atom"
  },
  "uri:cgi_get_form/1": {
    "body":"cgi_get_form(${1:Form})$2\n$0",
    "description":"cgi_get_form(-Form).\nDecodes standard input and the environment variables to obtain a list of  arguments passed to the CGI script. This predicate both deals with the  CGI GET method as well as the POST method. If the data  cannot be obtained, an existence_error exception is raised.",
    "prefix":"cgi_get_form"
  },
  "uri:crypt/2": {
    "body":"crypt(${1:Plain}, ${2:Encrypted})$3\n$0",
    "description":"crypt(+Plain, ?Encrypted).\nThis predicate can be used in three modes. To test whether a password  matches an encrypted version thereof, simply run with both arguments  fully instantiated. To generate a default encrypted version of Plain, run with unbound Encrypted and this  argument is unified to a list of character codes holding an encrypted  version.  The library supports two encryption formats: traditional Unix  DES-hashes2On non-Unix systems,  crypt() is provided by the NetBSD library. The license header is added  at the end of this document. and FreeBSD compatible MD5  hashes (all platforms). MD5 hashes start with the magic sequence $1$,  followed by an up to 8 character salt. DES hashes start with a  2 character salt. Note that a DES hash considers only the first 8  characters. The MD5 considers the whole string. \n\nSalt and algorithm can be forced by instantiating the start of Encrypted with it. This is typically used to force MD5  hashes: \n\n\n\n?- phrase(\"$1$\", E, _),\n   crypt(\"My password\", E),\n   format('~s~n', [E]).\n\n$1$qdaDeDZn$ZUxSQEESEHIDCHPNc3fxZ1\n\n  Encrypted is always a list of ASCII character codes. Plain  only supports ISO-Latin-1 passwords in the current implementation. \n\nPlain is either an atom, SWI-Prolog string, list of  characters or list of character-codes. It is not advised to use atoms,  as this implies the password will be available from the Prolog heap as a  defined atom.\n\n",
    "prefix":"crypt"
  },
  "uri:iri_normalized/2": {
    "body":"iri_normalized(${1:IRI}, ${2:NormalizedIRI})$3\n$0",
    "description":"[det]iri_normalized(+IRI, -NormalizedIRI).\nNormalizedIRI is the normalized form of IRI.  Normalization is syntactic and involves the following steps:  \n\n6.2.2.1. Case Normalization\n6.2.2.3. Path Segment Normalization\n\n  See also: This is similar to uri_normalized/2,  but does not do normalization of %-escapes.\n\n ",
    "prefix":"iri_normalized"
  },
  "uri:iri_normalized/3": {
    "body":"iri_normalized(${1:IRI}, ${2:Base}, ${3:NormalizedGlobalIRI})$4\n$0",
    "description":"[det]iri_normalized(+IRI, +Base, -NormalizedGlobalIRI).\nNormalizedGlobalIRI is the normalized global version of IRI.  This is similar to uri_normalized/3,  but does not do %-escape normalization.",
    "prefix":"iri_normalized"
  },
  "uri:stream_pool_main_loop/0": {
    "body":"stream_pool_main_loop$1\n$0",
    "description":"stream_pool_main_loop.\nCalls dispatch_stream_pool/1  in a loop until the pool is empty.",
    "prefix":"stream_pool_main_loop"
  },
  "uri:uri_authority_components/2": {
    "body":"uri_authority_components(${1:Authority}, ${2:Components})$3\n$0",
    "description":"[det]uri_authority_components(-Authority, +Components).\nBreak-down the authority component of a URI. The fields of the structure Components  can be accessed using uri_authority_data/3.",
    "prefix":"uri_authority_components"
  },
  "uri:uri_authority_data/3": {
    "body":"uri_authority_data(${1:Field}, ${2:Components}, ${3:Data})$4\n$0",
    "description":"[semidet]uri_authority_data(+Field, ?Components, ?Data).\nProvide access the uri_authority structure. Defined field-names are: user, password, host  and port",
    "prefix":"uri_authority_data"
  },
  "uri:uri_components/2": {
    "body":"uri_components(${1:URI}, ${2:Components})$3\n$0",
    "description":"[det]uri_components(-URI, +Components).\nBreak a URI into its 5 basic components according to the  RFC-3986 regular expression:  \n\n^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?\n 12            3  4          5       6  7        8 9\n\n  Components is a term uri_components(Scheme, Authority, Path, Search, Fragment).  If a URI is parsed, i.e., using mode (+,-), components  that are not found are left uninstantiated (variable). See uri_data/3  for accessing this structure. ",
    "prefix":"uri_components"
  },
  "uri:uri_data/3": {
    "body":"uri_data(${1:Field}, ${2:Components}, ${3:Data})$4\n$0",
    "description":"[semidet]uri_data(?Field, +Components, ?Data).\nProvide access the uri_component structure. Defined field-names are: scheme, authority, path, search  and fragment",
    "prefix":"uri_data"
  },
  "uri:uri_data/4": {
    "body":"uri_data(${1:Field}, ${2:Components}, ${3:Data}, ${4:NewComponents})$5\n$0",
    "description":"[semidet]uri_data(+Field, +Components, +Data, -NewComponents).\nNewComponents is the same as Components with Field  set to Data.",
    "prefix":"uri_data"
  },
  "uri:uri_encoded/3": {
    "body":"uri_encoded(${1:Component}, ${2:Value}, ${3:Encoded})$4\n$0",
    "description":"[det]uri_encoded(+Component, -Value, +Encoded).\nEncoded is the URI encoding for Value. When  encoding (Value->Encoded), Component  specifies the URI component where the value is used. It is one of query_value, fragment  or path. Besides alphanumerical characters, the following  characters are passed verbatim (the set is split in logical groups  according to RFC3986).  query_value, fragment: \"-._~\" | \"!$'()*,;\" | \":@\" |  \"/?\"\n\npath: \"-._~\" | \"!$&'()*,;=\" | \":@\" |  \"/\"\n\n ",
    "prefix":"uri_encoded"
  },
  "uri:uri_file_name/2": {
    "body":"uri_file_name(${1:URI}, ${2:FileName})$3\n$0",
    "description":"[det]uri_file_name(-URI, +FileName).\nConvert between a URI and a local file_name. This protocol is  covered by RFC 1738. Please note that file-URIs use absolute  paths. The mode (-, +) translates a possible relative path into an  absolute one.",
    "prefix":"uri_file_name"
  },
  "uri:uri_iri/2": {
    "body":"uri_iri(${1:URI}, ${2:IRI})$3\n$0",
    "description":"[det]uri_iri(-URI, +IRI).\nConvert between a URI, encoded in US-ASCII and an IRI.  An IRI is a fully expanded Unicode string. Unicode strings  are first encoded into UTF-8, after which %-encoding takes place.  Errors: syntax_error(Culprit) in mode (+,-) if URI is  not a legally percent-encoded UTF-8 string.\n\n ",
    "prefix":"uri_iri"
  },
  "uri:uri_is_global/1": {
    "body":"uri_is_global(${1:URI})$2\n$0",
    "description":"[semidet]uri_is_global(+URI).\nTrue if URI has a scheme. The semantics is the same as the  code below, but the implementation is more efficient as it does not need  to parse the other components, nor needs to bind the scheme.  \n\nuri_is_global(URI) :-\n        uri_components(URI, Components),\n        uri_data(scheme, Components, Scheme),\n        nonvar(Scheme).\n\n ",
    "prefix":"uri_is_global"
  },
  "uri:uri_normalized/2": {
    "body":"uri_normalized(${1:URI}, ${2:NormalizedURI})$3\n$0",
    "description":"[det]uri_normalized(+URI, -NormalizedURI).\nNormalizedURI is the normalized form of URI.  Normalization is syntactic and involves the following steps:  \n\n6.2.2.1. Case Normalization\n6.2.2.2. Percent-Encoding Normalization\n6.2.2.3. Path Segment Normalization\n\n",
    "prefix":"uri_normalized"
  },
  "uri:uri_normalized/3": {
    "body":"uri_normalized(${1:URI}, ${2:Base}, ${3:NormalizedGlobalURI})$4\n$0",
    "description":"[det]uri_normalized(+URI, +Base, -NormalizedGlobalURI).\nNormalizedGlobalURI is the normalized global version of URI.  Behaves as if defined by:  \n\nuri_normalized(URI, Base, NormalizedGlobalURI) :-\n        uri_resolve(URI, Base, GlobalURI),\n        uri_normalized(GlobalURI, NormalizedGlobalURI).\n\n ",
    "prefix":"uri_normalized"
  },
  "uri:uri_normalized_iri/2": {
    "body":"uri_normalized_iri(${1:URI}, ${2:NormalizedIRI})$3\n$0",
    "description":"[det]uri_normalized_iri(+URI, -NormalizedIRI).\nAs uri_normalized/2, but  percent-encoding is translated into IRI Unicode characters. The  translation is liberal: valid UTF-8 sequences of %-encoded bytes are  mapped to the Unicode character. Other %XX-sequences are mapped to the  corresponding ISO-Latin-1 character and sole % characters are left  untouched.  See also: uri_iri/2.\n\n ",
    "prefix":"uri_normalized_iri"
  },
  "uri:uri_normalized_iri/3": {
    "body":"uri_normalized_iri(${1:URI}, ${2:Base}, ${3:NormalizedGlobalIRI})$4\n$0",
    "description":"[det]uri_normalized_iri(+URI, +Base, -NormalizedGlobalIRI).\nNormalizedGlobalIRI is the normalized global IRI of URI.  Behaves as if defined by:  \n\nuri_normalized(URI, Base, NormalizedGlobalIRI) :-\n        uri_resolve(URI, Base, GlobalURI),\n        uri_normalized_iri(GlobalURI, NormalizedGlobalIRI).\n\n ",
    "prefix":"uri_normalized_iri"
  },
  "uri:uri_query_components/2": {
    "body":"uri_query_components(${1:String}, ${2:Query})$3\n$0",
    "description":"[det]uri_query_components(-String, +Query).\nPerform encoding and decoding of an URI query string. Query  is a list of fully decoded (Unicode) Name=Value pairs. In mode (-,+),  query elements of the forms Name(Value) and Name-Value are also accepted  to enhance interoperability with the option and pairs libraries. E.g.  \n\n?- uri_query_components(QS, [a=b, c('d+w'), n-'VU Amsterdam']).\nQS = 'a=b&c=d%2Bw&n=VU%20Amsterdam'.\n\n?- uri_query_components('a=b&c=d%2Bw&n=VU%20Amsterdam', Q).\nQ = [a=b, c='d+w', n='VU Amsterdam'].\n\n ",
    "prefix":"uri_query_components"
  },
  "uri:uri_resolve/3": {
    "body":"uri_resolve(${1:URI}, ${2:Base}, ${3:GlobalURI})$4\n$0",
    "description":"[det]uri_resolve(+URI, +Base, -GlobalURI).\nResolve a possibly local URI relative to Base.  This implements http://labs.apache.org/webarch/uri/rfc/rfc3986.html#relative-transform",
    "prefix":"uri_resolve"
  },
  "url:file_name_to_url/2": {
    "body":"file_name_to_url(${1:File}, ${2:URL})$3\n$0",
    "description":"[semidet]file_name_to_url(-File, +URL).\nTranslate between a filename and a file:// URL.  To be done: Current implementation does not deal with paths that need special  encoding.\n\n ",
    "prefix":"file_name_to_url"
  },
  "url:global_url/3": {
    "body":"global_url(${1:URL}, ${2:Base}, ${3:Global})$4\n$0",
    "description":"[det]global_url(+URL, +Base, -Global).\nTranslate a possibly relative URL into an absolute one.  Errors: syntax_error(illegal_url) if URL is not legal.\n\n ",
    "prefix":"global_url"
  },
  "url:http_location/2": {
    "body":"http_location(${1:Parts}, ${2:Location})$3\n$0",
    "description":"http_location(?Parts, ?Location).\nConstruct or analyze an HTTP location. This is similar to parse_url/2, but only  deals with the location part of an HTTP URL. That is, the path, search  and fragment specifiers. In the HTTP protocol, the first line of a  message is  \n\n<Action> <Location> HTTP/<version>\n\n  Location Atom or list of  character codes. ",
    "prefix":"http_location"
  },
  "url:is_absolute_url/1": {
    "body":"is_absolute_url(${1:URL})$2\n$0",
    "description":"is_absolute_url(+URL).\nTrue if URL is an absolute URL. That is, a URL  that starts with a protocol identifier.",
    "prefix":"is_absolute_url"
  },
  "url:parse_url/2": {
    "body":"parse_url(${1:URL}, ${2:Attributes})$3\n$0",
    "description":"[det]parse_url(?URL, ?Attributes).\nConstruct or analyse a URL. URL is an atom holding  a URL or a variable. Attributes is a list of  components. Each component is of the format Name(Value). Defined  components are:  protocol(Protocol): The used protocol. This is, after the optional url:, an  identifier separated from the remainder of the URL using :. parse_url/2 assumes the http  protocol if no protocol is specified and the URL can be  parsed as a valid HTTP url. In addition to the RFC-1738 specified  protocols, the file protocol is supported as well.\n\nhost(Host): Host-name or IP-address on which the resource is located.  Supported by all network-based protocols.\n\nport(Port): Integer port-number to access on the \\arg{Host}. This only  appears if the port is explicitly specified in the URL.  Implicit default ports (e.g., 80 for HTTP) do not appear in the  part-list.\n\npath(Path): (File-) path addressed by the URL. This is supported for the ftp, http and file protocols. If  no path appears, the library generates the path /.\n\nsearch(ListOfNameValue): Search-specification of HTTP URL. This is the part after the ?, normally used to transfer data from HTML forms that use  the GET protocol. In the URL it consists of a  www-form-encoded list of Name=Value pairs. This is mapped to a list of  Prolog Name=Value terms with decoded names and values.\n\nfragment(Fragment): Fragment specification of HTTP URL. This is the  part after the # character.\n\n  The example below illustrates all of this for an HTTP URL. \n\n\n\n?- parse_url('http://www.xyz.org/hello?msg=Hello+World%21#x',\n       P).\n\nP = [ protocol(http),\n      host('www.xyz.org'),\n      fragment(x),\n      search([ msg = 'Hello World!'\n             ]),\n      path('/hello')\n    ]\n\n  By instantiating the parts-list this predicate can be used to create  a URL.\n\n",
    "prefix":"parse_url"
  },
  "url:parse_url/3": {
    "body":"parse_url(${1:URL}, ${2:BaseURL}, ${3:Attributes})$4\n$0",
    "description":"[det]parse_url(+URL, +BaseURL, -Attributes).\nSimilar to parse_url/2  for relative URLs. If URL is relative, it is resolved using  the absolute URL BaseURL.",
    "prefix":"parse_url"
  },
  "url:parse_url_search/2": {
    "body":"parse_url_search(${1:Spec}, ${2:Fields})$3\n$0",
    "description":"[det]parse_url_search(?Spec, ?Fields:list(Name=Value)).\nConstruct or analyze an HTTP search specification. This deals with form  data using the MIME-type application/x-www-form-urlencoded as used in HTTP GET  requests.",
    "prefix":"parse_url_search"
  },
  "url:set_url_encoding/2": {
    "body":"set_url_encoding(${1:Old}, ${2:New})$3\n$0",
    "description":"[semidet]set_url_encoding(?Old, +New).\nQuery and set the encoding for URLs. The default is utf8.  The only other defined value is iso_latin_1.  To be done: Having a global flag is highly inconvenient, but a work-around for old  sites using ISO Latin 1 encoding.\n\n ",
    "prefix":"set_url_encoding"
  },
  "url:url_iri/2": {
    "body":"url_iri(${1:Encoded}, ${2:Decoded})$3\n$0",
    "description":"[det]url_iri(-Encoded, +Decoded).\nConvert between a URL, encoding in US-ASCII and an IRI. An IRI is a  fully expanded Unicode string. Unicode strings are first encoded into  UTF-8, after which %-encoding takes place.",
    "prefix":"url_iri"
  },
  "url:www_form_encode/2": {
    "body":"www_form_encode(${1:Value}, ${2:XWWWFormEncoded})$3\n$0",
    "description":"[det]www_form_encode(-Value, +XWWWFormEncoded).\nEn/decode to/from application/x-www-form-encoded. Encoding encodes all  characters except RFC 3986 unreserved (ASCII alnum (see code_type/2)),  and one of \"-._~\" using percent encoding. Newline is mapped  to %OD%OA. When decoding, newlines appear as a single  newline (10) character.  Note that a space is encoded as %20 instead of +.  Decoding decodes both to a space. \n\ndeprecated: Use uri_encoded/3 for new code.\n\n ",
    "prefix":"www_form_encode"
  },
  "use_module/1": {
    "body":"use_module(${1:Files})$2\n$0",
    "description":"use_module(+Files).\nLoad the file(s) specified with Files just like ensure_loaded/1.  The files must all be module files. All exported predicates from the  loaded files are imported into the module from which this predicate is  called. This predicate is equivalent to ensure_loaded/1,  except that it raises an error if Files are not module files.  The imported predicates act as weak symbols in the module  into which they are imported. This implies that a local definition of a  predicate overrides (clobbers) the imported definition. If the flag warn_override_implicit_import  is true (default), a warning is printed. Below is an  example of a module that uses library(lists), but redefines flatten/2,  giving it a totally different meaning: \n\n\n\n:- module(shapes, []).\n:- use_module(library(lists)).\n\nflatten(cube, square).\nflatten(ball, circle).\n\n  Loading the above file prints the following message: \n\n\n\nWarning: /home/janw/Bugs/Import/t.pl:5:\n        Local definition of shapes:flatten/2\n        overrides weak import from lists\n\n  This warning can be avoided by (1) using use_module/2  to only import the predicates from the lists library that  are actually used in the `shapes' module, (2) using the except([flatten/2])  option of use_module/2,  (3) use :- abolish(flatten/2).  before the local definition or (4) setting warn_override_implicit_import  to false. Globally disabling this warning is only  recommended if overriding imported predicates is common as a result of  design choices or the program is ported from a system that silently  overrides imported predicates. \n\nNote that it is always an error to import two modules with use_module/1  that export the same predicate. Such conflicts must be resolved with use_module/2  as described above.\n\n",
    "prefix":"use_module"
  },
  "use_module/2": {
    "body":"use_module(${1:File}, ${2:ImportList})$3\n$0",
    "description":"use_module(+File, +ImportList).\nLoad File, which must be a module file, and import the  predicates as specified by ImportList. ImportList  is a list of predicate indicators specifying the predicates that will be  imported from the loaded module. ImportList also allows for  renaming or import-everything-except. See also the import  option of load_files/2.  The first example below loads member/2  from the lists library and append/2  under the name list_concat, which is how this predicate is  named in YAP. The second example loads all exports from library option  except for meta_options/3.  These renaming facilities are generally used to deal with portability  issues with as few changes as possible to the actual code. See also section  C and section 6.7.  \n\n:- use_module(library(lists), [ member/2,\n                                append/2 as list_concat\n                              ]).\n:- use_module(library(option), except([meta_options/3])).\n\n  \n\n",
    "prefix":"use_module"
  },
  "utf8:utf8_codes/3": {
    "body": ["utf8_codes(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"utf8_codes('Param1','Param2','Param3')",
    "prefix":"utf8_codes"
  },
  "uuid:crypt/2": {
    "body":"crypt(${1:Plain}, ${2:Encrypted})$3\n$0",
    "description":"crypt(+Plain, ?Encrypted).\nThis predicate can be used in three modes. To test whether a password  matches an encrypted version thereof, simply run with both arguments  fully instantiated. To generate a default encrypted version of Plain, run with unbound Encrypted and this  argument is unified to a list of character codes holding an encrypted  version.  The library supports two encryption formats: traditional Unix  DES-hashes2On non-Unix systems,  crypt() is provided by the NetBSD library. The license header is added  at the end of this document. and FreeBSD compatible MD5  hashes (all platforms). MD5 hashes start with the magic sequence $1$,  followed by an up to 8 character salt. DES hashes start with a  2 character salt. Note that a DES hash considers only the first 8  characters. The MD5 considers the whole string. \n\nSalt and algorithm can be forced by instantiating the start of Encrypted with it. This is typically used to force MD5  hashes: \n\n\n\n?- phrase(\"$1$\", E, _),\n   crypt(\"My password\", E),\n   format('~s~n', [E]).\n\n$1$qdaDeDZn$ZUxSQEESEHIDCHPNc3fxZ1\n\n  Encrypted is always a list of ASCII character codes. Plain  only supports ISO-Latin-1 passwords in the current implementation. \n\nPlain is either an atom, SWI-Prolog string, list of  characters or list of character-codes. It is not advised to use atoms,  as this implies the password will be available from the Prolog heap as a  defined atom.\n\n",
    "prefix":"crypt"
  },
  "uuid:hash_atom/2": {
    "body":"hash_atom(${1:Hash}, ${2:HexAtom})$3\n$0",
    "description":"hash_atom(+Hash, -HexAtom).\nTrue when HexAtom is the commonly used hexadecimal encoding  of the hash code. E.g.,  \n\n?- sha_hash('SWI-Prolog', Hash, []),\n   hash_atom(Hash, Hex).\nHash = [61, 128, 252, 38, 121, 69, 229, 85, 199|...],\nHex = '3d80fc267945e555c730403bd0ab0716e2a68c68'.\n\n  \n\n",
    "prefix":"hash_atom"
  },
  "uuid:hmac_sha/4": {
    "body":"hmac_sha(${1:Key}, ${2:Data}, ${3:HMAC}, ${4:Options})$5\n$0",
    "description":"hmac_sha(+Key, +Data, -HMAC, +Options).\nQuoting http://en.wikipedia.org/wiki/HMACWikipedia: ``A keyed-hash message authentication code, or HMAC, is a type of  message authentication code (MAC) calculated using a cryptographic hash  function in combination with a secret key. As with any MAC, it may be  used to simultaneously verify both the data integrity and the  authenticity of a message. Any iterative cryptographic hash function,  such as MD5 or SHA-1, may be used in the calculation of an HMAC; the  resulting MAC algorithm is termed HMAC-MD5 or HMAC-SHA-1 accordingly.  The cryptographic strength of the HMAC depends upon the cryptographic  strength of the underlying hash function, on the size and quality of the  key and the size of the hash output length in bits.''  Key and Data are either an atom, packed string  or list of character codes. HMAC is unified with a list of  integers representing the authentication code. Options is the  same as for sha_hash/3,  but currently only sha1 and sha256 are  supported.\n\n",
    "prefix":"hmac_sha"
  },
  "uuid:sha_hash/3": {
    "body":"sha_hash(${1:Data}, ${2:Hash}, ${3:Options})$4\n$0",
    "description":"sha_hash(+Data, -Hash, +Options).\nHash is the SHA hash of Data. Data is either an atom, packed  string or list of character codes. Hash is unified with a  list of bytes (integers in the range 0..255) representing the hash. See hash_atom/2  to convert this into the more commonly seen hexadecimal representation.  The conversion is controlled by Options:  algorithm(+Algorithm): One of sha1 (default), sha224, sha256, sha384 or sha512\n\nencoding(+Encoding): This option defines the mapping from Prolog (Unicode) text to bytes on  which the SHA algorithm is performed. It has two values. The defualt is utf8,  which implies that Unicode text is encoded as UTF-8 bytes. This option  can deal with any atom. The alternative is octet, which implies that the text is considered as a  sequence of bytes. This is suitable for e.g., atoms that represent  binary data. An error is raised if the text contains code-points outside  the range 0..255.\n\n ",
    "prefix":"sha_hash"
  },
  "uuid:uuid/1": {
    "body":"uuid(${1:UUID})$2\n$0",
    "description":"[det]uuid(-UUID).\nUUID is an atom representing a new UUID. This is  the same as calling uuid(UUID, []). See uuid/2  for options.",
    "prefix":"uuid"
  },
  "uuid:uuid/2": {
    "body":"uuid(${1:UUID}, ${2:Options})$3\n$0",
    "description":"[det]uuid(-UUID, +Options).\nCreate a new UUID according to Options. The  following options are defined:  version(+Versions): Integer in the range 1..5, which specifies the UUID version  that is created. Default is 1.\n\ndns(DNS): url(URL): oid(OID): x500(X500): Provide additional context information for UUIDs using version 3 or 5.  If there is no explicit version option, UUID version 3 is  used.\n\nformat(+Format): Representation of the UUID. Default is atom,  yielding atoms such as 8304efdd-bd6e-5b7c-a27f-83f3f05c64e0.  The alternative is integer, returning a large integer that  represents the 128 bits of the UUID.\n\n ",
    "prefix":"uuid"
  },
  "var/1": {
    "body":"var(${1:Term})$2\n$0",
    "description":"[ISO]var(@Term).\nTrue if Term currently is a free variable.",
    "prefix":"var"
  },
  "var_number/2": {
    "body":"var_number(${1:Term}, ${2:VarNumber})$3\n$0",
    "description":"var_number(@Term, -VarNumber).\nTrue if Term is numbered by numbervars/3  and VarNumber is the number given to this variable. This  predicate avoids the need for unification with '$VAR'(X)  and opens the path for replacing this valid Prolog term by an internal  representation that has no textual equivalent.",
    "prefix":"var_number"
  },
  "var_property/2": {
    "body":"var_property(${1:Var}, ${2:Property})$3\n$0",
    "description":"var_property(+Var, ?Property).\nTrue when Property is a property of Var. These  properties are available during goal- and term-expansion. Defined  properties are below. Future versions are likely to provide more  properties, such as whether the variable is a singleton or whether the  variable is referenced in the remainder of the term. See also goal_expansion/2.  fresh(Bool): Bool has the value true if the variable is guaranteed to be  unbound at entry of the goal, otherwise its value is false.  This implies that the variable first appears in this goal or a previous  appearance was in a negation (\\+/1)  or a different branch of a disjunction.\n\nname(Name): True when variable appears with the given name in the source.\n\n ",
    "prefix":"var_property"
  },
  "variant_hash/2": {
    "body":"variant_hash(${1:Term}, ${2:HashKey})$3\n$0",
    "description":"[det]variant_hash(+Term, -HashKey).\nSimilar to variant_sha1/2,  but using a non-cryptographic hash and produces an integer result like term_hash/2.  This version does deal with attributed variables, processing them as  normal variables. This hash is primarily intended to speedup finding  variant terms in a set of terms. bugAs variant_sha1/2,  cyclic terms result in an exception.",
    "prefix":"variant_hash"
  },
  "variant_sha1/2": {
    "body":"variant_sha1(${1:Term}, ${2:SHA1})$3\n$0",
    "description":"[det]variant_sha1(+Term, -SHA1).\nCompute a SHA1-hash from Term. The hash is represented as a  40-byte hexadecimal atom. Unlike term_hash/2  and friends, this predicate produces a hash key for non-ground terms.  The hash is invariant over variable-renaming (see =@=/2)  and constants over different invocations of Prolog.bugThe  hash depends on word order (big/little-endian) and the wordsize (32/64  bits).  This predicate raises an exception when trying to compute the hash on  a cyclic term or attributed term. Attributed terms are not handled  because subsumes_chk/2  is not considered well defined for attributed terms. Cyclic terms are  not supported because this would require establishing a canonical cycle.  That is, given A=[a|A] and B=[a,a|B], A and B should produce the same hash. This is not  (yet) implemented. \n\nThis hash was developed for lookup of solutions to a goal stored in a  table. By using a cryptographic hash, heuristic algorithms can often  ignore the possibility of hash collisions and thus avoid storing the  goal term itself as well as testing using =@=/2.\n\n",
    "prefix":"variant_sha1"
  },
  "varnumbers:max_var_number/3": {
    "body":"max_var_number(${1:Term}, ${2:Start}, ${3:Max})$4\n$0",
    "description":"[det]max_var_number(+Term, +Start, -Max).\nTrue when Max is the max of Start and the highest  numbered $VAR(N) term.  author: Vitor Santos Costa\n\nCompatibility: YAP\n\n ",
    "prefix":"max_var_number"
  },
  "varnumbers:numbervars/1": {
    "body":"numbervars(${1:Term})$2\n$0",
    "description":"[det]numbervars(+Term).\nNumber variables in Term using $VAR(N). Equivalent to numbervars(Term, 0, _).  See also: numbervars/3, numbervars/4\n\n ",
    "prefix":"numbervars"
  },
  "varnumbers:varnumbers/2": {
    "body":"varnumbers(${1:Term}, ${2:Copy})$3\n$0",
    "description":"[det]varnumbers(+Term, -Copy).\nInverse of numbervars/1.  Equivalent to varnumbers(Term, 0, Copy).",
    "prefix":"varnumbers"
  },
  "varnumbers:varnumbers/3": {
    "body":"varnumbers(${1:Term}, ${2:Start}, ${3:Copy})$4\n$0",
    "description":"[det]varnumbers(+Term, +Start, -Copy).\nInverse of numbervars/3.  True when Copy is a copy of Term with all  variables numbered >= Start consistently  replaced by fresh variables. Variables in Term are shared  with Copy rather than replaced by fresh variables.  Errors: domain_error(acyclic_term, Term) if Term is  cyclic.\n\nCompatibility: Quintus, SICStus. Not in YAP version of this library\n\n ",
    "prefix":"varnumbers"
  },
  "varnumbers:varnumbers_names/3": {
    "body":"varnumbers_names(${1:Term}, ${2:Copy}, ${3:VariableNames})$4\n$0",
    "description":"[det]varnumbers_names(+Term, -Copy, -VariableNames).\nIf Term is a term with numbered and named variables using the  reserved term '$VAR'(X), Copy is a copy of Term  where each '$VAR'(X) is consistently replaced by a fresh variable and  Bindings is a list X = Var, relating the X terms  with the variable it is mapped to.  See also: numbervars/3, varnumbers/3, read_term/3  using the variable_names option.\n\n ",
    "prefix":"varnumbers_names"
  },
  "version/0": {
    "body":"version$1\n$0",
    "description":"version.\nWrite the SWI-Prolog banner message as well as additional messages  registered using version/1.  This is the default initialization goal which can be modified  using -g.",
    "prefix":"version"
  },
  "version/1": {
    "body":"version(${1:Message})$2\n$0",
    "description":"version(+Message).\nRegister additional messages to be printed by version/0.  Each registered message is handed to the message translation DCG and can  thus be defined using the hook prolog:message//1. If not defined, it is  simply printed.",
    "prefix":"version"
  },
  "visible/1": {
    "body":"visible(${1:Ports})$2\n$0",
    "description":"visible(+Ports).\nSet the ports shown by the debugger. See leash/1  for a description of the Ports specification. Default is full.",
    "prefix":"visible"
  },
  "wait_for_input/3": {
    "body":"wait_for_input(${1:ListOfStreams}, ${2:ReadyList}, ${3:TimeOut})$4\n$0",
    "description":"[det]wait_for_input(+ListOfStreams, -ReadyList, +TimeOut).\nWait for input on one of the streams in ListOfStreams and  return a list of streams on which input is available in ReadyList. wait_for_input/3  waits for at most TimeOut seconds. TimeOut may be  specified as a floating point number to specify fractions of a second.  If TimeOut equals infinite, wait_for_input/3  waits indefinitely. If Timeout is 0 or 0.0 this predicate  returns without waiting.85Prior to  7.3.23, the integer value `0' was the same as infinite.  This predicate can be used to implement timeout while reading and to  handle input from multiple sources and is typically used to wait for  multiple (network) sockets. On Unix systems it may be used on any stream  that is associated with a system file descriptor. On Windows it can only  be used on sockets. If ListOfStreams contains a stream that  is not associated with a supported device, a domain_error(waitable_stream,  Stream) is raised. \n\nThe example below waits for input from the user and an explicitly  opened secondary terminal stream. On return, Inputs may hold user_input or P4 or both. \n\n\n\n?- open('/dev/ttyp4', read, P4),\n   wait_for_input([user_input, P4], Inputs, 0).\n\n  When  available, the implementation is based on the poll() system call. The  poll() puts no additional restriction on the number of open files the  process may have. It does limit the time to 2^31-1  milliseconds (a bit less than 25 days). Specifying a too large timeout  raises a representation_error(timeout) exception. If poll() is not  supported by the OS, select() is used. The select() call can only handle  file descriptors up to FD_SETSIZE. If the set contains a  descriptor that exceeds this limit a representation_error('FD_SETSIZE') is raised. \n\nNote that wait_for_input/3  returns streams that have data waiting. This does not mean you can, for  example, call read/2  on the stream without blocking as the stream might hold an incomplete  term. The predicate set_stream/2  using the option timeout(Seconds) can be used to make the  stream generate an exception if no new data arrives within the timeout  period. Suppose two processes communicate by exchanging Prolog terms.  The following code makes the server immune for clients that write an  incomplete term: \n\n\n\n    ...,\n    tcp_accept(Server, Socket, _Peer),\n    tcp_open(Socket, In, Out),\n    set_stream(In, timeout(10)),\n    catch(read(In, Term), _, (close(Out), close(In), fail)),\n    ...,\n\n ",
    "prefix":"wait_for_input"
  },
  "when/2": {
    "body":"when(${1:Condition}, ${2:Goal})$3\n$0",
    "description":"when(@Condition, :Goal).\nExecute Goal when Condition becomes true. Condition  is one of ?=(X, Y), nonvar(X), ground(X), ,(Cond1, Cond2) or ;(Cond1,  Cond2). See also freeze/2  and dif/2.  The implementation can deal with cyclic terms in X and Y.  The when/2  predicate is realised using attributed variables associated with the  module when. It is defined in the autoload library library(when).\n\n",
    "prefix":"when"
  },
  "when:when/2": {
    "body": ["when(${1:Condition}, ${2:Goal})$3\n$0" ],
    "description":"  when(+Condition, :Goal)\n\n   Execute Goal when Condition is satisfied. I.e., Goal is executed\n   as by call/1  if  Condition  is   true  when  when/2  is called.\n   Otherwise  Goal  is  _delayed_  until  Condition  becomes  true.\n   Condition is one of the following:\n\n       * nonvar(X)\n       * ground(X)\n       * ?=(X,Y)\n       * (Cond1,Cond2)\n       * (Cond2;Cond2)\n\n   For example (note the order =a= and =b= are written):\n\n       ==\n       ?- when(nonvar(X), writeln(a)), writeln(b), X = x.\n       b\n       a\n       X = x\n       ==",
    "prefix":"when"
  },
  "wildcard_match/2": {
    "body":"wildcard_match(${1:Pattern}, ${2:String})$3\n$0",
    "description":"wildcard_match(+Pattern, +String).\nTrue if String matches the wildcard pattern Pattern. Pattern is very similar to the Unix csh pattern  matcher. The patterns are given below: ? Matches one  arbitrary character. * Matches any  number of arbitrary characters. [ ... ] Matches one of the  characters specified between the brackets. <char1>-<char2>  indicates a range. {...} Matches any of the  patterns of the comma-separated list between the braces.  Example: \n\n\n\n?- wildcard_match('[a-z]*.{pro,pl}[%~]', 'a_hello.pl%').\ntrue.\n\n ",
    "prefix":"wildcard_match"
  },
  "win_add_dll_directory/1": {
    "body":"win_add_dll_directory(${1:AbsDir})$2\n$0",
    "description":"win_add_dll_directory(+AbsDir).\nThis predicate adds a directory to the search path for dependent DLL  files. If possible, this is achieved with win_add_dll_directory/2.  Otherwise, %PATH% is extended with the provided directory. AbsDir may be specified in the Prolog canonical syntax. See prolog_to_os_filename/2.  Note that use_foreign_library/1  passes an absolute path to the DLL if the destination DLL can be located  from the specification using absolute_file_name/3.",
    "prefix":"win_add_dll_directory"
  },
  "win_add_dll_directory/2": {
    "body":"win_add_dll_directory(${1:AbsDir}, ${2:Cookie})$3\n$0",
    "description":"win_add_dll_directory(+AbsDir, -Cookie).\nThis predicate adds a directory to the search path for dependent DLL  files. If the call is successful it unifies Cookie with a  handle that must be passed to win_remove_dll_directory/1  to remove the directory from the search path. Error conditions:  \n\nThis predicate is available in the Windows port of SWI-Prolog  starting from 6.3.8/6.2.6.\nThis predicate fails if Windows does not yet support the  underlying primitives. These are available in recently patched Windows7  systems and later.\nThis predicate throws an acception if the provided path is invalid  or the underlying Windows API returns an error.\n\n  If open_shared_object/2  is passed an absolute path to a DLL on a Windows installation  that supports AddDllDirectory() and friends,124Windows7  with up-to-date patches or Windows8. SWI-Prolog uses  LoadLibraryEx() with the flags LOAD_LIBRARY_SEARCH_DLL_LOAD_DIR and LOAD_LIBRARY_SEARCH_DEFAULT_DIRS. In this scenario,  directories from %PATH% and not searched.  Additional directories can be added using win_add_dll_directory/2.\n\n",
    "prefix":"win_add_dll_directory"
  },
  "win_exec/2": {
    "body":"win_exec(${1:Command}, ${2:Show})$3\n$0",
    "description":"win_exec(+Command, +Show).\nWindows only. Spawns a Windows task without waiting for its completion. Show  is one of the Win32 SW_* constants written in lowercase  without the SW_*: hide maximize minimize restore show showdefault showmaximized showminimized showminnoactive showna shownoactive shownormal. In addition, iconic is a synonym  for minimize and normal for shownormal.",
    "prefix":"win_exec"
  },
  "win_folder/2": {
    "body":"win_folder(${1:Name}, ${2:Directory})$3\n$0",
    "description":"win_folder(?Name, -Directory).\nTrue if Name is the Windows `CSIDL' of Directory.  If Name is unbound, all known Windows special paths are  generated. Name is the CSIDL after deleting the leading CSIDL_  and mapping the constant to lowercase. Check the Windows documentation  for the function SHGetSpecialFolderPath() for a description of the  defined constants. This example extracts the `My Documents' folder:  \n\n?- win_folder(personal, MyDocuments).\n\nMyDocuments = 'C:/Documents and Settings/jan/My Documents'\n\n ",
    "prefix":"win_folder"
  },
  "win_has_menu/0": {
    "body":"win_has_menu$1\n$0",
    "description":"win_has_menu.\nTrue if win_insert_menu/2  and win_insert_menu_item/4  are present.",
    "prefix":"win_has_menu"
  },
  "win_insert_menu/2": {
    "body":"win_insert_menu(${1:Label}, ${2:Before})$3\n$0",
    "description":"win_insert_menu(+Label, +Before).\nInsert a new entry (pulldown) in the menu. If the menu already contains  this entry, nothing is done. The Label is the label and,  using the Windows convention, a letter prefixed with &  is underlined and defines the associated accelerator key. Before  is the label before which this one must be inserted. Using -  adds the new entry at the end (right). For example, the call below adds  an Application entry just before the Help menu.  \n\nwin_insert_menu('&Application', '&Help')\n\n ",
    "prefix":"win_insert_menu"
  },
  "win_insert_menu_item/4": {
    "body":"win_insert_menu_item(${1:Pulldown}, ${2:Label}, ${3:Before}, ${4:Goal})$5\n$0",
    "description":"win_insert_menu_item(+Pulldown, +Label, +Before, :Goal).\nAdd an item to the named Pulldown menu. Label and Before are handled as in win_insert_menu/2,  but the label - inserts a separator. Goal  is called if the user selects the item.",
    "prefix":"win_insert_menu_item"
  },
  "win_menu:init_win_menus/0": {
    "body": ["init_win_menus$1\n$0" ],
    "description":"init_win_menus",
    "prefix":"init_win_menus"
  },
  "win_registry_get_value/3": {
    "body":"win_registry_get_value(${1:Key}, ${2:Name}, ${3:Value})$4\n$0",
    "description":"win_registry_get_value(+Key, +Name, -Value).\nWindows only. Fetches the value of a Windows registry key. Key  is an atom formed as a path name describing the desired registry key. Name is the desired attribute name of the key. Value  is unified with the value. If the value is of type DWORD,  the value is returned as an integer. If the value is a string, it is  returned as a Prolog atom. Other types are currently not supported. The  default `root' is HKEY_CURRENT_USER. Other roots can be  specified explicitly as HKEY_CLASSES_ROOT, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE or HKEY_USERS. The example  below fetches the extension to use for Prolog files (see README.TXT  on the Windows version):  \n\n?- win_registry_get_value(\n       'HKEY_LOCAL_MACHINE/Software/SWI/Prolog',\n       fileExtension,\n       Ext).\n\nExt = pl\n\n ",
    "prefix":"win_registry_get_value"
  },
  "win_remove_dll_directory/1": {
    "body":"win_remove_dll_directory(${1:Cookie})$2\n$0",
    "description":"win_remove_dll_directory(-Cookie).\nRemove a DLL search directory installed using win_add_dll_directory/2.",
    "prefix":"win_remove_dll_directory"
  },
  "win_shell/2": {
    "body":"win_shell(${1:Operation}, ${2:File})$3\n$0",
    "description":"win_shell(+Operation, +File).\nSame as win_shell(Operation, File, normal)",
    "prefix":"win_shell"
  },
  "win_shell/3": {
    "body":"win_shell(${1:Operation}, ${2:File}, ${3:Show})$4\n$0",
    "description":"win_shell(+Operation, +File, +Show).\nWindows only. Opens the document File using the Windows shell  rules for doing so. Operation is one of open, print or explore or another operation  registered with the shell for the given document type. On modern systems  it is also possible to pass a URL as File,  opening the URL in Windows default browser. This call interfaces to the  Win32 API ShellExecute(). The Show argument determines the  initial state of the opened window (if any). See win_exec/2  for defined values.",
    "prefix":"win_shell"
  },
  "win_window_pos/1": {
    "body":"win_window_pos(${1:ListOfOptions})$2\n$0",
    "description":"win_window_pos(+ListOfOptions).\nInterface to the MS-Windows SetWindowPos() function, controlling size,  position and stacking order of the window. ListOfOptions is a  list that may hold any number of the terms below:  size(W, H): Change the size of the window. W and H are  expressed in character units.\n\nposition(X, Y): Change the top-left corner of the window. The values are expressed in  pixel units.\n\nzorder(ZOrder): Change the location in the window stacking order. Values are bottom, top, topmost and notopmost. Topmost windows are displayed above all other windows.\n\nshow(Bool): If true, show the window, if false hide the  window.\n\nactivate: If present, activate the window.\n\n ",
    "prefix":"win_window_pos"
  },
  "window_title/2": {
    "body":"window_title(${1:Old}, ${2:New})$3\n$0",
    "description":"window_title(-Old, +New).\nUnify Old with the title displayed in the console and change  the title to New.bugThis  predicate should have been called win_window_title for  consistent naming.",
    "prefix":"window_title"
  },
  "with_mutex/2": {
    "body":"with_mutex(${1:MutexId}, ${2:Goal})$3\n$0",
    "description":"with_mutex(+MutexId, :Goal).\nExecute Goal while holding MutexId. If Goal  leaves choice points, these are destroyed (as in once/1).  The mutex is unlocked regardless of whether Goal succeeds,  fails or raises an exception. An exception thrown by Goal is  re-thrown after the mutex has been successfully unlocked. See also mutex_create/1  and setup_call_cleanup/3.  Although described in the thread section, this predicate is also  available in the single-threaded version, where it behaves simply as once/1.\n\n",
    "prefix":"with_mutex"
  },
  "with_output_to/2": {
    "body":"with_output_to(${1:Output}, ${2:Goal})$3\n$0",
    "description":"with_output_to(+Output, :Goal).\nRun Goal as once/1,  while characters written to the current output are sent to Output.  The predicate is SWI-Prolog-specific, inspired by various posts to the  mailinglist. It provides a flexible replacement for predicates such as  sformat/3 , swritef/3, term_to_atom/2, atom_number/2  converting numbers to atoms, etc. The predicate format/3  accepts the same terms as output argument.  Applications should generally avoid creating atoms by breaking and  concatenating other atoms, as the creation of large numbers of  intermediate atoms generally leads to poor performance, even more so in  multithreaded applications. This predicate supports creating difference  lists from character data efficiently. The example below defines the DCG  rule term/3  to insert a term in the output: \n\n\n\nterm(Term, In, Tail) :-\n        with_output_to(codes(In, Tail), write(Term)).\n\n?- phrase(term(hello), X).\n\nX = [104, 101, 108, 108, 111]\n\n  A Stream handle or alias: Temporarily switch current output to the given stream. Redirection using with_output_to/2  guarantees the original output is restored, also if Goal fails or raises an exception. See also call_cleanup/2.\n\natom(-Atom): Create an atom from the emitted characters. Please note the remark  above.\n\nstring(-String): Create a string object as defined in section  5.2.\n\ncodes(-Codes): Create a list of character codes from the emitted characters, similar to atom_codes/2.\n\ncodes(-Codes, -Tail): Create a list of character codes as a difference list.\n\nchars(-Chars): Create a list of one-character atoms from the emitted characters,  similar to atom_chars/2.\n\nchars(-Chars, -Tail): Create a list of one-character atoms as a difference list.\n\n ",
    "prefix":"with_output_to"
  },
  "working_directory/2": {
    "body":"working_directory(${1:Old}, ${2:New})$3\n$0",
    "description":"working_directory(-Old, +New).\nUnify Old with an absolute path to the current working  directory and change working directory to New. Use the  pattern working_directory(CWD, CWD) to get the current directory.  See also absolute_file_name/2  and chdir/1.bugSome  of the file I/O predicates use local filenames. Changing directory while  file-bound streams are open causes wrong results on telling/1, seeing/1  and current_stream/3.  Note that the working directory is shared between all threads.",
    "prefix":"working_directory"
  },
  "write/1": {
    "body":"write(${1:Term})$2\n$0",
    "description":"[ISO]write(+Term).\nWrite Term to the current output, using brackets and  operators where appropriate.",
    "prefix":"write"
  },
  "write/2": {
    "body":"write(${1:Stream}, ${2:Term})$3\n$0",
    "description":"[ISO]write(+Stream, +Term).\nWrite Term to Stream.",
    "prefix":"write"
  },
  "write_canonical/1": {
    "body":"write_canonical(${1:Term})$2\n$0",
    "description":"[ISO]write_canonical(+Term).\nWrite Term on the current output stream using standard  parenthesised prefix notation (i.e., ignoring operator declarations).  Atoms that need quotes are quoted. Terms written with this predicate can  always be read back, regardless of current operator declarations.  Equivalent to write_term/2  using the options ignore_ops, quoted and numbervars after numbervars/4  using the singletons option.  Note that due to the use of numbervars/4,  non-ground terms must be written using a single write_canonical/1  call. This used to be the case anyhow, as garbage collection between  multiple calls to one of the write predicates can change the _G<NNN>  identity of the variables.\n\n",
    "prefix":"write_canonical"
  },
  "write_canonical/2": {
    "body":"write_canonical(${1:Stream}, ${2:Term})$3\n$0",
    "description":"[ISO]write_canonical(+Stream, +Term).\nWrite Term in canonical form on Stream.",
    "prefix":"write_canonical"
  },
  "write_length/3": {
    "body":"write_length(${1:Term}, ${2:Length}, ${3:Options})$4\n$0",
    "description":"[semidet]write_length(+Term, -Length, +Options).\nTrue when Length is the number of characters emitted for write_termTerm, Options . In addition to valid options for write_term/2,  it processes the option:  max_length(+MaxLength): If provided, fail if Length would be larger than MaxLength.  The implementation ensures that the runtime is limited when computing  the length of a huge term with a bounded maximum.\n\n ",
    "prefix":"write_length"
  },
  "write_term/2": {
    "body":"write_term(${1:Term}, ${2:Options})$3\n$0",
    "description":"[ISO]write_term(+Term, +Options).\nThe predicate write_term/2  is the generic form of all Prolog term-write predicates. Valid options  are:  attributes(Atom): Define how attributed variables (see section  7.1) are written. The default is determined by the Prolog flag write_attributes.  Defined values are ignore (ignore the attribute), dots  (write the attributes as {...}), write (simply  hand the attributes recursively to write_term/2)  and portray (hand the attributes to attr_portray_hook/2).\n\nback_quotes(Atom): Fulfills the same role as the back_quotes  prolog flag. Notably, the value string causes string  objects to be printed between back quotes and symbol_char  causes the backquote to be printed unquoted. In all other cases the  backquote is printed as a quoted atom.\n\nbrace_terms(Bool): If true (default), write {}(X) as {X}.  See also dotlists and ignore_ops.\n\nblobs(Atom): Define how non-text blobs are handled. By default, this is left to the  write handler specified with the blob type. Using portray, portray/1  is called for each blob encountered. See section  11.4.7.\n\ncharacter_escapes(Bool): If true and quoted(true) is active, special  characters in quoted atoms and strings are emitted as ISO escape  sequences. Default is taken from the reference module (see below).\n\ncycles(Bool): If true (default), cyclic terms are written as @(Template, Substitutions), where Substitutions  is a list Var = Value. If cycles is false, max_depth is not given, and Term is cyclic, write_term/2  raises a domain_error.86The  cycles option and the cyclic term representation using the @-term are  copied from SICStus Prolog. However, the default in SICStus is set to false  and SICStus writes an infinite term if not protected by, e.g., the depth_limit  option. See also the cycles option in read_term/2.\n\ndotlists(Bool): If true (default false), write lists using the  dotted term notation rather than the list notation.87Copied  from ECLiPSe. Note that as of version7, the list  constructor is '[|]'. Using dotlists(true), write_term/2  writes a list using `.' as constructor. This is intended for  communication with programs such as other Prolog systems, that rely on  this notation.\n\nfullstop(Bool): If true (default false), add a fullstop token  to the output. The dot is preceeded by a space if needed and followed by  a space (default) or newline if the nl(true) option is also  given.88Compatible with http://eclipseclp.org/doc/bips/kernel/ioterm/write_term-3.htmlECLiPSe\n\nignore_ops(Bool): If true, the generic term representation (<functor>(<args>  ... )) will be used for all terms. Otherwise (default), operators will  be used where appropriate.89In  traditional systems this flag also stops the syntactic sugar notation  for lists and brace terms. In SWI-Prolog, these are controlled by the  separate options dotlists and brace_terms.\n\nmax_depth(Integer): If the term is nested deeper than Integer, print the  remainder as ellipses ( ... ). A 0 (zero) value (default) imposes no  depth limit. This option also delimits the number of printed items in a  list. Example:  \n\n?- write_term(a(s(s(s(s(0)))), [a,b,c,d,e,f]),\n              [max_depth(3)]).\na(s(s(...)), [a, b|...])\ntrue.\n\n  Used by the top level and debugger to limit screen output. See also  the Prolog flags answer_write_options  and debugger_write_options.\n\nmodule(Module): Define the reference module (default user). This defines  the default value for the character_escapes  option as well as the operator definitions to use. See also op/3.\n\nnl(Bool): Add a newline to the output. See also the fullstop option.\n\nnumbervars(Bool): If true, terms of the format $VAR(N), where N  is a non-negative integer, will be written as a variable name. If N  is an atom it is written without quotes. This extension allows for  writing variables with user-provided names. The default is false.  See also numbervars/3  and the option variable_names.\n\npartial(Bool): If true (default false), do not reset the  logic that inserts extra spaces that separate tokens where needed. This  is intended to solve the problems with the code below. Calling write_value(.)  writes .., which cannot be read. By adding partial(true)  to the option list, it correctly emits . .. Similar  problems appear when emitting operators using multiple calls to write_term/3.  \n\nwrite_value(Value) :-\n        write_term(Value, [partial(true)]),\n        write('.'), nl.\n\n \n\nportray(Bool): Same as portrayed(Bool). Deprecated.\n\nportray_goal(:Goal): Implies portray(true), but calls Goal rather  than the predefined hook portray/1. Goal  is called through call/3,  where the first argument is Goal, the second is the term to  be printed and the 3rd argument is the current write option list. The  write option list is copied from the write_term call, but the list is  guaranteed to hold an option priority that reflects the  current priority.\n\nportrayed(Bool): If true, the hook portray/1  is called before printing a term that is not a variable. If portray/1  succeeds, the term is considered printed. See also print/1.  The default is false. This option is an extension to the  ISO write_term options.\n\npriority(Integer): An integer between 0 and 1200 representing the `context priority'.  Default is 1200. Can be used to write partial terms appearing as the  argument to an operator. For example:  \n\n        format('~w = ', [VarName]),\n        write_term(Value, [quoted(true), priority(699)])\n\n \n\nquoted(Bool): If true, atoms and functors that need quotes will be  quoted. The default is false.\n\nspacing(+Spacing): Determines whether and where extra white space is added to enhance  readability. The default is standard, adding only space  where needed for proper tokenization by read_term/3.  Currently, the only other value is next_argument, adding a  space after a comma used to separate arguments in a term or list.\n\nvariable_names(+List): Assign names to variables in Term. List is a list  of terms Name = Var, where Name is an atom that  represents a valid Prolog variable name. Terms where Var is  bound or is a variable that does not appear in Term are  ignored. Raises an error if List is not a list, one of the  members is not a term Name = Var, Name is not an atom or Name does not represent a valid Prolog variable name.  The implementation binds the variables from List to a term '$VAR'(Name). Like write_canonical/1,  terms that where already bound to '$VAR'(X)  before write_term/2  are printed normally, unless the option numbervars(true) is  also provided. If the option numbervars(true) is used, the  user is responsible for avoiding collisions between assigned names and  numbered names. See also the variable_names option of read_term/2. Possible variable attributes (see section  7.1) are ignored. In most cases one should use copy_term/3  to obtain a copy that is free of attributed variables and handle the  associated constraints as appropriate for the use-case.\n\n ",
    "prefix":"write_term"
  },
  "write_term/3": {
    "body":"write_term(${1:Stream}, ${2:Term}, ${3:Options})$4\n$0",
    "description":"[ISO]write_term(+Stream, +Term, +Options).\nAs write_term/2,  but output is sent to Stream rather than the current output.",
    "prefix":"write_term"
  },
  "writef/1": {
    "body":"writef(${1:Atom})$2\n$0",
    "description":"[deprecated]writef(+Atom).\nEquivalent to writef(Atom, []). See writef/2  for details.",
    "prefix":"writef"
  },
  "writef/2": {
    "body":"writef(${1:Format}, ${2:Arguments})$3\n$0",
    "description":"[deprecated]writef(+Format, +Arguments).\nFormatted write. Format is an atom whose characters will be  printed. Format may contain certain special character sequences which  specify certain formatting and substitution actions. Arguments  provides all the terms required to be output.  Escape sequences to generate a single special character: \n\n\n\n\\n Output a newline character  (see also nl/[0,1]) \\l Output a line separator  (same as \\n) \\r Output a carriage return  character (ASCII 13) \\t Output the ASCII character  TAB (9) \\\\ The character \\  is output \\% The character %  is output \\nnn where <nnn>  is an integer (1-3 digits); the character with code <nnn>  is output (NB : <nnn> is read as decimal)   Note that \\l, \\nnn and \\\\ are  interpreted differently when character escapes are in effect. See section 2.15.1.3. \n\nEscape sequences to include arguments from Arguments. Each  time a % escape sequence is found in Format the next argument from Arguments  is formatted according to the specification. \n\n\n\n%t print/1  the next item (mnemonic: term) %w write/1  the next item %q writeq/1  the next item %d Write the term, ignoring  operators. See also write_term/2.  Mnemonic: old Edinburgh display/1 %p print/1  the next item (identical to %t) %n Put the next item as a  character (i.e., it is a character code) %r Write the next item N  times where N is the second item (an integer) %s Write the next item as a  String (so it must be a list of characters) %f Perform a ttyflush/0  (no items used) %Nc Write the next item  Centered in N columns %Nl Write the next item Left  justified in N columns %Nr Write the next item Right  justified in N columns. N is a decimal number with at least one digit. The item must  be an atom, integer, float or string. ",
    "prefix":"writef"
  },
  "writef:swritef/2": {
    "body": ["swritef(${1:String}, ${2:Format})$3\n$0" ],
    "description":"  swritef(-String, +Format) is det.\n  swritef(-String, +Format, +Arguments) is det.\n\n   Use writef/1 or writef/2 and  write   the  result to a _string_.\n   Note that this is a  string   in  the sense of string_codes/2,\n   _not_ a list of character(-code)s.\n\n   @deprecated.  See format/2,3 and/or with_output_to/2.",
    "prefix":"swritef"
  },
  "writef:swritef/3": {
    "body": ["swritef(${1:String}, ${2:Format}, ${3:Arguments})$4\n$0" ],
    "description":"  swritef(-String, +Format) is det.\n  swritef(-String, +Format, +Arguments) is det.\n\n   Use writef/1 or writef/2 and  write   the  result to a _string_.\n   Note that this is a  string   in  the sense of string_codes/2,\n   _not_ a list of character(-code)s.\n\n   @deprecated.  See format/2,3 and/or with_output_to/2.",
    "prefix":"swritef"
  },
  "writef:writef/1": {
    "body": ["writef(${1:Format})$2\n$0" ],
    "description":"  writef(+Format) is det.\n  writef(+Format, +Arguments) is det.\n\n   Formatted write to the  =current_output=.   Format  is  a format\n   specifier. Some escape sequences require  arguments that must be\n   provided in the list Arguments. There   are  two types of escape\n   sequences: special characters  start  with   =|\\|=  and  include\n   arguments start with =|%|=. The special character sequences are:\n\n       | =|\\n|= | Output a newline character |\n       | =|\\l|= | Output a line separator (same as =|\\n|=) |\n       | =|\\r|= | Output a carriage-return character (ASCII 13) |\n       | =|\\r|= | Output a TAB character (ASCII 9) |\n       | =|\\\\|= | Output =|\\|= |\n       | =|\\%|= | Output =|%|= |\n       | =|\\nnn|= | Output character <nnn>. <nnn> is a 1-3 decimal number |\n\n   Escape sequences to include arguments  from Arguments. Each time\n   a %-escape sequence is found in   Format  the next argument from\n   Arguments is formatted according to the specification.\n\n       | =|%t|= | print/1 the next item (mnemonic: term) |\n       | =|%w|= | write/1 the next item |\n       | =|%q|= | writeq/1 the next item  |\n       | =|%d|= | display/1 the next item |\n       | =|%n|= | Put the next item as a character |\n       | =|%r|= | Write the next item N times where N is the second item (an integer) |\n       | =|%s|= | Write the next item as a String (so it must be a list of characters) |\n       | =|%f|= |Perform a ttyflush/0 (no items used) |\n       | =|%Nc|= | Write the next item Centered in N columns. |\n       | =|%Nl|= | Write the next item Left justified in N columns. |\n       | =|%Nr|= | Write the next item Right justified in N columns. |\n\n   @deprecated New code should use format/1, format/2, etc.",
    "prefix":"writef"
  },
  "writef:writef/2": {
    "body": ["writef(${1:Format}, ${2:Arguments})$3\n$0" ],
    "description":"  writef(+Format) is det.\n  writef(+Format, +Arguments) is det.\n\n   Formatted write to the  =current_output=.   Format  is  a format\n   specifier. Some escape sequences require  arguments that must be\n   provided in the list Arguments. There   are  two types of escape\n   sequences: special characters  start  with   =|\\|=  and  include\n   arguments start with =|%|=. The special character sequences are:\n\n       | =|\\n|= | Output a newline character |\n       | =|\\l|= | Output a line separator (same as =|\\n|=) |\n       | =|\\r|= | Output a carriage-return character (ASCII 13) |\n       | =|\\r|= | Output a TAB character (ASCII 9) |\n       | =|\\\\|= | Output =|\\|= |\n       | =|\\%|= | Output =|%|= |\n       | =|\\nnn|= | Output character <nnn>. <nnn> is a 1-3 decimal number |\n\n   Escape sequences to include arguments  from Arguments. Each time\n   a %-escape sequence is found in   Format  the next argument from\n   Arguments is formatted according to the specification.\n\n       | =|%t|= | print/1 the next item (mnemonic: term) |\n       | =|%w|= | write/1 the next item |\n       | =|%q|= | writeq/1 the next item  |\n       | =|%d|= | display/1 the next item |\n       | =|%n|= | Put the next item as a character |\n       | =|%r|= | Write the next item N times where N is the second item (an integer) |\n       | =|%s|= | Write the next item as a String (so it must be a list of characters) |\n       | =|%f|= |Perform a ttyflush/0 (no items used) |\n       | =|%Nc|= | Write the next item Centered in N columns. |\n       | =|%Nl|= | Write the next item Left justified in N columns. |\n       | =|%Nr|= | Write the next item Right justified in N columns. |\n\n   @deprecated New code should use format/1, format/2, etc.",
    "prefix":"writef"
  },
  "writeln/1": {
    "body":"writeln(${1:Term})$2\n$0",
    "description":"writeln(+Term).\nEquivalent to write(Term), nl.. The output stream is  locked, which implies no output from other threads can appear between  the term and newline.",
    "prefix":"writeln"
  },
  "writeln/2": {
    "body":"writeln(${1:Stream}, ${2:Term})$3\n$0",
    "description":"writeln(+Stream, +Term).\nEquivalent to write(Stream, Term), nl(Stream).. The output  stream is locked, which implies no output from other threads can appear  between the term and newline.",
    "prefix":"writeln"
  },
  "writeq/1": {
    "body":"writeq(${1:Term})$2\n$0",
    "description":"[ISO]writeq(+Term).\nWrite Term to the current output, using brackets and  operators where appropriate. Atoms that need quotes are quoted. Terms  written with this predicate can be read back with read/1  provided the currently active operator declarations are identical.",
    "prefix":"writeq"
  },
  "writeq/2": {
    "body":"writeq(${1:Stream}, ${2:Term})$3\n$0",
    "description":"[ISO]writeq(+Stream, +Term).\nWrite Term to Stream, inserting quotes.",
    "prefix":"writeq"
  },
  "www_browser:expand_url_path/2": {
    "body": ["expand_url_path(${1:Spec}, ${2:URL})$3\n$0" ],
    "description":"  expand_url_path(+Spec, -URL)\n\n   Expand URL specifications similar   to absolute_file_name/3. The\n   predicate url_path/2 plays the role of file_search_path/2.\n\n   @error  existence_error(url_path, Spec) if the location is not\n           defined.",
    "prefix":"expand_url_path"
  },
  "www_browser:www_open_url/1": {
    "body":"www_open_url(${1:URL})$2\n$0",
    "description":"www_open_url(+URL).\nOpen URL in an external web browser. The reason to place this  in the library is to centralise the maintenance on this highly platform-  and browser-specific task. It distinguishes between the following cases:  \n\nMS-Windows If it detects MS-Windows it uses win_shell/2  to open the URL. The behaviour and browser started depends on  the version of Windows and Windows-shell configuration, but in general  it should be the behaviour expected by the user.  \nOther platforms On other platforms it tests the environment variable (see getenv/2)  named BROWSER or uses netscape if this variable is  not set. If the browser is either mozilla or netscape, www_open_url/1  first tries to open a new window on a running browser using the -remote  option of Netscape. If this fails or the browser is not mozilla  or netscape the system simply passes the URL as first  argument to the program.\n\n",
    "prefix":"www_open_url"
  },
  "xml_is_dom/1": {
    "body":"xml_is_dom(${1:Term})$2\n$0",
    "description":"xml_is_dom(@Term).\nTrue if Term is an SGML/XML term as produced by one of the  above predciates and acceptable by xml_write/3  and friends.",
    "prefix":"xml_is_dom"
  },
  "xml_to_rdf/3": {
    "body":"xml_to_rdf(${1:XML}, ${2:BaseURI}, ${3:Triples})$4\n$0",
    "description":"xml_to_rdf(+XML, +BaseURI, -Triples).\nProcess an XML term produced by load_structure/3  using the dialect(xmlns) output option. XML is either a  complete <rdf:RDF> element, a list of RDF-objects  (container or description) or a single description of container.",
    "prefix":"xml_to_rdf"
  },
  "xmldsig:decrypt_xml/4": {
    "body":"decrypt_xml(${1:DOMIn}, ${2:DOMOut}, ${3:KeyCallback}, ${4:Options})$5\n$0",
    "description":"[det]decrypt_xml(+DOMIn, -DOMOut, :KeyCallback, +Options).\nKeyCallback may be called as  follows:  \n\ncall(KeyCallback, name, KeyName, Key)\ncall(KeyCallback, public_key, public_key(RSA), Key)\ncall(KeyCallback, certificate, Certificate, Key)\n\n  \n\n",
    "prefix":"decrypt_xml"
  },
  "xmldsig:xmld_signed_DOM/3": {
    "body":"xmld_signed_DOM(${1:DOM}, ${2:SignedDOM}, ${3:Options})$4\n$0",
    "description":"[det]xmld_signed_DOM(+DOM, -SignedDOM, +Options).\nTranslate an XML DOM structure in a signed version. Options:  key_file(+File): File holding the private key needed to sign\n\nkey_password(+Password): String holding the password to op the private key.\n\n  The SignedDOM must be emitted using xml_write/3  or xml_write_canonical/3. If xml_write/3  is used, the option layout(false) is needed to avoid changing the layout of the SignedInfo element and the signed DOM, which  will cause the signature to be invalid.\n\n",
    "prefix":"xmld_signed_DOM"
  },
  "xmldsig:xmld_verify_signature/4": {
    "body":"xmld_verify_signature(${1:DOM}, ${2:SignatureDOM}, ${3:Certificate}, ${4:Options})$5\n$0",
    "description":"[det]xmld_verify_signature(+DOM, +SignatureDOM, -Certificate, +Options).\nConfirm that an ds:Signature element contains a valid  signature. Certificate is bound to the certificate that  appears in the element if the signature is valid. It is up to the caller  to determine if the certificate is trusted or not.  Note: The DOM and SignatureDOM must have  been obtained using the load_structure/3  option keep_prefix(true) otherwise it is impossible to  generate an identical document for checking the signature. See also xml_write_canonical/3.\n\n",
    "prefix":"xmld_verify_signature"
  },
  "xmlenc:decrypt_xml/4": {
    "body":"decrypt_xml(${1:DOMIn}, ${2:DOMOut}, ${3:KeyCallback}, ${4:Options})$5\n$0",
    "description":"[det]decrypt_xml(+DOMIn, -DOMOut, :KeyCallback, +Options).\nKeyCallback may be called as  follows:  \n\ncall(KeyCallback, name, KeyName, Key)\ncall(KeyCallback, public_key, public_key(RSA), Key)\ncall(KeyCallback, certificate, Certificate, Key)\n\n  \n\n",
    "prefix":"decrypt_xml"
  },
  "xmlenc:evp_encrypt/6": {
    "body":"evp_encrypt(${1:PlainText}, ${2:Algorithm}, ${3:Key}, ${4:IV}, ${5:CipherTExt}, ${6:Options})$7\n$0",
    "description":"evp_encrypt(+PlainText, +Algorithm, +Key, +IV, -CipherTExt, +Options).\nEncrypt the given PlainText, using the symmetric algorithm Algorithm, key Key, and iv IV, to give  CipherText. See evp_decrypt/6.",
    "prefix":"evp_encrypt"
  },
  "xpath:sgml_register_catalog_file/2": {
    "body":"sgml_register_catalog_file(${1:File}, ${2:Location})$3\n$0",
    "description":"sgml_register_catalog_file(+File, +Location).\nRegister the indicated File as a catalog file. Location  is either start or end and defines whether the  catalog is considered first or last. This predicate has no effect if File  is already part of the catalog.  If no files are registered using this predicate, the first query on  the catalog examines SGML_CATALOG_FILES and fills the  catalog with all files in this path.\n\n",
    "prefix":"sgml_register_catalog_file"
  },
  "xpath:xml_is_dom/1": {
    "body":"xml_is_dom(${1:Term})$2\n$0",
    "description":"xml_is_dom(@Term).\nTrue if Term is an SGML/XML term as produced by one of the  above predciates and acceptable by xml_write/3  and friends.",
    "prefix":"xml_is_dom"
  },
  "xpath:xpath/3": {
    "body":"xpath(${1:DOM}, ${2:Spec}, ${3:Content})$4\n$0",
    "description":"[nondet]xpath(+DOM, +Spec, ?Content).\nMatch an element in a DOM structure. The syntax is inspired  by XPath, using () rather than [] to select inside an  element. First we can construct paths using / and //:  //Term: Select any node in the DOM matching term.\n\n/Term: Match the root against Term.\n\nTerm: Select the immediate children of the root matching Term.\n\n  The Terms above are of type callable. The functor specifies  the element name. The element name '*' refers to any element. The name self  refers to the top-element itself and is often used for processing  matches of an earlier xpath/3 query.  A term NS:Term refers to an XML name in the namespace NS. Optional  arguments specify additional constraints and functions. The arguments  are processed from left to right. Defined conditional argument values  are: \n\nindex(?Index): True if the element is the Index-th child of its parent, where 1 denotes  the first child. Index can be one of:  VarVar is unified with the index of the matched element.lastTrue for the last element.last - IntExprTrue for the last-minus-nth element. For example, last-1 is the element directly preceding the last one.IntExprTrue for the element whose index equals IntExpr. \n\nInteger: The N-th element with the given name, with 1 denoting the first element.  Same as index(Integer).\n\nlast: The last element with the given name. Same as index(last).\n\nlast - IntExpr: The IntExpr-th element before the last. Same as index(last-IntExpr).\n\n  Defined function argument values are: \n\nself: Evaluate to the entire element\n\ncontent: Evaluate to the content of the element (a list)\n\ntext: Evaluates to all text from the sub-tree as an atom\n\nnormalize_space: As text, but uses normalize_space/2  to normalise white-space in the output\n\nnumber: Extract an integer or float from the value. Ignores leading and trailing  white-space\n\n@Attribute: Evaluates to the value of the given attribute. Attribute can be a  compound term. In this case the functor name denotes the element and  arguments perform transformations on the attribute value. Defined  transformations are:  numberTranslate the value into a number using xsd_number_string/2 from library(sgml).integerAs number, but subsequently transform the value into an  integer using the round/1 function.floatAs number, but subsequently transform the value into a  float using the float/1 function.stringTranslate the value into a Prolog string.lowerTranslate the value to lower case, preserving the type.upperTranslate the value to upper case, preserving the type. \n\n  In addition, the argument-list can be conditions: \n\nLeft = Right: Succeeds if the left-hand unifies with the right-hand. If the left-hand  side is a function, this is evaluated. The right-hand side is never  evaluated, and thus the condition content = content defines  that the content of the element is the atom content. The  functions lower_case and upper_case can be  applied to Right (see example below).\n\ncontains(Haystack, Needle): Succeeds if Needle is a sub-string of Haystack.\n\nXPath: Succeeds if XPath matches in the currently selected sub-DOM.  For example, the following expression finds an h3 element  inside a div element, where the div element  itself contains an h2 child with a strong  child.  \n\n//div(h2/strong)/h3\n\n  This is equivalent to the conjunction of XPath goals below. \n\n   ...,\n   xpath(DOM, //(div), Div),\n   xpath(Div, h2/strong, _),\n   xpath(Div, h3, Result)\n\n  \n\n  Examples: \n\nMatch each table-row in DOM: \n\n\n\nxpath(DOM, //tr, TR)\n\n  Match the last cell of each tablerow in DOM. This example  illustrates that a result can be the input of subsequent xpath/3  queries. Using multiple queries on the intermediate TR term guarantee  that all results come from the same table-row: \n\n\n\nxpath(DOM, //tr, TR),\nxpath(TR,  /td(last), TD)\n\n  Match each href attribute in an <a>  element \n\n\n\nxpath(DOM, //a(@href), HREF)\n\n  Suppose we have a table containing rows where each first column is  the name of a product with a link to details and the second is the price  (a number). The following predicate matches the name, URL and price: \n\n\n\nproduct(DOM, Name, URL, Price) :-\n    xpath(DOM, //tr, TR),\n    xpath(TR, td(1), C1),\n    xpath(C1, /self(normalize_space), Name),\n    xpath(C1, a(@href), URL),\n    xpath(TR, td(2, number), Price).\n\n  Suppose we want to select books with genre=\"thriller\" from a tree  containing elements <book genre=...> \n\n\n\nthriller(DOM, Book) :-\n    xpath(DOM, //book(@genre=thiller), Book).\n\n  Match the elements <table align=\"center\"> and <table align=\"CENTER\">: \n\n\n\n    //table(@align(lower) = center)\n\n  Get the width and height of a div  element as a number, and the div node itself: \n\n\n\n    xpath(DOM, //div(@width(number)=W, @height(number)=H), Div)\n\n  Note that div is an infix operator, so parentheses must  be used in cases like the following: \n\n\n\n    xpath(DOM, //(div), Div)\n\n  \n\n",
    "prefix":"xpath"
  },
  "xpath:xpath_chk/3": {
    "body":"xpath_chk(${1:DOM}, ${2:Spec}, ${3:Content})$4\n$0",
    "description":"[semidet]xpath_chk(+DOM, +Spec, ?Content).\nSemi-deterministic version of xpath/3.",
    "prefix":"xpath_chk"
  },
  "xsdp_type:xsdp_convert/3": {
    "body": ["xsdp_convert(${1:Type}, ${2:Content}, ${3:Value})$4\n$0" ],
    "description":"  xsdp_convert(+Type, +Content, -Value)\n\n   Convert the content model Content to an  object of the given XSD\n   type and return the Prolog value in Value.",
    "prefix":"xsdp_convert"
  },
  "xsdp_type:xsdp_numeric_uri/2": {
    "body": ["xsdp_numeric_uri(${1:URI}, ${2:PromoteURI})$3\n$0" ],
    "description":"  xsdp_numeric_uri(?URI, -PromoteURI) is nondet.\n\n   Table mapping all XML-Schema numeric  URIs   into  the type they\n   promote to. Types are promoted   to =integer=, =float=, =double=\n   and =decimal=.",
    "prefix":"xsdp_numeric_uri"
  },
  "xsdp_type:xsdp_subtype_of/2": {
    "body": ["xsdp_subtype_of(${1:Type}, ${2:Super})$3\n$0" ],
    "description":"  xsdp_subtype_of(?Type, ?Super)\n\n   True if Type is a (transitive) subtype of Super.",
    "prefix":"xsdp_subtype_of"
  },
  "xsdp_type:xsdp_type/1": {
    "body": ["xsdp_type(${1:Type})$2\n$0" ],
    "description":"  xsdp_type(?Type)\n\n   Test/generate the names for the XML schema primitive types",
    "prefix":"xsdp_type"
  },
  "xsdp_type:xsdp_uri_type/2": {
    "body": ["xsdp_uri_type(${1:URI}, ${2:Type})$3\n$0" ],
    "description":"  xsdp_uri_type(?URI, ?Type)\n\n   True if URI is the URI for the the XML-Schema primitive Type.",
    "prefix":"xsdp_uri_type"
  },
  "yall:is_lambda/1": {
    "body":"is_lambda(${1:Term})$2\n$0",
    "description":"[semidet]is_lambda(@Term).\nTrue if Term is a valid Lambda expression.",
    "prefix":"is_lambda"
  },
  "yall:lambda_calls/2": {
    "body":"lambda_calls(${1:LambdaExpression}, ${2:Goal})$3\n$0",
    "description":"[det]lambda_calls(+LambdaExpression, -Goal).\n",
    "prefix":"lambda_calls"
  },
  "yall:lambda_calls/3": {
    "body":"lambda_calls(${1:LambdaExpression}, ${2:ExtraArgs}, ${3:Goal})$4\n$0",
    "description":"[det]lambda_calls(+LambdaExpression, +ExtraArgs, -Goal).\nGoal is the goal called if call/N is applied to LambdaExpression, where ExtraArgs are the  additional arguments to call/N. ExtraArgs can be an integer  or a list of concrete arguments. This predicate is used for  cross-referencing and code highlighting.",
    "prefix":"lambda_calls"
  },
  "zlib:gzopen/3": {
    "body": ["gzopen(${1:File}, ${2:Mode}, ${3:Stream})$4\n$0" ],
    "description":"  gzopen(+File, +Mode, -Stream) is det.\n  gzopen(+File, +Mode, -Stream, +Options) is det.\n\n   Open a file compatible with the  gzip   program.  Note that if a\n   file is opened in =append= mode,  a   second  gzip image will be\n   added to the end of the file.   The gzip standard defines that a\n   file can hold multiple  gzip  images   and  inflating  the  file\n   results in a concatenated stream of all inflated images.\n\n   Options are passed to open/4  and   zopen/3.  Default  format is\n   =gzip=.",
    "prefix":"gzopen"
  },
  "zlib:gzopen/4": {
    "body": ["gzopen(${1:File}, ${2:Mode}, ${3:Stream}, ${4:Options})$5\n$0" ],
    "description":"  gzopen(+File, +Mode, -Stream) is det.\n  gzopen(+File, +Mode, -Stream, +Options) is det.\n\n   Open a file compatible with the  gzip   program.  Note that if a\n   file is opened in =append= mode,  a   second  gzip image will be\n   added to the end of the file.   The gzip standard defines that a\n   file can hold multiple  gzip  images   and  inflating  the  file\n   results in a concatenated stream of all inflated images.\n\n   Options are passed to open/4  and   zopen/3.  Default  format is\n   =gzip=.",
    "prefix":"gzopen"
  },
  "zlib:zopen/3": {
    "body": ["zopen(${1:'Param1'}, ${2:'Param2'}, ${3:'Param3'})$4\n$0" ],
    "description":"zopen('Param1','Param2','Param3')",
    "prefix":"zopen"
  },
  "zopen/3": {
    "body":"zopen(${1:Stream}, ${2:ZStream}, ${3:Options})$4\n$0",
    "description":"zopen(+Stream, -ZStream, +Options).\nCreates ZStream, providing compressed access to Stream.  If an input stream is wrapped, it recognises a gzip or deflate header.  If an output stream is wrapped, Options define the desired  wrapper and compression level. The new ZStream inherits its encoding from Stream. In other words, if Stream  is a text-stream, so is ZStream. The original Stream  is switched to binary mode while it is wrapped. The original encoding of Stream is restored if ZStream is closed. Note that zopen/3  does not actually process any data and therefore succeeds on input  streams that do not contain valid data. Errors may be generated by read  operations performed on the stream.  Defined options on output streams are: \n\nformat(+Format): Either deflate (default), raw_deflate or gzip.  The deflate envelope is simple and short and is typically  used for compressed (network) communication. The raw_deflate  does not include an envelope and is often used as a step in crypographic  encodings. The gzip envelope is compatible to the gzip  program and intended to read/write compressed files.\n\nlevel(+Level): Number between 0 and 9, specifying the compression level, Higher levels  use more resources. Default is 6, generally believed to be a good  compromise between speed, memory requirement and compression.\n\nmulti_part(+Boolean): If true, restart reading if the input is not at  end-of-file. The default is true for gzip streams.\n\n  Generic options are: \n\nclose_parent(Bool): If true (default), closing the compressed stream also  closes (and thus invalidates) the wrapped stream. If false,  the wrapped stream is not closed. This can be used to  read/write a compressed data block as partial input/output on a stream.\n\n ",
    "prefix":"zopen"
  }
}